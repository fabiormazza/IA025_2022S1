{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Aula 7 - Exercício",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unicamp-dl/IA025_2022S1/blob/main/ex07/aula7_edmar_rodrigues.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nome = \"Edmar Rodrigues Filho\"\n",
        "print(f'Meu nome é {nome}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOdQB41_4ZxG",
        "outputId": "b00c9b76-18a1-4a72-d1d5-2ba1f3cdbeb2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meu nome é Edmar Rodrigues Filho\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IbuChoAPMEn"
      },
      "source": [
        "#  Exercício: Modelo de Linguagem (Bengio 2003) - MLP + Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_DBb0-Klwf2"
      },
      "source": [
        "Neste exercício iremos treinar uma rede neural simples para prever a proxima palavra de um texto, data as palavras anteriores como entrada. Esta tarefa é chamada de \"Modelagem da Língua\".\n",
        "\n",
        "Este dataset já possui um tamanho razoável e é bem provável que você vai precisar rodar seus experimentos com GPU.\n",
        "\n",
        "Alguns conselhos úteis:\n",
        "- **ATENÇÃO:** o dataset é bem grande. Não dê comando de imprimí-lo.\n",
        "- Durante a depuração, faça seu dataset ficar bem pequeno, para que a depuração seja mais rápida e não precise de GPU. Somente ligue a GPU quando o seu laço de treinamento já está funcionando\n",
        "- Não deixe para fazer esse exercício na véspera. Ele é trabalhoso."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# iremos utilizar a biblioteca dos transformers para ter acesso ao tokenizador do BERT.\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "3twP0YJC4jmJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdadf9c0-ebaa-496f-9fef-69b721443b7e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnyhJZtTRNMx"
      },
      "source": [
        "## Importação dos pacotes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlIOVCajPWcU"
      },
      "source": [
        "import collections\n",
        "import itertools\n",
        "import functools\n",
        "import math\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm_notebook\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check which GPU we are using\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "w9f3PfifAwpU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5441737d-9d21-42b2-f069-012e41dc59c2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue May 17 16:51:05 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available(): \n",
        "   dev = \"cuda:0\"\n",
        "else: \n",
        "   dev = \"cpu\"\n",
        "device = torch.device(dev)\n",
        "print('Using {}'.format(device))"
      ],
      "metadata": {
        "id": "whTCe2i7AtoV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0e6eadb-62dd-47c7-b29e-b15ecc3d41e6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZfxgV2DUk58"
      },
      "source": [
        "## Implementação do MyDataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_xhKm1EZ3bQ"
      },
      "source": [
        "from typing import List\n",
        "\n",
        "\n",
        "def tokenize(text: str, tokenizer):\n",
        "    return tokenizer(text, return_tensors=None, add_special_tokens=False).input_ids\n",
        "\n",
        "\n",
        "class MyDataset():\n",
        "    def __init__(self, texts: List[str], tokenizer, context_size: int):\n",
        "        # Escreva seu código aqui\n",
        "        # self.texts = texts\n",
        "        self.tokenizer = tokenizer\n",
        "        self.context_size = context_size\n",
        "\n",
        "        self.items = []\n",
        "        for text in texts:\n",
        "          text = tokenize(text, self.tokenizer)\n",
        "          for context_idx in range(0,len(text)-self.context_size):\n",
        "            x = text[context_idx:context_idx+self.context_size]\n",
        "            y = text[context_idx+self.context_size]\n",
        "            x = torch.tensor(x)\n",
        "            y = torch.tensor(y)\n",
        "            self.items.append((x,y))\n",
        "\n",
        "    def __len__(self):\n",
        "        # Escreva seu código aqui\n",
        "        return len(self.items)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Escreva seu código aqui\n",
        "        return self.items[idx]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teste se sua implementação do MyDataset está correta"
      ],
      "metadata": {
        "id": "wew-gFbWeBTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
        "\n",
        "dummy_texts = ['Eu gosto de correr', 'Ela gosta muito de comer pizza']\n",
        "\n",
        "dummy_dataset = MyDataset(texts=dummy_texts, tokenizer=tokenizer, context_size=3)\n",
        "dummy_loader = DataLoader(dummy_dataset, batch_size=6, shuffle=False)\n",
        "assert len(dummy_dataset) == 5\n",
        "print('passou no assert de tamanho do dataset')\n",
        "\n",
        "first_batch_input, first_batch_target = next(iter(dummy_loader))\n",
        "\n",
        "correct_first_batch_input = torch.LongTensor(\n",
        "    [[ 3396, 10303,   125],\n",
        "     [ 1660,  5971,   785],\n",
        "     [ 5971,   785,   125],\n",
        "     [  785,   125,  1847],\n",
        "     [  125,  1847, 13779]])\n",
        "\n",
        "correct_first_batch_target = torch.LongTensor([13239,   125,  1847, 13779, 15616])\n",
        "\n",
        "assert torch.equal(first_batch_input, correct_first_batch_input)\n",
        "print('Passou no assert de input')\n",
        "assert torch.equal(first_batch_target, correct_first_batch_target)\n",
        "print('Passou no assert de target')"
      ],
      "metadata": {
        "id": "8r7jBFFUeApe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "222f0f53-c349-4618-c4f6-387d133f5dbe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "passou no assert de tamanho do dataset\n",
            "Passou no assert de input\n",
            "Passou no assert de target\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l = [list(i) for i in list(correct_first_batch_input)]\n",
        "print(tokenizer.batch_decode(correct_first_batch_input))\n",
        "print(tokenizer.decode(correct_first_batch_target))\n",
        "# print(correct_first_batch_input)\n",
        "# print(tokenizer.decode(correct_first_batch_target))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oN54Af6qPQSa",
        "outputId": "24bb875d-9feb-4a44-febb-ec161c5df123"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Eu gosto de', 'Ela gosta muito', 'gosta muito de', 'muito de comer', 'de comer pi']\n",
            "correr de comer pizza\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LfrHHouleJ0"
      },
      "source": [
        "# Carregamento do dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2vFWjsSkmop"
      },
      "source": [
        "Iremos usar uma pequena amostra do dataset [BrWaC](https://www.inf.ufrgs.br/pln/wiki/index.php?title=BrWaC) para treinar e avaliar nosso modelo de linguagem."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://storage.googleapis.com/unicamp-dl/ia025a_2022s1/aula7/sample_brwac.txt"
      ],
      "metadata": {
        "id": "vGlN1WqrXPA6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b5da1df-d646-49a2-bc43-8a4b453be0a7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File ‘sample_brwac.txt’ already there; not retrieving.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "context_size = 9\n",
        "\n",
        "valid_examples = 100\n",
        "test_examples = 100\n",
        "texts = open('sample_brwac.txt').readlines()\n",
        "\n",
        "print('Truncating for debugging purposes.')\n",
        "texts = texts[:4000]  \n",
        "\n",
        "training_texts = texts[:-(valid_examples + test_examples)]\n",
        "valid_texts = texts[-(valid_examples + test_examples):-test_examples]\n",
        "test_texts = texts[-test_examples:]\n",
        "\n",
        "training_dataset = MyDataset(texts=training_texts, tokenizer=tokenizer, context_size=context_size)\n",
        "valid_dataset = MyDataset(texts=valid_texts, tokenizer=tokenizer, context_size=context_size)\n",
        "test_dataset = MyDataset(texts=test_texts, tokenizer=tokenizer, context_size=context_size)"
      ],
      "metadata": {
        "id": "gxa_4gmiA-wE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f383f47-ee5d-42e2-f96a-f72127c0852d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Truncating for debugging purposes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'training examples: {len(training_dataset)}')\n",
        "print(f'valid examples: {len(valid_dataset)}')\n",
        "print(f'test examples: {len(test_dataset)}')"
      ],
      "metadata": {
        "id": "KCSGJ5m7py4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b83e73ac-5ad0-4778-c508-099c9ecc102f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training examples: 4568433\n",
            "valid examples: 150914\n",
            "test examples: 84266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGaAjYDfWdd1"
      },
      "source": [
        "class LanguageModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, context_size, embedding_dim, hidden_size):\n",
        "        \"\"\"\n",
        "        Implements the Neural Language Model proposed by Bengio et al.\"\n",
        "\n",
        "        Args:\n",
        "            vocab_size (int): Size of the input vocabulary.\n",
        "            context_size (int): Size of the sequence to consider as context for prediction.\n",
        "            embedding_dim (int): Dimension of the embedding layer for each word in the context.\n",
        "            hidden_size (int): Size of the hidden layer.\n",
        "        \"\"\"\n",
        "        # Escreva seu código aqui.\n",
        "        super(LanguageModel, self).__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.context_size = context_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embeddings = torch.nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.hidden = torch.nn.Linear(self.context_size*self.embedding_dim,self.hidden_size)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.output = torch.nn.Linear(self.hidden_size, self.vocab_size)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            inputs is a LongTensor of shape (batch_size, context_size)\n",
        "        \"\"\"\n",
        "        # Escreva seu código aqui.\n",
        "        # embeds = self.embeddings(inputs).view((inputs.shape[0],-1))\n",
        "        embeds = self.embeddings(inputs).view(-1, self.context_size*self.embedding_dim)\n",
        "        out = self.hidden(embeds)\n",
        "        out = self.relu(out)\n",
        "        logits = self.output(out)\n",
        "\n",
        "        return logits"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teste o modelo com um exemplo"
      ],
      "metadata": {
        "id": "Rm6_PTH2i98e"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwnxfZlrZoT_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a438de89-f68c-43c3-98ee-3df84e5b2199"
      },
      "source": [
        "model = LanguageModel(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    context_size=context_size,\n",
        "    embedding_dim=64,\n",
        "    hidden_size=128,\n",
        ").to(device)\n",
        "\n",
        "sample_train, _ = next(iter(DataLoader(training_dataset)))\n",
        "sample_train_gpu = sample_train.to(device)\n",
        "model(sample_train_gpu).shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 29794])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.embeddings(sample_train_gpu).shape"
      ],
      "metadata": {
        "id": "VZd6Wr4qjXwQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "726b0db3-50e6-4074-9c13-a24830c46b8f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 9, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3Vh6B-VkA01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdba7981-7594-4fa9-c679-46b1bf80ed29"
      },
      "source": [
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'Number of model parameters: {num_params}')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of model parameters: 5824098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assert da Perplexidade\n"
      ],
      "metadata": {
        "id": "8nhbUVsYnVAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(123)\n",
        "np.random.seed(123)\n",
        "torch.manual_seed(123)\n",
        "\n",
        "def perplexity(logits, target):\n",
        "    \"\"\"\n",
        "    Computes the perplexity.\n",
        "\n",
        "    Args:\n",
        "        logits: a FloatTensor of shape (batch_size, vocab_size)\n",
        "        target: a LongTensor of shape (batch_size,)\n",
        "\n",
        "    Returns:\n",
        "        A float corresponding to the perplexity.\n",
        "    \"\"\"\n",
        "    # Escreva seu código aqui.\n",
        "    loss = torch.nn.CrossEntropyLoss()(logits, target)\n",
        "    return torch.exp(loss).sum()\n",
        "\n",
        "\n",
        "n_examples = 1000\n",
        "\n",
        "sample_train, target_token_ids = next(iter(DataLoader(training_dataset, batch_size=n_examples)))\n",
        "sample_train_gpu = sample_train.to(device)\n",
        "target_token_ids = target_token_ids.to(device)\n",
        "logits = model(sample_train_gpu)\n",
        "\n",
        "my_perplexity = perplexity(logits=logits, target=target_token_ids)\n",
        "\n",
        "print(f'my perplexity:              {int(my_perplexity)}')\n",
        "print(f'correct initial perplexity: {tokenizer.vocab_size}')\n",
        "\n",
        "assert math.isclose(my_perplexity, tokenizer.vocab_size, abs_tol=2000)\n",
        "print('Passou o no assert da perplexidade')"
      ],
      "metadata": {
        "id": "gbMP8VAUncfX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6e75eca-f937-4072-f96a-fbf4156627b3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my perplexity:              31013\n",
            "correct initial perplexity: 29794\n",
            "Passou o no assert da perplexidade\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Laço de Treinamento e Validação"
      ],
      "metadata": {
        "id": "KiJtrsqPnE_l"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIMSaY-UUGUE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3063803f-a9e5-48f5-c1f7-1fc3a7571ca6"
      },
      "source": [
        "max_examples = 100_000_000\n",
        "eval_every_steps = 5000\n",
        "lr = 3e-5\n",
        "\n",
        "\n",
        "model = LanguageModel(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    context_size=context_size,\n",
        "    embedding_dim=128,\n",
        "    hidden_size=256,\n",
        ").to(device)\n",
        "\n",
        "train_loader = DataLoader(training_dataset, batch_size=64, shuffle=True, drop_last=True)\n",
        "validation_loader = DataLoader(valid_dataset, batch_size=64)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "def train_step(input, target):\n",
        "    model.train()\n",
        "    model.zero_grad()\n",
        "\n",
        "    logits = model(input.to(device))\n",
        "    loss = nn.functional.cross_entropy(logits, target.to(device))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "def validation_step(input, target):\n",
        "    logits = model(input)\n",
        "    loss = nn.functional.cross_entropy(logits, target)\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "train_losses = []\n",
        "n_examples = 0\n",
        "step = 0\n",
        "while n_examples < max_examples:\n",
        "    for input, target in train_loader:\n",
        "        loss = train_step(input.to(device), target.to(device))\n",
        "        train_losses.append(loss)\n",
        "        \n",
        "        if step % eval_every_steps == 0:\n",
        "            train_ppl = np.exp(np.average(train_losses))\n",
        "\n",
        "            with torch.no_grad():\n",
        "                valid_ppl = np.exp(np.average([\n",
        "                    validation_step(input.to(device), target.to(device))\n",
        "                    for input, target in validation_loader]))\n",
        "\n",
        "            print(f'{step} steps; {n_examples} examples so far; train ppl: {train_ppl:.2f}, valid ppl: {valid_ppl:.2f}')\n",
        "            train_losses = []\n",
        "\n",
        "        n_examples += len(input)  # Increment of batch size\n",
        "        step += 1\n",
        "        if n_examples >= max_examples:\n",
        "            break"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 steps; 0 examples so far; train ppl: 31203.47, valid ppl: 30559.22\n",
            "5000 steps; 320000 examples so far; train ppl: 3074.02, valid ppl: 1811.35\n",
            "10000 steps; 640000 examples so far; train ppl: 1693.88, valid ppl: 1582.28\n",
            "15000 steps; 960000 examples so far; train ppl: 1557.51, valid ppl: 1486.97\n",
            "20000 steps; 1280000 examples so far; train ppl: 1458.32, valid ppl: 1419.08\n",
            "25000 steps; 1600000 examples so far; train ppl: 1387.72, valid ppl: 1350.96\n",
            "30000 steps; 1920000 examples so far; train ppl: 1309.47, valid ppl: 1279.52\n",
            "35000 steps; 2240000 examples so far; train ppl: 1224.43, valid ppl: 1211.22\n",
            "40000 steps; 2560000 examples so far; train ppl: 1168.36, valid ppl: 1150.77\n",
            "45000 steps; 2880000 examples so far; train ppl: 1100.40, valid ppl: 1100.59\n",
            "50000 steps; 3200000 examples so far; train ppl: 1051.33, valid ppl: 1055.78\n",
            "55000 steps; 3520000 examples so far; train ppl: 1009.27, valid ppl: 1017.07\n",
            "60000 steps; 3840000 examples so far; train ppl: 962.91, valid ppl: 982.48\n",
            "65000 steps; 4160000 examples so far; train ppl: 925.29, valid ppl: 952.97\n",
            "70000 steps; 4480000 examples so far; train ppl: 896.76, valid ppl: 928.20\n",
            "75000 steps; 4800000 examples so far; train ppl: 818.67, valid ppl: 912.17\n",
            "80000 steps; 5120000 examples so far; train ppl: 788.82, valid ppl: 897.15\n",
            "85000 steps; 5440000 examples so far; train ppl: 777.14, valid ppl: 878.48\n",
            "90000 steps; 5760000 examples so far; train ppl: 764.05, valid ppl: 863.14\n",
            "95000 steps; 6080000 examples so far; train ppl: 753.22, valid ppl: 847.96\n",
            "100000 steps; 6400000 examples so far; train ppl: 739.83, valid ppl: 834.10\n",
            "105000 steps; 6720000 examples so far; train ppl: 727.62, valid ppl: 818.36\n",
            "110000 steps; 7040000 examples so far; train ppl: 723.50, valid ppl: 805.06\n",
            "115000 steps; 7360000 examples so far; train ppl: 713.09, valid ppl: 794.21\n",
            "120000 steps; 7680000 examples so far; train ppl: 700.50, valid ppl: 782.16\n",
            "125000 steps; 8000000 examples so far; train ppl: 699.03, valid ppl: 769.78\n",
            "130000 steps; 8320000 examples so far; train ppl: 691.77, valid ppl: 758.86\n",
            "135000 steps; 8640000 examples so far; train ppl: 679.29, valid ppl: 749.35\n",
            "140000 steps; 8960000 examples so far; train ppl: 674.76, valid ppl: 738.08\n",
            "145000 steps; 9280000 examples so far; train ppl: 637.45, valid ppl: 734.70\n",
            "150000 steps; 9600000 examples so far; train ppl: 592.73, valid ppl: 729.53\n",
            "155000 steps; 9920000 examples so far; train ppl: 592.17, valid ppl: 722.76\n",
            "160000 steps; 10240000 examples so far; train ppl: 587.27, valid ppl: 715.64\n",
            "165000 steps; 10560000 examples so far; train ppl: 587.63, valid ppl: 707.71\n",
            "170000 steps; 10880000 examples so far; train ppl: 584.91, valid ppl: 700.09\n",
            "175000 steps; 11200000 examples so far; train ppl: 582.94, valid ppl: 696.27\n",
            "180000 steps; 11520000 examples so far; train ppl: 576.03, valid ppl: 688.82\n",
            "185000 steps; 11840000 examples so far; train ppl: 572.11, valid ppl: 682.09\n",
            "190000 steps; 12160000 examples so far; train ppl: 572.04, valid ppl: 675.66\n",
            "195000 steps; 12480000 examples so far; train ppl: 570.88, valid ppl: 671.40\n",
            "200000 steps; 12800000 examples so far; train ppl: 569.02, valid ppl: 664.19\n",
            "205000 steps; 13120000 examples so far; train ppl: 566.16, valid ppl: 657.74\n",
            "210000 steps; 13440000 examples so far; train ppl: 557.73, valid ppl: 652.67\n",
            "215000 steps; 13760000 examples so far; train ppl: 551.81, valid ppl: 650.04\n",
            "220000 steps; 14080000 examples so far; train ppl: 504.14, valid ppl: 647.88\n",
            "225000 steps; 14400000 examples so far; train ppl: 506.07, valid ppl: 645.92\n",
            "230000 steps; 14720000 examples so far; train ppl: 498.67, valid ppl: 641.16\n",
            "235000 steps; 15040000 examples so far; train ppl: 506.54, valid ppl: 636.00\n",
            "240000 steps; 15360000 examples so far; train ppl: 503.66, valid ppl: 631.76\n",
            "245000 steps; 15680000 examples so far; train ppl: 501.39, valid ppl: 630.19\n",
            "250000 steps; 16000000 examples so far; train ppl: 496.53, valid ppl: 624.81\n",
            "255000 steps; 16320000 examples so far; train ppl: 497.68, valid ppl: 621.11\n",
            "260000 steps; 16640000 examples so far; train ppl: 502.93, valid ppl: 615.41\n",
            "265000 steps; 16960000 examples so far; train ppl: 496.92, valid ppl: 612.16\n",
            "270000 steps; 17280000 examples so far; train ppl: 494.27, valid ppl: 608.99\n",
            "275000 steps; 17600000 examples so far; train ppl: 499.74, valid ppl: 604.74\n",
            "280000 steps; 17920000 examples so far; train ppl: 494.97, valid ppl: 600.82\n",
            "285000 steps; 18240000 examples so far; train ppl: 490.49, valid ppl: 598.14\n",
            "290000 steps; 18560000 examples so far; train ppl: 452.49, valid ppl: 597.05\n",
            "295000 steps; 18880000 examples so far; train ppl: 450.87, valid ppl: 596.87\n",
            "300000 steps; 19200000 examples so far; train ppl: 446.26, valid ppl: 594.19\n",
            "305000 steps; 19520000 examples so far; train ppl: 448.69, valid ppl: 592.99\n",
            "310000 steps; 19840000 examples so far; train ppl: 454.97, valid ppl: 587.61\n",
            "315000 steps; 20160000 examples so far; train ppl: 454.18, valid ppl: 586.66\n",
            "320000 steps; 20480000 examples so far; train ppl: 448.60, valid ppl: 584.53\n",
            "325000 steps; 20800000 examples so far; train ppl: 454.49, valid ppl: 581.37\n",
            "330000 steps; 21120000 examples so far; train ppl: 450.09, valid ppl: 577.94\n",
            "335000 steps; 21440000 examples so far; train ppl: 451.32, valid ppl: 573.98\n",
            "340000 steps; 21760000 examples so far; train ppl: 451.48, valid ppl: 571.72\n",
            "345000 steps; 22080000 examples so far; train ppl: 449.99, valid ppl: 569.55\n",
            "350000 steps; 22400000 examples so far; train ppl: 445.84, valid ppl: 566.90\n",
            "355000 steps; 22720000 examples so far; train ppl: 450.63, valid ppl: 564.48\n",
            "360000 steps; 23040000 examples so far; train ppl: 426.57, valid ppl: 566.77\n",
            "365000 steps; 23360000 examples so far; train ppl: 412.19, valid ppl: 564.88\n",
            "370000 steps; 23680000 examples so far; train ppl: 412.99, valid ppl: 562.81\n",
            "375000 steps; 24000000 examples so far; train ppl: 414.63, valid ppl: 560.54\n",
            "380000 steps; 24320000 examples so far; train ppl: 414.67, valid ppl: 558.59\n",
            "385000 steps; 24640000 examples so far; train ppl: 417.18, valid ppl: 557.28\n",
            "390000 steps; 24960000 examples so far; train ppl: 421.26, valid ppl: 553.67\n",
            "395000 steps; 25280000 examples so far; train ppl: 419.24, valid ppl: 552.18\n",
            "400000 steps; 25600000 examples so far; train ppl: 420.78, valid ppl: 549.30\n",
            "405000 steps; 25920000 examples so far; train ppl: 416.06, valid ppl: 547.31\n",
            "410000 steps; 26240000 examples so far; train ppl: 419.01, valid ppl: 545.65\n",
            "415000 steps; 26560000 examples so far; train ppl: 416.69, valid ppl: 543.66\n",
            "420000 steps; 26880000 examples so far; train ppl: 417.85, valid ppl: 541.56\n",
            "425000 steps; 27200000 examples so far; train ppl: 416.16, valid ppl: 539.89\n",
            "430000 steps; 27520000 examples so far; train ppl: 406.83, valid ppl: 541.36\n",
            "435000 steps; 27840000 examples so far; train ppl: 382.81, valid ppl: 540.27\n",
            "440000 steps; 28160000 examples so far; train ppl: 387.88, valid ppl: 538.61\n",
            "445000 steps; 28480000 examples so far; train ppl: 387.25, valid ppl: 536.91\n",
            "450000 steps; 28800000 examples so far; train ppl: 394.36, valid ppl: 535.23\n",
            "455000 steps; 29120000 examples so far; train ppl: 390.33, valid ppl: 532.51\n",
            "460000 steps; 29440000 examples so far; train ppl: 392.59, valid ppl: 531.94\n",
            "465000 steps; 29760000 examples so far; train ppl: 395.13, valid ppl: 529.17\n",
            "470000 steps; 30080000 examples so far; train ppl: 391.39, valid ppl: 528.82\n",
            "475000 steps; 30400000 examples so far; train ppl: 393.59, valid ppl: 526.38\n",
            "480000 steps; 30720000 examples so far; train ppl: 395.79, valid ppl: 524.87\n",
            "485000 steps; 31040000 examples so far; train ppl: 397.26, valid ppl: 523.45\n",
            "490000 steps; 31360000 examples so far; train ppl: 391.16, valid ppl: 522.52\n",
            "495000 steps; 31680000 examples so far; train ppl: 394.36, valid ppl: 520.32\n",
            "500000 steps; 32000000 examples so far; train ppl: 391.02, valid ppl: 520.32\n",
            "505000 steps; 32320000 examples so far; train ppl: 362.85, valid ppl: 521.48\n",
            "510000 steps; 32640000 examples so far; train ppl: 366.75, valid ppl: 521.05\n",
            "515000 steps; 32960000 examples so far; train ppl: 370.11, valid ppl: 520.27\n",
            "520000 steps; 33280000 examples so far; train ppl: 373.96, valid ppl: 520.02\n",
            "525000 steps; 33600000 examples so far; train ppl: 373.40, valid ppl: 516.94\n",
            "530000 steps; 33920000 examples so far; train ppl: 372.06, valid ppl: 515.46\n",
            "535000 steps; 34240000 examples so far; train ppl: 374.11, valid ppl: 513.43\n",
            "540000 steps; 34560000 examples so far; train ppl: 371.90, valid ppl: 514.29\n",
            "545000 steps; 34880000 examples so far; train ppl: 372.44, valid ppl: 512.12\n",
            "550000 steps; 35200000 examples so far; train ppl: 371.35, valid ppl: 509.60\n",
            "555000 steps; 35520000 examples so far; train ppl: 375.26, valid ppl: 508.48\n",
            "560000 steps; 35840000 examples so far; train ppl: 379.63, valid ppl: 508.03\n",
            "565000 steps; 36160000 examples so far; train ppl: 374.88, valid ppl: 506.02\n",
            "570000 steps; 36480000 examples so far; train ppl: 375.29, valid ppl: 506.56\n",
            "575000 steps; 36800000 examples so far; train ppl: 349.55, valid ppl: 508.57\n",
            "580000 steps; 37120000 examples so far; train ppl: 349.95, valid ppl: 506.90\n",
            "585000 steps; 37440000 examples so far; train ppl: 353.48, valid ppl: 506.65\n",
            "590000 steps; 37760000 examples so far; train ppl: 353.81, valid ppl: 505.73\n",
            "595000 steps; 38080000 examples so far; train ppl: 356.00, valid ppl: 505.28\n",
            "600000 steps; 38400000 examples so far; train ppl: 354.97, valid ppl: 506.82\n",
            "605000 steps; 38720000 examples so far; train ppl: 358.74, valid ppl: 504.61\n",
            "610000 steps; 39040000 examples so far; train ppl: 361.46, valid ppl: 500.43\n",
            "615000 steps; 39360000 examples so far; train ppl: 359.78, valid ppl: 501.36\n",
            "620000 steps; 39680000 examples so far; train ppl: 358.52, valid ppl: 499.87\n",
            "625000 steps; 40000000 examples so far; train ppl: 360.06, valid ppl: 497.98\n",
            "630000 steps; 40320000 examples so far; train ppl: 361.40, valid ppl: 496.85\n",
            "635000 steps; 40640000 examples so far; train ppl: 363.09, valid ppl: 494.43\n",
            "640000 steps; 40960000 examples so far; train ppl: 362.20, valid ppl: 494.46\n",
            "645000 steps; 41280000 examples so far; train ppl: 349.24, valid ppl: 496.69\n",
            "650000 steps; 41600000 examples so far; train ppl: 337.38, valid ppl: 498.70\n",
            "655000 steps; 41920000 examples so far; train ppl: 339.38, valid ppl: 498.31\n",
            "660000 steps; 42240000 examples so far; train ppl: 343.84, valid ppl: 495.08\n",
            "665000 steps; 42560000 examples so far; train ppl: 344.13, valid ppl: 494.44\n",
            "670000 steps; 42880000 examples so far; train ppl: 345.79, valid ppl: 494.45\n",
            "675000 steps; 43200000 examples so far; train ppl: 343.51, valid ppl: 495.07\n",
            "680000 steps; 43520000 examples so far; train ppl: 346.20, valid ppl: 492.76\n",
            "685000 steps; 43840000 examples so far; train ppl: 345.67, valid ppl: 492.15\n",
            "690000 steps; 44160000 examples so far; train ppl: 350.12, valid ppl: 489.59\n",
            "695000 steps; 44480000 examples so far; train ppl: 346.33, valid ppl: 489.23\n",
            "700000 steps; 44800000 examples so far; train ppl: 349.85, valid ppl: 487.47\n",
            "705000 steps; 45120000 examples so far; train ppl: 351.12, valid ppl: 488.20\n",
            "710000 steps; 45440000 examples so far; train ppl: 351.79, valid ppl: 487.25\n",
            "715000 steps; 45760000 examples so far; train ppl: 341.69, valid ppl: 489.88\n",
            "720000 steps; 46080000 examples so far; train ppl: 326.29, valid ppl: 490.49\n",
            "725000 steps; 46400000 examples so far; train ppl: 329.69, valid ppl: 490.61\n",
            "730000 steps; 46720000 examples so far; train ppl: 332.84, valid ppl: 488.93\n",
            "735000 steps; 47040000 examples so far; train ppl: 330.90, valid ppl: 489.19\n",
            "740000 steps; 47360000 examples so far; train ppl: 336.92, valid ppl: 488.38\n",
            "745000 steps; 47680000 examples so far; train ppl: 333.49, valid ppl: 486.55\n",
            "750000 steps; 48000000 examples so far; train ppl: 335.58, valid ppl: 488.06\n",
            "755000 steps; 48320000 examples so far; train ppl: 337.40, valid ppl: 485.49\n",
            "760000 steps; 48640000 examples so far; train ppl: 341.07, valid ppl: 485.64\n",
            "765000 steps; 48960000 examples so far; train ppl: 341.93, valid ppl: 483.52\n",
            "770000 steps; 49280000 examples so far; train ppl: 341.95, valid ppl: 483.56\n",
            "775000 steps; 49600000 examples so far; train ppl: 337.89, valid ppl: 483.51\n",
            "780000 steps; 49920000 examples so far; train ppl: 342.57, valid ppl: 482.53\n",
            "785000 steps; 50240000 examples so far; train ppl: 340.76, valid ppl: 481.51\n",
            "790000 steps; 50560000 examples so far; train ppl: 316.94, valid ppl: 483.80\n",
            "795000 steps; 50880000 examples so far; train ppl: 317.73, valid ppl: 485.42\n",
            "800000 steps; 51200000 examples so far; train ppl: 321.07, valid ppl: 485.00\n",
            "805000 steps; 51520000 examples so far; train ppl: 323.09, valid ppl: 484.82\n",
            "810000 steps; 51840000 examples so far; train ppl: 329.05, valid ppl: 481.31\n",
            "815000 steps; 52160000 examples so far; train ppl: 325.82, valid ppl: 482.21\n",
            "820000 steps; 52480000 examples so far; train ppl: 328.76, valid ppl: 480.42\n",
            "825000 steps; 52800000 examples so far; train ppl: 329.32, valid ppl: 479.75\n",
            "830000 steps; 53120000 examples so far; train ppl: 333.93, valid ppl: 481.54\n",
            "835000 steps; 53440000 examples so far; train ppl: 331.19, valid ppl: 479.78\n",
            "840000 steps; 53760000 examples so far; train ppl: 336.38, valid ppl: 479.67\n",
            "845000 steps; 54080000 examples so far; train ppl: 329.32, valid ppl: 479.04\n",
            "850000 steps; 54400000 examples so far; train ppl: 338.05, valid ppl: 477.64\n",
            "855000 steps; 54720000 examples so far; train ppl: 336.72, valid ppl: 478.82\n",
            "860000 steps; 55040000 examples so far; train ppl: 318.06, valid ppl: 480.21\n",
            "865000 steps; 55360000 examples so far; train ppl: 309.66, valid ppl: 479.39\n",
            "870000 steps; 55680000 examples so far; train ppl: 315.52, valid ppl: 479.04\n",
            "875000 steps; 56000000 examples so far; train ppl: 318.83, valid ppl: 480.48\n",
            "880000 steps; 56320000 examples so far; train ppl: 322.89, valid ppl: 479.10\n",
            "885000 steps; 56640000 examples so far; train ppl: 322.84, valid ppl: 478.13\n",
            "890000 steps; 56960000 examples so far; train ppl: 322.17, valid ppl: 477.92\n",
            "895000 steps; 57280000 examples so far; train ppl: 323.91, valid ppl: 476.31\n",
            "900000 steps; 57600000 examples so far; train ppl: 326.88, valid ppl: 477.09\n",
            "905000 steps; 57920000 examples so far; train ppl: 325.77, valid ppl: 476.70\n",
            "910000 steps; 58240000 examples so far; train ppl: 327.76, valid ppl: 475.44\n",
            "915000 steps; 58560000 examples so far; train ppl: 326.25, valid ppl: 474.56\n",
            "920000 steps; 58880000 examples so far; train ppl: 329.48, valid ppl: 475.33\n",
            "925000 steps; 59200000 examples so far; train ppl: 325.76, valid ppl: 474.86\n",
            "930000 steps; 59520000 examples so far; train ppl: 317.95, valid ppl: 476.06\n",
            "935000 steps; 59840000 examples so far; train ppl: 307.56, valid ppl: 477.39\n",
            "940000 steps; 60160000 examples so far; train ppl: 313.73, valid ppl: 478.38\n",
            "945000 steps; 60480000 examples so far; train ppl: 311.13, valid ppl: 477.80\n",
            "950000 steps; 60800000 examples so far; train ppl: 317.93, valid ppl: 477.38\n",
            "955000 steps; 61120000 examples so far; train ppl: 316.03, valid ppl: 475.66\n",
            "960000 steps; 61440000 examples so far; train ppl: 320.08, valid ppl: 475.86\n",
            "965000 steps; 61760000 examples so far; train ppl: 317.99, valid ppl: 471.92\n",
            "970000 steps; 62080000 examples so far; train ppl: 317.45, valid ppl: 471.77\n",
            "975000 steps; 62400000 examples so far; train ppl: 320.47, valid ppl: 471.16\n",
            "980000 steps; 62720000 examples so far; train ppl: 320.42, valid ppl: 472.09\n",
            "985000 steps; 63040000 examples so far; train ppl: 321.74, valid ppl: 469.11\n",
            "990000 steps; 63360000 examples so far; train ppl: 322.04, valid ppl: 469.60\n",
            "995000 steps; 63680000 examples so far; train ppl: 323.40, valid ppl: 470.70\n",
            "1000000 steps; 64000000 examples so far; train ppl: 318.30, valid ppl: 471.98\n",
            "1005000 steps; 64320000 examples so far; train ppl: 300.21, valid ppl: 475.66\n",
            "1010000 steps; 64640000 examples so far; train ppl: 303.33, valid ppl: 476.04\n",
            "1015000 steps; 64960000 examples so far; train ppl: 307.44, valid ppl: 474.56\n",
            "1020000 steps; 65280000 examples so far; train ppl: 310.04, valid ppl: 475.25\n",
            "1025000 steps; 65600000 examples so far; train ppl: 314.43, valid ppl: 473.54\n",
            "1030000 steps; 65920000 examples so far; train ppl: 311.79, valid ppl: 474.24\n",
            "1035000 steps; 66240000 examples so far; train ppl: 312.42, valid ppl: 472.38\n",
            "1040000 steps; 66560000 examples so far; train ppl: 316.08, valid ppl: 471.89\n",
            "1045000 steps; 66880000 examples so far; train ppl: 317.36, valid ppl: 471.47\n",
            "1050000 steps; 67200000 examples so far; train ppl: 318.83, valid ppl: 470.45\n",
            "1055000 steps; 67520000 examples so far; train ppl: 318.85, valid ppl: 470.38\n",
            "1060000 steps; 67840000 examples so far; train ppl: 318.41, valid ppl: 469.00\n",
            "1065000 steps; 68160000 examples so far; train ppl: 316.87, valid ppl: 467.70\n",
            "1070000 steps; 68480000 examples so far; train ppl: 321.12, valid ppl: 467.46\n",
            "1075000 steps; 68800000 examples so far; train ppl: 297.51, valid ppl: 472.03\n",
            "1080000 steps; 69120000 examples so far; train ppl: 300.99, valid ppl: 471.21\n",
            "1085000 steps; 69440000 examples so far; train ppl: 305.65, valid ppl: 475.64\n",
            "1090000 steps; 69760000 examples so far; train ppl: 306.97, valid ppl: 472.54\n",
            "1095000 steps; 70080000 examples so far; train ppl: 308.09, valid ppl: 473.19\n",
            "1100000 steps; 70400000 examples so far; train ppl: 308.49, valid ppl: 472.24\n",
            "1105000 steps; 70720000 examples so far; train ppl: 310.46, valid ppl: 471.05\n",
            "1110000 steps; 71040000 examples so far; train ppl: 312.81, valid ppl: 472.12\n",
            "1115000 steps; 71360000 examples so far; train ppl: 309.25, valid ppl: 469.24\n",
            "1120000 steps; 71680000 examples so far; train ppl: 314.57, valid ppl: 468.79\n",
            "1125000 steps; 72000000 examples so far; train ppl: 314.93, valid ppl: 471.00\n",
            "1130000 steps; 72320000 examples so far; train ppl: 316.70, valid ppl: 467.77\n",
            "1135000 steps; 72640000 examples so far; train ppl: 316.66, valid ppl: 467.07\n",
            "1140000 steps; 72960000 examples so far; train ppl: 315.50, valid ppl: 468.55\n",
            "1145000 steps; 73280000 examples so far; train ppl: 301.17, valid ppl: 473.11\n",
            "1150000 steps; 73600000 examples so far; train ppl: 296.48, valid ppl: 475.56\n",
            "1155000 steps; 73920000 examples so far; train ppl: 298.47, valid ppl: 472.90\n",
            "1160000 steps; 74240000 examples so far; train ppl: 304.33, valid ppl: 473.17\n",
            "1165000 steps; 74560000 examples so far; train ppl: 304.09, valid ppl: 470.56\n",
            "1170000 steps; 74880000 examples so far; train ppl: 305.57, valid ppl: 471.75\n",
            "1175000 steps; 75200000 examples so far; train ppl: 308.69, valid ppl: 469.78\n",
            "1180000 steps; 75520000 examples so far; train ppl: 309.72, valid ppl: 471.32\n",
            "1185000 steps; 75840000 examples so far; train ppl: 310.95, valid ppl: 468.53\n",
            "1190000 steps; 76160000 examples so far; train ppl: 312.13, valid ppl: 468.07\n",
            "1195000 steps; 76480000 examples so far; train ppl: 310.77, valid ppl: 469.38\n",
            "1200000 steps; 76800000 examples so far; train ppl: 309.21, valid ppl: 469.23\n",
            "1205000 steps; 77120000 examples so far; train ppl: 312.73, valid ppl: 465.21\n",
            "1210000 steps; 77440000 examples so far; train ppl: 315.55, valid ppl: 466.70\n",
            "1215000 steps; 77760000 examples so far; train ppl: 304.17, valid ppl: 470.60\n",
            "1220000 steps; 78080000 examples so far; train ppl: 292.37, valid ppl: 471.07\n",
            "1225000 steps; 78400000 examples so far; train ppl: 296.69, valid ppl: 470.35\n",
            "1230000 steps; 78720000 examples so far; train ppl: 299.59, valid ppl: 471.80\n",
            "1235000 steps; 79040000 examples so far; train ppl: 302.65, valid ppl: 471.75\n",
            "1240000 steps; 79360000 examples so far; train ppl: 302.91, valid ppl: 470.15\n",
            "1245000 steps; 79680000 examples so far; train ppl: 307.07, valid ppl: 470.20\n",
            "1250000 steps; 80000000 examples so far; train ppl: 306.08, valid ppl: 468.59\n",
            "1255000 steps; 80320000 examples so far; train ppl: 309.36, valid ppl: 469.56\n",
            "1260000 steps; 80640000 examples so far; train ppl: 308.41, valid ppl: 470.73\n",
            "1265000 steps; 80960000 examples so far; train ppl: 305.86, valid ppl: 468.11\n",
            "1270000 steps; 81280000 examples so far; train ppl: 307.29, valid ppl: 468.50\n",
            "1275000 steps; 81600000 examples so far; train ppl: 307.55, valid ppl: 466.11\n",
            "1280000 steps; 81920000 examples so far; train ppl: 312.09, valid ppl: 465.97\n",
            "1285000 steps; 82240000 examples so far; train ppl: 314.90, valid ppl: 466.71\n",
            "1290000 steps; 82560000 examples so far; train ppl: 287.95, valid ppl: 471.70\n",
            "1295000 steps; 82880000 examples so far; train ppl: 294.56, valid ppl: 471.38\n",
            "1300000 steps; 83200000 examples so far; train ppl: 298.54, valid ppl: 473.13\n",
            "1305000 steps; 83520000 examples so far; train ppl: 299.82, valid ppl: 472.36\n",
            "1310000 steps; 83840000 examples so far; train ppl: 303.37, valid ppl: 472.25\n",
            "1315000 steps; 84160000 examples so far; train ppl: 303.13, valid ppl: 469.57\n",
            "1320000 steps; 84480000 examples so far; train ppl: 302.51, valid ppl: 471.38\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-cef898f62e76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mn_examples\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_examples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-cef898f62e76>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(input, target)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliação final no dataset de teste\n",
        "\n",
        "\n",
        "Bonus: o modelo com menor perplexidade no dataset de testes ganhará 0.5 ponto na nota final."
      ],
      "metadata": {
        "id": "VgdNymJdNPXP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxN5YytzZ7Tn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37870b6d-c683-4525-ea08-764ab3b837e1"
      },
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_ppl = np.exp(np.average([\n",
        "        validation_step(input.to(device), target.to(device))\n",
        "        for input, target in test_loader\n",
        "    ]))\n",
        "\n",
        "print(f'test perplexity: {test_ppl}')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test perplexity: 477.6026845142197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teste seu modelo com uma sentença\n",
        "\n",
        "Escolha uma sentença gerada pelo modelo que ache interessante."
      ],
      "metadata": {
        "id": "BHvEs8mPszy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'Eu sou o melhor modelo do mundo e nada' # Ex: 'Eu gosto de comer pizza pois me faz'\n",
        "max_output_tokens = 10\n",
        "\n",
        "for _ in range(max_output_tokens):\n",
        "    input_ids = tokenize(text=prompt, tokenizer=tokenizer)\n",
        "    input_ids_truncated = input_ids[-context_size:]  # Usamos apenas os últimos <context_size> tokens como entrada para o modelo.\n",
        "    input_ids_truncated = torch.tensor(input_ids_truncated)#.unsqueeze(0)\n",
        "    logits = model(input_ids_truncated.to(device))\n",
        "    # Ao usarmos o argmax, a saída do modelo em cada passo é token de maior probabilidade.\n",
        "    # Isso se chama decodificação gulosa (greedy decoding).\n",
        "    predicted_id = torch.argmax(logits).item()\n",
        "    input_ids += [predicted_id]  # Concatenamos a entrada com o token escolhido nesse passo.\n",
        "    prompt = tokenizer.decode(input_ids)\n",
        "    print(prompt)"
      ],
      "metadata": {
        "id": "-CFElf4tsytW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "721bb20e-dc9b-4b5b-96d6-c7a4271dc224"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eu sou o melhor modelo do mundo e nada,\n",
            "Eu sou o melhor modelo do mundo e nada, que\n",
            "Eu sou o melhor modelo do mundo e nada, que o\n",
            "Eu sou o melhor modelo do mundo e nada, que o que\n",
            "Eu sou o melhor modelo do mundo e nada, que o que,\n",
            "Eu sou o melhor modelo do mundo e nada, que o que, em\n",
            "Eu sou o melhor modelo do mundo e nada, que o que, em que\n",
            "Eu sou o melhor modelo do mundo e nada, que o que, em que a\n",
            "Eu sou o melhor modelo do mundo e nada, que o que, em que a partir\n",
            "Eu sou o melhor modelo do mundo e nada, que o que, em que a partir de\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'Eu sou a maior inteligência do mundo, humanos' # Ex: 'Eu gosto de comer pizza pois me faz'\n",
        "max_output_tokens = 10\n",
        "\n",
        "for _ in range(max_output_tokens):\n",
        "    input_ids = tokenize(text=prompt, tokenizer=tokenizer)\n",
        "    input_ids_truncated = input_ids[-context_size:]  # Usamos apenas os últimos <context_size> tokens como entrada para o modelo.\n",
        "    input_ids_truncated = torch.tensor(input_ids_truncated)#.unsqueeze(0)\n",
        "    logits = model(input_ids_truncated.to(device))\n",
        "    # Ao usarmos o argmax, a saída do modelo em cada passo é token de maior probabilidade.\n",
        "    # Isso se chama decodificação gulosa (greedy decoding).\n",
        "    predicted_id = torch.argmax(logits).item()\n",
        "    input_ids += [predicted_id]  # Concatenamos a entrada com o token escolhido nesse passo.\n",
        "    prompt = tokenizer.decode(input_ids)\n",
        "    print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0_aVW8Zdt0W",
        "outputId": "f3be9233-bb02-4ea1-c963-93213143d1aa"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eu sou a maior inteligência do mundo, humanos,\n",
            "Eu sou a maior inteligência do mundo, humanos, o\n",
            "Eu sou a maior inteligência do mundo, humanos, o que\n",
            "Eu sou a maior inteligência do mundo, humanos, o que não\n",
            "Eu sou a maior inteligência do mundo, humanos, o que não é\n",
            "Eu sou a maior inteligência do mundo, humanos, o que não é o\n",
            "Eu sou a maior inteligência do mundo, humanos, o que não é o que\n",
            "Eu sou a maior inteligência do mundo, humanos, o que não é o que é\n",
            "Eu sou a maior inteligência do mundo, humanos, o que não é o que é o\n",
            "Eu sou a maior inteligência do mundo, humanos, o que não é o que é o que\n"
          ]
        }
      ]
    }
  ]
}