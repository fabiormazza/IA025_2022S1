{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aula 7 - Exercício - Leonardo de Lellis Rossi RA261900",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ce8181c5aafb46e38da86458f2b0ba98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a614900af90442c985a9121d2816c2f7",
              "IPY_MODEL_fcb7aa9bffc44cb9bb66429d3016fa48",
              "IPY_MODEL_de3c5fd284c1428d8c542b8f23124fc3"
            ],
            "layout": "IPY_MODEL_bd8a058ec9cd47c1b24f91cff1ba5d70"
          }
        },
        "a614900af90442c985a9121d2816c2f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f33d0fc0bd6d4df78cafea1aed7d8d9a",
            "placeholder": "​",
            "style": "IPY_MODEL_06b427afc46046aba5e914c3f9bf5994",
            "value": "Downloading: 100%"
          }
        },
        "fcb7aa9bffc44cb9bb66429d3016fa48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c4c4b7c4be246e999b3a500b20a07b1",
            "max": 209528,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f1607dabff764f76961af4d68e335068",
            "value": 209528
          }
        },
        "de3c5fd284c1428d8c542b8f23124fc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21ab19386ca24846a8782725faace161",
            "placeholder": "​",
            "style": "IPY_MODEL_e134c49fc4ef4d2db8d1bfeae563495e",
            "value": " 205k/205k [00:00&lt;00:00, 1.34MB/s]"
          }
        },
        "bd8a058ec9cd47c1b24f91cff1ba5d70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f33d0fc0bd6d4df78cafea1aed7d8d9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06b427afc46046aba5e914c3f9bf5994": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c4c4b7c4be246e999b3a500b20a07b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1607dabff764f76961af4d68e335068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "21ab19386ca24846a8782725faace161": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e134c49fc4ef4d2db8d1bfeae563495e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd977e8eb82b461e8a78b3a526b49608": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_425da9a7a95245f3b1747de42f124091",
              "IPY_MODEL_4f64caa677e644a2a6712966e8732af4",
              "IPY_MODEL_f6704447afc84223890a10302928342e"
            ],
            "layout": "IPY_MODEL_2b0ccf24e1a84cd394b02d21d7d21af6"
          }
        },
        "425da9a7a95245f3b1747de42f124091": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9321f1b9fd342f896ac14c7740a32df",
            "placeholder": "​",
            "style": "IPY_MODEL_900cbcfe01df4395a10c5cb6316eb18f",
            "value": "Downloading: 100%"
          }
        },
        "4f64caa677e644a2a6712966e8732af4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04c1ec01572f40408758b4b3d1e18013",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d3ff2d94b48c4d15963837673f79f6e2",
            "value": 2
          }
        },
        "f6704447afc84223890a10302928342e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f8f2d68557445e6b3dc2946be767f34",
            "placeholder": "​",
            "style": "IPY_MODEL_e726fee27a5845bb95a1432c07a2873f",
            "value": " 2.00/2.00 [00:00&lt;00:00, 62.4B/s]"
          }
        },
        "2b0ccf24e1a84cd394b02d21d7d21af6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9321f1b9fd342f896ac14c7740a32df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "900cbcfe01df4395a10c5cb6316eb18f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04c1ec01572f40408758b4b3d1e18013": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3ff2d94b48c4d15963837673f79f6e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f8f2d68557445e6b3dc2946be767f34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e726fee27a5845bb95a1432c07a2873f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12cd18c41aea4ba59873c3dea7995cc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63d28f16e0f846f8a0b6d9ece0126c30",
              "IPY_MODEL_67a64f5bef2542539489def2814ef3ff",
              "IPY_MODEL_c9bf098afdab4a57af25a4422bb8ba7e"
            ],
            "layout": "IPY_MODEL_844f584422624304986d4ec009651a55"
          }
        },
        "63d28f16e0f846f8a0b6d9ece0126c30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_860cda875f53433abdbf464cafa1f24e",
            "placeholder": "​",
            "style": "IPY_MODEL_fb9b2d1dce4d470fb48b0d08d67be9a7",
            "value": "Downloading: 100%"
          }
        },
        "67a64f5bef2542539489def2814ef3ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ccf98bf4e9d4aa2b9083697934a27ee",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11506b2b6810458798471ef8358bdfdb",
            "value": 112
          }
        },
        "c9bf098afdab4a57af25a4422bb8ba7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a913a084251459bb298286b914bb915",
            "placeholder": "​",
            "style": "IPY_MODEL_c1ff1aa29d6b4c6c998c1fb293ce1eca",
            "value": " 112/112 [00:00&lt;00:00, 3.89kB/s]"
          }
        },
        "844f584422624304986d4ec009651a55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "860cda875f53433abdbf464cafa1f24e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb9b2d1dce4d470fb48b0d08d67be9a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ccf98bf4e9d4aa2b9083697934a27ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11506b2b6810458798471ef8358bdfdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a913a084251459bb298286b914bb915": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1ff1aa29d6b4c6c998c1fb293ce1eca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7b381ca56c640128eb6e065184c878b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36189c9dbe794eafa75aa71cb0c885c4",
              "IPY_MODEL_f16c2e541f8845228bf67a671631d550",
              "IPY_MODEL_06b9cf261c654f1595dbca0218f081fe"
            ],
            "layout": "IPY_MODEL_e865154c186445c88af4c0176218242f"
          }
        },
        "36189c9dbe794eafa75aa71cb0c885c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5960f4a530ea4755b58e0a72fa9e62bd",
            "placeholder": "​",
            "style": "IPY_MODEL_885ef45becef4068921a781549d845cf",
            "value": "Downloading: 100%"
          }
        },
        "f16c2e541f8845228bf67a671631d550": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3993740439446759ea15c320896164b",
            "max": 43,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_90a79c374a2c4d88ac33e7bf69f2efb2",
            "value": 43
          }
        },
        "06b9cf261c654f1595dbca0218f081fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae0ea2c7fae44326977380783115a27b",
            "placeholder": "​",
            "style": "IPY_MODEL_0de41075207848cdb604ea6b31cdf8b8",
            "value": " 43.0/43.0 [00:00&lt;00:00, 1.08kB/s]"
          }
        },
        "e865154c186445c88af4c0176218242f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5960f4a530ea4755b58e0a72fa9e62bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "885ef45becef4068921a781549d845cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3993740439446759ea15c320896164b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90a79c374a2c4d88ac33e7bf69f2efb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae0ea2c7fae44326977380783115a27b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0de41075207848cdb604ea6b31cdf8b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d62983cba46b40c685c92ebac456beec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12762651cad143629acee111fc665777",
              "IPY_MODEL_0e8283009c0945249b2cdfab8333af6e",
              "IPY_MODEL_442e87c9a7cc4119bee062ad5a9fe583"
            ],
            "layout": "IPY_MODEL_9e125444ac7d456abc59fa757ebd160c"
          }
        },
        "12762651cad143629acee111fc665777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd92f12ce5924b28a548526808e7f55b",
            "placeholder": "​",
            "style": "IPY_MODEL_08c3047f96bd4f65aae09505c49e9f26",
            "value": "Downloading: 100%"
          }
        },
        "0e8283009c0945249b2cdfab8333af6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2f3ce15aaca47ceb17b5180b72d7604",
            "max": 647,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e170b747e0d4298a203890113132645",
            "value": 647
          }
        },
        "442e87c9a7cc4119bee062ad5a9fe583": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e255bd84759343aaadf73bdd615631ea",
            "placeholder": "​",
            "style": "IPY_MODEL_69e3d3fadea64d9099853688efb72d7e",
            "value": " 647/647 [00:00&lt;00:00, 17.5kB/s]"
          }
        },
        "9e125444ac7d456abc59fa757ebd160c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd92f12ce5924b28a548526808e7f55b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08c3047f96bd4f65aae09505c49e9f26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2f3ce15aaca47ceb17b5180b72d7604": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e170b747e0d4298a203890113132645": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e255bd84759343aaadf73bdd615631ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69e3d3fadea64d9099853688efb72d7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unicamp-dl/IA025_2022S1/blob/main/ex07/leonardo_lellis/Aula_7_Exerc%C3%ADcio_Leonardo_de_Lellis_Rossi_RA261900.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nome = \"Leonardo de Lellis Rossi RA261900\"\n",
        "print(f'Meu nome é {nome}')"
      ],
      "metadata": {
        "id": "jOdQB41_4ZxG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e73e97b6-ed9a-4f6b-e3c9-dc1cd55c71ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meu nome é Leonardo de Lellis Rossi RA261900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neptune charts: https://app.neptune.ai/leolellisr/dl-ia025/e/DLIA-56/charts\n",
        "\n",
        "parameters: https://app.neptune.ai/leolellisr/dl-ia025/e/DLIA-56/all?path=parameters%2F"
      ],
      "metadata": {
        "id": "cJZR2ZrFk78G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "debug = False\n",
        "checkinpoint = True"
      ],
      "metadata": {
        "id": "NJSkx1gPxORT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IbuChoAPMEn"
      },
      "source": [
        "#  Exercício: Modelo de Linguagem (Bengio 2003) - MLP + Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_DBb0-Klwf2"
      },
      "source": [
        "Neste exercício iremos treinar uma rede neural simples para prever a proxima palavra de um texto, data as palavras anteriores como entrada. Esta tarefa é chamada de \"Modelagem da Língua\".\n",
        "\n",
        "Este dataset já possui um tamanho razoável e é bem provável que você vai precisar rodar seus experimentos com GPU.\n",
        "\n",
        "Alguns conselhos úteis:\n",
        "- **ATENÇÃO:** o dataset é bem grande. Não dê comando de imprimí-lo.\n",
        "- Durante a depuração, faça seu dataset ficar bem pequeno, para que a depuração seja mais rápida e não precise de GPU. Somente ligue a GPU quando o seu laço de treinamento já está funcionando\n",
        "- Não deixe para fazer esse exercício na véspera. Ele é trabalhoso."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# iremos utilizar a biblioteca dos transformers para ter acesso ao tokenizador do BERT.\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "3twP0YJC4jmJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbfc768f-7249-4c0d-839c-99eae0d59823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 69.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 54.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !pip install -U neptune-client\n",
        " import neptune.new as neptune"
      ],
      "metadata": {
        "id": "ir0MUg89XzSG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd6b6432-726f-47c0-cc5b-683f26e9b590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting neptune-client\n",
            "  Downloading neptune-client-0.16.2.tar.gz (316 kB)\n",
            "\u001b[K     |████████████████████████████████| 316 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting bravado\n",
            "  Downloading bravado-11.0.3-py2.py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (7.1.2)\n",
            "Collecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 61.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauthlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (3.2.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.3.5)\n",
            "Requirement already satisfied: Pillow>=1.1.6 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (7.1.2)\n",
            "Collecting PyJWT\n",
            "  Downloading PyJWT-2.4.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.3.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.15.0)\n",
            "Collecting websocket-client!=1.0.0,>=0.35.0\n",
            "  Downloading websocket_client-1.3.2-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.1 MB/s \n",
            "\u001b[?25hCollecting GitPython>=2.0.8\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 56.8 MB/s \n",
            "\u001b[?25hCollecting boto3>=1.16.0\n",
            "  Downloading boto3-1.23.2-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 63.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from neptune-client) (21.3)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.24.3)\n",
            "Collecting swagger-spec-validator>=2.7.4\n",
            "  Downloading swagger_spec_validator-2.7.4-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from neptune-client) (5.4.8)\n",
            "Collecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.7 MB/s \n",
            "\u001b[?25hCollecting botocore<1.27.0,>=1.26.2\n",
            "  Downloading botocore-1.26.2-py3-none-any.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 37.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.27.0,>=1.26.2->boto3>=1.16.0->neptune-client) (2.8.2)\n",
            "Collecting urllib3\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 33.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=2.0.8->neptune-client) (4.2.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 992 kB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (3.0.4)\n",
            "Collecting urllib3\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 58.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from swagger-spec-validator>=2.7.4->neptune-client) (6.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from swagger-spec-validator>=2.7.4->neptune-client) (4.3.3)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from bravado->neptune-client) (1.0.3)\n",
            "Collecting bravado-core>=5.16.1\n",
            "  Downloading bravado_core-5.17.0-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting monotonic\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting simplejson\n",
            "  Downloading simplejson-3.17.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 52.8 MB/s \n",
            "\u001b[?25hCollecting jsonref\n",
            "  Downloading jsonref-0.2-py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from bravado-core>=5.16.1->bravado->neptune-client) (2022.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (5.7.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (4.11.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (21.4.0)\n",
            "Collecting uri-template\n",
            "  Downloading uri_template-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting rfc3339-validator\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Collecting rfc3987\n",
            "  Downloading rfc3987-1.3.8-py2.py3-none-any.whl (13 kB)\n",
            "Collecting jsonpointer>1.13\n",
            "  Downloading jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting isoduration\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Collecting webcolors>=1.11\n",
            "  Downloading webcolors-1.11.1-py3-none-any.whl (9.9 kB)\n",
            "Collecting fqdn\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (3.8.0)\n",
            "Requirement already satisfied: cached-property>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from fqdn->jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.5.2)\n",
            "Collecting arrow>=0.15.0\n",
            "  Downloading arrow-1.2.2-py3-none-any.whl (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 3.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->neptune-client) (3.0.9)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->neptune-client) (1.21.6)\n",
            "Building wheels for collected packages: neptune-client, future\n",
            "  Building wheel for neptune-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for neptune-client: filename=neptune_client-0.16.2-py2.py3-none-any.whl size=566337 sha256=6d3107485b81d2951d63eb8723480d98c6f1dfed92571885cf2f3e623f3c538a\n",
            "  Stored in directory: /root/.cache/pip/wheels/6f/e9/85/964258b089a9890c505f5024f049fdbef3b59f4e3039474be7\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=0060a6f46cf54983d74631546ba6e57ed03a353bde051b91d3cedbf64d9d4173\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "Successfully built neptune-client future\n",
            "Installing collected packages: arrow, webcolors, urllib3, uri-template, rfc3987, rfc3339-validator, jsonpointer, jmespath, isoduration, fqdn, swagger-spec-validator, smmap, simplejson, jsonref, botocore, s3transfer, monotonic, gitdb, bravado-core, websocket-client, PyJWT, GitPython, future, bravado, boto3, neptune-client\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed GitPython-3.1.27 PyJWT-2.4.0 arrow-1.2.2 boto3-1.23.2 botocore-1.26.2 bravado-11.0.3 bravado-core-5.17.0 fqdn-1.5.1 future-0.18.2 gitdb-4.0.9 isoduration-20.11.0 jmespath-1.0.0 jsonpointer-2.3 jsonref-0.2 monotonic-1.6 neptune-client-0.16.2 rfc3339-validator-0.1.4 rfc3987-1.3.8 s3transfer-0.5.2 simplejson-3.17.6 smmap-5.0.0 swagger-spec-validator-2.7.4 uri-template-1.2.0 urllib3-1.25.11 webcolors-1.11.1 websocket-client-1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run = neptune.init(name= 'Ex. Aula 7', tags=['Aula 7', 'BrWaC', 'MLP', 'bengio2003', 'checkinpoint', 'CrossEntropy', 'Adam', 'perplexity'],\n",
        "    project=\"leolellisr/dl-ia025\",\n",
        "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI1NjY1YmJkZi1hYmM5LTQ3M2QtOGU1ZC1iZTFlNWY4NjE1NDQifQ==\",\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "0pNdE5fU1Xkf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cd61d0d-105f-434d-d45f-1868419b828d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://app.neptune.ai/leolellisr/dl-ia025/e/DLIA-56\n",
            "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnyhJZtTRNMx"
      },
      "source": [
        "## Importação dos pacotes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlIOVCajPWcU"
      },
      "source": [
        "import collections\n",
        "import itertools\n",
        "import functools\n",
        "import math\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm, tqdm_notebook\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check which GPU we are using\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "w9f3PfifAwpU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39e9a0d7-4596-4d08-bde1-a6f45e74c62c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: string series 'monitoring/stdout' value was longer than 1000 characters and was truncated. This warning is printed only once per series.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue May 17 21:34:54 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available(): \n",
        "   dev = \"cuda:0\"\n",
        "else: \n",
        "   dev = \"cpu\"\n",
        "device = torch.device(dev)\n",
        "print('Using {}'.format(device))"
      ],
      "metadata": {
        "id": "whTCe2i7AtoV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0e0a062-0096-40b6-a5aa-ee8fd30fe1c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seeds():\n",
        "  random.seed(123)\n",
        "  np.random.seed(123)\n",
        "  torch.manual_seed(123)\n",
        "  torch.cuda.manual_seed(123)\n",
        "set_seeds()"
      ],
      "metadata": {
        "id": "hZsMk2ZPX1EH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZfxgV2DUk58"
      },
      "source": [
        "## Implementação do MyDataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_xhKm1EZ3bQ"
      },
      "source": [
        "from typing import List\n",
        "\n",
        "\n",
        "def tokenize(text: str, tokenizer):\n",
        "    return tokenizer(text, return_tensors=None, add_special_tokens=False).input_ids\n",
        "\n",
        "\n",
        "class MyDataset():\n",
        "    def __init__(self, texts: List[str], tokenizer, context_size: int):\n",
        "        # Escreva seu código aqui\n",
        "      self.X = []\n",
        "      self.y = []\n",
        "      for text in texts:\n",
        "        tokens_ids = tokenize(text, tokenizer)\n",
        "        if len(tokens_ids) > context_size:\n",
        "          for i in range(len(tokens_ids)-context_size):\n",
        "              self.X.append(tokens_ids[i:i+context_size])      \n",
        "              self.y.append(tokens_ids[i+context_size])\n",
        "\n",
        "    def __len__(self):\n",
        "        # Escreva seu código aqui\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Escreva seu código aqui\n",
        "        return torch.tensor(self.X[idx]).long(), torch.tensor(self.y[idx]).long()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teste se sua implementação do MyDataset está correta"
      ],
      "metadata": {
        "id": "wew-gFbWeBTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
        "\n",
        "dummy_texts = ['Eu gosto de correr', 'Ela gosta muito de comer pizza']\n",
        "\n",
        "dummy_dataset = MyDataset(texts=dummy_texts, tokenizer=tokenizer, context_size=3)\n",
        "dummy_loader = DataLoader(dummy_dataset, batch_size=6, shuffle=False)\n",
        "assert len(dummy_dataset) == 5\n",
        "print('passou no assert de tamanho do dataset')\n",
        "\n",
        "first_batch_input, first_batch_target = next(iter(dummy_loader))\n",
        "\n",
        "correct_first_batch_input = torch.LongTensor(\n",
        "    [[ 3396, 10303,   125],\n",
        "     [ 1660,  5971,   785],\n",
        "     [ 5971,   785,   125],\n",
        "     [  785,   125,  1847],\n",
        "     [  125,  1847, 13779]])\n",
        "\n",
        "correct_first_batch_target = torch.LongTensor([13239,   125,  1847, 13779, 15616])\n",
        "\n",
        "assert torch.equal(first_batch_input, correct_first_batch_input)\n",
        "print('Passou no assert de input')\n",
        "assert torch.equal(first_batch_target, correct_first_batch_target)\n",
        "print('Passou no assert de target')"
      ],
      "metadata": {
        "id": "8r7jBFFUeApe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229,
          "referenced_widgets": [
            "ce8181c5aafb46e38da86458f2b0ba98",
            "a614900af90442c985a9121d2816c2f7",
            "fcb7aa9bffc44cb9bb66429d3016fa48",
            "de3c5fd284c1428d8c542b8f23124fc3",
            "bd8a058ec9cd47c1b24f91cff1ba5d70",
            "f33d0fc0bd6d4df78cafea1aed7d8d9a",
            "06b427afc46046aba5e914c3f9bf5994",
            "3c4c4b7c4be246e999b3a500b20a07b1",
            "f1607dabff764f76961af4d68e335068",
            "21ab19386ca24846a8782725faace161",
            "e134c49fc4ef4d2db8d1bfeae563495e",
            "fd977e8eb82b461e8a78b3a526b49608",
            "425da9a7a95245f3b1747de42f124091",
            "4f64caa677e644a2a6712966e8732af4",
            "f6704447afc84223890a10302928342e",
            "2b0ccf24e1a84cd394b02d21d7d21af6",
            "e9321f1b9fd342f896ac14c7740a32df",
            "900cbcfe01df4395a10c5cb6316eb18f",
            "04c1ec01572f40408758b4b3d1e18013",
            "d3ff2d94b48c4d15963837673f79f6e2",
            "9f8f2d68557445e6b3dc2946be767f34",
            "e726fee27a5845bb95a1432c07a2873f",
            "12cd18c41aea4ba59873c3dea7995cc7",
            "63d28f16e0f846f8a0b6d9ece0126c30",
            "67a64f5bef2542539489def2814ef3ff",
            "c9bf098afdab4a57af25a4422bb8ba7e",
            "844f584422624304986d4ec009651a55",
            "860cda875f53433abdbf464cafa1f24e",
            "fb9b2d1dce4d470fb48b0d08d67be9a7",
            "4ccf98bf4e9d4aa2b9083697934a27ee",
            "11506b2b6810458798471ef8358bdfdb",
            "7a913a084251459bb298286b914bb915",
            "c1ff1aa29d6b4c6c998c1fb293ce1eca",
            "a7b381ca56c640128eb6e065184c878b",
            "36189c9dbe794eafa75aa71cb0c885c4",
            "f16c2e541f8845228bf67a671631d550",
            "06b9cf261c654f1595dbca0218f081fe",
            "e865154c186445c88af4c0176218242f",
            "5960f4a530ea4755b58e0a72fa9e62bd",
            "885ef45becef4068921a781549d845cf",
            "a3993740439446759ea15c320896164b",
            "90a79c374a2c4d88ac33e7bf69f2efb2",
            "ae0ea2c7fae44326977380783115a27b",
            "0de41075207848cdb604ea6b31cdf8b8",
            "d62983cba46b40c685c92ebac456beec",
            "12762651cad143629acee111fc665777",
            "0e8283009c0945249b2cdfab8333af6e",
            "442e87c9a7cc4119bee062ad5a9fe583",
            "9e125444ac7d456abc59fa757ebd160c",
            "fd92f12ce5924b28a548526808e7f55b",
            "08c3047f96bd4f65aae09505c49e9f26",
            "a2f3ce15aaca47ceb17b5180b72d7604",
            "9e170b747e0d4298a203890113132645",
            "e255bd84759343aaadf73bdd615631ea",
            "69e3d3fadea64d9099853688efb72d7e"
          ]
        },
        "outputId": "1bc16f97-8ff3-4f8d-9216-df097e9577c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/205k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce8181c5aafb46e38da86458f2b0ba98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd977e8eb82b461e8a78b3a526b49608"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12cd18c41aea4ba59873c3dea7995cc7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/43.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7b381ca56c640128eb6e065184c878b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/647 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d62983cba46b40c685c92ebac456beec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "passou no assert de tamanho do dataset\n",
            "Passou no assert de input\n",
            "Passou no assert de target\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LfrHHouleJ0"
      },
      "source": [
        "# Carregamento do dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2vFWjsSkmop"
      },
      "source": [
        "Iremos usar uma pequena amostra do dataset [BrWaC](https://www.inf.ufrgs.br/pln/wiki/index.php?title=BrWaC) para treinar e avaliar nosso modelo de linguagem."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://storage.googleapis.com/unicamp-dl/ia025a_2022s1/aula7/sample_brwac.txt"
      ],
      "metadata": {
        "id": "vGlN1WqrXPA6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7b85195-4037-4233-e7a5-b5ca90368c79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-17 21:35:39--  https://storage.googleapis.com/unicamp-dl/ia025a_2022s1/aula7/sample_brwac.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.128.128, 142.251.6.128, 142.250.152.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.128.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 123983611 (118M) [text/plain]\n",
            "Saving to: ‘sample_brwac.txt’\n",
            "\n",
            "sample_brwac.txt    100%[===================>] 118.24M   145MB/s    in 0.8s    \n",
            "\n",
            "2022-05-17 21:35:40 (145 MB/s) - ‘sample_brwac.txt’ saved [123983611/123983611]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "context_size = 9\n",
        "\n",
        "valid_examples = 100\n",
        "test_examples = 100\n",
        "texts = open('sample_brwac.txt').readlines()\n",
        "\n",
        "if debug:\n",
        "  print('Truncating for debugging purposes.')\n",
        "  texts = texts[:500]  \n",
        "\n",
        "training_texts = texts[:-(valid_examples + test_examples)]\n",
        "valid_texts = texts[-(valid_examples + test_examples):-test_examples]\n",
        "test_texts = texts[-test_examples:]\n",
        "\n",
        "training_dataset = MyDataset(texts=training_texts, tokenizer=tokenizer, context_size=context_size)\n",
        "valid_dataset = MyDataset(texts=valid_texts, tokenizer=tokenizer, context_size=context_size)\n",
        "test_dataset = MyDataset(texts=test_texts, tokenizer=tokenizer, context_size=context_size)"
      ],
      "metadata": {
        "id": "gxa_4gmiA-wE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'training examples: {len(training_dataset)}')\n",
        "print(f'valid examples: {len(valid_dataset)}')\n",
        "print(f'test examples: {len(test_dataset)}')"
      ],
      "metadata": {
        "id": "KCSGJ5m7py4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f05a1435-e388-4204-c114-f88cc1224bff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training examples: 27675945\n",
            "valid examples: 82070\n",
            "test examples: 166726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGaAjYDfWdd1"
      },
      "source": [
        "class LanguageModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, context_size, embedding_dim, hidden_size):\n",
        "        \"\"\"\n",
        "        Implements the Neural Language Model proposed by Bengio et al.\"\n",
        "\n",
        "        Args:\n",
        "            vocab_size (int): Size of the input vocabulary.\n",
        "            context_size (int): Size of the sequence to consider as context for prediction.\n",
        "            embedding_dim (int): Dimension of the embedding layer for each word in the context.\n",
        "            hidden_size (int): Size of the hidden layer.\n",
        "        \"\"\"\n",
        "        # Escreva seu código aqui.\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear_layer1 = nn.Linear(context_size*embedding_dim, hidden_size)\n",
        "        self.linear_layer2 = nn.Linear(hidden_size, vocab_size, bias=False)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            inputs is a LongTensor of shape (batch_size, context_size)\n",
        "        \"\"\"\n",
        "        # Escreva seu código aqui.\n",
        "        out = self.embeddings(inputs)\n",
        "        out = out.view(inputs.shape[0],-1)\n",
        "        out = self.linear_layer1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear_layer2(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teste o modelo com um exemplo"
      ],
      "metadata": {
        "id": "Rm6_PTH2i98e"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwnxfZlrZoT_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d599009-9e37-46fe-81a9-ecbd29c52950"
      },
      "source": [
        "model = LanguageModel(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    context_size=context_size,\n",
        "    embedding_dim=64,\n",
        "    hidden_size=128,\n",
        ").to(device)\n",
        "\n",
        "sample_train, _ = next(iter(DataLoader(training_dataset)))\n",
        "sample_train_gpu = sample_train.to(device)\n",
        "model(sample_train_gpu).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 29794])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3Vh6B-VkA01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb314942-ec0b-4983-d987-8f2d20c50878"
      },
      "source": [
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'Number of model parameters: {num_params}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of model parameters: 5794304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assert da Perplexidade\n"
      ],
      "metadata": {
        "id": "8nhbUVsYnVAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_seeds()\n",
        "\n",
        "\n",
        "def perplexity(logits, target):\n",
        "    \"\"\"\n",
        "    Computes the perplexity.\n",
        "\n",
        "    Args:\n",
        "        logits: a FloatTensor of shape (batch_size, vocab_size)\n",
        "        target: a LongTensor of shape (batch_size,)\n",
        "\n",
        "    Returns:\n",
        "        A float corresponding to the perplexity.\n",
        "    \"\"\"\n",
        "    # Escreva seu código aqui.\n",
        "     \n",
        "    return torch.exp(nn.functional.cross_entropy(logits,target))\n",
        "\n",
        "\n",
        "n_examples = 1000\n",
        "\n",
        "sample_train, target_token_ids = next(iter(DataLoader(training_dataset, batch_size=n_examples)))\n",
        "sample_train_gpu = sample_train.to(device)\n",
        "target_token_ids = target_token_ids.to(device)\n",
        "logits = model(sample_train_gpu)\n",
        "\n",
        "my_perplexity = perplexity(logits=logits, target=target_token_ids)\n",
        "\n",
        "print(f'my perplexity:              {int(my_perplexity)}')\n",
        "print(f'correct initial perplexity: {tokenizer.vocab_size}')\n",
        "\n",
        "assert math.isclose(my_perplexity, tokenizer.vocab_size, abs_tol=2000)\n",
        "print('Passou o no assert da perplexidade')"
      ],
      "metadata": {
        "id": "gbMP8VAUncfX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dd4e8c5-1a8e-4068-badd-a9691c186a97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my perplexity:              30321\n",
            "correct initial perplexity: 29794\n",
            "Passou o no assert da perplexidade\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Laço de Treinamento e Validação"
      ],
      "metadata": {
        "id": "KiJtrsqPnE_l"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIMSaY-UUGUE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22162b95-ea31-4c0d-bf3b-1cb64ef795a9"
      },
      "source": [
        "\n",
        "params = {\n",
        "    'max_examples': 200_000_000,\n",
        "    'eval_every_steps': 5000,\n",
        "    'lr': 3e-5,\n",
        "    'batch_size': 512,\n",
        "    'embedding_dim': 128,\n",
        "    'hidden_size': 256,\n",
        "    'optimizer': 'Adam'\n",
        "}\n",
        "run['parameters'] = params\n",
        "\n",
        "model = LanguageModel(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    context_size=context_size,\n",
        "    embedding_dim=params['embedding_dim'],\n",
        "    hidden_size=params['hidden_size'],\n",
        ").to(device)\n",
        "\n",
        "train_loader = DataLoader(training_dataset, batch_size=params['batch_size'], shuffle=True, drop_last=True)\n",
        "validation_loader = DataLoader(valid_dataset, batch_size=params['batch_size'])\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'])\n",
        "\n",
        "\n",
        "def train_step(input, target):\n",
        "    model.train()\n",
        "    model.zero_grad()\n",
        "\n",
        "    logits = model(input.to(device))\n",
        "    loss = nn.functional.cross_entropy(logits, target.to(device))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "def validation_step(input, target):\n",
        "    logits = model(input)\n",
        "    loss = nn.functional.cross_entropy(logits, target)\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "train_losses = []\n",
        "n_examples = 0\n",
        "step = 0\n",
        "best_valid_ppl = 10e9\n",
        "while n_examples < params['max_examples']:\n",
        "    for input, target in train_loader:\n",
        "        loss = train_step(input.to(device), target.to(device)) \n",
        "        train_losses.append(loss)\n",
        "        run['train/loss'].log(loss) # Envia loss para o Neptune.\n",
        "        if step % params['eval_every_steps'] == 0:\n",
        "            train_ppl = np.exp(np.average(train_losses))\n",
        "            run['train/ppl'].log(train_ppl) # Envia train ppl para o Neptune.\n",
        "\n",
        "            with torch.no_grad():\n",
        "                valid_ppl = np.exp(np.average([\n",
        "                    validation_step(input.to(device), target.to(device))\n",
        "                    for input, target in validation_loader]))\n",
        "                run['valid/ppl'].log(valid_ppl) # Envia valid ppl para o Neptune.\n",
        "            \n",
        "                if checkinpoint and valid_ppl < best_valid_ppl:\n",
        "                  torch.save(model.state_dict(), 'best_model.pt')\n",
        "                  print(f\"Best model found in step {step}. valid ppl: {valid_ppl:.2f}, best_valid_ppl: {best_valid_ppl:.2f} \")\n",
        "                  best_valid_ppl = valid_ppl\n",
        "                  \n",
        "            ex_least = params['max_examples']-n_examples\n",
        "            print(f'{step} steps; {n_examples} examples so far; at least {ex_least} examples to go; train ppl: {train_ppl:.2f}, valid ppl: {valid_ppl:.2f}, best_valid_ppl: {best_valid_ppl:.2f}')\n",
        "            train_losses = []\n",
        "            \n",
        "        n_examples += len(input)  # Increment of batch size\n",
        "        step += 1\n",
        "        if n_examples >= params['max_examples']:\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model found in step 0. valid ppl: 30484.00, best_valid_ppl: 10000000000.00 \n",
            "0 steps; 0 examples so far; at least 200000000 examples to go; train ppl: 30218.07, valid ppl: 30484.00, best_valid_ppl: 30484.00\n",
            "Best model found in step 5000. valid ppl: 1547.47, best_valid_ppl: 30484.00 \n",
            "5000 steps; 2560000 examples so far; at least 197440000 examples to go; train ppl: 2437.98, valid ppl: 1547.47, best_valid_ppl: 1547.47\n",
            "Best model found in step 10000. valid ppl: 1216.27, best_valid_ppl: 1547.47 \n",
            "10000 steps; 5120000 examples so far; at least 194880000 examples to go; train ppl: 1349.30, valid ppl: 1216.27, best_valid_ppl: 1216.27\n",
            "Best model found in step 15000. valid ppl: 1011.50, best_valid_ppl: 1216.27 \n",
            "15000 steps; 7680000 examples so far; at least 192320000 examples to go; train ppl: 1102.53, valid ppl: 1011.50, best_valid_ppl: 1011.50\n",
            "Best model found in step 20000. valid ppl: 874.68, best_valid_ppl: 1011.50 \n",
            "20000 steps; 10240000 examples so far; at least 189760000 examples to go; train ppl: 933.89, valid ppl: 874.68, best_valid_ppl: 874.68\n",
            "Best model found in step 25000. valid ppl: 779.72, best_valid_ppl: 874.68 \n",
            "25000 steps; 12800000 examples so far; at least 187200000 examples to go; train ppl: 819.59, valid ppl: 779.72, best_valid_ppl: 779.72\n",
            "Best model found in step 30000. valid ppl: 707.40, best_valid_ppl: 779.72 \n",
            "30000 steps; 15360000 examples so far; at least 184640000 examples to go; train ppl: 734.10, valid ppl: 707.40, best_valid_ppl: 707.40\n",
            "Best model found in step 35000. valid ppl: 649.81, best_valid_ppl: 707.40 \n",
            "35000 steps; 17920000 examples so far; at least 182080000 examples to go; train ppl: 673.62, valid ppl: 649.81, best_valid_ppl: 649.81\n",
            "Best model found in step 40000. valid ppl: 602.27, best_valid_ppl: 649.81 \n",
            "40000 steps; 20480000 examples so far; at least 179520000 examples to go; train ppl: 623.08, valid ppl: 602.27, best_valid_ppl: 602.27\n",
            "Best model found in step 45000. valid ppl: 562.57, best_valid_ppl: 602.27 \n",
            "45000 steps; 23040000 examples so far; at least 176960000 examples to go; train ppl: 581.32, valid ppl: 562.57, best_valid_ppl: 562.57\n",
            "Best model found in step 50000. valid ppl: 527.31, best_valid_ppl: 562.57 \n",
            "50000 steps; 25600000 examples so far; at least 174400000 examples to go; train ppl: 543.75, valid ppl: 527.31, best_valid_ppl: 527.31\n",
            "Best model found in step 55000. valid ppl: 498.23, best_valid_ppl: 527.31 \n",
            "55000 steps; 28160000 examples so far; at least 171840000 examples to go; train ppl: 509.93, valid ppl: 498.23, best_valid_ppl: 498.23\n",
            "Best model found in step 60000. valid ppl: 471.70, best_valid_ppl: 498.23 \n",
            "60000 steps; 30720000 examples so far; at least 169280000 examples to go; train ppl: 477.31, valid ppl: 471.70, best_valid_ppl: 471.70\n",
            "Best model found in step 65000. valid ppl: 448.48, best_valid_ppl: 471.70 \n",
            "65000 steps; 33280000 examples so far; at least 166720000 examples to go; train ppl: 451.19, valid ppl: 448.48, best_valid_ppl: 448.48\n",
            "Best model found in step 70000. valid ppl: 427.77, best_valid_ppl: 448.48 \n",
            "70000 steps; 35840000 examples so far; at least 164160000 examples to go; train ppl: 430.58, valid ppl: 427.77, best_valid_ppl: 427.77\n",
            "Best model found in step 75000. valid ppl: 409.39, best_valid_ppl: 427.77 \n",
            "75000 steps; 38400000 examples so far; at least 161600000 examples to go; train ppl: 411.58, valid ppl: 409.39, best_valid_ppl: 409.39\n",
            "Best model found in step 80000. valid ppl: 393.17, best_valid_ppl: 409.39 \n",
            "80000 steps; 40960000 examples so far; at least 159040000 examples to go; train ppl: 394.46, valid ppl: 393.17, best_valid_ppl: 393.17\n",
            "Best model found in step 85000. valid ppl: 378.65, best_valid_ppl: 393.17 \n",
            "85000 steps; 43520000 examples so far; at least 156480000 examples to go; train ppl: 380.73, valid ppl: 378.65, best_valid_ppl: 378.65\n",
            "Best model found in step 90000. valid ppl: 365.53, best_valid_ppl: 378.65 \n",
            "90000 steps; 46080000 examples so far; at least 153920000 examples to go; train ppl: 366.35, valid ppl: 365.53, best_valid_ppl: 365.53\n",
            "Best model found in step 95000. valid ppl: 353.95, best_valid_ppl: 365.53 \n",
            "95000 steps; 48640000 examples so far; at least 151360000 examples to go; train ppl: 353.01, valid ppl: 353.95, best_valid_ppl: 353.95\n",
            "Best model found in step 100000. valid ppl: 343.39, best_valid_ppl: 353.95 \n",
            "100000 steps; 51200000 examples so far; at least 148800000 examples to go; train ppl: 342.95, valid ppl: 343.39, best_valid_ppl: 343.39\n",
            "Best model found in step 105000. valid ppl: 333.46, best_valid_ppl: 343.39 \n",
            "105000 steps; 53760000 examples so far; at least 146240000 examples to go; train ppl: 333.28, valid ppl: 333.46, best_valid_ppl: 333.46\n",
            "Best model found in step 110000. valid ppl: 324.84, best_valid_ppl: 333.46 \n",
            "110000 steps; 56320000 examples so far; at least 143680000 examples to go; train ppl: 321.81, valid ppl: 324.84, best_valid_ppl: 324.84\n",
            "Best model found in step 115000. valid ppl: 317.58, best_valid_ppl: 324.84 \n",
            "115000 steps; 58880000 examples so far; at least 141120000 examples to go; train ppl: 308.94, valid ppl: 317.58, best_valid_ppl: 317.58\n",
            "Best model found in step 120000. valid ppl: 310.27, best_valid_ppl: 317.58 \n",
            "120000 steps; 61440000 examples so far; at least 138560000 examples to go; train ppl: 301.66, valid ppl: 310.27, best_valid_ppl: 310.27\n",
            "Best model found in step 125000. valid ppl: 303.74, best_valid_ppl: 310.27 \n",
            "125000 steps; 64000000 examples so far; at least 136000000 examples to go; train ppl: 296.43, valid ppl: 303.74, best_valid_ppl: 303.74\n",
            "Best model found in step 130000. valid ppl: 297.13, best_valid_ppl: 303.74 \n",
            "130000 steps; 66560000 examples so far; at least 133440000 examples to go; train ppl: 289.41, valid ppl: 297.13, best_valid_ppl: 297.13\n",
            "Best model found in step 135000. valid ppl: 291.95, best_valid_ppl: 297.13 \n",
            "135000 steps; 69120000 examples so far; at least 130880000 examples to go; train ppl: 285.50, valid ppl: 291.95, best_valid_ppl: 291.95\n",
            "Best model found in step 140000. valid ppl: 286.87, best_valid_ppl: 291.95 \n",
            "140000 steps; 71680000 examples so far; at least 128320000 examples to go; train ppl: 280.22, valid ppl: 286.87, best_valid_ppl: 286.87\n",
            "Best model found in step 145000. valid ppl: 281.93, best_valid_ppl: 286.87 \n",
            "145000 steps; 74240000 examples so far; at least 125760000 examples to go; train ppl: 275.47, valid ppl: 281.93, best_valid_ppl: 281.93\n",
            "Best model found in step 150000. valid ppl: 277.34, best_valid_ppl: 281.93 \n",
            "150000 steps; 76800000 examples so far; at least 123200000 examples to go; train ppl: 270.98, valid ppl: 277.34, best_valid_ppl: 277.34\n",
            "Best model found in step 155000. valid ppl: 273.14, best_valid_ppl: 277.34 \n",
            "155000 steps; 79360000 examples so far; at least 120640000 examples to go; train ppl: 266.91, valid ppl: 273.14, best_valid_ppl: 273.14\n",
            "Best model found in step 160000. valid ppl: 269.35, best_valid_ppl: 273.14 \n",
            "160000 steps; 81920000 examples so far; at least 118080000 examples to go; train ppl: 263.07, valid ppl: 269.35, best_valid_ppl: 269.35\n",
            "Best model found in step 165000. valid ppl: 265.45, best_valid_ppl: 269.35 \n",
            "165000 steps; 84480000 examples so far; at least 115520000 examples to go; train ppl: 255.61, valid ppl: 265.45, best_valid_ppl: 265.45\n",
            "Best model found in step 170000. valid ppl: 262.26, best_valid_ppl: 265.45 \n",
            "170000 steps; 87040000 examples so far; at least 112960000 examples to go; train ppl: 249.81, valid ppl: 262.26, best_valid_ppl: 262.26\n",
            "Best model found in step 175000. valid ppl: 259.00, best_valid_ppl: 262.26 \n",
            "175000 steps; 89600000 examples so far; at least 110400000 examples to go; train ppl: 247.43, valid ppl: 259.00, best_valid_ppl: 259.00\n",
            "Best model found in step 180000. valid ppl: 256.40, best_valid_ppl: 259.00 \n",
            "180000 steps; 92160000 examples so far; at least 107840000 examples to go; train ppl: 245.90, valid ppl: 256.40, best_valid_ppl: 256.40\n",
            "Best model found in step 185000. valid ppl: 253.22, best_valid_ppl: 256.40 \n",
            "185000 steps; 94720000 examples so far; at least 105280000 examples to go; train ppl: 242.11, valid ppl: 253.22, best_valid_ppl: 253.22\n",
            "Best model found in step 190000. valid ppl: 250.71, best_valid_ppl: 253.22 \n",
            "190000 steps; 97280000 examples so far; at least 102720000 examples to go; train ppl: 240.15, valid ppl: 250.71, best_valid_ppl: 250.71\n",
            "Best model found in step 195000. valid ppl: 248.25, best_valid_ppl: 250.71 \n",
            "195000 steps; 99840000 examples so far; at least 100160000 examples to go; train ppl: 238.61, valid ppl: 248.25, best_valid_ppl: 248.25\n",
            "Best model found in step 200000. valid ppl: 245.81, best_valid_ppl: 248.25 \n",
            "200000 steps; 102400000 examples so far; at least 97600000 examples to go; train ppl: 236.22, valid ppl: 245.81, best_valid_ppl: 245.81\n",
            "Best model found in step 205000. valid ppl: 243.46, best_valid_ppl: 245.81 \n",
            "205000 steps; 104960000 examples so far; at least 95040000 examples to go; train ppl: 233.89, valid ppl: 243.46, best_valid_ppl: 243.46\n",
            "Best model found in step 210000. valid ppl: 240.89, best_valid_ppl: 243.46 \n",
            "210000 steps; 107520000 examples so far; at least 92480000 examples to go; train ppl: 232.53, valid ppl: 240.89, best_valid_ppl: 240.89\n",
            "Best model found in step 215000. valid ppl: 239.07, best_valid_ppl: 240.89 \n",
            "215000 steps; 110080000 examples so far; at least 89920000 examples to go; train ppl: 229.75, valid ppl: 239.07, best_valid_ppl: 239.07\n",
            "Best model found in step 220000. valid ppl: 237.22, best_valid_ppl: 239.07 \n",
            "220000 steps; 112640000 examples so far; at least 87360000 examples to go; train ppl: 224.56, valid ppl: 237.22, best_valid_ppl: 237.22\n",
            "Best model found in step 225000. valid ppl: 235.45, best_valid_ppl: 237.22 \n",
            "225000 steps; 115200000 examples so far; at least 84800000 examples to go; train ppl: 221.16, valid ppl: 235.45, best_valid_ppl: 235.45\n",
            "Best model found in step 230000. valid ppl: 233.86, best_valid_ppl: 235.45 \n",
            "230000 steps; 117760000 examples so far; at least 82240000 examples to go; train ppl: 220.18, valid ppl: 233.86, best_valid_ppl: 233.86\n",
            "Best model found in step 235000. valid ppl: 232.01, best_valid_ppl: 233.86 \n",
            "235000 steps; 120320000 examples so far; at least 79680000 examples to go; train ppl: 218.75, valid ppl: 232.01, best_valid_ppl: 232.01\n",
            "Best model found in step 240000. valid ppl: 230.22, best_valid_ppl: 232.01 \n",
            "240000 steps; 122880000 examples so far; at least 77120000 examples to go; train ppl: 217.44, valid ppl: 230.22, best_valid_ppl: 230.22\n",
            "Best model found in step 245000. valid ppl: 229.03, best_valid_ppl: 230.22 \n",
            "245000 steps; 125440000 examples so far; at least 74560000 examples to go; train ppl: 216.65, valid ppl: 229.03, best_valid_ppl: 229.03\n",
            "Best model found in step 250000. valid ppl: 227.32, best_valid_ppl: 229.03 \n",
            "250000 steps; 128000000 examples so far; at least 72000000 examples to go; train ppl: 215.77, valid ppl: 227.32, best_valid_ppl: 227.32\n",
            "Best model found in step 255000. valid ppl: 225.58, best_valid_ppl: 227.32 \n",
            "255000 steps; 130560000 examples so far; at least 69440000 examples to go; train ppl: 213.89, valid ppl: 225.58, best_valid_ppl: 225.58\n",
            "Best model found in step 260000. valid ppl: 224.19, best_valid_ppl: 225.58 \n",
            "260000 steps; 133120000 examples so far; at least 66880000 examples to go; train ppl: 212.57, valid ppl: 224.19, best_valid_ppl: 224.19\n",
            "Best model found in step 265000. valid ppl: 222.72, best_valid_ppl: 224.19 \n",
            "265000 steps; 135680000 examples so far; at least 64320000 examples to go; train ppl: 211.47, valid ppl: 222.72, best_valid_ppl: 222.72\n",
            "Best model found in step 270000. valid ppl: 221.43, best_valid_ppl: 222.72 \n",
            "270000 steps; 138240000 examples so far; at least 61760000 examples to go; train ppl: 209.98, valid ppl: 221.43, best_valid_ppl: 221.43\n",
            "Best model found in step 275000. valid ppl: 220.35, best_valid_ppl: 221.43 \n",
            "275000 steps; 140800000 examples so far; at least 59200000 examples to go; train ppl: 204.43, valid ppl: 220.35, best_valid_ppl: 220.35\n",
            "Best model found in step 280000. valid ppl: 219.33, best_valid_ppl: 220.35 \n",
            "280000 steps; 143360000 examples so far; at least 56640000 examples to go; train ppl: 202.77, valid ppl: 219.33, best_valid_ppl: 219.33\n",
            "Best model found in step 285000. valid ppl: 218.25, best_valid_ppl: 219.33 \n",
            "285000 steps; 145920000 examples so far; at least 54080000 examples to go; train ppl: 202.49, valid ppl: 218.25, best_valid_ppl: 218.25\n",
            "Best model found in step 290000. valid ppl: 217.01, best_valid_ppl: 218.25 \n",
            "290000 steps; 148480000 examples so far; at least 51520000 examples to go; train ppl: 201.98, valid ppl: 217.01, best_valid_ppl: 217.01\n",
            "Best model found in step 295000. valid ppl: 216.16, best_valid_ppl: 217.01 \n",
            "295000 steps; 151040000 examples so far; at least 48960000 examples to go; train ppl: 201.71, valid ppl: 216.16, best_valid_ppl: 216.16\n",
            "Best model found in step 300000. valid ppl: 215.06, best_valid_ppl: 216.16 \n",
            "300000 steps; 153600000 examples so far; at least 46400000 examples to go; train ppl: 201.51, valid ppl: 215.06, best_valid_ppl: 215.06\n",
            "Best model found in step 305000. valid ppl: 213.95, best_valid_ppl: 215.06 \n",
            "305000 steps; 156160000 examples so far; at least 43840000 examples to go; train ppl: 199.89, valid ppl: 213.95, best_valid_ppl: 213.95\n",
            "Best model found in step 310000. valid ppl: 212.58, best_valid_ppl: 213.95 \n",
            "310000 steps; 158720000 examples so far; at least 41280000 examples to go; train ppl: 200.15, valid ppl: 212.58, best_valid_ppl: 212.58\n",
            "Best model found in step 315000. valid ppl: 211.68, best_valid_ppl: 212.58 \n",
            "315000 steps; 161280000 examples so far; at least 38720000 examples to go; train ppl: 199.43, valid ppl: 211.68, best_valid_ppl: 211.68\n",
            "Best model found in step 320000. valid ppl: 210.87, best_valid_ppl: 211.68 \n",
            "320000 steps; 163840000 examples so far; at least 36160000 examples to go; train ppl: 198.83, valid ppl: 210.87, best_valid_ppl: 210.87\n",
            "Best model found in step 325000. valid ppl: 209.94, best_valid_ppl: 210.87 \n",
            "325000 steps; 166400000 examples so far; at least 33600000 examples to go; train ppl: 196.94, valid ppl: 209.94, best_valid_ppl: 209.94\n",
            "Best model found in step 330000. valid ppl: 209.12, best_valid_ppl: 209.94 \n",
            "330000 steps; 168960000 examples so far; at least 31040000 examples to go; train ppl: 191.41, valid ppl: 209.12, best_valid_ppl: 209.12\n",
            "Best model found in step 335000. valid ppl: 208.29, best_valid_ppl: 209.12 \n",
            "335000 steps; 171520000 examples so far; at least 28480000 examples to go; train ppl: 192.08, valid ppl: 208.29, best_valid_ppl: 208.29\n",
            "Best model found in step 340000. valid ppl: 207.44, best_valid_ppl: 208.29 \n",
            "340000 steps; 174080000 examples so far; at least 25920000 examples to go; train ppl: 191.40, valid ppl: 207.44, best_valid_ppl: 207.44\n",
            "Best model found in step 345000. valid ppl: 206.61, best_valid_ppl: 207.44 \n",
            "345000 steps; 176640000 examples so far; at least 23360000 examples to go; train ppl: 191.59, valid ppl: 206.61, best_valid_ppl: 206.61\n",
            "Best model found in step 350000. valid ppl: 206.00, best_valid_ppl: 206.61 \n",
            "350000 steps; 179200000 examples so far; at least 20800000 examples to go; train ppl: 191.06, valid ppl: 206.00, best_valid_ppl: 206.00\n",
            "Best model found in step 355000. valid ppl: 205.34, best_valid_ppl: 206.00 \n",
            "355000 steps; 181760000 examples so far; at least 18240000 examples to go; train ppl: 190.64, valid ppl: 205.34, best_valid_ppl: 205.34\n",
            "Best model found in step 360000. valid ppl: 204.58, best_valid_ppl: 205.34 \n",
            "360000 steps; 184320000 examples so far; at least 15680000 examples to go; train ppl: 189.86, valid ppl: 204.58, best_valid_ppl: 204.58\n",
            "Best model found in step 365000. valid ppl: 203.86, best_valid_ppl: 204.58 \n",
            "365000 steps; 186880000 examples so far; at least 13120000 examples to go; train ppl: 189.28, valid ppl: 203.86, best_valid_ppl: 203.86\n",
            "Best model found in step 370000. valid ppl: 203.00, best_valid_ppl: 203.86 \n",
            "370000 steps; 189440000 examples so far; at least 10560000 examples to go; train ppl: 189.12, valid ppl: 203.00, best_valid_ppl: 203.00\n",
            "Best model found in step 375000. valid ppl: 202.14, best_valid_ppl: 203.00 \n",
            "375000 steps; 192000000 examples so far; at least 8000000 examples to go; train ppl: 188.86, valid ppl: 202.14, best_valid_ppl: 202.14\n",
            "Best model found in step 380000. valid ppl: 201.98, best_valid_ppl: 202.14 \n",
            "380000 steps; 194560000 examples so far; at least 5440000 examples to go; train ppl: 186.59, valid ppl: 201.98, best_valid_ppl: 201.98\n",
            "Best model found in step 385000. valid ppl: 201.29, best_valid_ppl: 201.98 \n",
            "385000 steps; 197120000 examples so far; at least 2880000 examples to go; train ppl: 183.29, valid ppl: 201.29, best_valid_ppl: 201.29\n",
            "Best model found in step 390000. valid ppl: 200.93, best_valid_ppl: 201.29 \n",
            "390000 steps; 199680000 examples so far; at least 320000 examples to go; train ppl: 183.07, valid ppl: 200.93, best_valid_ppl: 200.93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliação final no dataset de teste\n",
        "\n",
        "\n",
        "Bonus: o modelo com menor perplexidade no dataset de testes ganhará 0.5 ponto na nota final."
      ],
      "metadata": {
        "id": "VgdNymJdNPXP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxN5YytzZ7Tn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0bf80f2-98ce-400f-f256-de617f885d01"
      },
      "source": [
        "best_model = 'best_model.pt'\n",
        "model.load_state_dict(torch.load(best_model))\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_ppl = np.exp(np.average([\n",
        "        validation_step(input.to(device), target.to(device))\n",
        "        for input, target in test_loader\n",
        "    ]))\n",
        "\n",
        "print(f'test perplexity: {test_ppl}')\n",
        "run['test/perplexity'].log(test_ppl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test perplexity: 184.53435886474884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run.stop()\n"
      ],
      "metadata": {
        "id": "IM4dj6G_Hhi2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1bedb9e-2816-4a92-fa7b-4f7eda2e17d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shutting down background jobs, please wait a moment...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Waiting for the remaining 4 operations to synchronize with Neptune. Do not kill this process.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All 4 operations synced, thanks for waiting!\n",
            "Explore the metadata in the Neptune app:\n",
            "https://app.neptune.ai/leolellisr/dl-ia025/e/DLIA-56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teste seu modelo com uma sentença\n",
        "\n",
        "Escolha uma sentença gerada pelo modelo que ache interessante."
      ],
      "metadata": {
        "id": "BHvEs8mPszy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'Eu gosto de comer pizza pois me faz'\n",
        "max_output_tokens = 10\n",
        "\n",
        "for _ in range(max_output_tokens):\n",
        "    input_ids = tokenize(text=prompt, tokenizer=tokenizer)\n",
        "    input_ids_truncated = input_ids[-context_size:]  # Usamos apenas os últimos <context_size> tokens como entrada para o modelo.\n",
        "    logits = model(torch.LongTensor([input_ids_truncated]).to(device))\n",
        "    # Ao usarmos o argmax, a saída do modelo em cada passo é token de maior probabilidade.\n",
        "    # Isso se chama decodificação gulosa (greedy decoding).\n",
        "    predicted_id = torch.argmax(logits).item()\n",
        "    input_ids += [predicted_id]  # Concatenamos a entrada com o token escolhido nesse passo.\n",
        "    prompt = tokenizer.decode(input_ids)\n",
        "    print(prompt)"
      ],
      "metadata": {
        "id": "-CFElf4tsytW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a0b8603-3a73-4432-8b02-20e10dfa50ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eu gosto de comer pizza pois me faz com\n",
            "Eu gosto de comer pizza pois me faz com que\n",
            "Eu gosto de comer pizza pois me faz com que o\n",
            "Eu gosto de comer pizza pois me faz com que o meu\n",
            "Eu gosto de comer pizza pois me faz com que o meu pai\n",
            "Eu gosto de comer pizza pois me faz com que o meu pai,\n",
            "Eu gosto de comer pizza pois me faz com que o meu pai, e\n",
            "Eu gosto de comer pizza pois me faz com que o meu pai, e o\n",
            "Eu gosto de comer pizza pois me faz com que o meu pai, e o que\n",
            "Eu gosto de comer pizza pois me faz com que o meu pai, e o que é\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt ='Ouviram do Ipiranga às margens'\n",
        "max_output_tokens = 10\n",
        "\n",
        "for _ in range(max_output_tokens):\n",
        "    input_ids = tokenize(text=prompt, tokenizer=tokenizer)\n",
        "    input_ids_truncated = input_ids[-context_size:]  # Usamos apenas os últimos <context_size> tokens como entrada para o modelo.\n",
        "    logits = model(torch.LongTensor([input_ids_truncated]).to(device))\n",
        "    # Ao usarmos o argmax, a saída do modelo em cada passo é token de maior probabilidade.\n",
        "    # Isso se chama decodificação gulosa (greedy decoding).\n",
        "    predicted_id = torch.argmax(logits).item()\n",
        "    input_ids += [predicted_id]  # Concatenamos a entrada com o token escolhido nesse passo.\n",
        "    prompt = tokenizer.decode(input_ids)\n",
        "    print(prompt)"
      ],
      "metadata": {
        "id": "TEiNZ1311Cl1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2ab3e48-1a6e-458d-eaa5-751af4b04cd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ouviram do Ipiranga às margens do\n",
            "Ouviram do Ipiranga às margens do Rio\n",
            "Ouviram do Ipiranga às margens do Rio de\n",
            "Ouviram do Ipiranga às margens do Rio de Janeiro\n",
            "Ouviram do Ipiranga às margens do Rio de Janeiro,\n",
            "Ouviram do Ipiranga às margens do Rio de Janeiro, o\n",
            "Ouviram do Ipiranga às margens do Rio de Janeiro, o que\n",
            "Ouviram do Ipiranga às margens do Rio de Janeiro, o que é\n",
            "Ouviram do Ipiranga às margens do Rio de Janeiro, o que é o\n",
            "Ouviram do Ipiranga às margens do Rio de Janeiro, o que é o caso\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt ='A galinha atravessou a rua para chegar'\n",
        "max_output_tokens = 10\n",
        "\n",
        "for _ in range(max_output_tokens):\n",
        "    input_ids = tokenize(text=prompt, tokenizer=tokenizer)\n",
        "    input_ids_truncated = input_ids[-context_size:]  # Usamos apenas os últimos <context_size> tokens como entrada para o modelo.\n",
        "    logits = model(torch.LongTensor([input_ids_truncated]).to(device))\n",
        "    # Ao usarmos o argmax, a saída do modelo em cada passo é token de maior probabilidade.\n",
        "    # Isso se chama decodificação gulosa (greedy decoding).\n",
        "    predicted_id = torch.argmax(logits).item()\n",
        "    input_ids += [predicted_id]  # Concatenamos a entrada com o token escolhido nesse passo.\n",
        "    prompt = tokenizer.decode(input_ids)\n",
        "    print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vh6dytMueYjU",
        "outputId": "f1100dec-8ab2-48cf-9870-160b990b8d4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A galinha atravessou a rua para chegar a\n",
            "A galinha atravessou a rua para chegar a sua\n",
            "A galinha atravessou a rua para chegar a sua vida\n",
            "A galinha atravessou a rua para chegar a sua vida.\n",
            "A galinha atravessou a rua para chegar a sua vida. O\n",
            "A galinha atravessou a rua para chegar a sua vida. O que\n",
            "A galinha atravessou a rua para chegar a sua vida. O que é\n",
            "A galinha atravessou a rua para chegar a sua vida. O que é o\n",
            "A galinha atravessou a rua para chegar a sua vida. O que é o que\n",
            "A galinha atravessou a rua para chegar a sua vida. O que é o que é\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt ='Ouça com cuidado, o segredo para a felicidade é'\n",
        "max_output_tokens = 10\n",
        "\n",
        "for _ in range(max_output_tokens):\n",
        "    input_ids = tokenize(text=prompt, tokenizer=tokenizer)\n",
        "    input_ids_truncated = input_ids[-context_size:]  # Usamos apenas os últimos <context_size> tokens como entrada para o modelo.\n",
        "    logits = model(torch.LongTensor([input_ids_truncated]).to(device))\n",
        "    # Ao usarmos o argmax, a saída do modelo em cada passo é token de maior probabilidade.\n",
        "    # Isso se chama decodificação gulosa (greedy decoding).\n",
        "    predicted_id = torch.argmax(logits).item()\n",
        "    input_ids += [predicted_id]  # Concatenamos a entrada com o token escolhido nesse passo.\n",
        "    prompt = tokenizer.decode(input_ids)\n",
        "    print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXiQRDQTeJ0Y",
        "outputId": "9087caa7-5f96-4775-da56-57bddf661819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ouça com cuidado, o segredo para a felicidade é a\n",
            "Ouça com cuidado, o segredo para a felicidade é a sua\n",
            "Ouça com cuidado, o segredo para a felicidade é a sua vida\n",
            "Ouça com cuidado, o segredo para a felicidade é a sua vida.\n",
            "Ouça com cuidado, o segredo para a felicidade é a sua vida. O\n",
            "Ouça com cuidado, o segredo para a felicidade é a sua vida. O que\n",
            "Ouça com cuidado, o segredo para a felicidade é a sua vida. O que é\n",
            "Ouça com cuidado, o segredo para a felicidade é a sua vida. O que é o\n",
            "Ouça com cuidado, o segredo para a felicidade é a sua vida. O que é o que\n",
            "Ouça com cuidado, o segredo para a felicidade é a sua vida. O que é o que é\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt ='Desejo a todas as inimigas vida longa'\n",
        "max_output_tokens = 10\n",
        "\n",
        "for _ in range(max_output_tokens):\n",
        "    input_ids = tokenize(text=prompt, tokenizer=tokenizer)\n",
        "    input_ids_truncated = input_ids[-context_size:]  # Usamos apenas os últimos <context_size> tokens como entrada para o modelo.\n",
        "    logits = model(torch.LongTensor([input_ids_truncated]).to(device))\n",
        "    # Ao usarmos o argmax, a saída do modelo em cada passo é token de maior probabilidade.\n",
        "    # Isso se chama decodificação gulosa (greedy decoding).\n",
        "    predicted_id = torch.argmax(logits).item()\n",
        "    input_ids += [predicted_id]  # Concatenamos a entrada com o token escolhido nesse passo.\n",
        "    prompt = tokenizer.decode(input_ids)\n",
        "    print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQe_NdxSepJl",
        "outputId": "a2d6bac1-11b9-4360-fc33-6be3a9d98eb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Desejo a todas as inimigas vida longa que\n",
            "Desejo a todas as inimigas vida longa que,\n",
            "Desejo a todas as inimigas vida longa que, em\n",
            "Desejo a todas as inimigas vida longa que, em que\n",
            "Desejo a todas as inimigas vida longa que, em que o\n",
            "Desejo a todas as inimigas vida longa que, em que o Brasil\n",
            "Desejo a todas as inimigas vida longa que, em que o Brasil é\n",
            "Desejo a todas as inimigas vida longa que, em que o Brasil é o\n",
            "Desejo a todas as inimigas vida longa que, em que o Brasil é o que\n",
            "Desejo a todas as inimigas vida longa que, em que o Brasil é o que se\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mn2UuHvOe_vQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Mw1OyXGCe_nj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}