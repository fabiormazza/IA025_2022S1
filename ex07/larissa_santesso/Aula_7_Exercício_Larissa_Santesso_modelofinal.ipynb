{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aula_7_Exercício_Larissa_Santesso_modelofinal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08543aa0afa14db48f039bcbd2aa116d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81edd810ca0a4a2bb282eee8067b1086",
              "IPY_MODEL_093c958df38e417a9037484d2e214791",
              "IPY_MODEL_ccab89c37fb443cd88772346e04b48a7"
            ],
            "layout": "IPY_MODEL_7d65d143963b437ba8787c9a463e4376"
          }
        },
        "81edd810ca0a4a2bb282eee8067b1086": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcc77b0b16fb4b57831b3af42c397e9a",
            "placeholder": "​",
            "style": "IPY_MODEL_ca903719cbb744a590451e4aafda4157",
            "value": "Downloading: 100%"
          }
        },
        "093c958df38e417a9037484d2e214791": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64b104e28e7f47309c6e1dd54b9d377a",
            "max": 209528,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0212a3a7c55495dbdce4e963b188be0",
            "value": 209528
          }
        },
        "ccab89c37fb443cd88772346e04b48a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_393630ea007e4f589693830f6be2c6f6",
            "placeholder": "​",
            "style": "IPY_MODEL_379f188a07d84844bc16646ce40b801e",
            "value": " 205k/205k [00:00&lt;00:00, 1.66MB/s]"
          }
        },
        "7d65d143963b437ba8787c9a463e4376": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcc77b0b16fb4b57831b3af42c397e9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca903719cbb744a590451e4aafda4157": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64b104e28e7f47309c6e1dd54b9d377a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0212a3a7c55495dbdce4e963b188be0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "393630ea007e4f589693830f6be2c6f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "379f188a07d84844bc16646ce40b801e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26f6816b5f41414aa48e87f64faca5b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ff95ae6799a49a9a03c822ee78c2de3",
              "IPY_MODEL_6d0f1f1457d74a7ca702d71adfd53e8b",
              "IPY_MODEL_9f179269877347bdaffa50b9d78fc134"
            ],
            "layout": "IPY_MODEL_868d0b15dda64c0d99843e6ff9347e36"
          }
        },
        "1ff95ae6799a49a9a03c822ee78c2de3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90ffd27a227b407298e5f2206b2bf95d",
            "placeholder": "​",
            "style": "IPY_MODEL_5c6df14bbd11450b844b9c2e34030c86",
            "value": "Downloading: 100%"
          }
        },
        "6d0f1f1457d74a7ca702d71adfd53e8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_600fd2b5b5424b92998b191dc07ba116",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_297493a03eae487892760fdbe2794c8d",
            "value": 2
          }
        },
        "9f179269877347bdaffa50b9d78fc134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6921d78a75b444efb3a0da4f334b5157",
            "placeholder": "​",
            "style": "IPY_MODEL_607ecc00769c4b3ca52458f2a837f413",
            "value": " 2.00/2.00 [00:00&lt;00:00, 50.1B/s]"
          }
        },
        "868d0b15dda64c0d99843e6ff9347e36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90ffd27a227b407298e5f2206b2bf95d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c6df14bbd11450b844b9c2e34030c86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "600fd2b5b5424b92998b191dc07ba116": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "297493a03eae487892760fdbe2794c8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6921d78a75b444efb3a0da4f334b5157": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "607ecc00769c4b3ca52458f2a837f413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4c0601ad97e411e824e8937ffad1b78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_06d8f46a144e4a7da7e9a5a28278e196",
              "IPY_MODEL_fcd11cc3cd1042e6b03c8183ae720a14",
              "IPY_MODEL_23d495e9f9cf491d8ebd13f6e0f4c543"
            ],
            "layout": "IPY_MODEL_c2c6620988114a58ac6048c1924a98a2"
          }
        },
        "06d8f46a144e4a7da7e9a5a28278e196": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_360974ebfb0448ef8c7e15557adaa4ec",
            "placeholder": "​",
            "style": "IPY_MODEL_f130730c4c8148b199dca1948c35aeb6",
            "value": "Downloading: 100%"
          }
        },
        "fcd11cc3cd1042e6b03c8183ae720a14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1913e1b50194b31b7ed6c586adec352",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_882a97a8bdca4452b7dc4616e8593488",
            "value": 112
          }
        },
        "23d495e9f9cf491d8ebd13f6e0f4c543": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e155b582370541d8a616e4c9769e74f2",
            "placeholder": "​",
            "style": "IPY_MODEL_b178a4c99b0043a09ed72ad136ddfdae",
            "value": " 112/112 [00:00&lt;00:00, 1.95kB/s]"
          }
        },
        "c2c6620988114a58ac6048c1924a98a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "360974ebfb0448ef8c7e15557adaa4ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f130730c4c8148b199dca1948c35aeb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1913e1b50194b31b7ed6c586adec352": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "882a97a8bdca4452b7dc4616e8593488": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e155b582370541d8a616e4c9769e74f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b178a4c99b0043a09ed72ad136ddfdae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf30f7dfe4f141c4871b4d2cf2fb6af9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb6e5b32b4514904b6baed843f006a01",
              "IPY_MODEL_30d9721bece648c8888245f8b7dc4a0c",
              "IPY_MODEL_ae749e2ef7b443df8ee3d5a27f2f82f4"
            ],
            "layout": "IPY_MODEL_3b82f4ecbfae4163ac8686694dfca8a6"
          }
        },
        "eb6e5b32b4514904b6baed843f006a01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7c823f5c93048cdbfa512c5b8361dc9",
            "placeholder": "​",
            "style": "IPY_MODEL_33146c14e26444c1a21d4568fd80389f",
            "value": "Downloading: 100%"
          }
        },
        "30d9721bece648c8888245f8b7dc4a0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b20e74593c904234bc038cc70b320ef9",
            "max": 43,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff7ecd2758984756a0ca851d4b89b0fd",
            "value": 43
          }
        },
        "ae749e2ef7b443df8ee3d5a27f2f82f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b4f172df0ae4f6887e8af897f47994a",
            "placeholder": "​",
            "style": "IPY_MODEL_4859075dcbdc4a0e9e808feb82666553",
            "value": " 43.0/43.0 [00:00&lt;00:00, 1.09kB/s]"
          }
        },
        "3b82f4ecbfae4163ac8686694dfca8a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7c823f5c93048cdbfa512c5b8361dc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33146c14e26444c1a21d4568fd80389f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b20e74593c904234bc038cc70b320ef9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff7ecd2758984756a0ca851d4b89b0fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b4f172df0ae4f6887e8af897f47994a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4859075dcbdc4a0e9e808feb82666553": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b343204921042de9be7eae77d2c0240": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa31393368004a34b19d4ba85ff617dd",
              "IPY_MODEL_c17fc3102d7a4478a6baf2b4de114d30",
              "IPY_MODEL_66a51936dee94b57b79b25fe76cb9a0e"
            ],
            "layout": "IPY_MODEL_91207d0552d34a2da95c4ad3420ba0b2"
          }
        },
        "fa31393368004a34b19d4ba85ff617dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6eb914701df647b195ab45a7026f6a9d",
            "placeholder": "​",
            "style": "IPY_MODEL_26d310b135bb43ea8346850fb42c20cc",
            "value": "Downloading: 100%"
          }
        },
        "c17fc3102d7a4478a6baf2b4de114d30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7205649952a64e3f9644efa089622f1b",
            "max": 647,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fcf25224aa894317be8f12fd4f88ac3b",
            "value": 647
          }
        },
        "66a51936dee94b57b79b25fe76cb9a0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0d04551e98c4d8ab2c9f3cb702fd489",
            "placeholder": "​",
            "style": "IPY_MODEL_c94e4fcc0c5b47c4afbc4a32b23d3fb8",
            "value": " 647/647 [00:00&lt;00:00, 13.0kB/s]"
          }
        },
        "91207d0552d34a2da95c4ad3420ba0b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6eb914701df647b195ab45a7026f6a9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26d310b135bb43ea8346850fb42c20cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7205649952a64e3f9644efa089622f1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcf25224aa894317be8f12fd4f88ac3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0d04551e98c4d8ab2c9f3cb702fd489": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c94e4fcc0c5b47c4afbc4a32b23d3fb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unicamp-dl/IA025_2022S1/blob/main/ex07/larissa_santesso/Aula_7_Exerc%C3%ADcio_Larissa_Santesso_modelofinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nome = \"Larissa Antonelli Santesso\"\n",
        "print(f'Meu nome é {nome}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOdQB41_4ZxG",
        "outputId": "165b7319-f2ba-4bf1-e779-bb27ebf9fbd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meu nome é Larissa Antonelli Santesso\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IbuChoAPMEn"
      },
      "source": [
        "#  Exercício: Modelo de Linguagem (Bengio 2003) - MLP + Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_DBb0-Klwf2"
      },
      "source": [
        "Neste exercício iremos treinar uma rede neural simples para prever a proxima palavra de um texto, data as palavras anteriores como entrada. Esta tarefa é chamada de \"Modelagem da Língua\".\n",
        "\n",
        "Este dataset já possui um tamanho razoável e é bem provável que você vai precisar rodar seus experimentos com GPU.\n",
        "\n",
        "Alguns conselhos úteis:\n",
        "- **ATENÇÃO:** o dataset é bem grande. Não dê comando de imprimí-lo.\n",
        "- Durante a depuração, faça seu dataset ficar bem pequeno, para que a depuração seja mais rápida e não precise de GPU. Somente ligue a GPU quando o seu laço de treinamento já está funcionando\n",
        "- Não deixe para fazer esse exercício na véspera. Ele é trabalhoso."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# iremos utilizar a biblioteca dos transformers para ter acesso ao tokenizador do BERT.\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "3twP0YJC4jmJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ebb8132-ec03-40d6-943d-b781bd165cbc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 54.9 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 40.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "zaBXst1SKwJ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94a256e6-f147-41a9-fedf-54a69587a420"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnyhJZtTRNMx"
      },
      "source": [
        "## Importação dos pacotes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlIOVCajPWcU"
      },
      "source": [
        "import collections\n",
        "import itertools\n",
        "import functools\n",
        "import math\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm_notebook\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check which GPU we are using\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "w9f3PfifAwpU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "433bdf03-4e89-441f-edcf-579a5f311462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon May 16 22:43:52 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check which GPU we are using (2nd run)\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "wlLv9aIkopx9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9f763a4-100b-4e38-aa7c-e7160e1f3d8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue May 17 17:21:37 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available(): \n",
        "   dev = \"cuda:0\"\n",
        "else: \n",
        "   dev = \"cpu\"\n",
        "device = torch.device(dev)\n",
        "print('Using {}'.format(device))"
      ],
      "metadata": {
        "id": "whTCe2i7AtoV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f3bb64f-5e8f-4f3d-f62b-91f14405e955"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(123)\n",
        "np.random.seed(123)\n",
        "torch.manual_seed(123)\n",
        "torch.cuda.manual_seed(123)"
      ],
      "metadata": {
        "id": "GEU5yWmbbl82"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZfxgV2DUk58"
      },
      "source": [
        "## Implementação do MyDataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_xhKm1EZ3bQ"
      },
      "source": [
        "from typing import List\n",
        "\n",
        "\n",
        "def tokenize(text: str, tokenizer):\n",
        "    return tokenizer(text, return_tensors=None, add_special_tokens=False).input_ids\n",
        "\n",
        "\n",
        "class MyDataset():\n",
        "    def __init__(self, texts: List[str], tokenizer, context_size: int):\n",
        "        self.tokensIds_n = []\n",
        "        self.y = []\n",
        "        for text in texts:\n",
        "            tokens_ids = tokenize(text, tokenizer)\n",
        "            for i in range(len(tokens_ids)-context_size):\n",
        "                self.tokensIds_n.append(tokens_ids[i:i+context_size])      \n",
        "                self.y.append(tokens_ids[i+context_size])\n",
        "                \n",
        "    def __len__(self):  \n",
        "        return len(self.tokensIds_n)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        return torch.tensor(self.tokensIds_n[idx]).long(), torch.tensor(self.y[idx]).long()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teste se sua implementação do MyDataset está correta"
      ],
      "metadata": {
        "id": "wew-gFbWeBTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
        "\n",
        "dummy_texts = ['Eu gosto de correr', 'Ela gosta muito de comer pizza']\n",
        "\n",
        "dummy_dataset = MyDataset(texts=dummy_texts, tokenizer=tokenizer, context_size=3)\n",
        "dummy_loader = DataLoader(dummy_dataset, batch_size=6, shuffle=False)\n",
        "assert len(dummy_dataset) == 5\n",
        "print('passou no assert de tamanho do dataset')\n",
        "\n",
        "first_batch_input, first_batch_target = next(iter(dummy_loader))\n",
        "\n",
        "correct_first_batch_input = torch.LongTensor(\n",
        "    [[ 3396, 10303,   125],\n",
        "     [ 1660,  5971,   785],\n",
        "     [ 5971,   785,   125],\n",
        "     [  785,   125,  1847],\n",
        "     [  125,  1847, 13779]])\n",
        "\n",
        "correct_first_batch_target = torch.LongTensor([13239,   125,  1847, 13779, 15616])\n",
        "\n",
        "assert torch.equal(first_batch_input, correct_first_batch_input)\n",
        "print('Passou no assert de input')\n",
        "assert torch.equal(first_batch_target, correct_first_batch_target)\n",
        "print('Passou no assert de target')"
      ],
      "metadata": {
        "id": "8r7jBFFUeApe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229,
          "referenced_widgets": [
            "08543aa0afa14db48f039bcbd2aa116d",
            "81edd810ca0a4a2bb282eee8067b1086",
            "093c958df38e417a9037484d2e214791",
            "ccab89c37fb443cd88772346e04b48a7",
            "7d65d143963b437ba8787c9a463e4376",
            "fcc77b0b16fb4b57831b3af42c397e9a",
            "ca903719cbb744a590451e4aafda4157",
            "64b104e28e7f47309c6e1dd54b9d377a",
            "d0212a3a7c55495dbdce4e963b188be0",
            "393630ea007e4f589693830f6be2c6f6",
            "379f188a07d84844bc16646ce40b801e",
            "26f6816b5f41414aa48e87f64faca5b2",
            "1ff95ae6799a49a9a03c822ee78c2de3",
            "6d0f1f1457d74a7ca702d71adfd53e8b",
            "9f179269877347bdaffa50b9d78fc134",
            "868d0b15dda64c0d99843e6ff9347e36",
            "90ffd27a227b407298e5f2206b2bf95d",
            "5c6df14bbd11450b844b9c2e34030c86",
            "600fd2b5b5424b92998b191dc07ba116",
            "297493a03eae487892760fdbe2794c8d",
            "6921d78a75b444efb3a0da4f334b5157",
            "607ecc00769c4b3ca52458f2a837f413",
            "f4c0601ad97e411e824e8937ffad1b78",
            "06d8f46a144e4a7da7e9a5a28278e196",
            "fcd11cc3cd1042e6b03c8183ae720a14",
            "23d495e9f9cf491d8ebd13f6e0f4c543",
            "c2c6620988114a58ac6048c1924a98a2",
            "360974ebfb0448ef8c7e15557adaa4ec",
            "f130730c4c8148b199dca1948c35aeb6",
            "b1913e1b50194b31b7ed6c586adec352",
            "882a97a8bdca4452b7dc4616e8593488",
            "e155b582370541d8a616e4c9769e74f2",
            "b178a4c99b0043a09ed72ad136ddfdae",
            "cf30f7dfe4f141c4871b4d2cf2fb6af9",
            "eb6e5b32b4514904b6baed843f006a01",
            "30d9721bece648c8888245f8b7dc4a0c",
            "ae749e2ef7b443df8ee3d5a27f2f82f4",
            "3b82f4ecbfae4163ac8686694dfca8a6",
            "b7c823f5c93048cdbfa512c5b8361dc9",
            "33146c14e26444c1a21d4568fd80389f",
            "b20e74593c904234bc038cc70b320ef9",
            "ff7ecd2758984756a0ca851d4b89b0fd",
            "0b4f172df0ae4f6887e8af897f47994a",
            "4859075dcbdc4a0e9e808feb82666553",
            "1b343204921042de9be7eae77d2c0240",
            "fa31393368004a34b19d4ba85ff617dd",
            "c17fc3102d7a4478a6baf2b4de114d30",
            "66a51936dee94b57b79b25fe76cb9a0e",
            "91207d0552d34a2da95c4ad3420ba0b2",
            "6eb914701df647b195ab45a7026f6a9d",
            "26d310b135bb43ea8346850fb42c20cc",
            "7205649952a64e3f9644efa089622f1b",
            "fcf25224aa894317be8f12fd4f88ac3b",
            "a0d04551e98c4d8ab2c9f3cb702fd489",
            "c94e4fcc0c5b47c4afbc4a32b23d3fb8"
          ]
        },
        "outputId": "187fb3a5-374f-491e-f8b1-0b5c8eedfda6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/205k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08543aa0afa14db48f039bcbd2aa116d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26f6816b5f41414aa48e87f64faca5b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4c0601ad97e411e824e8937ffad1b78"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/43.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf30f7dfe4f141c4871b4d2cf2fb6af9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/647 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b343204921042de9be7eae77d2c0240"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "passou no assert de tamanho do dataset\n",
            "Passou no assert de input\n",
            "Passou no assert de target\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_batch_input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ri-KQGUqtb2p",
        "outputId": "264dbffd-a0ed-48e5-b2cd-cc041f9b3513"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 3396, 10303,   125],\n",
              "        [ 1660,  5971,   785],\n",
              "        [ 5971,   785,   125],\n",
              "        [  785,   125,  1847],\n",
              "        [  125,  1847, 13779]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_batch_target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxxR-PDpthdu",
        "outputId": "a97c5e01-0728-4da6-bf52-5b9c415e6f9f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([13239,   125,  1847, 13779, 15616])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LfrHHouleJ0"
      },
      "source": [
        "# Carregamento do dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2vFWjsSkmop"
      },
      "source": [
        "Iremos usar uma pequena amostra do dataset [BrWaC](https://www.inf.ufrgs.br/pln/wiki/index.php?title=BrWaC) para treinar e avaliar nosso modelo de linguagem."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://storage.googleapis.com/unicamp-dl/ia025a_2022s1/aula7/sample_brwac.txt"
      ],
      "metadata": {
        "id": "vGlN1WqrXPA6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b274d473-ad22-4574-bc5a-d190a2ab345b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-18 21:55:44--  https://storage.googleapis.com/unicamp-dl/ia025a_2022s1/aula7/sample_brwac.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.213.128, 173.194.210.128, 173.194.216.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.213.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 123983611 (118M) [text/plain]\n",
            "Saving to: ‘sample_brwac.txt’\n",
            "\n",
            "sample_brwac.txt    100%[===================>] 118.24M   136MB/s    in 0.9s    \n",
            "\n",
            "2022-05-18 21:55:45 (136 MB/s) - ‘sample_brwac.txt’ saved [123983611/123983611]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "context_size = 9\n",
        "\n",
        "valid_examples = 100\n",
        "test_examples = 100\n",
        "texts = open('sample_brwac.txt').readlines()\n",
        "\n",
        "#print('Truncating for debugging purposes.')\n",
        "#texts = texts[:500]  \n",
        "\n",
        "training_texts = texts[:-(valid_examples + test_examples)]\n",
        "valid_texts = texts[-(valid_examples + test_examples):-test_examples]\n",
        "test_texts = texts[-test_examples:]\n",
        "\n",
        "training_dataset = MyDataset(texts=training_texts, tokenizer=tokenizer, context_size=context_size)\n",
        "valid_dataset = MyDataset(texts=valid_texts, tokenizer=tokenizer, context_size=context_size)\n",
        "test_dataset = MyDataset(texts=test_texts, tokenizer=tokenizer, context_size=context_size)"
      ],
      "metadata": {
        "id": "gxa_4gmiA-wE"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'training examples: {len(training_dataset)}')\n",
        "print(f'valid examples: {len(valid_dataset)}')\n",
        "print(f'test examples: {len(test_dataset)}')"
      ],
      "metadata": {
        "id": "KCSGJ5m7py4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26fdf88f-4348-4a20-9ded-7c6a183b3baa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training examples: 27675945\n",
            "valid examples: 82070\n",
            "test examples: 166726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGaAjYDfWdd1"
      },
      "source": [
        "class LanguageModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, context_size, embedding_dim, hidden_size):\n",
        "        \"\"\"\n",
        "        Implements the Neural Language Model proposed by Bengio et al.\"\n",
        "\n",
        "        Args:\n",
        "            vocab_size (int): Size of the input vocabulary.\n",
        "            context_size (int): Size of the sequence to consider as context for prediction.\n",
        "            embedding_dim (int): Dimension of the embedding layer for each word in the context.\n",
        "            hidden_size (int): Size of the hidden layer.\n",
        "        \"\"\"\n",
        "        super(LanguageModel, self).__init__()\n",
        "\n",
        "        self.context_size = context_size\n",
        "        self.embeddings_dim = embedding_dim\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear1 = nn.Linear(self.context_size*self.embeddings_dim, hidden_size)\n",
        "        self.linear2 = nn.Linear(hidden_size, hidden_size*2) # adicionei uma camada a mais que o modelo original de Bengio\n",
        "        self.linear3 = nn.Linear(hidden_size*2, vocab_size, bias=False)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            inputs is a LongTensor of shape (batch_size, context_size)\n",
        "        \"\"\"\n",
        "        out =  self.embeddings(inputs).view(-1,self.context_size*self.embeddings_dim)\n",
        "        out = self.linear1(out)\n",
        "        out = self.relu1(out)\n",
        "        out = self.linear2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.linear3(out)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teste o modelo com um exemplo"
      ],
      "metadata": {
        "id": "Rm6_PTH2i98e"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwnxfZlrZoT_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6f36147-29e8-466f-c9e2-1241204f6d3c"
      },
      "source": [
        "model = LanguageModel(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    context_size=context_size,\n",
        "    embedding_dim=128,\n",
        "    hidden_size=256,\n",
        ").to(device)\n",
        "\n",
        "sample_train, _ = next(iter(DataLoader(training_dataset)))\n",
        "sample_train_gpu = sample_train.to(device)\n",
        "model(sample_train_gpu).shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 29794])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3Vh6B-VkA01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96f32efc-1574-497f-d8b4-692b821d738f"
      },
      "source": [
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'Number of model parameters: {num_params}')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of model parameters: 19494912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assert da Perplexidade\n"
      ],
      "metadata": {
        "id": "8nhbUVsYnVAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perplexity(logits, target):\n",
        "    \"\"\"\n",
        "    Computes the perplexity.\n",
        "\n",
        "    Args:\n",
        "        logits: a FloatTensor of shape (batch_size, vocab_size)\n",
        "        target: a LongTensor of shape (batch_size,)\n",
        "\n",
        "    Returns:\n",
        "        A float corresponding to the perplexity.\n",
        "    \"\"\"\n",
        "    crossentropy =  nn.functional.cross_entropy(logits,target)\n",
        "    p = torch.exp(crossentropy)\n",
        "    #p = np.exp(crossentropy.item())\n",
        "\n",
        "    return p\n",
        "\n",
        "\n",
        "n_examples = 1000\n",
        "\n",
        "sample_train, target_token_ids = next(iter(DataLoader(training_dataset, batch_size=n_examples)))\n",
        "sample_train_gpu = sample_train.to(device)\n",
        "target_token_ids = target_token_ids.to(device)\n",
        "logits = model(sample_train_gpu)\n",
        "\n",
        "my_perplexity = perplexity(logits=logits, target=target_token_ids)\n",
        "\n",
        "print(f'my perplexity:              {int(my_perplexity)}')\n",
        "print(f'correct initial perplexity: {tokenizer.vocab_size}')\n",
        "\n",
        "assert math.isclose(my_perplexity, tokenizer.vocab_size, abs_tol=2000)\n",
        "print('Passou o no assert da perplexidade')"
      ],
      "metadata": {
        "id": "gbMP8VAUncfX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8a2ea9b-1441-4fdb-9c98-a2a794bee697"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my perplexity:              29788\n",
            "correct initial perplexity: 29794\n",
            "Passou o no assert da perplexidade\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Laço de Treinamento e Validação"
      ],
      "metadata": {
        "id": "KiJtrsqPnE_l"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIMSaY-UUGUE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6ace392-8a66-4003-e8a5-83acff037a7e"
      },
      "source": [
        "max_examples = 200_000_000\n",
        "eval_every_steps = 5000\n",
        "lr = 3e-5\n",
        "compare=1e10\n",
        "\n",
        "model = LanguageModel(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    context_size=context_size,\n",
        "    embedding_dim=128,\n",
        "    hidden_size=256,\n",
        ").to(device)\n",
        "\n",
        "train_loader = DataLoader(training_dataset, batch_size=1024, shuffle=True, drop_last=True)\n",
        "validation_loader = DataLoader(valid_dataset, batch_size=1024)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "def train_step(input, target):\n",
        "    model.train()\n",
        "    model.zero_grad()\n",
        "\n",
        "    logits = model(input.to(device))\n",
        "    loss = nn.functional.cross_entropy(logits, target.to(device))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "def validation_step(input, target):\n",
        "    model.eval()\n",
        "    logits = model(input)\n",
        "    loss = nn.functional.cross_entropy(logits, target)\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "train_losses = []\n",
        "n_examples = 0\n",
        "step = 0\n",
        "while n_examples < max_examples:\n",
        "    for input, target in train_loader:\n",
        "        loss = train_step(input.to(device), target.to(device)) \n",
        "        train_losses.append(loss)\n",
        "        \n",
        "        if step % eval_every_steps == 0:\n",
        "            train_ppl = np.exp(np.average(train_losses))\n",
        "\n",
        "            with torch.no_grad():\n",
        "                valid_ppl = np.exp(np.average([\n",
        "                    validation_step(input.to(device), target.to(device))\n",
        "                    for input, target in validation_loader]))\n",
        "                \n",
        "                if valid_ppl<compare:\n",
        "                    compare=valid_ppl\n",
        "                    torch.save(model, \"gdrive/MyDrive/Colab Notebooks/\"+\"model03.pt\")\n",
        "                    with open(\"gdrive/MyDrive/Colab Notebooks/\"+\"valid_ppl_model03.txt\", 'w') as f:\n",
        "                        f.write(\"%s\\n\" % valid_ppl)\n",
        "                    f.close()\n",
        "\n",
        "            print(f'{step} steps; {n_examples} examples so far; train ppl: {train_ppl:.2f}, valid ppl: {valid_ppl:.2f}')\n",
        "            train_losses = []\n",
        "\n",
        "        n_examples += len(input)  # Increment of batch size\n",
        "        step += 1\n",
        "        if n_examples >= max_examples:\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 steps; 0 examples so far; train ppl: 29601.35, valid ppl: 29523.83\n",
            "5000 steps; 5120000 examples so far; train ppl: 1643.86, valid ppl: 1232.53\n",
            "10000 steps; 10240000 examples so far; train ppl: 1032.56, valid ppl: 888.63\n",
            "15000 steps; 15360000 examples so far; train ppl: 807.39, valid ppl: 742.06\n",
            "20000 steps; 20480000 examples so far; train ppl: 694.06, valid ppl: 649.06\n",
            "25000 steps; 25600000 examples so far; train ppl: 614.35, valid ppl: 577.70\n",
            "30000 steps; 30720000 examples so far; train ppl: 546.86, valid ppl: 522.68\n",
            "35000 steps; 35840000 examples so far; train ppl: 495.75, valid ppl: 478.36\n",
            "40000 steps; 40960000 examples so far; train ppl: 453.89, valid ppl: 440.98\n",
            "45000 steps; 46080000 examples so far; train ppl: 421.97, valid ppl: 409.35\n",
            "50000 steps; 51200000 examples so far; train ppl: 392.51, valid ppl: 382.76\n",
            "55000 steps; 56320000 examples so far; train ppl: 368.45, valid ppl: 361.60\n",
            "60000 steps; 61440000 examples so far; train ppl: 344.28, valid ppl: 343.50\n",
            "65000 steps; 66560000 examples so far; train ppl: 328.34, valid ppl: 326.55\n",
            "70000 steps; 71680000 examples so far; train ppl: 313.54, valid ppl: 313.04\n",
            "75000 steps; 76800000 examples so far; train ppl: 301.98, valid ppl: 300.81\n",
            "80000 steps; 81920000 examples so far; train ppl: 291.16, valid ppl: 289.56\n",
            "85000 steps; 87040000 examples so far; train ppl: 277.43, valid ppl: 280.73\n",
            "90000 steps; 92160000 examples so far; train ppl: 268.78, valid ppl: 272.51\n",
            "95000 steps; 97280000 examples so far; train ppl: 261.88, valid ppl: 265.43\n",
            "100000 steps; 102400000 examples so far; train ppl: 255.33, valid ppl: 258.55\n",
            "105000 steps; 107520000 examples so far; train ppl: 249.41, valid ppl: 252.41\n",
            "110000 steps; 112640000 examples so far; train ppl: 241.86, valid ppl: 246.54\n",
            "115000 steps; 117760000 examples so far; train ppl: 234.21, valid ppl: 241.94\n",
            "120000 steps; 122880000 examples so far; train ppl: 230.74, valid ppl: 236.97\n",
            "125000 steps; 128000000 examples so far; train ppl: 226.17, valid ppl: 232.19\n",
            "130000 steps; 133120000 examples so far; train ppl: 222.79, valid ppl: 228.57\n",
            "135000 steps; 138240000 examples so far; train ppl: 219.65, valid ppl: 224.64\n",
            "140000 steps; 143360000 examples so far; train ppl: 211.59, valid ppl: 221.36\n",
            "145000 steps; 148480000 examples so far; train ppl: 208.48, valid ppl: 218.35\n",
            "150000 steps; 153600000 examples so far; train ppl: 206.54, valid ppl: 215.14\n",
            "155000 steps; 158720000 examples so far; train ppl: 204.36, valid ppl: 212.37\n",
            "160000 steps; 163840000 examples so far; train ppl: 201.93, valid ppl: 209.46\n",
            "165000 steps; 168960000 examples so far; train ppl: 197.08, valid ppl: 207.03\n",
            "170000 steps; 174080000 examples so far; train ppl: 193.32, valid ppl: 205.41\n",
            "175000 steps; 179200000 examples so far; train ppl: 191.64, valid ppl: 202.89\n",
            "180000 steps; 184320000 examples so far; train ppl: 190.67, valid ppl: 200.39\n",
            "185000 steps; 189440000 examples so far; train ppl: 188.38, valid ppl: 198.19\n",
            "190000 steps; 194560000 examples so far; train ppl: 186.48, valid ppl: 196.40\n",
            "195000 steps; 199680000 examples so far; train ppl: 181.10, valid ppl: 194.78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"gdrive/MyDrive/Colab Notebooks/\"+\"valid_ppl_model03.txt\") as f:\n",
        "    txt = list(f)\n",
        "    compare = float(txt[-1])\n",
        "    f.close()"
      ],
      "metadata": {
        "id": "M1UDy0v9rWfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85efd159-ee84-4cd2-dea2-0b3a98795649",
        "id": "XcDp66hxCmYU"
      },
      "source": [
        "max_examples = 600_000_000\n",
        "eval_every_steps = 5000\n",
        "lr = 3e-5\n",
        "print(compare)\n",
        "\n",
        "model = LanguageModel(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    context_size=context_size,\n",
        "    embedding_dim=128,\n",
        "    hidden_size=256,\n",
        ").to(device)\n",
        "\n",
        "model = torch.load(\"gdrive/MyDrive/Colab Notebooks/\"+\"model03.pt\")\n",
        "model.to(device)\n",
        "\n",
        "train_loader = DataLoader(training_dataset, batch_size=1024, shuffle=True, drop_last=True)\n",
        "validation_loader = DataLoader(valid_dataset, batch_size=1024)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "def train_step(input, target):\n",
        "    model.train()\n",
        "    model.zero_grad()\n",
        "\n",
        "    logits = model(input.to(device))\n",
        "    loss = nn.functional.cross_entropy(logits, target.to(device))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "def validation_step(input, target):\n",
        "    model.eval()\n",
        "    logits = model(input)\n",
        "    loss = nn.functional.cross_entropy(logits, target)\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "train_losses = []\n",
        "n_examples = 0\n",
        "step = 0\n",
        "while n_examples < max_examples:\n",
        "    for input, target in train_loader:\n",
        "        loss = train_step(input.to(device), target.to(device)) \n",
        "        train_losses.append(loss)\n",
        "        \n",
        "        if step % eval_every_steps == 0:\n",
        "            train_ppl = np.exp(np.average(train_losses))\n",
        "\n",
        "            with torch.no_grad():\n",
        "                valid_ppl = np.exp(np.average([\n",
        "                    validation_step(input.to(device), target.to(device))\n",
        "                    for input, target in validation_loader]))\n",
        "                \n",
        "                if valid_ppl<compare:\n",
        "                    compare=valid_ppl\n",
        "                    torch.save(model, \"gdrive/MyDrive/Colab Notebooks/\"+\"model03_run02.pt\")\n",
        "                    with open(\"gdrive/MyDrive/Colab Notebooks/\"+\"valid_ppl_model03_run02.txt\", 'w') as f:\n",
        "                        f.write(\"%s\\n\" % valid_ppl)\n",
        "                    f.close()\n",
        "\n",
        "            print(f'{step} steps; {n_examples} examples so far; train ppl: {train_ppl:.2f}, valid ppl: {valid_ppl:.2f}')\n",
        "            train_losses = []\n",
        "\n",
        "        n_examples += len(input)  # Increment of batch size\n",
        "        step += 1\n",
        "        if n_examples >= max_examples:\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "194.7833877148957\n",
            "0 steps; 0 examples so far; train ppl: 179.25, valid ppl: 194.82\n",
            "5000 steps; 5120000 examples so far; train ppl: 183.87, valid ppl: 196.37\n",
            "10000 steps; 10240000 examples so far; train ppl: 180.88, valid ppl: 193.46\n",
            "15000 steps; 15360000 examples so far; train ppl: 179.46, valid ppl: 191.38\n",
            "20000 steps; 20480000 examples so far; train ppl: 178.24, valid ppl: 188.96\n",
            "25000 steps; 25600000 examples so far; train ppl: 176.59, valid ppl: 187.42\n",
            "30000 steps; 30720000 examples so far; train ppl: 171.86, valid ppl: 186.13\n",
            "35000 steps; 35840000 examples so far; train ppl: 170.14, valid ppl: 184.85\n",
            "40000 steps; 40960000 examples so far; train ppl: 169.51, valid ppl: 183.67\n",
            "45000 steps; 46080000 examples so far; train ppl: 168.65, valid ppl: 182.24\n",
            "50000 steps; 51200000 examples so far; train ppl: 168.06, valid ppl: 180.98\n",
            "55000 steps; 56320000 examples so far; train ppl: 166.44, valid ppl: 179.88\n",
            "60000 steps; 61440000 examples so far; train ppl: 162.17, valid ppl: 178.88\n",
            "65000 steps; 66560000 examples so far; train ppl: 161.98, valid ppl: 177.77\n",
            "70000 steps; 71680000 examples so far; train ppl: 161.70, valid ppl: 176.61\n",
            "75000 steps; 76800000 examples so far; train ppl: 161.64, valid ppl: 175.70\n",
            "80000 steps; 81920000 examples so far; train ppl: 160.87, valid ppl: 174.64\n",
            "85000 steps; 87040000 examples so far; train ppl: 156.48, valid ppl: 173.97\n",
            "90000 steps; 92160000 examples so far; train ppl: 155.81, valid ppl: 173.03\n",
            "95000 steps; 97280000 examples so far; train ppl: 155.60, valid ppl: 172.07\n",
            "100000 steps; 102400000 examples so far; train ppl: 155.83, valid ppl: 171.31\n",
            "105000 steps; 107520000 examples so far; train ppl: 155.28, valid ppl: 170.30\n",
            "110000 steps; 112640000 examples so far; train ppl: 153.36, valid ppl: 169.73\n",
            "115000 steps; 117760000 examples so far; train ppl: 150.55, valid ppl: 169.19\n",
            "120000 steps; 122880000 examples so far; train ppl: 150.64, valid ppl: 168.02\n",
            "125000 steps; 128000000 examples so far; train ppl: 150.56, valid ppl: 167.82\n",
            "130000 steps; 133120000 examples so far; train ppl: 150.46, valid ppl: 166.86\n",
            "135000 steps; 138240000 examples so far; train ppl: 150.50, valid ppl: 166.37\n",
            "140000 steps; 143360000 examples so far; train ppl: 146.14, valid ppl: 166.17\n",
            "145000 steps; 148480000 examples so far; train ppl: 146.01, valid ppl: 165.35\n",
            "150000 steps; 153600000 examples so far; train ppl: 146.15, valid ppl: 164.53\n",
            "155000 steps; 158720000 examples so far; train ppl: 146.54, valid ppl: 164.10\n",
            "160000 steps; 163840000 examples so far; train ppl: 146.36, valid ppl: 163.46\n",
            "165000 steps; 168960000 examples so far; train ppl: 143.41, valid ppl: 163.33\n",
            "170000 steps; 174080000 examples so far; train ppl: 142.50, valid ppl: 162.60\n",
            "175000 steps; 179200000 examples so far; train ppl: 142.34, valid ppl: 162.21\n",
            "180000 steps; 184320000 examples so far; train ppl: 142.62, valid ppl: 161.23\n",
            "185000 steps; 189440000 examples so far; train ppl: 142.69, valid ppl: 160.51\n",
            "190000 steps; 194560000 examples so far; train ppl: 141.70, valid ppl: 160.67\n",
            "195000 steps; 199680000 examples so far; train ppl: 138.66, valid ppl: 160.81\n",
            "200000 steps; 204800000 examples so far; train ppl: 139.20, valid ppl: 160.20\n",
            "205000 steps; 209920000 examples so far; train ppl: 139.34, valid ppl: 159.56\n",
            "210000 steps; 215040000 examples so far; train ppl: 139.38, valid ppl: 159.03\n",
            "215000 steps; 220160000 examples so far; train ppl: 139.39, valid ppl: 158.20\n",
            "220000 steps; 225280000 examples so far; train ppl: 136.30, valid ppl: 158.32\n",
            "225000 steps; 230400000 examples so far; train ppl: 135.96, valid ppl: 158.25\n",
            "230000 steps; 235520000 examples so far; train ppl: 136.39, valid ppl: 157.53\n",
            "235000 steps; 240640000 examples so far; train ppl: 136.38, valid ppl: 157.25\n",
            "240000 steps; 245760000 examples so far; train ppl: 136.66, valid ppl: 156.81\n",
            "245000 steps; 250880000 examples so far; train ppl: 135.05, valid ppl: 156.59\n",
            "250000 steps; 256000000 examples so far; train ppl: 132.95, valid ppl: 156.51\n",
            "255000 steps; 261120000 examples so far; train ppl: 133.71, valid ppl: 155.98\n",
            "260000 steps; 266240000 examples so far; train ppl: 133.83, valid ppl: 155.50\n",
            "265000 steps; 271360000 examples so far; train ppl: 134.28, valid ppl: 155.53\n",
            "270000 steps; 276480000 examples so far; train ppl: 134.26, valid ppl: 155.16\n",
            "275000 steps; 281600000 examples so far; train ppl: 130.73, valid ppl: 154.91\n",
            "280000 steps; 286720000 examples so far; train ppl: 131.36, valid ppl: 154.84\n",
            "285000 steps; 291840000 examples so far; train ppl: 131.34, valid ppl: 154.24\n",
            "290000 steps; 296960000 examples so far; train ppl: 131.60, valid ppl: 153.96\n",
            "295000 steps; 302080000 examples so far; train ppl: 131.93, valid ppl: 153.59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliação final no dataset de teste\n",
        "\n",
        "\n",
        "Bonus: o modelo com menor perplexidade no dataset de testes ganhará 0.5 ponto na nota final."
      ],
      "metadata": {
        "id": "VgdNymJdNPXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load(\"gdrive/MyDrive/Colab Notebooks/\"+\"model03_run02.pt\", map_location=device)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "ANSf_tXZshq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "671ca6a6-6a54-49a8-e7c3-bc2bd4f2af1b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageModel(\n",
              "  (embeddings): Embedding(29794, 128)\n",
              "  (linear1): Linear(in_features=1152, out_features=256, bias=True)\n",
              "  (linear2): Linear(in_features=256, out_features=512, bias=True)\n",
              "  (linear3): Linear(in_features=512, out_features=29794, bias=False)\n",
              "  (relu1): ReLU()\n",
              "  (relu2): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f286ae3-c22a-4717-9ccd-db4860d57439",
        "id": "Kyyf6g3bLA9S"
      },
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "def validation_step(input, target):\n",
        "    model.eval()\n",
        "    logits = model(input)\n",
        "    loss = nn.functional.cross_entropy(logits, target)\n",
        "    return loss.item()\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_ppl = np.exp(np.average([\n",
        "        validation_step(input.to(device), target.to(device))\n",
        "        for input, target in test_loader\n",
        "    ]))\n",
        "\n",
        "print(f'test perplexity: {test_ppl}')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test perplexity: 141.6671717478626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teste seu modelo com uma sentença\n",
        "\n",
        "Escolha uma sentença gerada pelo modelo que ache interessante."
      ],
      "metadata": {
        "id": "BHvEs8mPszy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Temos que pensar no futuro e guardar o que aprendemos na \"  # Ex: 'Eu gosto de comer pizza pois me faz'\n",
        "max_output_tokens = 10\n",
        "\n",
        "for _ in range(max_output_tokens):\n",
        "    input_ids = tokenize(text=prompt, tokenizer=tokenizer)\n",
        "    input_ids_truncated = input_ids[-context_size:]  # Usamos apenas os últimos <context_size> tokens como entrada para o modelo.\n",
        "    input_ids_truncated = torch.tensor(input_ids_truncated).long()\n",
        "    logits = model(torch.LongTensor(input_ids_truncated).to(device))\n",
        "    # Ao usarmos o argmax, a saída do modelo em cada passo é token de maior probabilidade.\n",
        "    # Isso se chama decodificação gulosa (greedy decoding).\n",
        "    predicted_id = torch.argmax(logits).item()\n",
        "    input_ids += [predicted_id]  # Concatenamos a entrada com o token escolhido nesse passo.\n",
        "    prompt = tokenizer.decode(input_ids)\n",
        "    print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "153Y6TBezvPW",
        "outputId": "b91c257f-dd41-4278-ebb5-fc47a3345e6a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Temos que pensar no futuro e guardar o que aprendemos na vida\n",
            "Temos que pensar no futuro e guardar o que aprendemos na vida de\n",
            "Temos que pensar no futuro e guardar o que aprendemos na vida de um\n",
            "Temos que pensar no futuro e guardar o que aprendemos na vida de um homem\n",
            "Temos que pensar no futuro e guardar o que aprendemos na vida de um homem,\n",
            "Temos que pensar no futuro e guardar o que aprendemos na vida de um homem, e\n",
            "Temos que pensar no futuro e guardar o que aprendemos na vida de um homem, e que\n",
            "Temos que pensar no futuro e guardar o que aprendemos na vida de um homem, e que não\n",
            "Temos que pensar no futuro e guardar o que aprendemos na vida de um homem, e que não se\n",
            "Temos que pensar no futuro e guardar o que aprendemos na vida de um homem, e que não se pode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Uma xícara de café e um livro são as\"  # Ex: 'Eu gosto de comer pizza pois me faz'\n",
        "max_output_tokens = 10\n",
        "\n",
        "for _ in range(max_output_tokens):\n",
        "    input_ids = tokenize(text=prompt, tokenizer=tokenizer)\n",
        "    input_ids_truncated = input_ids[-context_size:]  # Usamos apenas os últimos <context_size> tokens como entrada para o modelo.\n",
        "    input_ids_truncated = torch.tensor(input_ids_truncated).long()\n",
        "    logits = model(torch.LongTensor(input_ids_truncated).to(device))\n",
        "    # Ao usarmos o argmax, a saída do modelo em cada passo é token de maior probabilidade.\n",
        "    # Isso se chama decodificação gulosa (greedy decoding).\n",
        "    predicted_id = torch.argmax(logits).item()\n",
        "    input_ids += [predicted_id]  # Concatenamos a entrada com o token escolhido nesse passo.\n",
        "    prompt = tokenizer.decode(input_ids)\n",
        "    print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLZQboZ-3_ba",
        "outputId": "5b864df9-b2d1-4195-ab95-af37db9f96fe"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uma xícara de café e um livro são as melhores\n",
            "Uma xícara de café e um livro são as melhores opções\n",
            "Uma xícara de café e um livro são as melhores opções de\n",
            "Uma xícara de café e um livro são as melhores opções de vida\n",
            "Uma xícara de café e um livro são as melhores opções de vida,\n",
            "Uma xícara de café e um livro são as melhores opções de vida, e\n",
            "Uma xícara de café e um livro são as melhores opções de vida, e a\n",
            "Uma xícara de café e um livro são as melhores opções de vida, e a sua\n",
            "Uma xícara de café e um livro são as melhores opções de vida, e a sua vida\n",
            "Uma xícara de café e um livro são as melhores opções de vida, e a sua vida,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Cachorro e gato são os melhores amigos do\"  # Ex: 'Eu gosto de comer pizza pois me faz'\n",
        "max_output_tokens = 10\n",
        "\n",
        "for _ in range(max_output_tokens):\n",
        "    input_ids = tokenize(text=prompt, tokenizer=tokenizer)\n",
        "    input_ids_truncated = input_ids[-context_size:]  # Usamos apenas os últimos <context_size> tokens como entrada para o modelo.\n",
        "    input_ids_truncated = torch.tensor(input_ids_truncated).long()\n",
        "    logits = model(torch.LongTensor(input_ids_truncated).to(device))\n",
        "    # Ao usarmos o argmax, a saída do modelo em cada passo é token de maior probabilidade.\n",
        "    # Isso se chama decodificação gulosa (greedy decoding).\n",
        "    predicted_id = torch.argmax(logits).item()\n",
        "    input_ids += [predicted_id]  # Concatenamos a entrada com o token escolhido nesse passo.\n",
        "    prompt = tokenizer.decode(input_ids)\n",
        "    print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e1e2662-7b56-45cc-a18e-fc626bfea206",
        "id": "MY13rXbQLmyu"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cachorro e gato são os melhores amigos do mundo\n",
            "Cachorro e gato são os melhores amigos do mundo.\n",
            "Cachorro e gato são os melhores amigos do mundo. A\n",
            "Cachorro e gato são os melhores amigos do mundo. A partir\n",
            "Cachorro e gato são os melhores amigos do mundo. A partir de\n",
            "Cachorro e gato são os melhores amigos do mundo. A partir de agora\n",
            "Cachorro e gato são os melhores amigos do mundo. A partir de agora,\n",
            "Cachorro e gato são os melhores amigos do mundo. A partir de agora, a\n",
            "Cachorro e gato são os melhores amigos do mundo. A partir de agora, a partir\n",
            "Cachorro e gato são os melhores amigos do mundo. A partir de agora, a partir de\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"A exposição da Tarsila ocorrerá na cidade\"  # Ex: 'Eu gosto de comer pizza pois me faz'\n",
        "max_output_tokens = 10\n",
        "\n",
        "for _ in range(max_output_tokens):\n",
        "    input_ids = tokenize(text=prompt, tokenizer=tokenizer)\n",
        "    input_ids_truncated = input_ids[-context_size:]  # Usamos apenas os últimos <context_size> tokens como entrada para o modelo.\n",
        "    input_ids_truncated = torch.tensor(input_ids_truncated).long()\n",
        "    logits = model(torch.LongTensor(input_ids_truncated).to(device))\n",
        "    # Ao usarmos o argmax, a saída do modelo em cada passo é token de maior probabilidade.\n",
        "    # Isso se chama decodificação gulosa (greedy decoding).\n",
        "    predicted_id = torch.argmax(logits).item()\n",
        "    input_ids += [predicted_id]  # Concatenamos a entrada com o token escolhido nesse passo.\n",
        "    prompt = tokenizer.decode(input_ids)\n",
        "    print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ef7f0f0-3ec9-4b78-83c2-5e5bca824c73",
        "id": "45rTx9JZypEX"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A exposição da Tarsila ocorrerá na cidade de\n",
            "A exposição da Tarsila ocorrerá na cidade de São\n",
            "A exposição da Tarsila ocorrerá na cidade de São Paulo\n",
            "A exposição da Tarsila ocorrerá na cidade de São Paulo.\n",
            "A exposição da Tarsila ocorrerá na cidade de São Paulo. O\n",
            "A exposição da Tarsila ocorrerá na cidade de São Paulo. O que\n",
            "A exposição da Tarsila ocorrerá na cidade de São Paulo. O que é\n",
            "A exposição da Tarsila ocorrerá na cidade de São Paulo. O que é o\n",
            "A exposição da Tarsila ocorrerá na cidade de São Paulo. O que é o primeiro\n",
            "A exposição da Tarsila ocorrerá na cidade de São Paulo. O que é o primeiro passo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"As mulheres estão cada vez mais presentes comparado a\"  # Ex: 'Eu gosto de comer pizza pois me faz'\n",
        "max_output_tokens = 10\n",
        "\n",
        "for _ in range(max_output_tokens):\n",
        "    input_ids = tokenize(text=prompt, tokenizer=tokenizer)\n",
        "    input_ids_truncated = input_ids[-context_size:]  # Usamos apenas os últimos <context_size> tokens como entrada para o modelo.\n",
        "    input_ids_truncated = torch.tensor(input_ids_truncated).long()\n",
        "    logits = model(torch.LongTensor(input_ids_truncated).to(device))\n",
        "    # Ao usarmos o argmax, a saída do modelo em cada passo é token de maior probabilidade.\n",
        "    # Isso se chama decodificação gulosa (greedy decoding).\n",
        "    predicted_id = torch.argmax(logits).item()\n",
        "    input_ids += [predicted_id]  # Concatenamos a entrada com o token escolhido nesse passo.\n",
        "    prompt = tokenizer.decode(input_ids)\n",
        "    print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2455b23b-185a-41d1-9dbd-0eed42108a5b",
        "id": "zHyp55iAy4lO"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As mulheres estão cada vez mais presentes comparado a um\n",
            "As mulheres estão cada vez mais presentes comparado a um ano\n",
            "As mulheres estão cada vez mais presentes comparado a um ano de\n",
            "As mulheres estão cada vez mais presentes comparado a um ano de 2013\n",
            "As mulheres estão cada vez mais presentes comparado a um ano de 2013.\n",
            "As mulheres estão cada vez mais presentes comparado a um ano de 2013. O\n",
            "As mulheres estão cada vez mais presentes comparado a um ano de 2013. O primeiro\n",
            "As mulheres estão cada vez mais presentes comparado a um ano de 2013. O primeiro passo\n",
            "As mulheres estão cada vez mais presentes comparado a um ano de 2013. O primeiro passo é\n",
            "As mulheres estão cada vez mais presentes comparado a um ano de 2013. O primeiro passo é que\n"
          ]
        }
      ]
    }
  ]
}