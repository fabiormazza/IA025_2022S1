{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tentativa_2_Atividade_9_Beatriz_Celante",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e6e9f58d88484cc192a9a5820fdc568b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5c9c6bf7b0948a89ec9889f69186f45",
              "IPY_MODEL_2c2ab024bd614882a1b25492ed2b7025",
              "IPY_MODEL_003f669378594c8ba4704c0528124c18"
            ],
            "layout": "IPY_MODEL_d7755a415083419eaa5dfe233669d26e"
          }
        },
        "d5c9c6bf7b0948a89ec9889f69186f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_602d0b1e0b964d31a20e323bf4567aa6",
            "placeholder": "​",
            "style": "IPY_MODEL_8a6c493583de412eb60c069f7fd0d7d3",
            "value": "Downloading: 100%"
          }
        },
        "2c2ab024bd614882a1b25492ed2b7025": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_585dd36f11014f62898ac3b3b80cc355",
            "max": 209528,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3e949e00a2274599ac09a8836e7346ea",
            "value": 209528
          }
        },
        "003f669378594c8ba4704c0528124c18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13d2ae28dd694050901fff79f51e8df6",
            "placeholder": "​",
            "style": "IPY_MODEL_7989a5f32b2446e9b66e2a2d265127e2",
            "value": " 205k/205k [00:00&lt;00:00, 828kB/s]"
          }
        },
        "d7755a415083419eaa5dfe233669d26e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "602d0b1e0b964d31a20e323bf4567aa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a6c493583de412eb60c069f7fd0d7d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "585dd36f11014f62898ac3b3b80cc355": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e949e00a2274599ac09a8836e7346ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13d2ae28dd694050901fff79f51e8df6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7989a5f32b2446e9b66e2a2d265127e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54d039bcdfd04d96ac1b8b02a9f8716a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff79c43859c343cdadce5411b96ae4ac",
              "IPY_MODEL_d6bf2a3472c34665b80eee8d9e97ea7f",
              "IPY_MODEL_17e0cd7d1c7b49ac844b55c20dffc96e"
            ],
            "layout": "IPY_MODEL_84d3d5c6fbe7404ea03367c4b92fc1a9"
          }
        },
        "ff79c43859c343cdadce5411b96ae4ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce3d3babc9034aa98cf16bbd07764dcc",
            "placeholder": "​",
            "style": "IPY_MODEL_69bf384030ee4f5f8903c0bffc378890",
            "value": "Downloading: 100%"
          }
        },
        "d6bf2a3472c34665b80eee8d9e97ea7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88a1b28dcfe346199cbb9b5db7655c94",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_313f2460938746f7b244038210b47d34",
            "value": 2
          }
        },
        "17e0cd7d1c7b49ac844b55c20dffc96e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae6e4ee0489e47d0af2165b41dc0494e",
            "placeholder": "​",
            "style": "IPY_MODEL_ef9d2a9173e94c6e8f712873010c0009",
            "value": " 2.00/2.00 [00:00&lt;00:00, 62.5B/s]"
          }
        },
        "84d3d5c6fbe7404ea03367c4b92fc1a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce3d3babc9034aa98cf16bbd07764dcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69bf384030ee4f5f8903c0bffc378890": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88a1b28dcfe346199cbb9b5db7655c94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "313f2460938746f7b244038210b47d34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae6e4ee0489e47d0af2165b41dc0494e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef9d2a9173e94c6e8f712873010c0009": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55d26fd8e610401cbfb3baaf933a8c2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f533c733cf8a4a6f954fe565b673b731",
              "IPY_MODEL_c5ac7e3ce6244190b67c2e5bc4ebba03",
              "IPY_MODEL_dfcba20023c1434dab49f8335bcfd9b7"
            ],
            "layout": "IPY_MODEL_adc71652684c42ec89e36f3b689feb92"
          }
        },
        "f533c733cf8a4a6f954fe565b673b731": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6db6cb15d17e4be6863e19a9f0b039f6",
            "placeholder": "​",
            "style": "IPY_MODEL_8fc7c36d733d4e22a4f09caf374412e0",
            "value": "Downloading: 100%"
          }
        },
        "c5ac7e3ce6244190b67c2e5bc4ebba03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21993b3f69d84195a904e43ab60ddaa9",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd88cf5dce2c4dd9aad889f930acd9a7",
            "value": 112
          }
        },
        "dfcba20023c1434dab49f8335bcfd9b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7d164659a7348458b3a1a51b1e44660",
            "placeholder": "​",
            "style": "IPY_MODEL_153c5c38e230406aa0d762c3b8a1b764",
            "value": " 112/112 [00:00&lt;00:00, 3.48kB/s]"
          }
        },
        "adc71652684c42ec89e36f3b689feb92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6db6cb15d17e4be6863e19a9f0b039f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fc7c36d733d4e22a4f09caf374412e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21993b3f69d84195a904e43ab60ddaa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd88cf5dce2c4dd9aad889f930acd9a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7d164659a7348458b3a1a51b1e44660": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "153c5c38e230406aa0d762c3b8a1b764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f242c2181a1468da58ef9cac10d62b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d940386cf6df41af92954bce27be2ac9",
              "IPY_MODEL_fdd2c94ccf4e42c4b5fe815d53f0b5e7",
              "IPY_MODEL_558fde2d0b774e5da0b27989345e5e96"
            ],
            "layout": "IPY_MODEL_933992dd24aa4758a6bc040eff4308eb"
          }
        },
        "d940386cf6df41af92954bce27be2ac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69360e03aaf14e778fb7b2a7e54a0916",
            "placeholder": "​",
            "style": "IPY_MODEL_7edafb4fa0b0425aae8ce4fbc7fec306",
            "value": "Downloading: 100%"
          }
        },
        "fdd2c94ccf4e42c4b5fe815d53f0b5e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bdd3e5bf397465f9442deb11c0f3367",
            "max": 43,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_36925d4bae9a48f3bc508768d5bb2df4",
            "value": 43
          }
        },
        "558fde2d0b774e5da0b27989345e5e96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e43d7a00ea86432eac645f6a2f742ba2",
            "placeholder": "​",
            "style": "IPY_MODEL_b68a42ef8916459c80bb928218fd1073",
            "value": " 43.0/43.0 [00:00&lt;00:00, 1.17kB/s]"
          }
        },
        "933992dd24aa4758a6bc040eff4308eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69360e03aaf14e778fb7b2a7e54a0916": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7edafb4fa0b0425aae8ce4fbc7fec306": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bdd3e5bf397465f9442deb11c0f3367": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36925d4bae9a48f3bc508768d5bb2df4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e43d7a00ea86432eac645f6a2f742ba2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b68a42ef8916459c80bb928218fd1073": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6d9ff96490949028d9e089570151672": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_faf9a0561be94a778b3a7a2b259b6a09",
              "IPY_MODEL_ed81dc47564c443ab9b84a21f281ef19",
              "IPY_MODEL_8cef85853217428f9439155492608be1"
            ],
            "layout": "IPY_MODEL_afb361b5a9304866aea604f25ab77498"
          }
        },
        "faf9a0561be94a778b3a7a2b259b6a09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29dfda7ba2f64ac6906463bd994c3b16",
            "placeholder": "​",
            "style": "IPY_MODEL_706136cfdf6e4c3da50d38c2bcff6191",
            "value": "Downloading: 100%"
          }
        },
        "ed81dc47564c443ab9b84a21f281ef19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc6519722c934899b878887a98e3b7ad",
            "max": 647,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f88f2d6dca3f49d18d85023e1196df05",
            "value": 647
          }
        },
        "8cef85853217428f9439155492608be1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7320e35bb5b4aa8b08e45f50f9c8fd0",
            "placeholder": "​",
            "style": "IPY_MODEL_d678afacd60d4c0bb3af7f437355af49",
            "value": " 647/647 [00:00&lt;00:00, 19.0kB/s]"
          }
        },
        "afb361b5a9304866aea604f25ab77498": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29dfda7ba2f64ac6906463bd994c3b16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "706136cfdf6e4c3da50d38c2bcff6191": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc6519722c934899b878887a98e3b7ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f88f2d6dca3f49d18d85023e1196df05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7320e35bb5b4aa8b08e45f50f9c8fd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d678afacd60d4c0bb3af7f437355af49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unicamp-dl/IA025_2022S1/blob/main/ex09/Beatriz_Celante/Tentativa_2_Atividade_9_Beatriz_Celante.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nome = \"Beatriz Celante\"\n",
        "print(f'Meu nome é {nome}')"
      ],
      "metadata": {
        "id": "jOdQB41_4ZxG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0502a94-467c-4889-8800-01e7f82f9dc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meu nome é Beatriz Celante\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IbuChoAPMEn"
      },
      "source": [
        "#  Exercício: Modelo de Linguagem com auto-atenção"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_DBb0-Klwf2"
      },
      "source": [
        "Este exercício é similar ao da Aula 8, mas iremos agora treinar uma rede neural com **duas camadas** de auto-atenção **causais** para prever a próxima palavra de um texto, data as palavras anteriores como entrada. \n",
        "\n",
        "Iremos também trabalhar com sequencias de tamanho variável.\n",
        "\n",
        "Na camada de auto-atenção, não se esqueça de implementar:\n",
        "- Embeddings de posição\n",
        "- Projeções lineares (WQ, WK, WV, WO)\n",
        "- Conexões residuais\n",
        "- Camada de feed forward (2-layer MLP)\n",
        "\n",
        "\n",
        "O dataset usado neste exercício (BrWaC) possui um tamanho razoável e você vai precisar rodar seus experimentos com GPU.\n",
        "\n",
        "Alguns conselhos úteis:\n",
        "- **ATENÇÃO:** o dataset é bem grande. Não dê comando de imprimí-lo.\n",
        "- Durante a depuração, faça seu dataset ficar bem pequeno, para que a depuração seja mais rápida e não precise de GPU. Somente ligue a GPU quando o seu laço de treinamento já está funcionando\n",
        "- Não deixe para fazer esse exercício na véspera. Ele é trabalhoso."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# iremos utilizar a biblioteca dos transformers para ter acesso ao tokenizador do BERT.\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3twP0YJC4jmJ",
        "outputId": "5e2edc74-dcf0-4f91-f2f3-88f9710a3738"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 56.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 6.8 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 48.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnyhJZtTRNMx"
      },
      "source": [
        "## Importação dos pacotes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlIOVCajPWcU"
      },
      "source": [
        "import collections\n",
        "import itertools\n",
        "import functools\n",
        "import math\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm_notebook\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check which GPU we are using\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "w9f3PfifAwpU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c43c472e-e15a-4d78-c1d7-f6edfdf3243e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jun  7 18:56:25 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available(): \n",
        "   dev = \"cuda:0\"\n",
        "else: \n",
        "   dev = \"cpu\"\n",
        "device = torch.device(dev)\n",
        "print('Using {}'.format(device))"
      ],
      "metadata": {
        "id": "whTCe2i7AtoV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "185db7d2-0456-4696-ea96-fc12219fd0ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZfxgV2DUk58"
      },
      "source": [
        "## Implementação do MyDataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_xhKm1EZ3bQ"
      },
      "source": [
        "from typing import List\n",
        "from pandas.core.common import flatten\n",
        "\n",
        "'''\n",
        "=\n",
        "Refiz o MyDataset, a implementação dele estava incorreta e esse era o principal fator que gerava o overfitting\n",
        "\n",
        "'''\n",
        "\n",
        "def tokenize(text: str, tokenizer):\n",
        "    # Recomenda-se usar o tokenizer.batch_encode_plus pois é mais rápido.\n",
        "    return tokenizer(text, return_tensors=None, add_special_tokens=False).input_ids\n",
        "\n",
        "\n",
        "class MyDataset():\n",
        "    def __init__(self, texts: List[str], tokenizer, max_seq_length: int):\n",
        "        # Escreva aqui seu código.\n",
        "        self.texts = texts\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_seq_length = max_seq_length\n",
        "\n",
        "        self.toekenized = []\n",
        "\n",
        "        #Tokeniza os textos e insere o token de início\n",
        "        for t in texts:\n",
        "          to_token = tokenize(f'[CLS] {t}', tokenizer)\n",
        "          \n",
        "          #Adiciona o PAD\n",
        "          pad_size = max(0, 1 + self.max_seq_length - len(to_token))\n",
        "          to_token = to_token + [tokenizer.vocab['[PAD]']] * max(0, pad_size)\n",
        "\n",
        "          #Separa os tokens por pedaço - percorre de 0 até o tamanho máximo, com um step do tamanho máximo da sequência:  \n",
        "          for i in range (0, len(to_token) - 1, max_seq_length):\n",
        "            part_input = to_token[i*max_seq_length : (i + 1)*max_seq_length]\n",
        "            part_target = to_token[1 + i*max_seq_length : 1 + (i + 1)*max_seq_length]\n",
        "\n",
        "            #Adiciona a sequência tokenizada no vetor\n",
        "            if i + max_seq_length < len(to_token):\n",
        "              self.toekenized.append(to_token[i: i + max_seq_length + 1])\n",
        "            else:\n",
        "              self.toekenized.append(to_token[-max_seq_length - 1:])\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.toekenized)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        output = self.toekenized[idx]\n",
        "        return torch.LongTensor(output[:-1]), torch.LongTensor(output[1:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testando se a implementação do MyDataset está correta"
      ],
      "metadata": {
        "id": "wew-gFbWeBTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
        "\n",
        "dummy_texts = ['Eu gosto de correr', 'Ela gosta muito de comer pizza']\n",
        "\n",
        "dummy_dataset = MyDataset(texts=dummy_texts, tokenizer=tokenizer, max_seq_length=9)\n",
        "dummy_loader = DataLoader(dummy_dataset, batch_size=6, shuffle=False)\n",
        "assert len(dummy_dataset) == 2\n",
        "print('Passou no assert de tamanho do dataset.')\n",
        "\n",
        "first_batch_input, first_batch_target = next(iter(dummy_loader))\n",
        "\n",
        "correct_first_batch_input = torch.LongTensor(\n",
        "    [[  101,  3396, 10303,   125, 13239,     0,     0,     0,     0],\n",
        "     [  101,  1660,  5971,   785,   125,  1847, 13779, 15616,     0]])\n",
        "\n",
        "correct_first_batch_target = torch.LongTensor(\n",
        "    [[ 3396, 10303,   125, 13239,     0,     0,     0,     0,     0],\n",
        "     [ 1660,  5971,   785,   125,  1847, 13779, 15616,     0,     0]])\n",
        "\n",
        "assert torch.equal(first_batch_input, correct_first_batch_input)\n",
        "assert torch.equal(first_batch_target, correct_first_batch_target)\n",
        "\n",
        "print('Passou no assert de dataset.')"
      ],
      "metadata": {
        "id": "8r7jBFFUeApe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214,
          "referenced_widgets": [
            "e6e9f58d88484cc192a9a5820fdc568b",
            "d5c9c6bf7b0948a89ec9889f69186f45",
            "2c2ab024bd614882a1b25492ed2b7025",
            "003f669378594c8ba4704c0528124c18",
            "d7755a415083419eaa5dfe233669d26e",
            "602d0b1e0b964d31a20e323bf4567aa6",
            "8a6c493583de412eb60c069f7fd0d7d3",
            "585dd36f11014f62898ac3b3b80cc355",
            "3e949e00a2274599ac09a8836e7346ea",
            "13d2ae28dd694050901fff79f51e8df6",
            "7989a5f32b2446e9b66e2a2d265127e2",
            "54d039bcdfd04d96ac1b8b02a9f8716a",
            "ff79c43859c343cdadce5411b96ae4ac",
            "d6bf2a3472c34665b80eee8d9e97ea7f",
            "17e0cd7d1c7b49ac844b55c20dffc96e",
            "84d3d5c6fbe7404ea03367c4b92fc1a9",
            "ce3d3babc9034aa98cf16bbd07764dcc",
            "69bf384030ee4f5f8903c0bffc378890",
            "88a1b28dcfe346199cbb9b5db7655c94",
            "313f2460938746f7b244038210b47d34",
            "ae6e4ee0489e47d0af2165b41dc0494e",
            "ef9d2a9173e94c6e8f712873010c0009",
            "55d26fd8e610401cbfb3baaf933a8c2c",
            "f533c733cf8a4a6f954fe565b673b731",
            "c5ac7e3ce6244190b67c2e5bc4ebba03",
            "dfcba20023c1434dab49f8335bcfd9b7",
            "adc71652684c42ec89e36f3b689feb92",
            "6db6cb15d17e4be6863e19a9f0b039f6",
            "8fc7c36d733d4e22a4f09caf374412e0",
            "21993b3f69d84195a904e43ab60ddaa9",
            "dd88cf5dce2c4dd9aad889f930acd9a7",
            "c7d164659a7348458b3a1a51b1e44660",
            "153c5c38e230406aa0d762c3b8a1b764",
            "9f242c2181a1468da58ef9cac10d62b1",
            "d940386cf6df41af92954bce27be2ac9",
            "fdd2c94ccf4e42c4b5fe815d53f0b5e7",
            "558fde2d0b774e5da0b27989345e5e96",
            "933992dd24aa4758a6bc040eff4308eb",
            "69360e03aaf14e778fb7b2a7e54a0916",
            "7edafb4fa0b0425aae8ce4fbc7fec306",
            "5bdd3e5bf397465f9442deb11c0f3367",
            "36925d4bae9a48f3bc508768d5bb2df4",
            "e43d7a00ea86432eac645f6a2f742ba2",
            "b68a42ef8916459c80bb928218fd1073",
            "c6d9ff96490949028d9e089570151672",
            "faf9a0561be94a778b3a7a2b259b6a09",
            "ed81dc47564c443ab9b84a21f281ef19",
            "8cef85853217428f9439155492608be1",
            "afb361b5a9304866aea604f25ab77498",
            "29dfda7ba2f64ac6906463bd994c3b16",
            "706136cfdf6e4c3da50d38c2bcff6191",
            "bc6519722c934899b878887a98e3b7ad",
            "f88f2d6dca3f49d18d85023e1196df05",
            "f7320e35bb5b4aa8b08e45f50f9c8fd0",
            "d678afacd60d4c0bb3af7f437355af49"
          ]
        },
        "outputId": "e289cf78-ce60-439a-c384-456327c5153a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/205k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6e9f58d88484cc192a9a5820fdc568b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54d039bcdfd04d96ac1b8b02a9f8716a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55d26fd8e610401cbfb3baaf933a8c2c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/43.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f242c2181a1468da58ef9cac10d62b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/647 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6d9ff96490949028d9e089570151672"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passou no assert de tamanho do dataset.\n",
            "Passou no assert de dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LfrHHouleJ0"
      },
      "source": [
        "# Carregamento do dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2vFWjsSkmop"
      },
      "source": [
        "Iremos usar uma pequena amostra do dataset [BrWaC](https://www.inf.ufrgs.br/pln/wiki/index.php?title=BrWaC) para treinar e avaliar nosso modelo de linguagem."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://storage.googleapis.com/unicamp-dl/ia025a_2022s1/aula9/sample-1gb.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGlN1WqrXPA6",
        "outputId": "0a41daff-5cb0-4e49-984e-d40ea72caaed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-07 18:56:47--  https://storage.googleapis.com/unicamp-dl/ia025a_2022s1/aula9/sample-1gb.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.135.128, 74.125.142.128, 172.253.117.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.135.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1230909256 (1.1G) [text/plain]\n",
            "Saving to: ‘sample-1gb.txt’\n",
            "\n",
            "sample-1gb.txt      100%[===================>]   1.15G   273MB/s    in 4.3s    \n",
            "\n",
            "2022-06-07 18:56:51 (276 MB/s) - ‘sample-1gb.txt’ saved [1230909256/1230909256]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "max_seq_length = 9\n",
        "\n",
        "train_examples = 50000\n",
        "valid_examples = 500\n",
        "test_examples = 500\n",
        "texts = open('sample-1gb.txt').readlines()\n",
        "\n",
        "print(f'Read {len(texts)} lines.')\n",
        "\n",
        "max_lines = train_examples + valid_examples + test_examples\n",
        "print(f'Truncating to {max_lines} lines.')\n",
        "texts = texts[:max_lines]  \n",
        "\n",
        "training_texts = texts[:-(valid_examples + test_examples)]\n",
        "valid_texts = texts[-(valid_examples + test_examples):-test_examples]\n",
        "test_texts = texts[-test_examples:]\n",
        "\n",
        "training_dataset = MyDataset(texts=training_texts, tokenizer=tokenizer, max_seq_length=max_seq_length)\n",
        "valid_dataset = MyDataset(texts=valid_texts, tokenizer=tokenizer, max_seq_length=max_seq_length)\n",
        "test_dataset = MyDataset(texts=test_texts, tokenizer=tokenizer, max_seq_length=max_seq_length)"
      ],
      "metadata": {
        "id": "gxa_4gmiA-wE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07717169-6e0c-495d-a21d-9525757746fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read 250000 lines.\n",
            "Truncating to 51000 lines.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'training examples: {len(training_dataset)}')\n",
        "print(f'valid examples: {len(valid_dataset)}')\n",
        "print(f'test examples: {len(test_dataset)}')"
      ],
      "metadata": {
        "id": "KCSGJ5m7py4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3936559-b6ff-406c-8661-425653644033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training examples: 6186062\n",
            "valid examples: 68157\n",
            "test examples: 68599\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementando a atenção e a atenção de várias cabeças"
      ],
      "metadata": {
        "id": "hH1k_G4OSkIy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Querry, key e value possuem o formato (batch_size, seq_lenght, n_features). Fazer a multiplicação do query com a key resulta na importância de cada elemento da sequência para o modelo, e essa multiplicação possui dimensões de (batch_size, seq_lenght, seq_lenght). Isso é o que chamamos de atenção. Essa ateção é normalizada usando softmax porque a soma de todos os pesos têm que dar 1 (probabilidade). "
      ],
      "metadata": {
        "id": "ZN6DUA1YTM1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Multi_Attention(nn.Module):\n",
        "    def __init__(self, max_len, dim, n_heads):\n",
        "      super().__init__()\n",
        "\n",
        "      self.dim = dim\n",
        "      self.n_heads = n_heads\n",
        "      self.max_len = max_len\n",
        "      self.dim\n",
        "\n",
        "      self.projection_q = nn.Linear(dim, dim, bias=False)\n",
        "      self.projection_k = nn.Linear(dim, dim, bias=False)\n",
        "      self.projection_v = nn.Linear(dim, dim, bias=False)\n",
        "\n",
        "      self.mask = torch.tril(torch.ones(max_len, max_len)).unsqueeze(0).to(device)\n",
        "\n",
        "    def attention(self, q, v, k, mask):\n",
        "      scores = torch.matmul(q, k.transpose(-2, -1))\n",
        "      scores = scores/math.sqrt(self.dim) #Fator de escala - estava errado na outra versão\n",
        "      scores = scores.masked_fill(mask.unsqueeze(1) == 0, float('-inf'))\n",
        "      \n",
        "      #Aplica a softmax e multiplica por v para calcular a probabilidade\n",
        "      soft = nn.functional.softmax(scores, dim = -1)\n",
        "      prob = torch.matmul(soft, v)\n",
        "      prob = prob.transpose(1,2)\n",
        "      return prob\n",
        "\n",
        "    def forward(self, inputs, mask):\n",
        "\n",
        "      self.batch_size = inputs.shape[0]\n",
        "\n",
        "      #Nessa segunda versão, implemento a conexão residual\n",
        "\n",
        "      res = inputs\n",
        "      \n",
        "      q = self.projection_q(inputs).reshape(self.batch_size, self.max_len, self.n_heads, (self.dim // self.n_heads))\n",
        "      k = self.projection_k(inputs).reshape(self.batch_size, self.max_len, self.n_heads, (self.dim // self.n_heads))\n",
        "      v = self.projection_v(inputs).reshape(self.batch_size, self.max_len, self.n_heads, (self.dim // self.n_heads))\n",
        "\n",
        "      q = q.transpose(1, 2)\n",
        "      k = k.transpose(1, 2)\n",
        "      v = v.transpose(1, 2)\n",
        "\n",
        "      out = self.attention(q, v, k, mask)\n",
        "      out = out.reshape(self.batch_size, self.max_len, self.dim)\n",
        "\n",
        "      out = out + res\n",
        "\n",
        "      return out"
      ],
      "metadata": {
        "id": "cfIisVBbSpO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGaAjYDfWdd1"
      },
      "source": [
        "class LanguageModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size: int, max_seq_length: int, dim: int, n_layers: int, pad_token_id: int):\n",
        "        \"\"\"\n",
        "        Implements the Self-attention, decoder-only.\"\n",
        "\n",
        "        Args:\n",
        "            vocab_size (int): Size of the input vocabulary.\n",
        "            max_seq_length (int): Size of the sequence to consider as context for prediction.\n",
        "            dim (int): Dimension of the embedding layer for each word in the context.\n",
        "            n_layers (int): number of self-attention layers.\n",
        "            pad_token_id (int): id of the pad token that will be ignored in the attention.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.dim = dim\n",
        "        self.n_layers = n_layers\n",
        "        self.pad_token_id = pad_token_id\n",
        "        self.n_heads = 4\n",
        "\n",
        "        #Embedding \n",
        "        self.embedding = nn.Embedding(vocab_size, dim, padding_idx=pad_token_id)\n",
        "\n",
        "        #Positional embedding\n",
        "        self.pos_embedding = nn.Embedding(vocab_size, dim, padding_idx=pad_token_id)\n",
        "\n",
        "        #Dropout\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "\n",
        "        #Projeções lineares\n",
        "        self.projection_W0 = nn.Linear(dim, dim, bias=False)\n",
        "\n",
        "        #Camadas lineares (feed forward)\n",
        "        self.feed_forward = nn.Sequential(\n",
        "        nn.Linear(dim, 2*dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(2*dim, vocab_size),\n",
        "        nn.Dropout(p=0.1))\n",
        "\n",
        "        #Camadas de normalização\n",
        "        self.layer_norm = nn.LayerNorm(self.dim, eps=1e-6)\n",
        "\n",
        "        #Multi-head attention (Tinha esquecido de implementar de acordo com o número de camadas passado)\n",
        "        self.multihead = nn.ModuleList([Multi_Attention(self.max_seq_length, self.dim, self.n_heads)\n",
        "                                                                for _ in range(n_layers)])\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            inputs is a LongTensor of shape (batch_size, max_seq_length)\n",
        "            \n",
        "        Returns:\n",
        "            logits of shape (batch_size, vocab_size)\n",
        "        \"\"\"\n",
        "\n",
        "        self.batch_size = inputs.shape[0]\n",
        "\n",
        "        \n",
        "        x_embed = self.embedding(inputs) + self.pos_embedding(inputs)\n",
        "        x_embed = self.dropout(x_embed)\n",
        "\n",
        "        #Definindo a máscara\n",
        "        mask = torch.tril(torch.ones(self.batch_size, self.max_seq_length, self.max_seq_length)).to(device)\n",
        "        mask = mask.masked_fill(inputs.unsqueeze(1) == self.pad_token_id, 0)\n",
        "        mask = mask.masked_fill(inputs.unsqueeze(2) == self.pad_token_id, 0)\n",
        "\n",
        "        for layer in self.multihead:\n",
        "          out = layer(x_embed, mask)\n",
        "          out = self.projection_W0(out)\n",
        "          out = self.dropout(out)\n",
        "          out =  self.layer_norm(out)\n",
        "\n",
        "        out = self.feed_forward(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teste o modelo com um exemplo"
      ],
      "metadata": {
        "id": "Rm6_PTH2i98e"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwnxfZlrZoT_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c2ad4f1-1d02-4a2d-f96a-904f3d640850"
      },
      "source": [
        "model = LanguageModel(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    max_seq_length=max_seq_length,\n",
        "    dim=64,\n",
        "    n_layers=2,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        ").to(device)\n",
        "\n",
        "sample_input, _ = next(iter(DataLoader(training_dataset)))\n",
        "sample_input = sample_input.to(device)\n",
        "sample_output = model(sample_input)\n",
        "print(f'sample_input.shape: {sample_input.shape}')\n",
        "print(f'sample_output.shape: {sample_output.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_input.shape: torch.Size([1, 9])\n",
            "sample_output.shape: torch.Size([1, 9, 29794])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3Vh6B-VkA01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a335d728-1244-43f9-cdd3-6cb495a5d015"
      },
      "source": [
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'Number of model parameters: {num_params}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of model parameters: 7694178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assert da Perplexidade\n"
      ],
      "metadata": {
        "id": "8nhbUVsYnVAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(123)\n",
        "np.random.seed(123)\n",
        "torch.manual_seed(123)\n",
        "\n",
        "\n",
        "def perplexity(logits, target, ignore_token_id: int):\n",
        "    \"\"\"\n",
        "    Computes the perplexity.\n",
        "\n",
        "    Args:\n",
        "        logits: a FloatTensor of shape (batch_size, seq_len, vocab_size)\n",
        "        target: a LongTensor of shape (batch_size, seq_len)\n",
        "\n",
        "    Returns:\n",
        "        A float corresponding to the perplexity\n",
        "    \"\"\"\n",
        "    logits = logits.reshape(-1, logits.shape[-1])\n",
        "    target = target.reshape(-1)\n",
        "    loss = nn.functional.cross_entropy(logits, target, reduction='mean', ignore_index=ignore_token_id)\n",
        "    return torch.exp(loss)\n",
        "\n",
        "\n",
        "n_examples = 1000\n",
        "\n",
        "train_input_ids, train_target_ids = next(iter(DataLoader(training_dataset, batch_size=n_examples)))\n",
        "train_input_ids = train_input_ids.to(device)\n",
        "train_target_ids = train_target_ids.to(device)\n",
        "\n",
        "logits = model(train_input_ids)\n",
        "\n",
        "my_perplexity = perplexity(logits=logits, target=train_target_ids, ignore_token_id=tokenizer.pad_token_id)\n",
        "\n",
        "print(f'my perplexity:              {int(my_perplexity)}')\n",
        "print(f'correct initial perplexity: {tokenizer.vocab_size}')\n",
        "\n",
        "assert math.isclose(my_perplexity, tokenizer.vocab_size, abs_tol=7000)\n",
        "print('Passou o no assert da perplexidade')"
      ],
      "metadata": {
        "id": "gbMP8VAUncfX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d929dab9-c6aa-47be-dc1e-955862e4c2ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my perplexity:              30715\n",
            "correct initial perplexity: 29794\n",
            "Passou o no assert da perplexidade\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Laço de Treinamento e Validação"
      ],
      "metadata": {
        "id": "KiJtrsqPnE_l"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIMSaY-UUGUE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "outputId": "63bff439-49c5-4130-d68c-96f20e57a2ae"
      },
      "source": [
        "max_examples = 150_000_000\n",
        "eval_every_steps = 10000\n",
        "lr = 3e-4\n",
        "\n",
        "\n",
        "model = LanguageModel(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    max_seq_length=max_seq_length,\n",
        "    dim=64,\n",
        "    n_layers=2,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        ").to(device)\n",
        "\n",
        "train_loader = DataLoader(training_dataset, batch_size=512, shuffle=True, drop_last=True)\n",
        "validation_loader = DataLoader(valid_dataset, batch_size=512)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "def train_step(input_ids, target_ids):\n",
        "    model.train()\n",
        "    model.zero_grad()\n",
        "    logits = model(input_ids)\n",
        "    logits = logits.reshape(-1, logits.shape[-1])\n",
        "    target_ids = target_ids.reshape(-1)\n",
        "    loss = nn.functional.cross_entropy(logits, target_ids, ignore_index=model.pad_token_id)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "def validation_step(input_ids, target_ids):\n",
        "    model.eval()\n",
        "    logits = model(input_ids)\n",
        "    logits = logits.reshape(-1, logits.shape[-1])\n",
        "    target_ids = target_ids.reshape(-1)\n",
        "    loss = nn.functional.cross_entropy(logits, target_ids, ignore_index=model.pad_token_id)\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "train_losses = []\n",
        "n_examples = 0\n",
        "step = 0\n",
        "while n_examples < max_examples:\n",
        "    for train_input_ids, train_target_ids in train_loader:\n",
        "        loss = train_step(train_input_ids.to(device), train_target_ids.to(device)) \n",
        "        train_losses.append(loss)\n",
        "        \n",
        "        if step % eval_every_steps == 0:\n",
        "            train_ppl = np.exp(np.average(train_losses))\n",
        "\n",
        "            with torch.no_grad():\n",
        "                valid_ppl = np.exp(np.average([\n",
        "                    validation_step(val_input_ids.to(device), val_target_ids.to(device))\n",
        "                    for val_input_ids, val_target_ids in validation_loader]))\n",
        "\n",
        "            print(f'{step} steps; {n_examples} examples so far; train ppl: {train_ppl:.2f}, valid ppl: {valid_ppl:.2f}')\n",
        "            train_losses = []\n",
        "\n",
        "        n_examples += len(train_input_ids)  # Increment of batch size\n",
        "        step += 1\n",
        "        if n_examples >= max_examples:\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 steps; 0 examples so far; train ppl: 30835.21, valid ppl: 30437.04\n",
            "10000 steps; 5120000 examples so far; train ppl: 862.86, valid ppl: 335.30\n",
            "20000 steps; 10240000 examples so far; train ppl: 520.14, valid ppl: 271.22\n",
            "30000 steps; 15360000 examples so far; train ppl: 457.31, valid ppl: 246.82\n",
            "40000 steps; 20480000 examples so far; train ppl: 426.74, valid ppl: 233.05\n",
            "50000 steps; 25600000 examples so far; train ppl: 407.16, valid ppl: 223.77\n",
            "60000 steps; 30720000 examples so far; train ppl: 393.80, valid ppl: 216.31\n",
            "70000 steps; 35840000 examples so far; train ppl: 382.79, valid ppl: 210.76\n",
            "80000 steps; 40960000 examples so far; train ppl: 374.35, valid ppl: 206.30\n",
            "90000 steps; 46080000 examples so far; train ppl: 367.62, valid ppl: 202.61\n",
            "100000 steps; 51200000 examples so far; train ppl: 361.86, valid ppl: 199.09\n",
            "110000 steps; 56320000 examples so far; train ppl: 356.99, valid ppl: 196.84\n",
            "120000 steps; 61440000 examples so far; train ppl: 352.51, valid ppl: 194.05\n",
            "130000 steps; 66560000 examples so far; train ppl: 348.39, valid ppl: 191.71\n",
            "140000 steps; 71680000 examples so far; train ppl: 345.38, valid ppl: 190.38\n",
            "150000 steps; 76800000 examples so far; train ppl: 341.81, valid ppl: 188.79\n",
            "160000 steps; 81920000 examples so far; train ppl: 339.50, valid ppl: 186.90\n",
            "170000 steps; 87040000 examples so far; train ppl: 337.24, valid ppl: 185.64\n",
            "180000 steps; 92160000 examples so far; train ppl: 334.83, valid ppl: 184.20\n",
            "190000 steps; 97280000 examples so far; train ppl: 332.40, valid ppl: 183.29\n",
            "200000 steps; 102400000 examples so far; train ppl: 330.58, valid ppl: 182.13\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-2bace4fbb163>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mn_examples\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_examples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target_ids\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-2bace4fbb163>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(input_ids, target_ids)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mtarget_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliação final no dataset de teste\n",
        "\n",
        "\n",
        "Bonus: o modelo com menor perplexidade no dataset de testes ganhará 0.5 ponto na nota final."
      ],
      "metadata": {
        "id": "VgdNymJdNPXP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxN5YytzZ7Tn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1be2ba95-a72a-40ca-d3ee-42f110053473"
      },
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_ppl = np.exp(np.average([\n",
        "        validation_step(test_input_ids.to(device), test_target_ids.to(device))\n",
        "        for test_input_ids, test_target_ids in test_loader\n",
        "    ]))\n",
        "\n",
        "print(f'test perplexity: {test_ppl}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test perplexity: 182.81023934259906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teste seu modelo com uma sentença\n",
        "\n",
        "Escolha uma sentença gerada pelo modelo que ache interessante."
      ],
      "metadata": {
        "id": "BHvEs8mPszy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'Eu gosto de comer pizza pois me faz'\n",
        "max_output_tokens = 20\n",
        "model.eval()\n",
        "\n",
        "for _ in range(max_output_tokens):\n",
        "    input_ids = tokenize(text=prompt, tokenizer=tokenizer)\n",
        "    input_ids_truncated = input_ids[-max_seq_length:]  # Usamos apenas os últimos <max_seq_length> tokens como entrada para o modelo.\n",
        "    logits = model(torch.LongTensor([input_ids_truncated]).to(device))\n",
        "    logits = logits[:, -1, :]  # Usamos apenas o ultimo token da sequencia\n",
        "    # Ao usarmos o argmax, a saída do modelo em cada passo é o token de maior probabilidade.\n",
        "    # Isso se chama decodificação gulosa (greedy decoding).\n",
        "    predicted_id = torch.argmax(logits).item()\n",
        "    input_ids += [predicted_id]  # Concatenamos a entrada com o token escolhido nesse passo.\n",
        "    prompt = tokenizer.decode(input_ids)\n",
        "    print(prompt)"
      ],
      "metadata": {
        "id": "-CFElf4tsytW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eac2cda5-bdd9-4c18-8a9d-a916b113ffb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eu gosto de comer pizza pois me faz parte\n",
            "Eu gosto de comer pizza pois me faz parte da\n",
            "Eu gosto de comer pizza pois me faz parte da vida\n",
            "Eu gosto de comer pizza pois me faz parte da vida,\n",
            "Eu gosto de comer pizza pois me faz parte da vida, mas\n",
            "Eu gosto de comer pizza pois me faz parte da vida, mas não\n",
            "Eu gosto de comer pizza pois me faz parte da vida, mas não é\n",
            "Eu gosto de comer pizza pois me faz parte da vida, mas não é o\n",
            "Eu gosto de comer pizza pois me faz parte da vida, mas não é o que\n",
            "Eu gosto de comer pizza pois me faz parte da vida, mas não é o que é\n",
            "Eu gosto de comer pizza pois me faz parte da vida, mas não é o que é o\n",
            "Eu gosto de comer pizza pois me faz parte da vida, mas não é o que é o que\n",
            "Eu gosto de comer pizza pois me faz parte da vida, mas não é o que é o que não\n",
            "Eu gosto de comer pizza pois me faz parte da vida, mas não é o que é o que não é\n",
            "Eu gosto de comer pizza pois me faz parte da vida, mas não é o que é o que não é o\n",
            "Eu gosto de comer pizza pois me faz parte da vida, mas não é o que é o que não é o que\n",
            "Eu gosto de comer pizza pois me faz parte da vida, mas não é o que é o que não é o que o\n",
            "Eu gosto de comer pizza pois me faz parte da vida, mas não é o que é o que não é o que o que\n",
            "Eu gosto de comer pizza pois me faz parte da vida, mas não é o que é o que não é o que o que o\n",
            "Eu gosto de comer pizza pois me faz parte da vida, mas não é o que é o que não é o que o que o que\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'Todas as cartas de amor são ridículas. Não seriam'\n",
        "max_output_tokens = 20\n",
        "model.eval()\n",
        "\n",
        "for _ in range(max_output_tokens):\n",
        "    input_ids = tokenize(text=prompt, tokenizer=tokenizer)\n",
        "    input_ids_truncated = input_ids[-max_seq_length:]  # Usamos apenas os últimos <max_seq_length> tokens como entrada para o modelo.\n",
        "    logits = model(torch.LongTensor([input_ids_truncated]).to(device))\n",
        "    logits = logits[:, -1, :]  # Usamos apenas o ultimo token da sequencia\n",
        "    # Ao usarmos o argmax, a saída do modelo em cada passo é o token de maior probabilidade.\n",
        "    # Isso se chama decodificação gulosa (greedy decoding).\n",
        "    predicted_id = torch.argmax(logits).item()\n",
        "    input_ids += [predicted_id]  # Concatenamos a entrada com o token escolhido nesse passo.\n",
        "    prompt = tokenizer.decode(input_ids)\n",
        "    print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWbeqd1dhyTy",
        "outputId": "8981b9ea-2ae2-426e-b17a-12add4b0c44f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Todas as cartas de amor são ridículas. Não seriam os\n",
            "Todas as cartas de amor são ridículas. Não seriam os seus\n",
            "Todas as cartas de amor são ridículas. Não seriam os seus filhos\n",
            "Todas as cartas de amor são ridículas. Não seriam os seus filhos,\n",
            "Todas as cartas de amor são ridículas. Não seriam os seus filhos, mas\n",
            "Todas as cartas de amor são ridículas. Não seriam os seus filhos, mas não\n",
            "Todas as cartas de amor são ridículas. Não seriam os seus filhos, mas não é\n",
            "Todas as cartas de amor são ridículas. Não seriam os seus filhos, mas não é o\n",
            "Todas as cartas de amor são ridículas. Não seriam os seus filhos, mas não é o que\n",
            "Todas as cartas de amor são ridículas. Não seriam os seus filhos, mas não é o que não\n",
            "Todas as cartas de amor são ridículas. Não seriam os seus filhos, mas não é o que não é\n",
            "Todas as cartas de amor são ridículas. Não seriam os seus filhos, mas não é o que não é o\n",
            "Todas as cartas de amor são ridículas. Não seriam os seus filhos, mas não é o que não é o que\n",
            "Todas as cartas de amor são ridículas. Não seriam os seus filhos, mas não é o que não é o que não\n",
            "Todas as cartas de amor são ridículas. Não seriam os seus filhos, mas não é o que não é o que não é\n",
            "Todas as cartas de amor são ridículas. Não seriam os seus filhos, mas não é o que não é o que não é o\n",
            "Todas as cartas de amor são ridículas. Não seriam os seus filhos, mas não é o que não é o que não é o que\n",
            "Todas as cartas de amor são ridículas. Não seriam os seus filhos, mas não é o que não é o que não é o que o\n",
            "Todas as cartas de amor são ridículas. Não seriam os seus filhos, mas não é o que não é o que não é o que o que\n",
            "Todas as cartas de amor são ridículas. Não seriam os seus filhos, mas não é o que não é o que não é o que o que o\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'Muito prazer meu nome é otário vindo de outros'\n",
        "max_output_tokens = 20\n",
        "model.eval()\n",
        "\n",
        "for _ in range(max_output_tokens):\n",
        "    input_ids = tokenize(text=prompt, tokenizer=tokenizer)\n",
        "    input_ids_truncated = input_ids[-max_seq_length:]  # Usamos apenas os últimos <max_seq_length> tokens como entrada para o modelo.\n",
        "    logits = model(torch.LongTensor([input_ids_truncated]).to(device))\n",
        "    logits = logits[:, -1, :]  # Usamos apenas o ultimo token da sequencia\n",
        "    # Ao usarmos o argmax, a saída do modelo em cada passo é o token de maior probabilidade.\n",
        "    # Isso se chama decodificação gulosa (greedy decoding).\n",
        "    predicted_id = torch.argmax(logits).item()\n",
        "    input_ids += [predicted_id]  # Concatenamos a entrada com o token escolhido nesse passo.\n",
        "    prompt = tokenizer.decode(input_ids)\n",
        "    print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7iDX8tXjRi8",
        "outputId": "fec68b8b-106d-49db-bd29-8ed4fa7ae12c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Muito prazer meu nome é otário vindo de outros.\n",
            "Muito prazer meu nome é otário vindo de outros. O\n",
            "Muito prazer meu nome é otário vindo de outros. O que\n",
            "Muito prazer meu nome é otário vindo de outros. O que o\n",
            "Muito prazer meu nome é otário vindo de outros. O que o que\n",
            "Muito prazer meu nome é otário vindo de outros. O que o que se\n",
            "Muito prazer meu nome é otário vindo de outros. O que o que se refere\n",
            "Muito prazer meu nome é otário vindo de outros. O que o que se refere ao\n",
            "Muito prazer meu nome é otário vindo de outros. O que o que se refere ao seu\n",
            "Muito prazer meu nome é otário vindo de outros. O que o que se refere ao seu trabalho\n",
            "Muito prazer meu nome é otário vindo de outros. O que o que se refere ao seu trabalho é\n",
            "Muito prazer meu nome é otário vindo de outros. O que o que se refere ao seu trabalho é o\n",
            "Muito prazer meu nome é otário vindo de outros. O que o que se refere ao seu trabalho é o que\n",
            "Muito prazer meu nome é otário vindo de outros. O que o que se refere ao seu trabalho é o que o\n",
            "Muito prazer meu nome é otário vindo de outros. O que o que se refere ao seu trabalho é o que o que\n",
            "Muito prazer meu nome é otário vindo de outros. O que o que se refere ao seu trabalho é o que o que o\n",
            "Muito prazer meu nome é otário vindo de outros. O que o que se refere ao seu trabalho é o que o que o que\n",
            "Muito prazer meu nome é otário vindo de outros. O que o que se refere ao seu trabalho é o que o que o que é\n",
            "Muito prazer meu nome é otário vindo de outros. O que o que se refere ao seu trabalho é o que o que o que é o\n",
            "Muito prazer meu nome é otário vindo de outros. O que o que se refere ao seu trabalho é o que o que o que é o que\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wtpi8UWni9Rf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bonus 1\n",
        "Quem conseguir a menor perplexidade no dataset de testes ganha 0.5 ponto na média final.\n",
        "\n",
        "## Bonus 2\n",
        "Qual é a complexidade (em notação O-grande) da função de geração de texto acima?\n",
        "\n",
        "Quem responder corretamente a pergunta acima e deixar a função com menor complexidade ganha 0.5 ponto na média final."
      ],
      "metadata": {
        "id": "nGdxlXhGq7Ua"
      }
    }
  ]
}