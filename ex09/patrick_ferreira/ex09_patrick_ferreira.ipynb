{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/unicamp-dl/IA025_2022S1/blob/main/ex09/patrick_ferreira/ex09_patrick_ferreira.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jOdQB41_4ZxG",
    "outputId": "c7fee724-047f-4375-96f9-5a3fb16f5ada"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meu nome é Patrick de Carvalho Tavares Rezende Ferreira\n"
     ]
    }
   ],
   "source": [
    "nome = \"Patrick de Carvalho Tavares Rezende Ferreira\"\n",
    "print(f'Meu nome é {nome}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2IbuChoAPMEn"
   },
   "source": [
    "#  Exercício: Modelo de Linguagem com auto-atenção"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_DBb0-Klwf2"
   },
   "source": [
    "Este exercício é similar ao da Aula 8, mas iremos agora treinar uma rede neural com **duas camadas** de auto-atenção **causais** para prever a próxima palavra de um texto, data as palavras anteriores como entrada. \n",
    "\n",
    "Iremos também trabalhar com sequencias de tamanho variável.\n",
    "\n",
    "Na camada de auto-atenção, não se esqueça de implementar:\n",
    "- Embeddings de posição\n",
    "- Projeções lineares (WQ, WK, WV, WO)\n",
    "- Conexões residuais\n",
    "- Camada de feed forward (2-layer MLP)\n",
    "\n",
    "\n",
    "O dataset usado neste exercício (BrWaC) possui um tamanho razoável e você vai precisar rodar seus experimentos com GPU.\n",
    "\n",
    "Alguns conselhos úteis:\n",
    "- **ATENÇÃO:** o dataset é bem grande. Não dê comando de imprimí-lo.\n",
    "- Durante a depuração, faça seu dataset ficar bem pequeno, para que a depuração seja mais rápida e não precise de GPU. Somente ligue a GPU quando o seu laço de treinamento já está funcionando\n",
    "- Não deixe para fazer esse exercício na véspera. Ele é trabalhoso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3twP0YJC4jmJ",
    "outputId": "25500d5b-4181-4e04-9dba-6a2f6a30082c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/patrickctrf/anaconda3/lib/python3.9/site-packages (4.19.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/patrickctrf/anaconda3/lib/python3.9/site-packages (from transformers) (2022.3.15)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /home/patrickctrf/anaconda3/lib/python3.9/site-packages (from transformers) (1.21.5)\r\n",
      "Requirement already satisfied: filelock in /home/patrickctrf/anaconda3/lib/python3.9/site-packages (from transformers) (3.6.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/patrickctrf/anaconda3/lib/python3.9/site-packages (from transformers) (21.3)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/patrickctrf/anaconda3/lib/python3.9/site-packages (from transformers) (0.12.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/patrickctrf/anaconda3/lib/python3.9/site-packages (from transformers) (0.7.0)\r\n",
      "Requirement already satisfied: requests in /home/patrickctrf/anaconda3/lib/python3.9/site-packages (from transformers) (2.27.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/patrickctrf/anaconda3/lib/python3.9/site-packages (from transformers) (6.0)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/patrickctrf/anaconda3/lib/python3.9/site-packages (from transformers) (4.64.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/patrickctrf/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/patrickctrf/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/patrickctrf/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.3)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/patrickctrf/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.9)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/patrickctrf/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/patrickctrf/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\r\n"
     ]
    }
   ],
   "source": [
    "# iremos utilizar a biblioteca dos transformers para ter acesso ao tokenizador do BERT.\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnyhJZtTRNMx"
   },
   "source": [
    "## Importação dos pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qlIOVCajPWcU"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import itertools\n",
    "import functools\n",
    "import math\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm_notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w9f3PfifAwpU",
    "outputId": "f56ab05f-e696-497f-f3b1-e751097e2cd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun  9 03:45:08 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 510.73.05    Driver Version: 510.73.05    CUDA Version: 11.6     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\r\n",
      "|  0%   47C    P8    13W / 170W |    184MiB / 12288MiB |      2%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1960      G   /usr/lib/xorg/Xorg                118MiB |\r\n",
      "|    0   N/A  N/A      2095      G   ...ome-remote-desktop-daemon        2MiB |\r\n",
      "|    0   N/A  N/A      2132      G   /usr/bin/gnome-shell               44MiB |\r\n",
      "|    0   N/A  N/A     38888      G   ..._38629.log --shared-files       16MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "# Check which GPU we are using\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "whTCe2i7AtoV",
    "outputId": "a1ca6873-c0b5-4ab4-83f5-719aff6f4947"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available(): \n",
    "   dev = \"cuda:0\"\n",
    "else: \n",
    "   dev = \"cpu\"\n",
    "device = torch.device(dev)\n",
    "print('Using {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ZfxgV2DUk58"
   },
   "source": [
    "## Implementação do MyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "n_xhKm1EZ3bQ"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def tokenize(text: str, tokenizer):\n",
    "    # Recomenda-se usar o tokenizer.batch_encode_plus pois é mais rápido.\n",
    "    return tokenizer(text, return_tensors=None, add_special_tokens=False).input_ids\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def pad_list(variable_len_list, output_len = 9, pad_value=0):\n",
    "    padded_list = [pad_value] * output_len\n",
    "    padded_list[:len(variable_len_list)] = variable_len_list[:]\n",
    "    return padded_list\n",
    "\n",
    "class MyDataset():\n",
    "    def __init__(self, texts: List[str], tokenizer, max_seq_length: int):\n",
    "        # Escreva seu código aqui\n",
    "        try:\n",
    "            self.x = np.load(\"x_\" + str(len(texts)) + \".npy\", mmap_mode=\"r\", allow_pickle=True)\n",
    "            self.y = np.load(\"y_\" + str(len(texts)) + \".npy\", mmap_mode=\"r\", allow_pickle=True)\n",
    "\n",
    "            print(\"Carregando dataset preprocessado\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Excecao: \", e)\n",
    "            print(\"Montando dataset\")\n",
    "\n",
    "            self.x = list()\n",
    "            self.y = list()\n",
    "\n",
    "            for text in tqdm(texts):\n",
    "                token_ids = tokenize(text, tokenizer)\n",
    "                for i in range(0,len(token_ids),max_seq_length):\n",
    "                    self.x.append(pad_list(tokenize(text='[CLS]', tokenizer=tokenizer) + token_ids[i:i+max_seq_length-1], output_len=max_seq_length, pad_value=tokenizer.pad_token_id))\n",
    "                    self.y.append(pad_list(token_ids[i:i+max_seq_length], output_len=max_seq_length, pad_value=tokenizer.pad_token_id))\n",
    "\n",
    "            self.x = np.array(self.x)\n",
    "            self.y = np.array(self.y)\n",
    "\n",
    "            np.save(\"x_\" + str(len(texts)) + \".npy\", self.x)\n",
    "            np.save(\"y_\" + str(len(texts)) + \".npy\", self.y)\n",
    "\n",
    "    def __len__(self):\n",
    "        # Escreva seu código aqui\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Escreva seu código aqui\n",
    "        return torch.tensor(self.x[idx]).long(), torch.tensor(self.y[idx]).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wew-gFbWeBTq"
   },
   "source": [
    "## Testando se a implementação do MyDataset está correta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395,
     "referenced_widgets": [
      "65353e8cc72b4e0ca3e8f1d473c52981",
      "b8f7590770694f54a458a27f9550e901",
      "50f4d4a9c04e4dbbb935af1a50443036",
      "36f249a65f6b4fd89a844177e560c22e",
      "2ad38c47cb4945dd8ca1cd9f58d26366",
      "948c4211ae4f431d9508f39341c87115",
      "8380bc0527c14f229009a0f07db8f943",
      "43105df07006440698ea7ceb0c3e9cea",
      "846bd0d8300d449e981f9fd629503d8f",
      "1d7ba288f7994a41934f924131848c8b",
      "bf72b3bf99e74c2fa6ede393314588df",
      "25fcb32ab6004207a61851ce06aca6b0",
      "a3d12be640b4410abfade3f74ad4eb93",
      "9daf832318a643cca5b36aa90ffddd63",
      "d0bb2ed4018e4099867e2e71d406e054",
      "0c1807c88ec4493782a59aafd3189524",
      "09ca6f3a160548b5b031e60333bceb7a",
      "8ae6ca6ae1a542e3af820b93a58d3b47",
      "6e767f283fbd4d81bf48cdd3c27ef9b8",
      "64d3c1102f764525bc0917ce15fe50ce",
      "511628d7aea6440eb7c7ceb4cc502cb9",
      "4e0ccbd570fd410e8ec5a3353c5ecd70",
      "d5004778faec4fd78e3c02979033613f",
      "1fd73c9ef2024ae8910179fbc34170de",
      "c6c3ed4552a0417fb033e40910ff4ad5",
      "dd2ffd9dd40e4cf2b3d03c7275302c69",
      "b0138036512b4f76b694890862f3157b",
      "4934ebc4b76645aca633d97c1bcaa4ad",
      "f3fc4417238f4f33a2f4194c427f9dd8",
      "44d4723a8c014891b164c8bcf52d03f5",
      "4536e27d89e74acf971faa86e6af5a52",
      "c66799fca73041bdaec8c506925f839b",
      "7779774d7e3848a5b4483a6835573720",
      "86cfec7bb7fd4c1cba0ee65600d49133",
      "725528bc269f400e8f6a2a321875e5fa",
      "f40544445eca4ad8ac232bf631faa4c6",
      "fa64718699f8409e94b480f20431f8e1",
      "a429e64a9fbb4aa5ba0ceab0ca80c7bd",
      "c93e3adfa6b04031b882b13f65c03c30",
      "df5cb1dd3c324d209316afc9e1a258b2",
      "6d18de7983e74a078f4f0a88ae2c3fdd",
      "478d77b6cf094843bfab38ee2c101b23",
      "489b591919e94a65ab61db9c8a36e7d8",
      "cf84f782913d4e8ba328da541b0c01de",
      "ce2666c9d3ea42f5951acf88860fd661",
      "7d7548b9569a4957a9dd08152820e10d",
      "c7b0c070d5ce4487891c878a269297fd",
      "3ab4bc7cb9824fd698b68638a36b05ea",
      "975caa6fb29a466ab282a97d5255b224",
      "120c9499a0384745b1454d0c0c6973ac",
      "3071b72c700e4afc9e2c25d0129f493c",
      "052d85df4565408080ff6a7346b35c5c",
      "4afc1399603942609718065dc03a462a",
      "612ededf3abc4e01a276b8599020b15d",
      "89f0d697a43046b2aa6a06b128dd6e81"
     ]
    },
    "id": "8r7jBFFUeApe",
    "outputId": "5f9c9b28-3bb0-45f4-83ef-1570cf176e77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dataset preprocessado\n",
      "Passou no assert de tamanho do dataset.\n",
      "Passou no assert de dataset.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
    "\n",
    "dummy_texts = ['Eu gosto de correr', 'Ela gosta muito de comer pizza']\n",
    "\n",
    "dummy_dataset = MyDataset(texts=dummy_texts, tokenizer=tokenizer, max_seq_length=9)\n",
    "dummy_loader = DataLoader(dummy_dataset, batch_size=6, shuffle=False)\n",
    "assert len(dummy_dataset) == 2\n",
    "print('Passou no assert de tamanho do dataset.')\n",
    "\n",
    "first_batch_input, first_batch_target = next(iter(dummy_loader))\n",
    "\n",
    "correct_first_batch_input = torch.LongTensor(\n",
    "    [[  101,  3396, 10303,   125, 13239,     0,     0,     0,     0],\n",
    "     [  101,  1660,  5971,   785,   125,  1847, 13779, 15616,     0]])\n",
    "\n",
    "correct_first_batch_target = torch.LongTensor(\n",
    "    [[ 3396, 10303,   125, 13239,     0,     0,     0,     0,     0],\n",
    "     [ 1660,  5971,   785,   125,  1847, 13779, 15616,     0,     0]])\n",
    "\n",
    "assert torch.equal(first_batch_input, correct_first_batch_input)\n",
    "assert torch.equal(first_batch_target, correct_first_batch_target)\n",
    "\n",
    "print('Passou no assert de dataset.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LfrHHouleJ0"
   },
   "source": [
    "# Carregamento do dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2vFWjsSkmop"
   },
   "source": [
    "Iremos usar uma pequena amostra do dataset [BrWaC](https://www.inf.ufrgs.br/pln/wiki/index.php?title=BrWaC) para treinar e avaliar nosso modelo de linguagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "vGlN1WqrXPA6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘sample-1gb.txt’ already there; not retrieving.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://storage.googleapis.com/unicamp-dl/ia025a_2022s1/aula9/sample-1gb.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gxa_4gmiA-wE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 250000 lines.\n",
      "Carregando dataset preprocessado\n",
      "Carregando dataset preprocessado\n",
      "Carregando dataset preprocessado\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "max_seq_length = 9\n",
    "\n",
    "train_examples = 500\n",
    "valid_examples = 101\n",
    "test_examples = 100\n",
    "\n",
    "texts = open('sample-1gb.txt').readlines()\n",
    "\n",
    "print(f'Read {len(texts)} lines.')\n",
    "\n",
    "# max_lines = train_examples + valid_examples + test_examples\n",
    "# print(f'Truncating to {max_lines} lines.')\n",
    "# texts = texts[:max_lines]\n",
    "\n",
    "training_texts = texts[:-(valid_examples + test_examples)]\n",
    "valid_texts = texts[-(valid_examples + test_examples):-test_examples]\n",
    "test_texts = texts[-test_examples:]\n",
    "\n",
    "training_dataset = MyDataset(texts=training_texts, tokenizer=tokenizer, max_seq_length=max_seq_length)\n",
    "valid_dataset = MyDataset(texts=valid_texts, tokenizer=tokenizer, max_seq_length=max_seq_length)\n",
    "test_dataset = MyDataset(texts=test_texts, tokenizer=tokenizer, max_seq_length=max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "KCSGJ5m7py4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training examples: 31158126\n",
      "valid examples: 14784\n",
      "test examples: 8302\n"
     ]
    }
   ],
   "source": [
    "print(f'training examples: {len(training_dataset)}')\n",
    "print(f'valid examples: {len(valid_dataset)}')\n",
    "print(f'test examples: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hGaAjYDfWdd1"
   },
   "outputs": [],
   "source": [
    "\n",
    "class AttentionLayer(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim: int,):\n",
    "        \"\"\"\n",
    "        Implements the Self-attention, decoder-only.\"\n",
    "\n",
    "        Args:\n",
    "            vocab_size (int): Size of the input vocabulary.\n",
    "            max_seq_length (int): Size of the sequence to consider as context for prediction.\n",
    "            dim (int): Dimension of the embedding layer for each word in the context.\n",
    "            n_layers (int): number of self-attention layers.\n",
    "            pad_token_id (int): id of the pad token that will be ignored in the attention.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        context_size = max_seq_length\n",
    "        self.context_size = context_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # hidden_size for MLP\n",
    "        hidden_size = 2048\n",
    "\n",
    "        # Linear projections\n",
    "        self.w_q = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.w_k = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.w_v = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.w_0 = nn.Linear(embedding_dim, embedding_dim)\n",
    "\n",
    "        # output MLP\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size, embedding_dim)\n",
    "        )\n",
    "\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        # cast to probabilities\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(embedding_dim)\n",
    "        self.norm2 = nn.LayerNorm(embedding_dim)\n",
    "\n",
    "        # Matriz triangular de mascara, convertida para Booleano\n",
    "        # Onde vale 1, o valor deve ser substituida por um valor negativo alto no tensor de scores.\n",
    "        self.casual_mask = torch.ones((max_seq_length, max_seq_length), device=device).triu(diagonal=1) == 1.0\n",
    "\n",
    "    def forward(self, x_embeddings):\n",
    "\n",
    "        k = self.w_k(x_embeddings)\n",
    "        v = self.w_v(x_embeddings)\n",
    "        q = self.w_q(x_embeddings)\n",
    "\n",
    "        scores = torch.matmul(q, k.transpose(1, 2))\n",
    "\n",
    "        # Onde a mascara vale 1, retornamos um valor negativo grande.\n",
    "        # Onde a mascara vale zero, matemos intacto.\n",
    "        probabilities = self.softmax(scores.masked_fill(self.casual_mask, -1e4))\n",
    "\n",
    "        e = self.w_0(self.norm1(x_embeddings + torch.matmul(probabilities, v)))\n",
    "\n",
    "        logits = self.mlp(e)\n",
    "\n",
    "        return self.activation(self.norm2(logits + e))\n",
    "\n",
    "class LanguageModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size: int, max_seq_length: int, dim: int, n_layers: int, pad_token_id: int):\n",
    "        \"\"\"\n",
    "        Implements the Self-attention, decoder-only.\"\n",
    "\n",
    "        Args:\n",
    "            vocab_size (int): Size of the input vocabulary.\n",
    "            max_seq_length (int): Size of the sequence to consider as context for prediction.\n",
    "            dim (int): Dimension of the embedding layer for each word in the context.\n",
    "            n_layers (int): number of self-attention layers.\n",
    "            pad_token_id (int): id of the pad token that will be ignored in the attention.\n",
    "        \"\"\"\n",
    "        # Escreva seu código aqui.\n",
    "        super().__init__()\n",
    "        embedding_dim = dim\n",
    "        context_size = max_seq_length\n",
    "        self.context_size = context_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.pad_token_id = pad_token_id\n",
    "\n",
    "        # hidden_size for MLP\n",
    "        hidden_size = 10 * embedding_dim\n",
    "\n",
    "        # tokens (words indexes) embedding and positional embedding\n",
    "        self.c_embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.p_embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        self.attention1 = AttentionLayer(embedding_dim=embedding_dim)\n",
    "        self.attention2 = AttentionLayer(embedding_dim=embedding_dim)\n",
    "\n",
    "        self.linear_output = nn.Linear(embedding_dim, vocab_size)\n",
    "\n",
    "        # cast to probabilities\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "        self.positional_indexes = torch.arange(self.context_size, device=device).view(1, -1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs is a LongTensor of shape (batch_size, max_seq_length)\n",
    "\n",
    "        Returns:\n",
    "            logits of shape (batch_size, max_seq_length, vocab_size)\n",
    "        \"\"\"\n",
    "        # Escreva seu código aqui.\n",
    "\n",
    "        input_embeddings = self.c_embedding(inputs)\n",
    "\n",
    "        positional_embeddings = self.p_embedding(self.positional_indexes.repeat(inputs.shape[0], 1))\n",
    "\n",
    "        x_embeddings = positional_embeddings + input_embeddings\n",
    "\n",
    "        logits = self.attention1(x_embeddings)\n",
    "        logits = self.attention2(logits)\n",
    "\n",
    "        return self.linear_output(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rm6_PTH2i98e"
   },
   "source": [
    "## Teste o modelo com um exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "RwnxfZlrZoT_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_input.shape: torch.Size([1, 9])\n",
      "sample_output.shape: torch.Size([1, 9, 29794])\n"
     ]
    }
   ],
   "source": [
    "# print(\"tokenizer.pad_token_id: \", tokenizer.pad_token_id)\n",
    "\n",
    "model = LanguageModel(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    max_seq_length=max_seq_length,\n",
    "    dim=64,\n",
    "    n_layers=2,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    ").to(device)\n",
    "\n",
    "sample_input, _ = next(iter(DataLoader(training_dataset)))\n",
    "sample_input = sample_input.to(device)\n",
    "sample_output = model(sample_input)\n",
    "print(f'sample_input.shape: {sample_input.shape}')\n",
    "print(f'sample_output.shape: {sample_output.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "I3Vh6B-VkA01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model parameters: 6312546\n"
     ]
    }
   ],
   "source": [
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Number of model parameters: {num_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8nhbUVsYnVAp"
   },
   "source": [
    "## Assert da Perplexidade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "gbMP8VAUncfX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my perplexity:              31422\n",
      "correct initial perplexity: 29794\n",
      "Passou o no assert da perplexidade\n"
     ]
    }
   ],
   "source": [
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "def perplexity(logits, target, ignore_token_id: int):\n",
    "    \"\"\"\n",
    "    Computes the perplexity.\n",
    "\n",
    "    Args:\n",
    "        logits: a FloatTensor of shape (batch_size, seq_length, vocab_size)\n",
    "        target: a LongTensor of shape (batch_size, seq_length)\n",
    "\n",
    "    Returns:\n",
    "        A float corresponding to the perplexity\n",
    "    \"\"\"\n",
    "    logits = logits.reshape(-1, logits.shape[-1])\n",
    "    target = target.reshape(-1)\n",
    "    loss = nn.functional.cross_entropy(logits, target, reduction='mean', ignore_index=ignore_token_id)\n",
    "    return torch.exp(loss)\n",
    "\n",
    "\n",
    "n_examples = 1024\n",
    "\n",
    "train_input_ids, train_target_ids = next(iter(DataLoader(training_dataset, batch_size=n_examples)))\n",
    "train_input_ids = train_input_ids.to(device)\n",
    "train_target_ids = train_target_ids.to(device)\n",
    "\n",
    "logits = model(train_input_ids)\n",
    "\n",
    "my_perplexity = perplexity(logits=logits, target=train_target_ids, ignore_token_id=tokenizer.pad_token_id)\n",
    "\n",
    "print(f'my perplexity:              {int(my_perplexity)}')\n",
    "print(f'correct initial perplexity: {tokenizer.vocab_size}')\n",
    "\n",
    "assert math.isclose(my_perplexity, tokenizer.vocab_size, abs_tol=7000)\n",
    "print('Passou o no assert da perplexidade')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KiJtrsqPnE_l"
   },
   "source": [
    "## Laço de Treinamento e Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "from threading import Thread\n",
    "\n",
    "\n",
    "class DataManager(Thread):\n",
    "    def __init__(self, data_loader, buffer_size=3, device=torch.device(\"cpu\"), data_type=torch.float32):\n",
    "        \"\"\"\n",
    "This manager intends to load a PyTorch dataloader like from disk into memory,\n",
    "reducing the acess time. It does not easily overflow memory, because we set a\n",
    "buffer size limiting how many samples will be loaded at once. Everytime a sample\n",
    "is consumed by the calling thread, another one is replaced in the\n",
    "buffer (unless we reach the end of dataloader).\n",
    "\n",
    "A manger may be called exactly like a dataloader, an it's based in an internal\n",
    "thread that loads samples into memory in parallel. This is specially useful\n",
    "when you are training in GPU and processor is almost idle.\n",
    "\n",
    "        :param data_loader: Base dataloader to load in parallel.\n",
    "        :param buffer_size: How many samples to keep loaded (caution to not overflow RAM). Default: 3.\n",
    "        :param device: Torch device to put samples in, like torch.device(\"cpu\") (default). It saves time by transfering in parallel.\n",
    "        :param data_type: Automatically casts tensor type. Default: torch.float32.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.buffer_queue = Queue(maxsize=buffer_size)\n",
    "        self.data_loader = data_loader\n",
    "        self.buffer_size = buffer_size\n",
    "        self.device = device\n",
    "        self.data_type = data_type\n",
    "\n",
    "        self.dataloader_finished = False\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "Runs the internal thread that iterates over the dataloader until fulfilling the\n",
    "buffer or the end of samples.\n",
    "        \"\"\"\n",
    "        for i, (x, y) in enumerate(self.data_loader):\n",
    "            # Important to set before put in queue to avoid race condition\n",
    "            # would happen if trying to get() in next() method before setting this flag\n",
    "            if i >= len(self) - 1:\n",
    "                self.dataloader_finished = True\n",
    "\n",
    "            self.buffer_queue.put([x.to(self.data_type).to(self.device),\n",
    "                                   y.to(self.data_type).to(self.device)])\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "Returns an iterable of itself.\n",
    "\n",
    "        :return: Iterable around this class.\n",
    "        \"\"\"\n",
    "        self.start()\n",
    "        self.dataloader_finished = False\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        \"\"\"\n",
    "Intended to be used as iterator.\n",
    "\n",
    "        :return: Next iteration element.\n",
    "        \"\"\"\n",
    "        if self.dataloader_finished is True and self.buffer_queue.empty():\n",
    "            raise StopIteration()\n",
    "\n",
    "        return self.buffer_queue.get()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "zIMSaY-UUGUE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3072/200000000 [00:04<69:26:12, 800.08it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 steps; 0 examples so far; train ppl: 32048.32, valid ppl: 31972.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 10244096/200000000 [11:10<12:17:36, 4287.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 steps; 10240000 examples so far; train ppl: 375.47, valid ppl: 313.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 20484096/200000000 [22:03<11:38:35, 4282.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 steps; 20480000 examples so far; train ppl: 278.54, valid ppl: 288.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 27660288/200000000 [29:40<3:03:39, 15639.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27009: reducing learning rate of group 0 to 4.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 30724096/200000000 [32:56<10:46:07, 4366.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 steps; 30720000 examples so far; train ppl: 263.32, valid ppl: 274.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 40963950/200000000 [43:54<11:05:21, 3983.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000 steps; 40959854 examples so far; train ppl: 252.79, valid ppl: 268.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 41316206/200000000 [44:16<2:48:26, 15701.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40346: reducing learning rate of group 0 to 3.2000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 51036014/200000000 [54:35<2:38:04, 15705.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49837: reducing learning rate of group 0 to 2.5600e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 51203950/200000000 [54:47<9:27:01, 4373.60it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 steps; 51199854 examples so far; train ppl: 247.32, valid ppl: 262.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 56156014/200000000 [1:00:02<2:32:54, 15677.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54838: reducing learning rate of group 0 to 2.0480e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 61443950/200000000 [1:05:40<7:03:01, 5458.86it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 steps; 61439854 examples so far; train ppl: 242.43, valid ppl: 258.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 71143132/200000000 [1:16:02<2:16:24, 15744.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69473: reducing learning rate of group 0 to 1.6384e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 71683804/200000000 [1:16:38<8:26:45, 4220.18it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000 steps; 71679708 examples so far; train ppl: 238.79, valid ppl: 255.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 76263132/200000000 [1:21:29<2:11:05, 15730.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74474: reducing learning rate of group 0 to 1.3107e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 81923804/200000000 [1:27:31<7:09:34, 4581.12it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000 steps; 81919708 examples so far; train ppl: 236.55, valid ppl: 253.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 90371804/200000000 [1:36:28<1:56:17, 15710.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88251: reducing learning rate of group 0 to 1.0486e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 92161756/200000000 [1:38:24<8:14:44, 3632.79it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90000 steps; 92159708 examples so far; train ppl: 235.35, valid ppl: 251.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 95491658/200000000 [1:42:00<1:50:34, 15752.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93252: reducing learning rate of group 0 to 9.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 102403658/200000000 [1:49:22<6:25:29, 4219.52it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 steps; 102399562 examples so far; train ppl: 233.14, valid ppl: 250.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 112643658/200000000 [2:00:28<4:55:23, 4928.72it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110000 steps; 112639562 examples so far; train ppl: 232.67, valid ppl: 250.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 122883658/200000000 [2:11:25<4:32:40, 4713.64it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120000 steps; 122879562 examples so far; train ppl: 232.42, valid ppl: 249.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 133123512/200000000 [2:22:23<4:55:22, 3773.44it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130000 steps; 133119416 examples so far; train ppl: 231.45, valid ppl: 249.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 143363512/200000000 [2:33:17<3:28:16, 4532.24it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140000 steps; 143359416 examples so far; train ppl: 231.42, valid ppl: 249.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 153603512/200000000 [2:44:10<2:49:47, 4554.08it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150000 steps; 153599416 examples so far; train ppl: 231.28, valid ppl: 248.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 163843366/200000000 [2:55:09<2:41:03, 3741.72it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160000 steps; 163839270 examples so far; train ppl: 230.43, valid ppl: 248.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 174083366/200000000 [3:06:03<1:38:16, 4394.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170000 steps; 174079270 examples so far; train ppl: 230.38, valid ppl: 248.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 184323366/200000000 [3:16:57<47:06, 5546.95it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180000 steps; 184319270 examples so far; train ppl: 230.28, valid ppl: 248.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 194563220/200000000 [3:27:56<24:21, 3719.08it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190000 steps; 194559124 examples so far; train ppl: 229.55, valid ppl: 247.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200000660it [3:33:42, 15597.66it/s]                               \n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "max_examples = 200_000_000\n",
    "eval_every_steps = 10000\n",
    "lr = 5e-4\n",
    "use_amp = True\n",
    "\n",
    "\n",
    "model = LanguageModel(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    max_seq_length=max_seq_length,\n",
    "    dim=256,\n",
    "    n_layers=2,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    ").to(device)\n",
    "\n",
    "train_loader = DataLoader(training_dataset, batch_size=1024, shuffle=True, num_workers=4)\n",
    "validation_loader = DataLoader(valid_dataset, batch_size=1024, num_workers=4, )\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.8, min_lr=9e-5, patience=5000, verbose=True)\n",
    "scaler=GradScaler()\n",
    "\n",
    "\n",
    "def train_step(input_ids, target_ids):\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    with autocast(enabled=use_amp):\n",
    "        logits = model(input_ids)\n",
    "        logits = logits.reshape(-1, logits.shape[-1])\n",
    "        target_ids = target_ids.reshape(-1)\n",
    "    loss = nn.functional.cross_entropy(logits, target_ids, ignore_index=model.pad_token_id)\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def validation_step(input_ids, target_ids):\n",
    "    model.eval()\n",
    "    with autocast(enabled=use_amp):\n",
    "        logits = model(input_ids)\n",
    "        logits = logits.reshape(-1, logits.shape[-1])\n",
    "        target_ids = target_ids.reshape(-1)\n",
    "        loss = nn.functional.cross_entropy(logits, target_ids, ignore_index=model.pad_token_id)\n",
    "    return loss.item()\n",
    "\n",
    "best_validation_ppl = 9999\n",
    "train_losses = []\n",
    "n_examples = 0\n",
    "step = 0\n",
    "pbar = tqdm(total=max_examples)\n",
    "while n_examples < max_examples:\n",
    "    for train_input_ids, train_target_ids in DataManager(train_loader, device=device, buffer_size=1, data_type=None):\n",
    "        loss = train_step(train_input_ids.to(device), train_target_ids.to(device)) \n",
    "        train_losses.append(loss)\n",
    "\n",
    "        # LR scheduler\n",
    "        scheduler.step(loss)\n",
    "\n",
    "        if step % eval_every_steps == 0:\n",
    "            train_ppl = np.exp(np.average(train_losses))\n",
    "\n",
    "            with torch.no_grad():\n",
    "                valid_ppl = np.exp(np.average([\n",
    "                    validation_step(val_input_ids.to(device), val_target_ids.to(device))\n",
    "                    for val_input_ids, val_target_ids in DataManager(validation_loader, device=device, buffer_size=1, data_type=None)]))\n",
    "                # Checkpoint to best models found.\n",
    "                if best_validation_ppl > valid_ppl:\n",
    "                    # Update the new best perplexity.\n",
    "                    best_validation_ppl = valid_ppl\n",
    "                    model.eval()\n",
    "                    torch.save(model, \"best_model.pth\")\n",
    "\n",
    "            print(f'{step} steps; {n_examples} examples so far; train ppl: {train_ppl:.2f}, valid ppl: {valid_ppl:.2f}')\n",
    "            train_losses = []\n",
    "\n",
    "        n_examples += len(train_input_ids)  # Increment of batch size\n",
    "        step += 1\n",
    "        pbar.update(len(train_input_ids))\n",
    "        if n_examples >= max_examples:\n",
    "            break\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "# Restore best model (checkpoint) found\n",
    "model = torch.load(\"best_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgdNymJdNPXP"
   },
   "source": [
    "## Avaliação final no dataset de teste\n",
    "\n",
    "\n",
    "Bonus: o modelo com menor perplexidade no dataset de testes ganhará 0.5 ponto na nota final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "nxN5YytzZ7Tn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test perplexity: 216.47589565220008\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_ppl = np.exp(np.average([\n",
    "        validation_step(test_input_ids.to(device), test_target_ids.to(device))\n",
    "        for test_input_ids, test_target_ids in test_loader\n",
    "    ]))\n",
    "\n",
    "print(f'test perplexity: {test_ppl}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHvEs8mPszy_"
   },
   "source": [
    "## Teste seu modelo com uma sentença\n",
    "\n",
    "Escolha uma sentença gerada pelo modelo que ache interessante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "-CFElf4tsytW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eu gosto de comer pizza pois me faz,\n",
      "Eu gosto de comer pizza pois me faz, não\n",
      "Eu gosto de comer pizza pois me faz, não se\n",
      "Eu gosto de comer pizza pois me faz, não se -\n",
      "Eu gosto de comer pizza pois me faz, não se - -\n",
      "Eu gosto de comer pizza pois me faz, não se - - se\n",
      "Eu gosto de comer pizza pois me faz, não se - - se não\n",
      "Eu gosto de comer pizza pois me faz, não se - - se não.\n",
      "Eu gosto de comer pizza pois me faz, não se - - se não..\n",
      "Eu gosto de comer pizza pois me faz, não se - - se não...\n",
      "Eu gosto de comer pizza pois me faz, não se - - se não....\n",
      "Eu gosto de comer pizza pois me faz, não se - - se não.....\n",
      "Eu gosto de comer pizza pois me faz, não se - - se não......\n",
      "Eu gosto de comer pizza pois me faz, não se - - se não.......\n",
      "Eu gosto de comer pizza pois me faz, não se - - se não........\n",
      "Eu gosto de comer pizza pois me faz, não se - - se não.........\n",
      "Eu gosto de comer pizza pois me faz, não se - - se não..........\n",
      "Eu gosto de comer pizza pois me faz, não se - - se não...........\n",
      "Eu gosto de comer pizza pois me faz, não se - - se não............\n",
      "Eu gosto de comer pizza pois me faz, não se - - se não.............\n"
     ]
    }
   ],
   "source": [
    "prompt = 'Eu gosto de comer pizza pois me faz'\n",
    "max_output_tokens = 20\n",
    "model.eval()\n",
    "\n",
    "for _ in range(max_output_tokens):\n",
    "    input_ids = tokenize(text=prompt, tokenizer=tokenizer)\n",
    "    input_ids_truncated = input_ids[-max_seq_length:]  # Usamos apenas os últimos <max_seq_length> tokens como entrada para o modelo.\n",
    "    logits = model(torch.LongTensor([input_ids_truncated]).to(device))\n",
    "    logits = logits[:, -1, :]  # Usamos apenas o ultimo token da sequencia\n",
    "    # Ao usarmos o argmax, a saída do modelo em cada passo é o token de maior probabilidade.\n",
    "    # Isso se chama decodificação gulosa (greedy decoding).\n",
    "    predicted_id = torch.argmax(logits).item()\n",
    "    input_ids += [predicted_id]  # Concatenamos a entrada com o token escolhido nesse passo.\n",
    "    prompt = tokenizer.decode(input_ids)\n",
    "    print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGdxlXhGq7Ua",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Bonus 1\n",
    "Quem conseguir a menor perplexidade no dataset de testes ganha 0.5 ponto na média final.\n",
    "\n",
    "## Bonus 2\n",
    "Qual é a complexidade (em notação O-grande) da função de geração de texto acima?\n",
    "\n",
    "Quem responder corretamente a pergunta acima e deixar a função com menor complexidade ganha 0.5 ponto na média final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 6.44 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "prompt = 'Eu gosto de comer pizza pois me faz'\n",
    "max_output_tokens = 2000\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# max_output_tokens == n\n",
    "for _ in range(max_output_tokens): # O(n) no loop, sem contar o interior\n",
    "    input_ids = tokenize(text=prompt, tokenizer=tokenizer) # O(n)\n",
    "    input_ids_truncated = input_ids[-max_seq_length:] # O(1), pois o tamanho da seq eh constante\n",
    "    logits = model(torch.LongTensor([input_ids_truncated]).to(device)) # O(1)\n",
    "    logits = logits[:, -1, :]  # O(1)\n",
    "    predicted_id = torch.argmax(logits).item() # O(1)\n",
    "    input_ids += [predicted_id]  # O(n + 1) == O(n), operacao de Concatenacao eh mais cara que Append (amortizado).\n",
    "    prompt = tokenizer.decode(input_ids) # O(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eu gosto de comer pizza pois me faz, não se - - se não.........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Complexidade == O(n^2)\n"
     ]
    }
   ],
   "source": [
    "print(prompt)\n",
    "\n",
    "print(\"Complexidade == O(n^2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 3.81 µs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%time\n",
    "prompt = 'Eu gosto de comer pizza pois me faz'\n",
    "max_output_tokens = 2000\n",
    "model.eval()\n",
    "\n",
    "input_ids = tokenize(text=prompt, tokenizer=tokenizer)\n",
    "\n",
    "# max_output_tokens == n\n",
    "for _ in range(max_output_tokens): # O(n) no loop, sem contar o interior\n",
    "    input_ids_truncated = input_ids[-max_seq_length:] # O(1), pois o tamanho da seq eh constante\n",
    "    logits = model(torch.LongTensor([input_ids_truncated]).to(device)) # O(1)\n",
    "    logits = logits[:, -1, :]  # O(1)\n",
    "    predicted_id = torch.argmax(logits).item() # O(1)\n",
    "    input_ids.append(predicted_id) # O(1)\n",
    "\n",
    "prompt = tokenizer.decode(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eu gosto de comer pizza pois me faz, não se - - se não.........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Complexidade == O(n)\n"
     ]
    }
   ],
   "source": [
    "print(prompt)\n",
    "\n",
    "print(\"Complexidade == O(n)\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ex09_patrick_ferreira",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "052d85df4565408080ff6a7346b35c5c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09ca6f3a160548b5b031e60333bceb7a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c1807c88ec4493782a59aafd3189524": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "120c9499a0384745b1454d0c0c6973ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d7ba288f7994a41934f924131848c8b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1fd73c9ef2024ae8910179fbc34170de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4934ebc4b76645aca633d97c1bcaa4ad",
      "placeholder": "​",
      "style": "IPY_MODEL_f3fc4417238f4f33a2f4194c427f9dd8",
      "value": "Downloading: 100%"
     }
    },
    "25fcb32ab6004207a61851ce06aca6b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a3d12be640b4410abfade3f74ad4eb93",
       "IPY_MODEL_9daf832318a643cca5b36aa90ffddd63",
       "IPY_MODEL_d0bb2ed4018e4099867e2e71d406e054"
      ],
      "layout": "IPY_MODEL_0c1807c88ec4493782a59aafd3189524"
     }
    },
    "2ad38c47cb4945dd8ca1cd9f58d26366": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3071b72c700e4afc9e2c25d0129f493c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "36f249a65f6b4fd89a844177e560c22e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1d7ba288f7994a41934f924131848c8b",
      "placeholder": "​",
      "style": "IPY_MODEL_bf72b3bf99e74c2fa6ede393314588df",
      "value": " 205k/205k [00:00&lt;00:00, 7.37kB/s]"
     }
    },
    "3ab4bc7cb9824fd698b68638a36b05ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_612ededf3abc4e01a276b8599020b15d",
      "placeholder": "​",
      "style": "IPY_MODEL_89f0d697a43046b2aa6a06b128dd6e81",
      "value": " 647/647 [00:00&lt;00:00, 5.57kB/s]"
     }
    },
    "43105df07006440698ea7ceb0c3e9cea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44d4723a8c014891b164c8bcf52d03f5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4536e27d89e74acf971faa86e6af5a52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "478d77b6cf094843bfab38ee2c101b23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "489b591919e94a65ab61db9c8a36e7d8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4934ebc4b76645aca633d97c1bcaa4ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4afc1399603942609718065dc03a462a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4e0ccbd570fd410e8ec5a3353c5ecd70": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "50f4d4a9c04e4dbbb935af1a50443036": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_43105df07006440698ea7ceb0c3e9cea",
      "max": 209528,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_846bd0d8300d449e981f9fd629503d8f",
      "value": 209528
     }
    },
    "511628d7aea6440eb7c7ceb4cc502cb9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "612ededf3abc4e01a276b8599020b15d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "64d3c1102f764525bc0917ce15fe50ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "65353e8cc72b4e0ca3e8f1d473c52981": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b8f7590770694f54a458a27f9550e901",
       "IPY_MODEL_50f4d4a9c04e4dbbb935af1a50443036",
       "IPY_MODEL_36f249a65f6b4fd89a844177e560c22e"
      ],
      "layout": "IPY_MODEL_2ad38c47cb4945dd8ca1cd9f58d26366"
     }
    },
    "6d18de7983e74a078f4f0a88ae2c3fdd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e767f283fbd4d81bf48cdd3c27ef9b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "725528bc269f400e8f6a2a321875e5fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c93e3adfa6b04031b882b13f65c03c30",
      "placeholder": "​",
      "style": "IPY_MODEL_df5cb1dd3c324d209316afc9e1a258b2",
      "value": "Downloading: 100%"
     }
    },
    "7779774d7e3848a5b4483a6835573720": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7d7548b9569a4957a9dd08152820e10d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_120c9499a0384745b1454d0c0c6973ac",
      "placeholder": "​",
      "style": "IPY_MODEL_3071b72c700e4afc9e2c25d0129f493c",
      "value": "Downloading: 100%"
     }
    },
    "8380bc0527c14f229009a0f07db8f943": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "846bd0d8300d449e981f9fd629503d8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "86cfec7bb7fd4c1cba0ee65600d49133": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_725528bc269f400e8f6a2a321875e5fa",
       "IPY_MODEL_f40544445eca4ad8ac232bf631faa4c6",
       "IPY_MODEL_fa64718699f8409e94b480f20431f8e1"
      ],
      "layout": "IPY_MODEL_a429e64a9fbb4aa5ba0ceab0ca80c7bd"
     }
    },
    "89f0d697a43046b2aa6a06b128dd6e81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8ae6ca6ae1a542e3af820b93a58d3b47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "948c4211ae4f431d9508f39341c87115": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "975caa6fb29a466ab282a97d5255b224": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9daf832318a643cca5b36aa90ffddd63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e767f283fbd4d81bf48cdd3c27ef9b8",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_64d3c1102f764525bc0917ce15fe50ce",
      "value": 2
     }
    },
    "a3d12be640b4410abfade3f74ad4eb93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_09ca6f3a160548b5b031e60333bceb7a",
      "placeholder": "​",
      "style": "IPY_MODEL_8ae6ca6ae1a542e3af820b93a58d3b47",
      "value": "Downloading: 100%"
     }
    },
    "a429e64a9fbb4aa5ba0ceab0ca80c7bd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b0138036512b4f76b694890862f3157b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b8f7590770694f54a458a27f9550e901": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_948c4211ae4f431d9508f39341c87115",
      "placeholder": "​",
      "style": "IPY_MODEL_8380bc0527c14f229009a0f07db8f943",
      "value": "Downloading: 100%"
     }
    },
    "bf72b3bf99e74c2fa6ede393314588df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c66799fca73041bdaec8c506925f839b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6c3ed4552a0417fb033e40910ff4ad5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_44d4723a8c014891b164c8bcf52d03f5",
      "max": 112,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4536e27d89e74acf971faa86e6af5a52",
      "value": 112
     }
    },
    "c7b0c070d5ce4487891c878a269297fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_052d85df4565408080ff6a7346b35c5c",
      "max": 647,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4afc1399603942609718065dc03a462a",
      "value": 647
     }
    },
    "c93e3adfa6b04031b882b13f65c03c30": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce2666c9d3ea42f5951acf88860fd661": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7d7548b9569a4957a9dd08152820e10d",
       "IPY_MODEL_c7b0c070d5ce4487891c878a269297fd",
       "IPY_MODEL_3ab4bc7cb9824fd698b68638a36b05ea"
      ],
      "layout": "IPY_MODEL_975caa6fb29a466ab282a97d5255b224"
     }
    },
    "cf84f782913d4e8ba328da541b0c01de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d0bb2ed4018e4099867e2e71d406e054": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_511628d7aea6440eb7c7ceb4cc502cb9",
      "placeholder": "​",
      "style": "IPY_MODEL_4e0ccbd570fd410e8ec5a3353c5ecd70",
      "value": " 2.00/2.00 [00:00&lt;00:00, 12.1B/s]"
     }
    },
    "d5004778faec4fd78e3c02979033613f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1fd73c9ef2024ae8910179fbc34170de",
       "IPY_MODEL_c6c3ed4552a0417fb033e40910ff4ad5",
       "IPY_MODEL_dd2ffd9dd40e4cf2b3d03c7275302c69"
      ],
      "layout": "IPY_MODEL_b0138036512b4f76b694890862f3157b"
     }
    },
    "dd2ffd9dd40e4cf2b3d03c7275302c69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c66799fca73041bdaec8c506925f839b",
      "placeholder": "​",
      "style": "IPY_MODEL_7779774d7e3848a5b4483a6835573720",
      "value": " 112/112 [00:00&lt;00:00, 708B/s]"
     }
    },
    "df5cb1dd3c324d209316afc9e1a258b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f3fc4417238f4f33a2f4194c427f9dd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f40544445eca4ad8ac232bf631faa4c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d18de7983e74a078f4f0a88ae2c3fdd",
      "max": 43,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_478d77b6cf094843bfab38ee2c101b23",
      "value": 43
     }
    },
    "fa64718699f8409e94b480f20431f8e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_489b591919e94a65ab61db9c8a36e7d8",
      "placeholder": "​",
      "style": "IPY_MODEL_cf84f782913d4e8ba328da541b0c01de",
      "value": " 43.0/43.0 [00:00&lt;00:00, 391B/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}