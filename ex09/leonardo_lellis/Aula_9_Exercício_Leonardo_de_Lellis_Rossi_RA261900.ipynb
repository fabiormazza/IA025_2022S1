{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aula 9 - Exercício - Leonardo de Lellis Rossi RA261900",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f31d2b0ed4cc4f62a705dda03925e664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87110423bcf1402680e59ea2f8616675",
              "IPY_MODEL_c2e35c8ad25845e3a7356faeead0edec",
              "IPY_MODEL_73321da5ae374541b62dd88f51c7fa11"
            ],
            "layout": "IPY_MODEL_84669b795c4a4a139ac9db6560d517b1"
          }
        },
        "87110423bcf1402680e59ea2f8616675": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43faaf1048394795afa4e71d744b8d06",
            "placeholder": "​",
            "style": "IPY_MODEL_e598ed9c3eed4e8f8dee74c6c6ae4c3d",
            "value": "Downloading: 100%"
          }
        },
        "c2e35c8ad25845e3a7356faeead0edec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81ade7f96a0742d4ae37d0a79b8f3f7e",
            "max": 209528,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5015d180123f4f33a53b63468399a36e",
            "value": 209528
          }
        },
        "73321da5ae374541b62dd88f51c7fa11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcfe91d5fba543ddacd063d4fce2c35b",
            "placeholder": "​",
            "style": "IPY_MODEL_c5e8e77998e94084bc98e1fbc9091140",
            "value": " 205k/205k [00:00&lt;00:00, 3.93MB/s]"
          }
        },
        "84669b795c4a4a139ac9db6560d517b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43faaf1048394795afa4e71d744b8d06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e598ed9c3eed4e8f8dee74c6c6ae4c3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81ade7f96a0742d4ae37d0a79b8f3f7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5015d180123f4f33a53b63468399a36e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bcfe91d5fba543ddacd063d4fce2c35b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5e8e77998e94084bc98e1fbc9091140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4561c6dc2994c069d1934e125800070": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a61c6609e3e48aab960ee13d89d6b48",
              "IPY_MODEL_aee12147f265466b9f2984bbcbf0c2e6",
              "IPY_MODEL_8c2d3f5ff43c485291a2467bda005b3a"
            ],
            "layout": "IPY_MODEL_adca7a87c2984de8bbcdebad4c15735c"
          }
        },
        "4a61c6609e3e48aab960ee13d89d6b48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2564c63fab3843bdb897daf43f588fea",
            "placeholder": "​",
            "style": "IPY_MODEL_c18a3aadbeb1413eb202893255675e95",
            "value": "Downloading: 100%"
          }
        },
        "aee12147f265466b9f2984bbcbf0c2e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0cf76d259ab4f5d888508ef52db2805",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a97615cf267407f8074a95a3fe94841",
            "value": 2
          }
        },
        "8c2d3f5ff43c485291a2467bda005b3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a742a732e6ec4d49a888d004be388bce",
            "placeholder": "​",
            "style": "IPY_MODEL_376625cda5684dacbe612125e57971a8",
            "value": " 2.00/2.00 [00:00&lt;00:00, 67.8B/s]"
          }
        },
        "adca7a87c2984de8bbcdebad4c15735c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2564c63fab3843bdb897daf43f588fea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c18a3aadbeb1413eb202893255675e95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0cf76d259ab4f5d888508ef52db2805": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a97615cf267407f8074a95a3fe94841": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a742a732e6ec4d49a888d004be388bce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "376625cda5684dacbe612125e57971a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e58d8629abe4b48bd4daa8e4ea50eb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_60c1292ba3134398b0febf841c675574",
              "IPY_MODEL_01b0a655a37c49de837ec5654b5f9e74",
              "IPY_MODEL_a6566118c83243eba0831094e53f9e35"
            ],
            "layout": "IPY_MODEL_7350c4f529dc46979e2d517f71214d0c"
          }
        },
        "60c1292ba3134398b0febf841c675574": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63ff173448164459a91193bb5efaa85a",
            "placeholder": "​",
            "style": "IPY_MODEL_010645a8d7724f209418294b2d8e4b2e",
            "value": "Downloading: 100%"
          }
        },
        "01b0a655a37c49de837ec5654b5f9e74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c055c9978984437786f595bc174b8c78",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_753ffbbedc214d7f9148242ea1450f71",
            "value": 112
          }
        },
        "a6566118c83243eba0831094e53f9e35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39795fdd713e461aa7c3253a2d4870f7",
            "placeholder": "​",
            "style": "IPY_MODEL_ad8086581712456580e6aba010d9fd29",
            "value": " 112/112 [00:00&lt;00:00, 2.90kB/s]"
          }
        },
        "7350c4f529dc46979e2d517f71214d0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63ff173448164459a91193bb5efaa85a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "010645a8d7724f209418294b2d8e4b2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c055c9978984437786f595bc174b8c78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "753ffbbedc214d7f9148242ea1450f71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "39795fdd713e461aa7c3253a2d4870f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad8086581712456580e6aba010d9fd29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70fd4a3028de411da7757824ca22baba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e0e2cbbd62b41d38d7fc16cfd5a4db4",
              "IPY_MODEL_baf13c09f37f49eda9401ebb82f12e50",
              "IPY_MODEL_c26e64d10a2b465585b98f946d8a118b"
            ],
            "layout": "IPY_MODEL_cae6669a18e249b3a5f93a104b1b560b"
          }
        },
        "9e0e2cbbd62b41d38d7fc16cfd5a4db4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28cbc4e4a85e4c4dae4cdfe4d7dd25f4",
            "placeholder": "​",
            "style": "IPY_MODEL_5e1af3931375436e976147048485eb32",
            "value": "Downloading: 100%"
          }
        },
        "baf13c09f37f49eda9401ebb82f12e50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2c874c90d5a40edb67c2136657f7443",
            "max": 43,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88c078bb9fb147c991fc544b921ede1a",
            "value": 43
          }
        },
        "c26e64d10a2b465585b98f946d8a118b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e02b60372e914bbfa0b29708232032ba",
            "placeholder": "​",
            "style": "IPY_MODEL_e85dec67917b467c822be68bd2c5ef68",
            "value": " 43.0/43.0 [00:00&lt;00:00, 1.46kB/s]"
          }
        },
        "cae6669a18e249b3a5f93a104b1b560b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28cbc4e4a85e4c4dae4cdfe4d7dd25f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e1af3931375436e976147048485eb32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2c874c90d5a40edb67c2136657f7443": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88c078bb9fb147c991fc544b921ede1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e02b60372e914bbfa0b29708232032ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e85dec67917b467c822be68bd2c5ef68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8df7e548fac4222945b354f8cd64264": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e58b5d08a0d46c099c13cd7166b2074",
              "IPY_MODEL_a720fe8f211c45e5ae3bebe5b09b0692",
              "IPY_MODEL_d5c5d552761e4dc48de411ac7a513d1e"
            ],
            "layout": "IPY_MODEL_d51397a9bef3442686a803da02e1265b"
          }
        },
        "9e58b5d08a0d46c099c13cd7166b2074": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a75c0e50cf5b4b138e0aea8656068b22",
            "placeholder": "​",
            "style": "IPY_MODEL_48e055f3eaf54d58ac565a6e5510c440",
            "value": "Downloading: 100%"
          }
        },
        "a720fe8f211c45e5ae3bebe5b09b0692": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9eebd5eb5e3740d589829671b718d13a",
            "max": 647,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b634c756b6a40f283d419c32b75bf6a",
            "value": 647
          }
        },
        "d5c5d552761e4dc48de411ac7a513d1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44fd3ab427844a31b28ebf5a9233708f",
            "placeholder": "​",
            "style": "IPY_MODEL_58f27012ec6548f8be90c6f96c688ca5",
            "value": " 647/647 [00:00&lt;00:00, 21.8kB/s]"
          }
        },
        "d51397a9bef3442686a803da02e1265b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a75c0e50cf5b4b138e0aea8656068b22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48e055f3eaf54d58ac565a6e5510c440": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9eebd5eb5e3740d589829671b718d13a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b634c756b6a40f283d419c32b75bf6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44fd3ab427844a31b28ebf5a9233708f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58f27012ec6548f8be90c6f96c688ca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8694e21ba132427e83c029c4ec800209": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91ac3c6747ff4adcb626ad94827f36e6",
              "IPY_MODEL_57bb0095ba1b4620a775423301f656b6",
              "IPY_MODEL_315237f07b014a4b827397c04cd119cf"
            ],
            "layout": "IPY_MODEL_32ff6c40de8442249cddd9ebdd7f2a15"
          }
        },
        "91ac3c6747ff4adcb626ad94827f36e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edb2d6762bbc4b6e98bb44b304344442",
            "placeholder": "​",
            "style": "IPY_MODEL_e5495682e41e4911a2bdd9b02d7b304a",
            "value": "100%"
          }
        },
        "57bb0095ba1b4620a775423301f656b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0425f316c4cb4f88a843228d67f8bbbb",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_429e414dc10b4778841b7986ea8415b6",
            "value": 2
          }
        },
        "315237f07b014a4b827397c04cd119cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7159f191bc4e4a019a697d919d6b4202",
            "placeholder": "​",
            "style": "IPY_MODEL_e11ca15ffe254ecfb9140d38e961400a",
            "value": " 2/2 [00:00&lt;00:00, 55.84it/s]"
          }
        },
        "32ff6c40de8442249cddd9ebdd7f2a15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edb2d6762bbc4b6e98bb44b304344442": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5495682e41e4911a2bdd9b02d7b304a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0425f316c4cb4f88a843228d67f8bbbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "429e414dc10b4778841b7986ea8415b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7159f191bc4e4a019a697d919d6b4202": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e11ca15ffe254ecfb9140d38e961400a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unicamp-dl/IA025_2022S1/blob/main/ex09/leonardo_lellis/Aula_9_Exerc%C3%ADcio_Leonardo_de_Lellis_Rossi_RA261900.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nome = \"Leonardo de Lellis Rossi RA261900\"\n",
        "print(f'Meu nome é {nome}')\n",
        "\n",
        "last = '22/06/01_18h20'\n",
        "print(f'Last update: {last}')\n"
      ],
      "metadata": {
        "id": "jOdQB41_4ZxG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c17df253-7bd1-4f1f-9be5-40fa37ef7457"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meu nome é Leonardo de Lellis Rossi RA261900\n",
            "Last update: 22/06/01_18h20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IbuChoAPMEn"
      },
      "source": [
        "#  Exercício: Modelo de Linguagem com auto-atenção"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_DBb0-Klwf2"
      },
      "source": [
        "Este exercício é similar ao da Aula 8, mas iremos agora treinar uma rede neural com **duas camadas** de auto-atenção **causais** para prever a próxima palavra de um texto, data as palavras anteriores como entrada. \n",
        "\n",
        "Iremos também trabalhar com sequencias de tamanho variável.\n",
        "\n",
        "Na camada de auto-atenção, não se esqueça de implementar:\n",
        "- Embeddings de posição\n",
        "- Projeções lineares (WQ, WK, WV, WO)\n",
        "- Conexões residuais\n",
        "- Camada de feed forward (2-layer MLP)\n",
        "\n",
        "\n",
        "O dataset usado neste exercício (BrWaC) possui um tamanho razoável e você vai precisar rodar seus experimentos com GPU.\n",
        "\n",
        "Alguns conselhos úteis:\n",
        "- **ATENÇÃO:** o dataset é bem grande. Não dê comando de imprimí-lo.\n",
        "- Durante a depuração, faça seu dataset ficar bem pequeno, para que a depuração seja mais rápida e não precise de GPU. Somente ligue a GPU quando o seu laço de treinamento já está funcionando\n",
        "- Não deixe para fazer esse exercício na véspera. Ele é trabalhoso."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# iremos utilizar a biblioteca dos transformers para ter acesso ao tokenizador do BERT.\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3twP0YJC4jmJ",
        "outputId": "628c9190-82b4-4e40-a69a-62046e5bd5b7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 28.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 52.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 60.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnyhJZtTRNMx"
      },
      "source": [
        "## Importação dos pacotes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlIOVCajPWcU"
      },
      "source": [
        "import collections\n",
        "import itertools\n",
        "import functools\n",
        "import math\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm_notebook\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "debug = False\n",
        "checkinpoint = True\n",
        "save_in_drive = True\n",
        "\n",
        "params = {\n",
        "    'max_examples': 150_000_000,\n",
        "    'eval_every_steps': 10000,\n",
        "    'lr': 3e-4,\n",
        "    'batch_size': 128,\n",
        "    'embedding_dim': 128,\n",
        "    'hidden_size': 2*128,\n",
        "    'optimizer': 'Adam',\n",
        "    'retrain': False,\n",
        "    'path_saved_model': 'gdrive/MyDrive/Colab Notebooks/best_model_',\n",
        "    'path_saved_datasets': 'gdrive/MyDrive/Colab Notebooks/ds_',\n",
        "    'download_ds': False,\n",
        "    'aula': 'Aula9',\n",
        "    'max_seq_length': 9,\n",
        "    'train_examples': 90_000,\n",
        "    'valid_examples': 40_000,\n",
        "    'test_examples': 25_000,\n",
        "    'n_heads':4\n",
        "}\n",
        "params['path_saved_model'] = params['path_saved_model']+params['aula']+'_BS'+str(params['batch_size'])+'_HS'+str(params['hidden_size'])+'_EmbDim'+str(params['embedding_dim'])+'_MaxEx'+str(params['max_examples'])+'.pt'"
      ],
      "metadata": {
        "id": "dnfTE2XvSr3X"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check which GPU we are using\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "w9f3PfifAwpU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25d43041-ec27-4bad-e930-8de7ed6d34db"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jun  2 01:43:13 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "whTCe2i7AtoV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seeds():\n",
        "  random.seed(123)\n",
        "  np.random.seed(123)\n",
        "  torch.manual_seed(123)\n",
        "  torch.cuda.manual_seed(123)\n",
        "set_seeds()"
      ],
      "metadata": {
        "id": "-O1Gy-aeUbv2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neptune config"
      ],
      "metadata": {
        "id": "9D9O0IdFUKdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " !pip install -U neptune-client\n",
        " import neptune.new as neptune"
      ],
      "metadata": {
        "id": "Ua-dPVPgUM3k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7be73d95-cd44-4573-af99-6f384dd88505"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting neptune-client\n",
            "  Downloading neptune-client-0.16.3.tar.gz (317 kB)\n",
            "\u001b[K     |████████████████████████████████| 317 kB 32.2 MB/s \n",
            "\u001b[?25hCollecting bravado\n",
            "  Downloading bravado-11.0.3-py2.py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (7.1.2)\n",
            "Collecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 64.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauthlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (3.2.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.3.5)\n",
            "Requirement already satisfied: Pillow>=1.1.6 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (7.1.2)\n",
            "Collecting PyJWT\n",
            "  Downloading PyJWT-2.4.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.3.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.15.0)\n",
            "Collecting websocket-client!=1.0.0,>=0.35.0\n",
            "  Downloading websocket_client-1.3.2-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.6 MB/s \n",
            "\u001b[?25hCollecting GitPython>=2.0.8\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 71.6 MB/s \n",
            "\u001b[?25hCollecting boto3>=1.16.0\n",
            "  Downloading boto3-1.24.1-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 54.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from neptune-client) (21.3)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.24.3)\n",
            "Collecting swagger-spec-validator>=2.7.4\n",
            "  Downloading swagger_spec_validator-2.7.4-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from neptune-client) (5.4.8)\n",
            "Collecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 9.7 MB/s \n",
            "\u001b[?25hCollecting botocore<1.28.0,>=1.27.1\n",
            "  Downloading botocore-1.27.1-py3-none-any.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 50.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.1->boto3>=1.16.0->neptune-client) (2.8.2)\n",
            "Collecting urllib3\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 57.4 MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=2.0.8->neptune-client) (4.2.0)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (2022.5.18.1)\n",
            "Collecting urllib3\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 58.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from swagger-spec-validator>=2.7.4->neptune-client) (6.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from swagger-spec-validator>=2.7.4->neptune-client) (4.3.3)\n",
            "Collecting simplejson\n",
            "  Downloading simplejson-3.17.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 54.9 MB/s \n",
            "\u001b[?25hCollecting monotonic\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting bravado-core>=5.16.1\n",
            "  Downloading bravado_core-5.17.0-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from bravado->neptune-client) (1.0.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from bravado-core>=5.16.1->bravado->neptune-client) (2022.1)\n",
            "Collecting jsonref\n",
            "  Downloading jsonref-0.2-py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (5.7.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (0.18.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (21.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (4.11.4)\n",
            "Collecting rfc3339-validator\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Collecting jsonpointer>1.13\n",
            "  Downloading jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting isoduration\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Collecting webcolors>=1.11\n",
            "  Downloading webcolors-1.12-py3-none-any.whl (9.9 kB)\n",
            "Collecting uri-template\n",
            "  Downloading uri_template-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting rfc3987\n",
            "  Downloading rfc3987-1.3.8-py2.py3-none-any.whl (13 kB)\n",
            "Collecting fqdn\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (3.8.0)\n",
            "Requirement already satisfied: cached-property>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from fqdn->jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.5.2)\n",
            "Collecting arrow>=0.15.0\n",
            "  Downloading arrow-1.2.2-py3-none-any.whl (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 3.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->neptune-client) (3.0.9)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->neptune-client) (1.21.6)\n",
            "Building wheels for collected packages: neptune-client, future\n",
            "  Building wheel for neptune-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for neptune-client: filename=neptune_client-0.16.3-py2.py3-none-any.whl size=570148 sha256=e8bc8344463a2083f04a28083cbdc564d123ebb1def5ca5da3476df36f18fb2d\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/67/63/794a7079b23b633de6a77fb7e9427e368980a755c1bc52a814\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=c54315c9681490fcf8a1ca6b9915d12c673893550ff414d1755fe7e0ac38999b\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "Successfully built neptune-client future\n",
            "Installing collected packages: arrow, webcolors, urllib3, uri-template, rfc3987, rfc3339-validator, jsonpointer, jmespath, isoduration, fqdn, swagger-spec-validator, smmap, simplejson, jsonref, botocore, s3transfer, monotonic, gitdb, bravado-core, websocket-client, PyJWT, GitPython, future, bravado, boto3, neptune-client\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed GitPython-3.1.27 PyJWT-2.4.0 arrow-1.2.2 boto3-1.24.1 botocore-1.27.1 bravado-11.0.3 bravado-core-5.17.0 fqdn-1.5.1 future-0.18.2 gitdb-4.0.9 isoduration-20.11.0 jmespath-1.0.0 jsonpointer-2.3 jsonref-0.2 monotonic-1.6 neptune-client-0.16.3 rfc3339-validator-0.1.4 rfc3987-1.3.8 s3transfer-0.6.0 simplejson-3.17.6 smmap-5.0.0 swagger-spec-validator-2.7.4 uri-template-1.2.0 urllib3-1.25.11 webcolors-1.12 websocket-client-1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run = neptune.init(name= params['aula'], tags=[params['aula'], 'Auto-atenção', 'Self-Attention', 'checkinpoint', 'CrossEntropy', 'Adam', 'perplexity', 'BrWaC'],\n",
        "    project=\"leolellisr/dl-ia025\",\n",
        "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI1NjY1YmJkZi1hYmM5LTQ3M2QtOGU1ZC1iZTFlNWY4NjE1NDQifQ==\",\n",
        ")"
      ],
      "metadata": {
        "id": "KNvj9TrsUOdI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46bb26dd-d11a-4c63-fcf0-35a05ad559c9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://app.neptune.ai/leolellisr/dl-ia025/e/DLIA-118\n",
            "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run['parameters'] = params"
      ],
      "metadata": {
        "id": "2Ld1XqRPVh21"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import itertools"
      ],
      "metadata": {
        "id": "K2517Ek9ZBv0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZfxgV2DUk58"
      },
      "source": [
        "## Implementação do MyDataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_xhKm1EZ3bQ"
      },
      "source": [
        "from typing import List\n",
        "\n",
        "\n",
        "def tokenize(text: str, tokenizer):\n",
        "    return tokenizer(text, return_tensors=None, add_special_tokens=False).input_ids\n",
        "\n",
        "\n",
        "class MyDataset():\n",
        "    def __init__(self, texts: List[str], tokenizer, max_seq_length: int):\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.X = []\n",
        "        for text in tqdm_notebook(texts):\n",
        "          token_ids = tokenize(f'[CLS] {text}', tokenizer) # + [tokenizer.vocab['[SEP]']]  \n",
        "          token_ids += [tokenizer.vocab['[PAD]']] * max(0, 1 + max_seq_length - len(token_ids))\n",
        "          for i in range(0, len(token_ids) - 1, max_seq_length):\n",
        "            if i + max_seq_length < len(token_ids):\n",
        "              self.X.append(token_ids[i: i + max_seq_length + 1])\n",
        "            else:\n",
        "              self.X.append(token_ids[-max_seq_length - 1:])\n",
        "        self.X = torch.LongTensor(self.X)\n",
        "\n",
        "    def __len__(self):\n",
        "        # Escreva seu código aqui\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Escreva seu código aqui\n",
        "        x_y_idx = self.X[idx]\n",
        "        return x_y_idx[:-1], x_y_idx[1:]       "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n"
      ],
      "metadata": {
        "id": "NOwJMEllqm4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "f31d2b0ed4cc4f62a705dda03925e664",
            "87110423bcf1402680e59ea2f8616675",
            "c2e35c8ad25845e3a7356faeead0edec",
            "73321da5ae374541b62dd88f51c7fa11",
            "84669b795c4a4a139ac9db6560d517b1",
            "43faaf1048394795afa4e71d744b8d06",
            "e598ed9c3eed4e8f8dee74c6c6ae4c3d",
            "81ade7f96a0742d4ae37d0a79b8f3f7e",
            "5015d180123f4f33a53b63468399a36e",
            "bcfe91d5fba543ddacd063d4fce2c35b",
            "c5e8e77998e94084bc98e1fbc9091140",
            "d4561c6dc2994c069d1934e125800070",
            "4a61c6609e3e48aab960ee13d89d6b48",
            "aee12147f265466b9f2984bbcbf0c2e6",
            "8c2d3f5ff43c485291a2467bda005b3a",
            "adca7a87c2984de8bbcdebad4c15735c",
            "2564c63fab3843bdb897daf43f588fea",
            "c18a3aadbeb1413eb202893255675e95",
            "e0cf76d259ab4f5d888508ef52db2805",
            "3a97615cf267407f8074a95a3fe94841",
            "a742a732e6ec4d49a888d004be388bce",
            "376625cda5684dacbe612125e57971a8",
            "8e58d8629abe4b48bd4daa8e4ea50eb8",
            "60c1292ba3134398b0febf841c675574",
            "01b0a655a37c49de837ec5654b5f9e74",
            "a6566118c83243eba0831094e53f9e35",
            "7350c4f529dc46979e2d517f71214d0c",
            "63ff173448164459a91193bb5efaa85a",
            "010645a8d7724f209418294b2d8e4b2e",
            "c055c9978984437786f595bc174b8c78",
            "753ffbbedc214d7f9148242ea1450f71",
            "39795fdd713e461aa7c3253a2d4870f7",
            "ad8086581712456580e6aba010d9fd29",
            "70fd4a3028de411da7757824ca22baba",
            "9e0e2cbbd62b41d38d7fc16cfd5a4db4",
            "baf13c09f37f49eda9401ebb82f12e50",
            "c26e64d10a2b465585b98f946d8a118b",
            "cae6669a18e249b3a5f93a104b1b560b",
            "28cbc4e4a85e4c4dae4cdfe4d7dd25f4",
            "5e1af3931375436e976147048485eb32",
            "e2c874c90d5a40edb67c2136657f7443",
            "88c078bb9fb147c991fc544b921ede1a",
            "e02b60372e914bbfa0b29708232032ba",
            "e85dec67917b467c822be68bd2c5ef68",
            "a8df7e548fac4222945b354f8cd64264",
            "9e58b5d08a0d46c099c13cd7166b2074",
            "a720fe8f211c45e5ae3bebe5b09b0692",
            "d5c5d552761e4dc48de411ac7a513d1e",
            "d51397a9bef3442686a803da02e1265b",
            "a75c0e50cf5b4b138e0aea8656068b22",
            "48e055f3eaf54d58ac565a6e5510c440",
            "9eebd5eb5e3740d589829671b718d13a",
            "9b634c756b6a40f283d419c32b75bf6a",
            "44fd3ab427844a31b28ebf5a9233708f",
            "58f27012ec6548f8be90c6f96c688ca5"
          ]
        },
        "outputId": "50e91d83-2480-4dbb-f4b0-6f2499a39fc9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/205k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f31d2b0ed4cc4f62a705dda03925e664"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d4561c6dc2994c069d1934e125800070"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e58d8629abe4b48bd4daa8e4ea50eb8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/43.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70fd4a3028de411da7757824ca22baba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/647 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a8df7e548fac4222945b354f8cd64264"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testando se a implementação do MyDataset está correta"
      ],
      "metadata": {
        "id": "wew-gFbWeBTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "debug = False\n",
        "params['batch_size'] = 10\n",
        "batch_size = params['batch_size'] \n",
        "dummy_texts = ['Eu gosto de correr', 'Ela gosta muito de comer pizza']\n",
        "\n",
        "dummy_dataset = MyDataset(texts=dummy_texts, tokenizer=tokenizer, max_seq_length=9)\n",
        "dummy_loader = DataLoader(dummy_dataset, batch_size=6, shuffle=False)\n",
        "print(f'len(dummy_dataset): {len(dummy_dataset)}')\n",
        "assert len(dummy_dataset) == 2\n",
        "print('Passou no assert de tamanho do dataset.')\n",
        "\n",
        "first_batch_input, first_batch_target = next(iter(dummy_loader))\n",
        "\n",
        "correct_first_batch_input = torch.LongTensor(\n",
        "    [[  101,  3396, 10303,   125, 13239,     0,     0,     0,     0],\n",
        "     [  101,  1660,  5971,   785,   125,  1847, 13779, 15616,     0]])\n",
        "\n",
        "correct_first_batch_target = torch.LongTensor(\n",
        "    [[ 3396, 10303,   125, 13239,     0,     0,     0,     0,     0],\n",
        "     [ 1660,  5971,   785,   125,  1847, 13779, 15616,     0,     0]])\n",
        "\n",
        "\n",
        "if debug: print(first_batch_input)\n",
        "\n",
        "assert torch.equal(first_batch_input, correct_first_batch_input)\n",
        "\n",
        "if debug:  print(first_batch_target)\n",
        "assert torch.equal(first_batch_target, correct_first_batch_target)\n",
        "\n",
        "print('Passou no assert de dataset.')"
      ],
      "metadata": {
        "id": "8r7jBFFUeApe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "8694e21ba132427e83c029c4ec800209",
            "91ac3c6747ff4adcb626ad94827f36e6",
            "57bb0095ba1b4620a775423301f656b6",
            "315237f07b014a4b827397c04cd119cf",
            "32ff6c40de8442249cddd9ebdd7f2a15",
            "edb2d6762bbc4b6e98bb44b304344442",
            "e5495682e41e4911a2bdd9b02d7b304a",
            "0425f316c4cb4f88a843228d67f8bbbb",
            "429e414dc10b4778841b7986ea8415b6",
            "7159f191bc4e4a019a697d919d6b4202",
            "e11ca15ffe254ecfb9140d38e961400a"
          ]
        },
        "outputId": "9607d829-ef2a-438c-ee71-4a83eeb672ba"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  if sys.path[0] == '':\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8694e21ba132427e83c029c4ec800209"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(dummy_dataset): 2\n",
            "Passou no assert de tamanho do dataset.\n",
            "Passou no assert de dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "if save_in_drive: drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIwYycaugsxY",
        "outputId": "bf0a43e9-4ead-48bb-9674-b521be8de52f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LfrHHouleJ0"
      },
      "source": [
        "# Carregamento do dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2vFWjsSkmop"
      },
      "source": [
        "Iremos usar uma pequena amostra do dataset [BrWaC](https://www.inf.ufrgs.br/pln/wiki/index.php?title=BrWaC) para treinar e avaliar nosso modelo de linguagem."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://storage.googleapis.com/unicamp-dl/ia025a_2022s1/aula9/sample-1gb.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGlN1WqrXPA6",
        "outputId": "57ff358b-b538-45bb-bddf-e2bf0277e5d5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-02 01:44:02--  https://storage.googleapis.com/unicamp-dl/ia025a_2022s1/aula9/sample-1gb.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.253.62.128, 172.253.115.128, 172.253.122.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.253.62.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1230909256 (1.1G) [text/plain]\n",
            "Saving to: ‘sample-1gb.txt’\n",
            "\n",
            "sample-1gb.txt      100%[===================>]   1.15G  94.3MB/s    in 23s     \n",
            "\n",
            "2022-06-02 01:44:24 (51.9 MB/s) - ‘sample-1gb.txt’ saved [1230909256/1230909256]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "max_seq_length = params['max_seq_length']\n",
        "\n",
        "train_examples = params['train_examples']\n",
        "valid_examples = params['valid_examples']\n",
        "test_examples = params['test_examples']\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "gxa_4gmiA-wE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NGpsakPdG4Nw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_lines = train_examples + valid_examples + test_examples\n",
        "print(f'Truncating to {max_lines} lines.')\n",
        "\n",
        "if params['download_ds']:\n",
        "  texts = open('sample-1gb.txt').readlines()\n",
        "  print(f'Read {len(texts)} lines.')\n",
        "  \n",
        "  #smart batching\n",
        "  texts = sorted(texts, key=lambda x: len(x[0]))\n",
        "\n",
        "  texts = texts[:max_lines]  \n",
        "  \n",
        "  training_texts = texts[:-(valid_examples + test_examples)]\n",
        "  valid_texts = texts[-(valid_examples + test_examples):-test_examples]\n",
        "  test_texts = texts[-test_examples:]\n",
        "\n",
        "  training_dataset = MyDataset(texts=training_texts, tokenizer=tokenizer, max_seq_length=max_seq_length)\n",
        "  valid_dataset = MyDataset(texts=valid_texts, tokenizer=tokenizer, max_seq_length=max_seq_length)\n",
        "  test_dataset = MyDataset(texts=test_texts, tokenizer=tokenizer, max_seq_length=max_seq_length)\n",
        "else:\n",
        "  path = params['path_saved_datasets']+'train.pt'\n",
        "  training_dataset = torch.load(path)\n",
        "  path = params['path_saved_datasets']+'val.pt'\n",
        "  valid_dataset = torch.load(path)\n",
        "  path = params['path_saved_datasets']+'test.pt'\n",
        "  test_dataset = torch.load(path)\n",
        "params['batch_size'] = 64\n",
        "batch_size = params['batch_size'] \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDari2UL78_5",
        "outputId": "f63f7773-f77f-491c-df11-24f937bdefe7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Truncating to 155000 lines.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'training examples: {len(training_dataset)}')\n",
        "print(f'valid examples: {len(valid_dataset)}')\n",
        "print(f'test examples: {len(test_dataset)}')"
      ],
      "metadata": {
        "id": "KCSGJ5m7py4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "355a99d0-12fa-41ed-b43f-cb8608d42687"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training examples: 11198040\n",
            "valid examples: 5011771\n",
            "test examples: 3041508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if save_in_drive and params['download_ds']:\n",
        "  torch.save(training_dataset, params['path_saved_datasets']+\"train.pt\")\n",
        "  torch.save(valid_dataset, params['path_saved_datasets']+\"val.pt\")\n",
        "  torch.save(test_dataset, params['path_saved_datasets']+\"test.pt\")"
      ],
      "metadata": {
        "id": "VeNzN6ZjWP09"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "CmjYdmqANlRn"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# É recomendado reiniciar as seeds antes de inicializar o modelo, pois assim\n",
        "# garantimos que os pesos vao ser sempre os mesmos.\n",
        "set_seeds()\n",
        "\n",
        "class SelfAttentionLayer(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, padding_idx, n_heads, dim, max_length):\n",
        "        super().__init__()\n",
        "        # n_heads: H\n",
        "        # dim: D\n",
        "        # max_lenght: L\n",
        "        # vocab_lenght: V\n",
        "        self.H = n_heads\n",
        "        self.D = dim\n",
        "        self.L = max_length\n",
        "        self.D_H = self.D // self.H # D / H\n",
        "        self.pad = padding_idx\n",
        "\n",
        "        self.W_q = torch.nn.Linear(self.D, self.D, bias=False) # (D, D)\n",
        "        self.W_k = torch.nn.Linear(self.D, self.D, bias=False)\n",
        "        self.W_v = torch.nn.Linear(self.D, self.D, bias=False)\n",
        "        self.W_o = torch.nn.Linear(self.D, self.D, bias=False)\n",
        "\n",
        "        self.layer_norm1  = torch.nn.LayerNorm(self.D, eps=1e-6)\n",
        "\n",
        "        self.feed_forward = torch.nn.Sequential(\n",
        "            torch.nn.Linear(self.D, self.D*10),  \n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(self.D*10, self.D)\n",
        "        )\n",
        "        self.layer_norm2  = torch.nn.LayerNorm(self.D, eps=1e-6)\n",
        "\n",
        "\n",
        "    def forward(self, x, att_mask):\n",
        "        B = len(x)      \n",
        "        # multi-head self-attention\n",
        "\n",
        "        fQ = self.W_q(x).reshape(B, self.L, self.H, self.D_H) # (B, L, H, D/H)\n",
        "        fK = self.W_k(x).reshape(B, self.L, self.H, self.D_H)\n",
        "        fV = self.W_v(x).reshape(B, self.L, self.H, self.D_H)\n",
        "\n",
        "        # (B, L, H, D/H) -> (B, H, L, D/H)\n",
        "        fQ_transposed = fQ.transpose(1, 2)                    # (B, H, L, D/H)\n",
        "        fK_transposed = fK.transpose(1, 2)\n",
        "        fV_transposed = fV.transpose(1, 2)\n",
        "\n",
        "        scores = torch.matmul(fQ_transposed, fK_transposed.transpose(-2, -1)) / math.sqrt(self.D_H) # (B, H, L, L)\n",
        "\n",
        "        scores = scores.masked_fill(att_mask.unsqueeze(1) == 0, -float(\"inf\"))\n",
        "\n",
        "        if debug: print(f\"scores (B, H, L, L): {scores.shape}\")  \n",
        "\n",
        "        probs = F.softmax(scores, dim=-1) # shape = B, L, L\n",
        "        if debug: print(f\"probs (B, H, L, L): {probs.shape}\")  \n",
        "\n",
        "        E = torch.matmul(probs, fV_transposed)\n",
        "        if debug: print(f\"E (B, H, L, D/H): {E.shape}\")  \n",
        "\n",
        "        out = E.transpose(1, 2).contiguous()                   # (B, L, H, D/H)\n",
        "        out = out.reshape(B, self.L, self.D) # (B, L, D) \n",
        "        out = self.W_o(out)\n",
        "        if debug: print(f\"out (B, L, D): {out.shape}\")  # (B, L, D)    \n",
        "\n",
        "        out = self.layer_norm1(x+out)               # (B, L, D) \n",
        "        out = self.feed_forward(out)\n",
        "        out = self.layer_norm2(x+out)           # (B, L, D) \n",
        "        #att_mean = att_norm2 * padMask.unsqueeze(-1)      \n",
        "        #mean_embeddings = att_mean.sum(dim=1) / padMask.count_nonzero(-1).unsqueeze(1)  \n",
        "        return out"
      ],
      "metadata": {
        "id": "GgdE_7xnMp7Y"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MsAs84KmQVXc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGaAjYDfWdd1"
      },
      "source": [
        "set_seeds()\n",
        "class LanguageModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size: int, max_seq_length: int, dim: int, n_layers: int, pad_token_id: int, hidden: int, n_heads):\n",
        "        \"\"\"\n",
        "        Implements the Self-attention, decoder-only.\"\n",
        "\n",
        "        Args:\n",
        "            vocab_size (int): Size of the input vocabulary.\n",
        "            max_seq_length (int): Size of the sequence to consider as context for prediction.\n",
        "            dim (int): Dimension of the embedding layer for each word in the context.\n",
        "            n_layers (int): number of self-attention layers.\n",
        "            pad_token_id (int): id of the pad token that will be ignored in the attention.\n",
        "          \n",
        "        \"\"\"\n",
        "        # Escreva seu código aqui.\n",
        "        super().__init__()\n",
        "        self.H = n_heads\n",
        "        self.D = dim\n",
        "        self.L = max_seq_length\n",
        "        self.D_H = self.D // self.H # D / H\n",
        "        self.pad_token_id = pad_token_id\n",
        "        self.V = vocab_size\n",
        "        self.hidden_size = hidden\n",
        "\n",
        "        # word embedding \n",
        "        self.embeddings_c = nn.Embedding(self.V, self.D,padding_idx=pad_token_id)\n",
        "        self.embeddings_p = torch.nn.Linear(self.D, self.L, bias=False)\n",
        "\n",
        "        self.att_layer = SelfAttentionLayer(padding_idx=pad_token_id, n_heads=self.H, dim=self.D, max_length=self.L)\n",
        "\n",
        "        self.feed_forward = torch.nn.Sequential(\n",
        "            torch.nn.Linear(dim, hidden),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(hidden, vocab_size)\n",
        "        )\n",
        "        \n",
        "\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            inputs is a LongTensor of shape (batch_size, max_seq_length)\n",
        "            B: batch_size\n",
        "            L: max_seq_length\n",
        "            D: embedding_dim\n",
        "            V: vocab_size\n",
        "            input shape: (B, L)\n",
        "            pos shape: (B, L)\n",
        "        Returns:\n",
        "            logits of shape (batch_size, max_seq_length, vocab_size)\n",
        "        \"\"\"\n",
        "        B = inputs.shape[0]\n",
        "\n",
        "        att_mask = torch.tril(torch.ones(B, self.L, self.L)).to(device)\n",
        "        att_mask = att_mask.masked_fill(inputs.unsqueeze(1) == self.pad_token_id, 0)\n",
        "        att_mask = att_mask.masked_fill(inputs.unsqueeze(2) == self.pad_token_id, 0)\n",
        "\n",
        "        # input shape: (B, L)\n",
        "        x_emb = self.embeddings_c(inputs) + self.embeddings_p.weight  # (B, L, D)\n",
        "        if debug: print(f'shape x_emb: {x_emb.shape}')                # (B, L, D)\n",
        "        logits =  self.att_layer(x_emb, att_mask)              # (B, L, D)\n",
        "        if debug: print(f'shape logits: {logits.shape}')              # (B, L, D)\n",
        "        logits = self.feed_forward(logits)                            # (B, L, V)\n",
        "        if debug: print(f'shape logits (B, L, V): {logits.shape}')             # (B, L, V)\n",
        "        \n",
        "\n",
        "        return logits"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available(): \n",
        "   dev = \"cuda:0\"\n",
        "else: \n",
        "   dev = \"cpu\"\n",
        "device = torch.device(dev)\n",
        "print('Using {}'.format(device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvVgqCENvNfT",
        "outputId": "e0f7b644-35b0-4277-eafe-9f9f034774fa"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teste o modelo com um exemplo"
      ],
      "metadata": {
        "id": "Rm6_PTH2i98e"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwnxfZlrZoT_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e816d5b0-442e-4909-85e7-6d7bed3c6d13"
      },
      "source": [
        "debug = True\n",
        "model = LanguageModel(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    max_seq_length=max_seq_length,\n",
        "    dim=64,\n",
        "    n_layers=2,\n",
        "    hidden = 128,\n",
        "    n_heads = 4,\n",
        "    pad_token_id=tokenizer.pad_token_id\n",
        ").to(device)\n",
        "\n",
        "\n",
        "sample_input, _ = next(iter(DataLoader(training_dataset)))\n",
        "sample_input = sample_input.to(device)\n",
        "sample_output = model(sample_input)\n",
        "print(f'sample_input.shape: {sample_input.shape}')\n",
        "print(f'sample_output.shape: {sample_output.shape}')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape x_emb: torch.Size([1, 9, 64])\n",
            "scores (B, H, L, L): torch.Size([1, 4, 9, 9])\n",
            "probs (B, H, L, L): torch.Size([1, 4, 9, 9])\n",
            "E (B, H, L, D/H): torch.Size([1, 4, 9, 16])\n",
            "out (B, L, D): torch.Size([1, 9, 64])\n",
            "shape logits: torch.Size([1, 9, 64])\n",
            "shape logits (B, L, V): torch.Size([1, 9, 29794])\n",
            "sample_input.shape: torch.Size([1, 9])\n",
            "sample_output.shape: torch.Size([1, 9, 29794])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0u4m2eFaeo5",
        "outputId": "f064d3ae-788f-4115-85e2-0aaafa4ec7ec"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101, 20100,  2308,  3074,  1089,   481,   117,   146,  1189]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3Vh6B-VkA01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "011ddf29-4e4f-4a1b-8f1b-6e9fd1886c75"
      },
      "source": [
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'Number of model parameters: {num_params}')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of model parameters: 5858402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assert da Perplexidade\n"
      ],
      "metadata": {
        "id": "8nhbUVsYnVAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(123)\n",
        "np.random.seed(123)\n",
        "torch.manual_seed(123)\n",
        "\n",
        "\n",
        "def perplexity(logits, target, ignore_token_id: int):\n",
        "    \"\"\"\n",
        "    Computes the perplexity.\n",
        "\n",
        "    Args:\n",
        "        logits: a FloatTensor of shape (batch_size, seq_length, vocab_size)\n",
        "        target: a LongTensor of shape (batch_size, seq_length)\n",
        "\n",
        "    Returns:\n",
        "        A float corresponding to the perplexity\n",
        "    \"\"\"\n",
        "    logits = logits.reshape(-1, logits.shape[-1])\n",
        "    target = target.reshape(-1)\n",
        "    if debug: \n",
        "      print(f'logits: {logits.shape}')\n",
        "      print(f'train_target_ids: {target.shape}')\n",
        "    loss = nn.functional.cross_entropy(logits, target, reduction='mean', ignore_index=ignore_token_id)\n",
        "    return torch.exp(loss)\n",
        "\n",
        "\n",
        "n_examples = 1000\n",
        "\n",
        "train_input_ids, train_target_ids = next(iter(DataLoader(training_dataset, batch_size=n_examples)))\n",
        "train_input_ids = train_input_ids.to(device)\n",
        "train_target_ids = train_target_ids.to(device)\n",
        "\n",
        "logits = model.forward(train_input_ids)\n",
        "if debug:\n",
        "  print(f'logits: {logits.shape}')\n",
        "  print(f'train_target_ids: {train_target_ids.shape}')\n",
        "\n",
        "my_perplexity = perplexity(logits=logits, target=train_target_ids, ignore_token_id=tokenizer.pad_token_id)\n",
        "if debug:\n",
        "  print(f'correct initial perplexity: {tokenizer.vocab_size}')\n",
        "  print(f'my perplexity:              {int(my_perplexity)}')\n",
        "\n",
        "\n",
        "assert math.isclose(my_perplexity, tokenizer.vocab_size, abs_tol=7000)\n",
        "print('Passou o no assert da perplexidade')\n",
        "run['perplexity'].log(my_perplexity) # Envia perplexity para o Neptune.\n"
      ],
      "metadata": {
        "id": "gbMP8VAUncfX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cc8786c-d7b9-4433-ffcf-5ccb59f38215"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape x_emb: torch.Size([1000, 9, 64])\n",
            "scores (B, H, L, L): torch.Size([1000, 4, 9, 9])\n",
            "probs (B, H, L, L): torch.Size([1000, 4, 9, 9])\n",
            "E (B, H, L, D/H): torch.Size([1000, 4, 9, 16])\n",
            "out (B, L, D): torch.Size([1000, 9, 64])\n",
            "shape logits: torch.Size([1000, 9, 64])\n",
            "shape logits (B, L, V): torch.Size([1000, 9, 29794])\n",
            "logits: torch.Size([1000, 9, 29794])\n",
            "train_target_ids: torch.Size([1000, 9])\n",
            "logits: torch.Size([9000, 29794])\n",
            "train_target_ids: torch.Size([9000])\n",
            "correct initial perplexity: 29794\n",
            "my perplexity:              30171\n",
            "Passou o no assert da perplexidade\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YyE_DJkfJ8sS"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Laço de Treinamento e Validação"
      ],
      "metadata": {
        "id": "KiJtrsqPnE_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = params['batch_size']\n",
        "\n",
        "debug = False\n",
        "model = LanguageModel(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    max_seq_length=params['max_seq_length'],\n",
        "    dim=params['embedding_dim'],\n",
        "    n_layers=2,\n",
        "    hidden = params['hidden_size'],\n",
        "    n_heads = params['n_heads'],\n",
        "    pad_token_id=tokenizer.pad_token_id\n",
        ").to(device)\n",
        "\n",
        "train_loader = DataLoader(training_dataset, batch_size=params['batch_size'], shuffle=True, drop_last=True)\n",
        "validation_loader = DataLoader(valid_dataset, batch_size=params['batch_size'])\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'])\n",
        "\n",
        "best_valid_ppl = 10e9\n",
        "\n",
        "if params['retrain']:\n",
        "  best_model = params['path_saved_model']\n",
        "  model = torch.load(best_model)\n",
        "\n",
        "def train_step(input_ids, target_ids):\n",
        "    model.train()\n",
        "    model.zero_grad()\n",
        "    logits = model(input_ids)\n",
        "    logits = logits.reshape(-1, logits.shape[-1])\n",
        "    target_ids = target_ids.reshape(-1)\n",
        "    loss = nn.functional.cross_entropy(logits, target_ids, ignore_index=model.pad_token_id)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "def validation_step(input_ids, target_ids):\n",
        "    model.eval()\n",
        "    logits = model(input_ids)\n",
        "    logits = logits.reshape(-1, logits.shape[-1])\n",
        "    target_ids = target_ids.reshape(-1)\n",
        "    loss = nn.functional.cross_entropy(logits, target_ids, ignore_index=model.pad_token_id)\n",
        "    return loss.item()"
      ],
      "metadata": {
        "id": "MI7smWjSLY93"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIMSaY-UUGUE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2323a8f4-dee6-48a8-bff4-826fb096ea08"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "train_losses = []\n",
        "n_examples = 0\n",
        "step = 0\n",
        "while n_examples < params['max_examples']:\n",
        "    for train_input_ids, train_target_ids in train_loader:\n",
        "        loss = train_step(train_input_ids.to(device), train_target_ids.to(device)) \n",
        "        train_losses.append(loss)\n",
        "        \n",
        "        if step %  params['eval_every_steps'] == 0:\n",
        "            train_ppl = np.exp(np.average(train_losses))\n",
        "            run['train/ppl'].log(train_ppl) # Envia train ppl para o Neptune.\n",
        "\n",
        "            with torch.no_grad():\n",
        "                valid_ppl = np.exp(np.average([\n",
        "                    validation_step(val_input_ids.to(device), val_target_ids.to(device))\n",
        "                    for val_input_ids, val_target_ids in validation_loader]))\n",
        "            run['valid/ppl'].log(valid_ppl) # Envia valid ppl para o Neptune.\n",
        "            if checkinpoint and valid_ppl < best_valid_ppl:\n",
        "              torch.save(model.state_dict(), 'best_model.pt')\n",
        "              if save_in_drive: torch.save(model, params['path_saved_model'])\n",
        "              print(f\"Best model found in step {step}. valid ppl: {valid_ppl:.2f}, best_valid_ppl: {best_valid_ppl:.2f} \")\n",
        "              best_valid_ppl = valid_ppl\n",
        "            ex_least = n_examples/params['max_examples']*100\n",
        "            print(f'{step} steps; {n_examples} examples so far; {ex_least:.2f} % ; train ppl: {train_ppl:.2f}, valid ppl: {valid_ppl:.2f}, best_valid_ppl: {best_valid_ppl:.2f}')\n",
        "            train_losses = []\n",
        "\n",
        "        n_examples += len(train_input_ids)  # Increment of batch size\n",
        "        step += 1\n",
        "        if n_examples >= params['max_examples']:\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model found in step 0. valid ppl: 30778.39, best_valid_ppl: 10000000000.00 \n",
            "0 steps; 0 examples so far; 0.00 % ; train ppl: 31305.56, valid ppl: 30778.39, best_valid_ppl: 30778.39\n",
            "Best model found in step 10000. valid ppl: 341.09, best_valid_ppl: 30778.39 \n",
            "10000 steps; 640000 examples so far; 0.43 % ; train ppl: 511.52, valid ppl: 341.09, best_valid_ppl: 341.09\n",
            "Best model found in step 20000. valid ppl: 283.21, best_valid_ppl: 341.09 \n",
            "20000 steps; 1280000 examples so far; 0.85 % ; train ppl: 301.92, valid ppl: 283.21, best_valid_ppl: 283.21\n",
            "Best model found in step 30000. valid ppl: 260.87, best_valid_ppl: 283.21 \n",
            "30000 steps; 1920000 examples so far; 1.28 % ; train ppl: 266.47, valid ppl: 260.87, best_valid_ppl: 260.87\n",
            "Best model found in step 40000. valid ppl: 248.09, best_valid_ppl: 260.87 \n",
            "40000 steps; 2560000 examples so far; 1.71 % ; train ppl: 248.87, valid ppl: 248.09, best_valid_ppl: 248.09\n",
            "Best model found in step 50000. valid ppl: 239.76, best_valid_ppl: 248.09 \n",
            "50000 steps; 3200000 examples so far; 2.13 % ; train ppl: 238.90, valid ppl: 239.76, best_valid_ppl: 239.76\n",
            "Best model found in step 60000. valid ppl: 232.92, best_valid_ppl: 239.76 \n",
            "60000 steps; 3840000 examples so far; 2.56 % ; train ppl: 230.80, valid ppl: 232.92, best_valid_ppl: 232.92\n",
            "Best model found in step 70000. valid ppl: 227.39, best_valid_ppl: 232.92 \n",
            "70000 steps; 4480000 examples so far; 2.99 % ; train ppl: 225.70, valid ppl: 227.39, best_valid_ppl: 227.39\n",
            "Best model found in step 80000. valid ppl: 222.70, best_valid_ppl: 227.39 \n",
            "80000 steps; 5120000 examples so far; 3.41 % ; train ppl: 220.66, valid ppl: 222.70, best_valid_ppl: 222.70\n",
            "Best model found in step 90000. valid ppl: 219.12, best_valid_ppl: 222.70 \n",
            "90000 steps; 5760000 examples so far; 3.84 % ; train ppl: 216.53, valid ppl: 219.12, best_valid_ppl: 219.12\n",
            "Best model found in step 100000. valid ppl: 216.01, best_valid_ppl: 219.12 \n",
            "100000 steps; 6400000 examples so far; 4.27 % ; train ppl: 213.17, valid ppl: 216.01, best_valid_ppl: 216.01\n",
            "Best model found in step 110000. valid ppl: 212.51, best_valid_ppl: 216.01 \n",
            "110000 steps; 7040000 examples so far; 4.69 % ; train ppl: 209.51, valid ppl: 212.51, best_valid_ppl: 212.51\n",
            "Best model found in step 120000. valid ppl: 209.61, best_valid_ppl: 212.51 \n",
            "120000 steps; 7680000 examples so far; 5.12 % ; train ppl: 206.82, valid ppl: 209.61, best_valid_ppl: 209.61\n",
            "Best model found in step 130000. valid ppl: 207.37, best_valid_ppl: 209.61 \n",
            "130000 steps; 8320000 examples so far; 5.55 % ; train ppl: 204.07, valid ppl: 207.37, best_valid_ppl: 207.37\n",
            "Best model found in step 140000. valid ppl: 204.52, best_valid_ppl: 207.37 \n",
            "140000 steps; 8960000 examples so far; 5.97 % ; train ppl: 201.38, valid ppl: 204.52, best_valid_ppl: 204.52\n",
            "Best model found in step 150000. valid ppl: 202.17, best_valid_ppl: 204.52 \n",
            "150000 steps; 9600000 examples so far; 6.40 % ; train ppl: 198.84, valid ppl: 202.17, best_valid_ppl: 202.17\n",
            "Best model found in step 160000. valid ppl: 199.87, best_valid_ppl: 202.17 \n",
            "160000 steps; 10240000 examples so far; 6.83 % ; train ppl: 196.45, valid ppl: 199.87, best_valid_ppl: 199.87\n",
            "Best model found in step 170000. valid ppl: 198.17, best_valid_ppl: 199.87 \n",
            "170000 steps; 10880000 examples so far; 7.25 % ; train ppl: 194.14, valid ppl: 198.17, best_valid_ppl: 198.17\n",
            "Best model found in step 180000. valid ppl: 196.48, best_valid_ppl: 198.17 \n",
            "180000 steps; 11520000 examples so far; 7.68 % ; train ppl: 190.18, valid ppl: 196.48, best_valid_ppl: 196.48\n",
            "Best model found in step 190000. valid ppl: 194.24, best_valid_ppl: 196.48 \n",
            "190000 steps; 12160000 examples so far; 8.11 % ; train ppl: 187.34, valid ppl: 194.24, best_valid_ppl: 194.24\n",
            "Best model found in step 200000. valid ppl: 193.07, best_valid_ppl: 194.24 \n",
            "200000 steps; 12800000 examples so far; 8.53 % ; train ppl: 186.03, valid ppl: 193.07, best_valid_ppl: 193.07\n",
            "Best model found in step 210000. valid ppl: 191.59, best_valid_ppl: 193.07 \n",
            "210000 steps; 13440000 examples so far; 8.96 % ; train ppl: 185.48, valid ppl: 191.59, best_valid_ppl: 191.59\n",
            "Best model found in step 220000. valid ppl: 189.86, best_valid_ppl: 191.59 \n",
            "220000 steps; 14080000 examples so far; 9.39 % ; train ppl: 184.25, valid ppl: 189.86, best_valid_ppl: 189.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliação final no dataset de teste\n",
        "\n",
        "\n",
        "Bonus: o modelo com menor perplexidade no dataset de testes ganhará 0.5 ponto na nota final."
      ],
      "metadata": {
        "id": "VgdNymJdNPXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if params['retrain']:\n",
        "  best_model = params['path_saved_model']\n",
        "  model = torch.load(best_model)"
      ],
      "metadata": {
        "id": "wKxF1aykIYdO"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_ids"
      ],
      "metadata": {
        "id": "GmR9IFQ1IYXg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6a11ef4-aa5e-4cc1-debe-15fcf6c43754"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101, 20100,  2308,  ...,   117,   146,  1189],\n",
              "        [  125, 13254,   143,  ...,   179,   695,   923],\n",
              "        [  320,   126,  7092,  ...,   466,   702,   495],\n",
              "        ...,\n",
              "        [  294,   118,  1877,  ..., 11143,   122,  9172],\n",
              "        [  387, 15037,  9815,  ...,   117,  3660,  5044],\n",
              "        [  118, 14258,   117,  ...,   125,   532,  7608]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxN5YytzZ7Tn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51d15256-c395-47b4-cc75-4ea3b6e6ab05"
      },
      "source": [
        "#best_model = 'best_model.pt'\n",
        "#model.load_state_dict(torch.load(best_model))\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=params['batch_size'])\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_ppl = np.exp(np.average([\n",
        "        validation_step(test_input_ids.to(device), test_target_ids.to(device))\n",
        "        for test_input_ids, test_target_ids in test_loader\n",
        "    ]))\n",
        "\n",
        "print(f'test perplexity: {test_ppl}')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test perplexity: 31426.272073640055\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run['test/perplexity'].log(test_ppl)\n"
      ],
      "metadata": {
        "id": "dqKk8eGXKgfO"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run.stop()"
      ],
      "metadata": {
        "id": "ZLT8x2WYKicU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0018412c-99d0-488d-9e2e-c3e5afc80d52"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shutting down background jobs, please wait a moment...\n",
            "Done!\n",
            "Waiting for the remaining 8 operations to synchronize with Neptune. Do not kill this process.\n",
            "All 8 operations synced, thanks for waiting!\n",
            "Explore the metadata in the Neptune app:\n",
            "https://app.neptune.ai/leolellisr/dl-ia025/e/DLIA-118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teste seu modelo com uma sentença\n",
        "\n",
        "Escolha uma sentença gerada pelo modelo que ache interessante."
      ],
      "metadata": {
        "id": "BHvEs8mPszy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'Eu gosto de comer pizza pois me faz'\n",
        "max_output_tokens = 20\n",
        "model.eval()\n",
        "\n",
        "for _ in range(max_output_tokens):\n",
        "    input_ids = tokenize(text=prompt, tokenizer=tokenizer)\n",
        "    input_ids_truncated = input_ids[-max_seq_length:]  # Usamos apenas os últimos <max_seq_length> tokens como entrada para o modelo.\n",
        "    logits = model(torch.LongTensor([input_ids_truncated]).to(device))\n",
        "    logits = logits[:, -1, :]  # Usamos apenas o ultimo token da sequencia\n",
        "    # Ao usarmos o argmax, a saída do modelo em cada passo é o token de maior probabilidade.\n",
        "    # Isso se chama decodificação gulosa (greedy decoding).\n",
        "    predicted_id = torch.argmax(logits).item()\n",
        "    input_ids += [predicted_id]  # Concatenamos a entrada com o token escolhido nesse passo.\n",
        "    print(f'pred: {predicted_id}')\n",
        "    print(f'input_ids: {input_ids}')\n",
        "    prompt = tokenizer.decode(input_ids)\n",
        "    print(prompt)"
      ],
      "metadata": {
        "id": "pqxFR-wRvflc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56e0c98d-0136-4128-9f25-1509cc892614"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred: 11486\n",
            "input_ids: [3396, 10303, 125, 1847, 13779, 15616, 1502, 311, 659, 11486]\n",
            "Eu gosto de comer pizza pois me fazcrimin\n",
            "pred: 9585\n",
            "input_ids: [3396, 10303, 125, 1847, 13779, 15616, 1502, 311, 659, 11486, 9585]\n",
            "Eu gosto de comer pizza pois me fazcrimin vivos\n",
            "pred: 5656\n",
            "input_ids: [3396, 10303, 125, 1847, 13779, 15616, 1502, 311, 659, 11486, 9585, 5656]\n",
            "Eu gosto de comer pizza pois me fazcrimin vivos disponível\n",
            "pred: 22001\n",
            "input_ids: [3396, 10303, 125, 1847, 13779, 15616, 1502, 311, 659, 11486, 9585, 5656, 22001]\n",
            "Eu gosto de comer pizza pois me fazcrimin vivos disponíveltrospec\n",
            "pred: 10774\n",
            "input_ids: [3396, 10303, 125, 1847, 13779, 15616, 1502, 311, 659, 11486, 9585, 5656, 22001, 10774]\n",
            "Eu gosto de comer pizza pois me fazcrimin vivos disponíveltrospec Sci\n",
            "pred: 13791\n",
            "input_ids: [3396, 10303, 125, 1847, 13779, 15616, 1502, 311, 659, 11486, 9585, 5656, 22001, 10774, 13791]\n",
            "Eu gosto de comer pizza pois me fazcrimin vivos disponíveltrospec Sci jurisdição\n",
            "pred: 12537\n",
            "input_ids: [3396, 10303, 125, 1847, 13779, 15616, 1502, 311, 659, 11486, 9585, 5656, 22001, 10774, 13791, 12537]\n",
            "Eu gosto de comer pizza pois me fazcrimin vivos disponíveltrospec Sci jurisdição Cru\n",
            "pred: 10779\n",
            "input_ids: [3396, 10303, 125, 1847, 13779, 15616, 1502, 311, 659, 11486, 9585, 5656, 22001, 10774, 13791, 12537, 10779]\n",
            "Eu gosto de comer pizza pois me fazcrimin vivos disponíveltrospec Sci jurisdição Cru computação\n",
            "pred: 4742\n",
            "input_ids: [3396, 10303, 125, 1847, 13779, 15616, 1502, 311, 659, 11486, 9585, 5656, 22001, 10774, 13791, 12537, 10779, 4742]\n",
            "Eu gosto de comer pizza pois me fazcrimin vivos disponíveltrospec Sci jurisdição Cru computação Teatro\n",
            "pred: 25646\n",
            "input_ids: [3396, 10303, 125, 1847, 13779, 15616, 1502, 311, 659, 11486, 9585, 5656, 22001, 10774, 13791, 12537, 10779, 4742, 25646]\n",
            "Eu gosto de comer pizza pois me fazcrimin vivos disponíveltrospec Sci jurisdição Cru computação Teatro⇐\n",
            "pred: 11840\n",
            "input_ids: [3396, 10303, 125, 1847, 13779, 15616, 1502, 311, 659, 11486, 9585, 5656, 22001, 10774, 13791, 12537, 10779, 4742, 25646, 11840]\n",
            "Eu gosto de comer pizza pois me fazcrimin vivos disponíveltrospec Sci jurisdição Cru computação Teatro⇐isfa\n",
            "pred: 22613\n",
            "input_ids: [3396, 10303, 125, 1847, 13779, 15616, 1502, 311, 659, 11486, 9585, 5656, 22001, 10774, 13791, 12537, 10779, 4742, 25646, 11840, 22613]\n",
            "Eu gosto de comer pizza pois me fazcrimin vivos disponíveltrospec Sci jurisdição Cru computação Teatro⇐isfaж\n",
            "pred: 7252\n",
            "input_ids: [3396, 10303, 125, 1847, 13779, 15616, 1502, 311, 659, 11486, 9585, 5656, 22001, 10774, 13791, 12537, 10779, 4742, 25646, 11840, 22613, 7252]\n",
            "Eu gosto de comer pizza pois me fazcrimin vivos disponíveltrospec Sci jurisdição Cru computação Teatro⇐isfaж Ya\n",
            "pred: 14137\n",
            "input_ids: [3396, 10303, 125, 1847, 13779, 15616, 1502, 311, 659, 11486, 9585, 5656, 22001, 10774, 13791, 12537, 10779, 4742, 25646, 11840, 22613, 7252, 14137]\n",
            "Eu gosto de comer pizza pois me fazcrimin vivos disponíveltrospec Sci jurisdição Cru computação Teatro⇐isfaж Ya decorrência\n",
            "pred: 27583\n",
            "input_ids: [3396, 10303, 125, 1847, 13779, 15616, 1502, 311, 659, 11486, 9585, 5656, 22001, 10774, 13791, 12537, 10779, 4742, 25646, 11840, 22613, 7252, 14137, 27583]\n",
            "Eu gosto de comer pizza pois me fazcrimin vivos disponíveltrospec Sci jurisdição Cru computação Teatro⇐isfaж Ya decorrência뜢\n",
            "pred: 11305\n",
            "input_ids: [3396, 10303, 125, 1847, 13779, 15616, 1502, 311, 659, 11486, 9585, 5656, 22001, 10774, 13791, 12537, 10779, 4742, 25646, 11840, 22613, 7252, 14137, 27583, 11305]\n",
            "Eu gosto de comer pizza pois me fazcrimin vivos disponíveltrospec Sci jurisdição Cru computação Teatro⇐isfaж Ya decorrência뜢 existiam\n",
            "pred: 18521\n",
            "input_ids: [3396, 10303, 125, 1847, 13779, 15616, 1502, 311, 659, 11486, 9585, 5656, 22001, 10774, 13791, 12537, 10779, 4742, 25646, 11840, 22613, 7252, 14137, 27583, 11305, 18521]\n",
            "Eu gosto de comer pizza pois me fazcrimin vivos disponíveltrospec Sci jurisdição Cru computação Teatro⇐isfaж Ya decorrência뜢 existiam Industry\n",
            "pred: 25998\n",
            "input_ids: [3396, 10303, 125, 1847, 13779, 15616, 1502, 311, 659, 11486, 9585, 5656, 22001, 10774, 13791, 12537, 10779, 4742, 25646, 11840, 22613, 7252, 14137, 27583, 11305, 18521, 25998]\n",
            "Eu gosto de comer pizza pois me fazcrimin vivos disponíveltrospec Sci jurisdição Cru computação Teatro⇐isfaж Ya decorrência뜢 existiam Industry就\n",
            "pred: 7445\n",
            "input_ids: [3396, 10303, 125, 1847, 13779, 15616, 1502, 311, 659, 11486, 9585, 5656, 22001, 10774, 13791, 12537, 10779, 4742, 25646, 11840, 22613, 7252, 14137, 27583, 11305, 18521, 100, 7445]\n",
            "Eu gosto de comer pizza pois me fazcrimin vivos disponíveltrospec Sci jurisdição Cru computação Teatro⇐isfaж Ya decorrência뜢 existiam Industry [UNK] Machado\n",
            "pred: 14395\n",
            "input_ids: [3396, 10303, 125, 1847, 13779, 15616, 1502, 311, 659, 11486, 9585, 5656, 22001, 10774, 13791, 12537, 10779, 4742, 25646, 11840, 22613, 7252, 14137, 27583, 11305, 18521, 100, 7445, 14395]\n",
            "Eu gosto de comer pizza pois me fazcrimin vivos disponíveltrospec Sci jurisdição Cru computação Teatro⇐isfaж Ya decorrência뜢 existiam Industry [UNK] Machadotocol\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'Ouviram do Ipiranga em suas margens plácidas um grito'\n",
        "max_output_tokens = 20\n",
        "model.eval()\n",
        "\n",
        "for _ in range(max_output_tokens):\n",
        "    input_ids = tokenize(text=prompt, tokenizer=tokenizer)\n",
        "    input_ids_truncated = input_ids[-max_seq_length:]  # Usamos apenas os últimos <max_seq_length> tokens como entrada para o modelo.\n",
        "    logits = model(torch.LongTensor([input_ids_truncated]).to(device))\n",
        "    logits = logits[:, -1, :]  # Usamos apenas o ultimo token da sequencia\n",
        "    # Ao usarmos o argmax, a saída do modelo em cada passo é o token de maior probabilidade.\n",
        "    # Isso se chama decodificação gulosa (greedy decoding).\n",
        "    predicted_id = torch.argmax(logits).item()\n",
        "    input_ids += [predicted_id]  # Concatenamos a entrada com o token escolhido nesse passo.\n",
        "    prompt = tokenizer.decode(input_ids)\n",
        "    print(prompt)"
      ],
      "metadata": {
        "id": "bzU6DHWHvhDT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b5019e7-ff4e-4db8-d260-1a1ae599b657"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ouviram do Ipiranga em suas margens plácidas um grito`\n",
            "Ouviram do Ipiranga em suas margens plácidas um grito ` LGBT\n",
            "Ouviram do Ipiranga em suas margens plácidas um grito ` LGBT rig\n",
            "Ouviram do Ipiranga em suas margens plácidas um grito ` LGBT rig|\n",
            "Ouviram do Ipiranga em suas margens plácidas um grito ` LGBT rig | experimento\n",
            "Ouviram do Ipiranga em suas margens plácidas um grito ` LGBT rig | experimento Acad\n",
            "Ouviram do Ipiranga em suas margens plácidas um grito ` LGBT rig | experimento Acad Leopoldina\n",
            "Ouviram do Ipiranga em suas margens plácidas um grito ` LGBT rig | experimento Acad Leopoldina itens\n",
            "Ouviram do Ipiranga em suas margens plácidas um grito ` LGBT rig | experimento Acad Leopoldina itens궁\n",
            "Ouviram do Ipiranga em suas margens plácidas um grito ` LGBT rig | experimento Acad Leopoldina itens궁큟\n",
            "Ouviram do Ipiranga em suas margens plácidas um grito ` LGBT rig | experimento Acad Leopoldina itens궁큟ificou\n",
            "Ouviram do Ipiranga em suas margens plácidas um grito ` LGBT rig | experimento Acad Leopoldina itens궁큟ificou Cis\n",
            "Ouviram do Ipiranga em suas margens plácidas um grito ` LGBT rig | experimento Acad Leopoldina itens궁큟ificou Cis Cru\n",
            "Ouviram do Ipiranga em suas margens plácidas um grito ` LGBT rig | experimento Acad Leopoldina itens궁큟ificou Cis Cru contex\n",
            "Ouviram do Ipiranga em suas margens plácidas um grito ` LGBT rig | experimento Acad Leopoldina itens궁큟ificou Cis Cru contex Usando\n",
            "Ouviram do Ipiranga em suas margens plácidas um grito ` LGBT rig | experimento Acad Leopoldina itens궁큟ificou Cis Cru contex Usandoupas\n",
            "Ouviram do Ipiranga em suas margens plácidas um grito ` LGBT rig | experimento Acad Leopoldina itens궁큟ificou Cis Cru contex Usandoupas pale\n",
            "Ouviram do Ipiranga em suas margens plácidas um grito ` LGBT rig | experimento Acad Leopoldina itens궁큟ificou Cis Cru contex Usandoupas pale와\n",
            "Ouviram do Ipiranga em suas margens plácidas um grito ` LGBT rig | experimento Acad Leopoldina itens궁큟ificou Cis Cru contex Usandoupas pale와 descrita\n",
            "Ouviram do Ipiranga em suas margens plácidas um grito ` LGBT rig | experimento Acad Leopoldina itens궁큟ificou Cis Cru contex Usandoupas pale와 descrita formam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'Ouviram do Ipiranga nas margens plácidas um grito'\n",
        "max_output_tokens = 20\n",
        "model.eval()\n",
        "for _ in range(max_output_tokens):\n",
        "    input_ids = tokenize(texts=prompt, tokenizer=tokenizer, max_length=max_seq_length)\n",
        "\n",
        "    print(f'input_ids: {input_ids.shape}')\n",
        "    \n",
        "    input_ids_truncated = input_ids[-max_seq_length:]  # Usamos apenas os últimos <max_seq_length> tokens como entrada para o modelo.\n",
        "    logits = model(torch.LongTensor(input_ids).to(device))\n",
        "    print(f'logits: {logits.shape}')\n",
        "    \n",
        "    logits = logits[:, -1, :]  # Usamos apenas o ultimo token da sequencia\n",
        "    print(f'logits: {logits.shape}')\n",
        "\n",
        "    # Ao usarmos o argmax, a saída do modelo em cada passo é o token de maior probabilidade.\n",
        "    # Isso se chama decodificação gulosa (greedy decoding).\n",
        "    predicted_id = torch.argmax(logits).item()\n",
        "    print(input_ids)\n",
        "    input_ids = input_ids.transpose(1,0)\n",
        "    print(input_ids.shape)\n",
        "    pred_tensor = torch.tensor([predicted_id]).long()\n",
        "    print(pred_tensor.shape)\n",
        "    input_ids = torch.cat((input_ids, pred_tensor.unsqueeze(1)), dim=0)  # Concatenamos a entrada com o token escolhido nesse passo.\n",
        "    # tokens: print(input_ids)\n",
        "    print(f'pred: {predicted_id}')\n",
        "    print(f'input_ids: {input_ids.shape}')\n",
        "    #input_ids = input_ids[1:].reshape(len(input_ids)-1)\n",
        "    #print(input_ids)\n",
        "    prompt = [tokenizer.decode(input_ids)] \n",
        "    print(prompt)\n",
        "    "
      ],
      "metadata": {
        "id": "-CFElf4tsytW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bonus 1\n",
        "Quem conseguir a menor perplexidade no dataset de testes ganha 0.5 ponto na média final.\n",
        "\n",
        "## Bonus 2\n",
        "Qual é a complexidade (em notação O-grande) da função de geração de texto acima?\n",
        "\n",
        "Quem responder corretamente a pergunta acima e deixar a função com menor complexidade ganha 0.5 ponto na média final."
      ],
      "metadata": {
        "id": "nGdxlXhGq7Ua"
      }
    }
  ]
}