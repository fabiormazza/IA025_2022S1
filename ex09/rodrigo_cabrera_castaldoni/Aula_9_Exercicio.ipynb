{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "New_Aula_9_Exercicio.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8d00dd246bc7488a99a97ebe0fa15715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c16e08f547d4c609176d6186d5e3a97",
              "IPY_MODEL_b2b9010d11164d088ba9d9b66afdbdf5",
              "IPY_MODEL_f50f7f1a5d574b2a80c60dc93ff3a8d4"
            ],
            "layout": "IPY_MODEL_306190cfe7524710b69196756584b11e"
          }
        },
        "8c16e08f547d4c609176d6186d5e3a97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dc15252a4ac4ff6b33c7ab06480e1f0",
            "placeholder": "​",
            "style": "IPY_MODEL_d9466721e49848f99cc1bbcdbecad099",
            "value": "100%"
          }
        },
        "b2b9010d11164d088ba9d9b66afdbdf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa04f5319b2544c8bcb1eaaf0b28c14b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef7d17a6bfcb44f08a3217f7dd79bc7c",
            "value": 2
          }
        },
        "f50f7f1a5d574b2a80c60dc93ff3a8d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25945a510ccc45cca45797065c4c888f",
            "placeholder": "​",
            "style": "IPY_MODEL_deff87bd4ffd45879380a07051bf7f7b",
            "value": " 2/2 [00:00&lt;00:00,  9.77it/s]"
          }
        },
        "306190cfe7524710b69196756584b11e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dc15252a4ac4ff6b33c7ab06480e1f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9466721e49848f99cc1bbcdbecad099": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa04f5319b2544c8bcb1eaaf0b28c14b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef7d17a6bfcb44f08a3217f7dd79bc7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "25945a510ccc45cca45797065c4c888f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "deff87bd4ffd45879380a07051bf7f7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59971bb26fdd46759ed9091f9314eec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12a0bf88c4c642c5b1622d7039e8f9bb",
              "IPY_MODEL_8b10f98d509d45108dfde743a39229b1",
              "IPY_MODEL_521d5f4af1cb448589e9730ec838f234"
            ],
            "layout": "IPY_MODEL_d15994a914d34695ab973ac6fbe51cd6"
          }
        },
        "12a0bf88c4c642c5b1622d7039e8f9bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5b4051037374bb3868f2ca0b0b74ac9",
            "placeholder": "​",
            "style": "IPY_MODEL_fa71ba179bb74a1da400f0f561002a4a",
            "value": "100%"
          }
        },
        "8b10f98d509d45108dfde743a39229b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d0f877615a64475a59b39a2c1895308",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_323687bc205644849f9a101ac763ce7f",
            "value": 50000
          }
        },
        "521d5f4af1cb448589e9730ec838f234": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15dce122b264407bb3d500138060eed0",
            "placeholder": "​",
            "style": "IPY_MODEL_87fdf3758f7b4bac9c99cc0fadbb1e18",
            "value": " 50000/50000 [16:58&lt;00:00, 90.69it/s]"
          }
        },
        "d15994a914d34695ab973ac6fbe51cd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5b4051037374bb3868f2ca0b0b74ac9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa71ba179bb74a1da400f0f561002a4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d0f877615a64475a59b39a2c1895308": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "323687bc205644849f9a101ac763ce7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "15dce122b264407bb3d500138060eed0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87fdf3758f7b4bac9c99cc0fadbb1e18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c6f5ce8beb246c3a7f38d4e34f021ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dacf77a7301e49a9b46ebd418173c89c",
              "IPY_MODEL_58a7a7c6bc484d85874b704532fc0ef7",
              "IPY_MODEL_ae8ac996fbeb408a804922779ff8976b"
            ],
            "layout": "IPY_MODEL_097bd5d4579c4086a60f10e5d6f5f600"
          }
        },
        "dacf77a7301e49a9b46ebd418173c89c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6d594fcba4844f49a57dfbea2649d86",
            "placeholder": "​",
            "style": "IPY_MODEL_6060aeefe52740038659a928b28f597e",
            "value": "100%"
          }
        },
        "58a7a7c6bc484d85874b704532fc0ef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f7cfe2edcfc4393b701a682e119ec20",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73546ce75bf04aa6a8bed40a3aa4f3e7",
            "value": 100
          }
        },
        "ae8ac996fbeb408a804922779ff8976b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18b70fd36d2b46afb4191aaa0c5aa6de",
            "placeholder": "​",
            "style": "IPY_MODEL_564f0c7be5e54b2ba3b0f58f20b0fa16",
            "value": " 100/100 [00:02&lt;00:00, 54.25it/s]"
          }
        },
        "097bd5d4579c4086a60f10e5d6f5f600": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6d594fcba4844f49a57dfbea2649d86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6060aeefe52740038659a928b28f597e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f7cfe2edcfc4393b701a682e119ec20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73546ce75bf04aa6a8bed40a3aa4f3e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18b70fd36d2b46afb4191aaa0c5aa6de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "564f0c7be5e54b2ba3b0f58f20b0fa16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7d758ded96e463888422b072aa2aa2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68f01019b103474289584dbf9874b910",
              "IPY_MODEL_90af127c6600463ab992223817907e2d",
              "IPY_MODEL_f22d5fcb84ef4636a0d52474efb10e8d"
            ],
            "layout": "IPY_MODEL_3dc6e4fd2cf04c1488bbb52eeb161b02"
          }
        },
        "68f01019b103474289584dbf9874b910": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4579a0676c8409fbdbe948f668a73d9",
            "placeholder": "​",
            "style": "IPY_MODEL_e9303132992c40e7985094433255c4b2",
            "value": "100%"
          }
        },
        "90af127c6600463ab992223817907e2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4caf677f6942450cadd9cc15b0755e1c",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf67d6998e9d4fbebb85c8f3ac0c290f",
            "value": 100
          }
        },
        "f22d5fcb84ef4636a0d52474efb10e8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ab7494e58034ce0ac2b03f63ae7d935",
            "placeholder": "​",
            "style": "IPY_MODEL_3595584727904d4f8abd3f86d9914657",
            "value": " 100/100 [00:02&lt;00:00, 48.33it/s]"
          }
        },
        "3dc6e4fd2cf04c1488bbb52eeb161b02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4579a0676c8409fbdbe948f668a73d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9303132992c40e7985094433255c4b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4caf677f6942450cadd9cc15b0755e1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf67d6998e9d4fbebb85c8f3ac0c290f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ab7494e58034ce0ac2b03f63ae7d935": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3595584727904d4f8abd3f86d9914657": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unicamp-dl/IA025_2022S1/blob/main/ex09/rodrigo_cabrera_castaldoni/Aula_9_Exercicio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nome = \"Rodrigo Cabrera Castaldoni\"\n",
        "print(f'Meu nome é {nome}')"
      ],
      "metadata": {
        "id": "jOdQB41_4ZxG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b188806c-58a1-4344-b6f1-fd09d4f6bee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meu nome é Rodrigo Cabrera Castaldoni\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IbuChoAPMEn"
      },
      "source": [
        "#  Exercício: Modelo de Linguagem com auto-atenção"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_DBb0-Klwf2"
      },
      "source": [
        "Este exercício é similar ao da Aula 8, mas iremos agora treinar uma rede neural com **duas camadas** de auto-atenção **causais** para prever a próxima palavra de um texto, data as palavras anteriores como entrada. \n",
        "\n",
        "Iremos também trabalhar com sequencias de tamanho variável.\n",
        "\n",
        "Na camada de auto-atenção, não se esqueça de implementar:\n",
        "- Embeddings de posição\n",
        "- Projeções lineares (WQ, WK, WV, WO)\n",
        "- Conexões residuais\n",
        "- Camada de feed forward (2-layer MLP)\n",
        "\n",
        "\n",
        "O dataset usado neste exercício (BrWaC) possui um tamanho razoável e você vai precisar rodar seus experimentos com GPU.\n",
        "\n",
        "Alguns conselhos úteis:\n",
        "- **ATENÇÃO:** o dataset é bem grande. Não dê comando de imprimí-lo.\n",
        "- Durante a depuração, faça seu dataset ficar bem pequeno, para que a depuração seja mais rápida e não precise de GPU. Somente ligue a GPU quando o seu laço de treinamento já está funcionando\n",
        "- Não deixe para fazer esse exercício na véspera. Ele é trabalhoso."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# iremos utilizar a biblioteca dos transformers para ter acesso ao tokenizador do BERT.\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3twP0YJC4jmJ",
        "outputId": "c555173b-e5b4-4177-c98e-b8760989a762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnyhJZtTRNMx"
      },
      "source": [
        "## Importação dos pacotes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlIOVCajPWcU"
      },
      "source": [
        "import collections\n",
        "import itertools\n",
        "import functools\n",
        "import math\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm_notebook\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check which GPU we are using\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "w9f3PfifAwpU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e0fbe3f-7699-4fec-c38b-5b8428b3e258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jun  5 20:38:30 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "   dev = \"cuda:0\"\n",
        "else: \n",
        "   dev = \"cpu\"\n",
        "device = torch.device(dev)\n",
        "print('Using {}'.format(device))"
      ],
      "metadata": {
        "id": "whTCe2i7AtoV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e0acb54-e606-4cdc-fbb4-91c2a7c497e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZfxgV2DUk58"
      },
      "source": [
        "## Implementação do MyDataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_xhKm1EZ3bQ"
      },
      "source": [
        "from typing import List\n",
        "\n",
        "\n",
        "class MyDataset():\n",
        "    def __init__(self, texts: List[str], tokenizer, max_seq_length: int):\n",
        "        # Escreva aqui seu código.\n",
        "        self.texts = texts\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_seq_length = max_seq_length \n",
        "        self.start_sequence_id = self.tokenizer.cls_token_id\n",
        "        self.dataset = self._create_dataset()\n",
        "\n",
        "    def _tokenize(self, text: str, tokenizer):\n",
        "        # Recomenda-se usar o tokenizer.batch_encode_plus pois é mais rápido.\n",
        "        return tokenizer.batch_encode_plus(text, return_tensors=None, add_special_tokens=False).input_ids\n",
        "\n",
        "    def _text2samples(self, text):\n",
        "      tokens = tokenizer(text, return_tensors=None, add_special_tokens=False).input_ids\n",
        "\n",
        "      num_examples, resto = divmod(len(tokens), self.max_seq_length-1)\n",
        "      num_examples += 1 if resto!= 0 else 0\n",
        "      total_elem = num_examples*(self.max_seq_length -1)\n",
        "\n",
        "      padded_text = nn.functional.pad(torch.tensor(tokens), (0, total_elem - len(tokens)))\n",
        "      padded_text = padded_text.reshape(num_examples,-1)\n",
        "\n",
        "      init_sequence = torch.ones((num_examples, 1))*torch.tensor(self.start_sequence_id)\n",
        "      return torch.cat((init_sequence, padded_text), dim=1).type(torch.LongTensor)\n",
        "\n",
        "    def _create_dataset(self):\n",
        "        return torch.cat([self._text2samples(text) for text in tqdm_notebook(self.texts)])\n",
        "\n",
        "    def __len__(self):\n",
        "        # Escreva aqui seu código.\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Escreva aqui seu código.\n",
        "        \"\"\"\n",
        "        Eu acho que não estou otimizando memória aqui ...\n",
        "        \"\"\"\n",
        "        target = nn.functional.pad(self.dataset[idx, 1:], (0, 1))\n",
        "        input = self.dataset[idx, :]\n",
        "\n",
        "        return input, target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def split_sequence(sequence_tokens, start_sequence_id, max_seq_length):\n",
        "\n",
        "#   tokens = start_sequence_id + sequence_tokens\n",
        "#   if len(tokens) < max_seq_length:\n",
        "#     return [np.pad(tokens, (0, max_seq_length - len(tokens)))]\n",
        "#   else:\n",
        "#     first_part = np.asarray(tokens[:max_seq_length])\n",
        "#     last_part = tokens[max_seq_length:]\n",
        "#     return [first_part] + split_sequence(last_part, start_sequence_id, max_seq_length)\n",
        "\n",
        "\n",
        "# sample_text = 'Eu gosto de correr muito'\n",
        "# tokens = tokenizer(sample_text, return_tensors=None, add_special_tokens=False).input_ids\n",
        "# start_sequence_id = tokenizer(\"[CLS]\", return_tensors=None, add_special_tokens=False).input_ids\n",
        "\n",
        "# print(tokens)\n",
        "# split_sequence(tokens, start_sequence_id, 4)"
      ],
      "metadata": {
        "id": "8BAS36Ont06j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testando se a implementação do MyDataset está correta"
      ],
      "metadata": {
        "id": "wew-gFbWeBTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
        "\n",
        "dummy_texts = ['Eu gosto de correr', 'Ela gosta muito de comer pizza']\n",
        "\n",
        "dummy_dataset = MyDataset(texts=dummy_texts, tokenizer=tokenizer, max_seq_length=9)\n",
        "dummy_loader = DataLoader(dummy_dataset, batch_size=6, shuffle=False)\n",
        "assert len(dummy_dataset) == 2\n",
        "print('Passou no assert de tamanho do dataset.')\n",
        "\n",
        "first_batch_input, first_batch_target = next(iter(dummy_loader))\n",
        "\n",
        "correct_first_batch_input = torch.LongTensor(\n",
        "    [[  101,  3396, 10303,   125, 13239,     0,     0,     0,     0],\n",
        "     [  101,  1660,  5971,   785,   125,  1847, 13779, 15616,     0]])\n",
        "\n",
        "correct_first_batch_target = torch.LongTensor(\n",
        "    [[ 3396, 10303,   125, 13239,     0,     0,     0,     0,     0],\n",
        "     [ 1660,  5971,   785,   125,  1847, 13779, 15616,     0,     0]])\n",
        "\n",
        "assert torch.equal(first_batch_input, correct_first_batch_input)\n",
        "assert torch.equal(first_batch_target, correct_first_batch_target)\n",
        "\n",
        "print('Passou no assert de dataset.')"
      ],
      "metadata": {
        "id": "8r7jBFFUeApe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "8d00dd246bc7488a99a97ebe0fa15715",
            "8c16e08f547d4c609176d6186d5e3a97",
            "b2b9010d11164d088ba9d9b66afdbdf5",
            "f50f7f1a5d574b2a80c60dc93ff3a8d4",
            "306190cfe7524710b69196756584b11e",
            "7dc15252a4ac4ff6b33c7ab06480e1f0",
            "d9466721e49848f99cc1bbcdbecad099",
            "aa04f5319b2544c8bcb1eaaf0b28c14b",
            "ef7d17a6bfcb44f08a3217f7dd79bc7c",
            "25945a510ccc45cca45797065c4c888f",
            "deff87bd4ffd45879380a07051bf7f7b"
          ]
        },
        "outputId": "b788987e-b0d5-419d-ba26-9fe74a74e675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d00dd246bc7488a99a97ebe0fa15715"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passou no assert de tamanho do dataset.\n",
            "Passou no assert de dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LfrHHouleJ0"
      },
      "source": [
        "# Carregamento do dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2vFWjsSkmop"
      },
      "source": [
        "Iremos usar uma pequena amostra do dataset [BrWaC](https://www.inf.ufrgs.br/pln/wiki/index.php?title=BrWaC) para treinar e avaliar nosso modelo de linguagem."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://storage.googleapis.com/unicamp-dl/ia025a_2022s1/aula9/sample-1gb.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGlN1WqrXPA6",
        "outputId": "b5c84287-369a-4fde-9fc3-154985fa8ac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File ‘sample-1gb.txt’ already there; not retrieving.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "max_seq_length = 12\n",
        "\n",
        "train_examples = 50000\n",
        "valid_examples = 100\n",
        "test_examples = 100\n",
        "\n",
        "texts = open('sample-1gb.txt').readlines()\n",
        "\n",
        "print(f'Read {len(texts)} lines.')\n",
        "\n",
        "max_lines = train_examples + valid_examples + test_examples\n",
        "print(f'Truncating to {max_lines} lines.')\n",
        "texts = texts[:max_lines]  \n",
        "\n",
        "training_texts = texts[:-(valid_examples + test_examples)]\n",
        "valid_texts = texts[-(valid_examples + test_examples):-test_examples]\n",
        "test_texts = texts[-test_examples:]\n",
        "\n",
        "training_dataset = MyDataset(texts=training_texts, tokenizer=tokenizer, max_seq_length=max_seq_length)\n",
        "valid_dataset = MyDataset(texts=valid_texts, tokenizer=tokenizer, max_seq_length=max_seq_length)\n",
        "test_dataset = MyDataset(texts=test_texts, tokenizer=tokenizer, max_seq_length=max_seq_length)"
      ],
      "metadata": {
        "id": "gxa_4gmiA-wE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181,
          "referenced_widgets": [
            "59971bb26fdd46759ed9091f9314eec5",
            "12a0bf88c4c642c5b1622d7039e8f9bb",
            "8b10f98d509d45108dfde743a39229b1",
            "521d5f4af1cb448589e9730ec838f234",
            "d15994a914d34695ab973ac6fbe51cd6",
            "f5b4051037374bb3868f2ca0b0b74ac9",
            "fa71ba179bb74a1da400f0f561002a4a",
            "8d0f877615a64475a59b39a2c1895308",
            "323687bc205644849f9a101ac763ce7f",
            "15dce122b264407bb3d500138060eed0",
            "87fdf3758f7b4bac9c99cc0fadbb1e18",
            "8c6f5ce8beb246c3a7f38d4e34f021ba",
            "dacf77a7301e49a9b46ebd418173c89c",
            "58a7a7c6bc484d85874b704532fc0ef7",
            "ae8ac996fbeb408a804922779ff8976b",
            "097bd5d4579c4086a60f10e5d6f5f600",
            "a6d594fcba4844f49a57dfbea2649d86",
            "6060aeefe52740038659a928b28f597e",
            "3f7cfe2edcfc4393b701a682e119ec20",
            "73546ce75bf04aa6a8bed40a3aa4f3e7",
            "18b70fd36d2b46afb4191aaa0c5aa6de",
            "564f0c7be5e54b2ba3b0f58f20b0fa16",
            "e7d758ded96e463888422b072aa2aa2d",
            "68f01019b103474289584dbf9874b910",
            "90af127c6600463ab992223817907e2d",
            "f22d5fcb84ef4636a0d52474efb10e8d",
            "3dc6e4fd2cf04c1488bbb52eeb161b02",
            "f4579a0676c8409fbdbe948f668a73d9",
            "e9303132992c40e7985094433255c4b2",
            "4caf677f6942450cadd9cc15b0755e1c",
            "cf67d6998e9d4fbebb85c8f3ac0c290f",
            "4ab7494e58034ce0ac2b03f63ae7d935",
            "3595584727904d4f8abd3f86d9914657"
          ]
        },
        "outputId": "cdefbf48-9596-4954-e3e4-b8bb021e9925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read 250000 lines.\n",
            "Truncating to 50200 lines.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59971bb26fdd46759ed9091f9314eec5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c6f5ce8beb246c3a7f38d4e34f021ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7d758ded96e463888422b072aa2aa2d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'training examples: {len(training_dataset)}')\n",
        "print(f'valid examples: {len(valid_dataset)}')\n",
        "print(f'test examples: {len(test_dataset)}')"
      ],
      "metadata": {
        "id": "KCSGJ5m7py4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d9b6c32-0aba-457e-a367-749f6ecd35b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training examples: 5065773\n",
            "valid examples: 11409\n",
            "test examples: 11438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CausalAttentionHead(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, mask, pad_token_id, embedding_dim, head_dim):\n",
        "    super(CausalAttentionHead, self).__init__()\n",
        "    self.mask = mask\n",
        "    self.pad_token_id = pad_token_id\n",
        "    self.head_dim = torch.tensor([head_dim], device=device) # somente um escalar para realizar a divisão.\n",
        "    self.WQ = nn.Linear(embedding_dim, head_dim, bias=False)\n",
        "    self.WK = nn.Linear(embedding_dim, head_dim, bias=False)\n",
        "    self.WV = nn.Linear(embedding_dim, head_dim, bias=False)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "\n",
        "    keys = self.WK(inputs) # size: (batch_size, num_tokens, head_dim)\n",
        "    querys = self.WQ(inputs) # size: (batch_size, num_tokens, head_dim)\n",
        "    values = self.WV(inputs) # size: (batch_size, num_tokens, head_dim)\n",
        "\n",
        "    # aplica multiplicação matricial em batch \n",
        "    scores = torch.bmm(querys, keys.transpose(dim0=1, dim1=2)) / torch.sqrt(self.head_dim) # size: (batch_size, num_tokens, num_tokens)\n",
        "    masked_scores = scores.masked_fill(self.mask == self.pad_token_id, -float(\"inf\")) # size: (batch_size, num_tokens, num_tokens); truque para dar atenção aos tokens corretos\n",
        "    weights = torch.nn.functional.softmax(masked_scores, dim=-1) # size: (batch_size, num_tokens, num_tokens); transforma os scores em probas ao longo do último eixo\n",
        "    attention_scores = torch.bmm(weights, values) # size: (batch_size, num_tokens, head_dim)\n",
        "    \n",
        "    return attention_scores\n",
        "\n",
        "class TransformerLayer(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, mask, dim: int, pad_token_id: int, num_attention_heads: int):\n",
        "    super(TransformerLayer, self).__init__()\n",
        "\n",
        "    # Encontra a dimensão correta de cada cabeça \n",
        "    head_dim = dim // num_attention_heads\n",
        "\n",
        "    # Constrói mascara do AttentionHeadLayer\n",
        "\n",
        "    # Encontra a dimensão correta de cada cabeça \n",
        "\n",
        "    self.attentions_heads = nn.ModuleList([CausalAttentionHead(mask, pad_token_id, dim, head_dim) for _ in range(num_attention_heads)])\n",
        "    self.WO = nn.Linear(dim, dim)\n",
        "    self.layer_norm1 = nn.LayerNorm(dim)\n",
        "    self.layer_norm2 = nn.LayerNorm(dim)\n",
        "\n",
        "    \"\"\"\n",
        "    A rule of thumb from the literature is for the hidden size of the first layer to be four times the size of the embeddings.\n",
        "\n",
        "    Essa aqui é uma position-wise feed-forward layer.\n",
        "    \"\"\"\n",
        "\n",
        "    self.feed_forward = nn.Sequential(\n",
        "        torch.nn.Linear(dim, 2*dim),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(2*dim, dim),\n",
        "        nn.Dropout(0.3)\n",
        "    )\n",
        "\n",
        "  def forward(self, inputs): \n",
        "\n",
        "    # No caso em que o numero de cabecas seja multiplo de embedding_dim\n",
        "    concat_heads = torch.cat([h(inputs) for h in self.attentions_heads], dim=-1) # size: (batch_size, num_tokens, embedding_dim) \n",
        "\n",
        "    out = self.layer_norm1(self.WO(concat_heads) + inputs)\n",
        "    \n",
        "    return self.layer_norm2(self.feed_forward(out) + inputs)"
      ],
      "metadata": {
        "id": "kh8pXKK-p4ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGaAjYDfWdd1"
      },
      "source": [
        "class LanguageModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size: int, max_seq_length: int, dim: int, n_layers: int, pad_token_id: int, num_attention_heads):\n",
        "      \"\"\"\n",
        "      Implements the Self-attention, decoder-only.\"\n",
        "\n",
        "      Args:\n",
        "          vocab_size (int): Size of the input vocabulary.\n",
        "          max_seq_length (int): Size of the sequence to consider as context for prediction.\n",
        "          dim (int): Dimension of the embedding layer for each word in the context.\n",
        "          n_layers (int): number of self-attention layers.\n",
        "          pad_token_id (int): id of the pad token that will be ignored in the attention.\n",
        "      \"\"\"\n",
        "      # Escreva seu código aqui.\n",
        "      super(LanguageModel, self).__init__()\n",
        "      self.pad_token_id = pad_token_id\n",
        "      self.token_embeddings = nn.Embedding(vocab_size, dim, padding_idx=pad_token_id)\n",
        "      self.position_embeddings = nn.Embedding(max_seq_length, dim)     \n",
        "      self.position_ids = torch.arange(max_seq_length, dtype=torch.long, device=device).unsqueeze(0)\n",
        "\n",
        "      mask = torch.tril(torch.ones(max_seq_length, max_seq_length)).unsqueeze(0).to(device)\n",
        "\n",
        "      self.transformer_layer = nn.ModuleList([TransformerLayer(mask, dim, pad_token_id, num_attention_heads) for _ in range(n_layers)])\n",
        "\n",
        "      self.classifier = nn.Sequential(\n",
        "        torch.nn.Linear(dim, 2*dim),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(2*dim, 4*dim),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(4*dim, vocab_size),\n",
        "      )\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "      \"\"\"\n",
        "      Args:\n",
        "          inputs is a LongTensor of shape (batch_size, max_seq_length)\n",
        "          \n",
        "      Returns:\n",
        "          logits of shape (batch_size, max_seq_length, vocab_size)\n",
        "      \"\"\"\n",
        "      # Escreva seu código aqui.\n",
        "      token_embeddings = self.token_embeddings(inputs) \n",
        "      position_embeddings = self.position_embeddings(self.position_ids)\n",
        "      x = position_embeddings + token_embeddings\n",
        "      for layer in self.transformer_layer:\n",
        "        x = layer(x)\n",
        "      \n",
        "      return self.classifier(x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.pad_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "892EKQK0tmS8",
        "outputId": "cff18dc8-f9f5-4fb6-ea1b-1de4d7933a26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teste o modelo com um exemplo"
      ],
      "metadata": {
        "id": "Rm6_PTH2i98e"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwnxfZlrZoT_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1e9acad-949a-492f-8e78-849413fccfb5"
      },
      "source": [
        "model = LanguageModel(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    max_seq_length=max_seq_length,\n",
        "    dim=64,\n",
        "    n_layers=1,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        "    num_attention_heads=32\n",
        ").to(device)\n",
        "\n",
        "sample_input, _ = next(iter(DataLoader(training_dataset,batch_size=2)))\n",
        "sample_input = sample_input.to(device)\n",
        "sample_output = model(sample_input)\n",
        "print(f'sample_input.shape: {sample_input.shape}')\n",
        "print(f'sample_output.shape: {sample_output.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_input.shape: torch.Size([2, 12])\n",
            "sample_output.shape: torch.Size([2, 12, 29794])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3Vh6B-VkA01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3e320e2-ed22-4a8c-c2a6-6778178add89"
      },
      "source": [
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'Number of model parameters: {num_params}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of model parameters: 9639266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assert da Perplexidade\n"
      ],
      "metadata": {
        "id": "8nhbUVsYnVAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(123)\n",
        "np.random.seed(123)\n",
        "torch.manual_seed(123)\n",
        "\n",
        "\n",
        "def perplexity(logits, target, ignore_token_id: int):\n",
        "    \"\"\"\n",
        "    Computes the perplexity.\n",
        "\n",
        "    Args:\n",
        "        logits: a FloatTensor of shape (batch_size, seq_length, vocab_size)\n",
        "        target: a LongTensor of shape (batch_size, seq_length)\n",
        "\n",
        "    Returns:\n",
        "        A float corresponding to the perplexity\n",
        "    \"\"\"\n",
        "    logits = logits.reshape(-1, logits.shape[-1])\n",
        "    target = target.reshape(-1)\n",
        "    loss = nn.functional.cross_entropy(logits, target, reduction='mean', ignore_index=ignore_token_id)\n",
        "    return torch.exp(loss)\n",
        "\n",
        "\n",
        "n_examples = 1000\n",
        "\n",
        "train_input_ids, train_target_ids = next(iter(DataLoader(training_dataset, batch_size=n_examples)))\n",
        "train_input_ids = train_input_ids.to(device)\n",
        "train_target_ids = train_target_ids.to(device)\n",
        "\n",
        "logits = model(train_input_ids)\n",
        "\n",
        "my_perplexity = perplexity(logits=logits, target=train_target_ids, ignore_token_id=tokenizer.pad_token_id)\n",
        "\n",
        "print(f'my perplexity:              {int(my_perplexity)}')\n",
        "print(f'correct initial perplexity: {tokenizer.vocab_size}')\n",
        "\n",
        "assert math.isclose(my_perplexity, tokenizer.vocab_size, abs_tol=7000)\n",
        "print('Passou o no assert da perplexidade')"
      ],
      "metadata": {
        "id": "gbMP8VAUncfX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89435c7e-7186-42f9-a9fe-63a9fd41019b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my perplexity:              30106\n",
            "correct initial perplexity: 29794\n",
            "Passou o no assert da perplexidade\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Laço de Treinamento e Validação"
      ],
      "metadata": {
        "id": "KiJtrsqPnE_l"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIMSaY-UUGUE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e518613f-090e-46f0-88b7-e66b524285e0"
      },
      "source": [
        "max_examples = 150_000_000\n",
        "eval_every_steps = 1000\n",
        "lr = 3e-4\n",
        "\n",
        "\n",
        "model = LanguageModel(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    max_seq_length=max_seq_length,\n",
        "    dim=256,\n",
        "    n_layers=2,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        "    num_attention_heads=32    \n",
        ").to(device)\n",
        "\n",
        "train_loader = DataLoader(training_dataset, batch_size=64, shuffle=True, drop_last=True)\n",
        "validation_loader = DataLoader(valid_dataset, batch_size=64)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "def train_step(input_ids, target_ids):\n",
        "    model.train()\n",
        "    model.zero_grad()\n",
        "    logits = model(input_ids)\n",
        "    logits = logits.reshape(-1, logits.shape[-1])\n",
        "    target_ids = target_ids.reshape(-1)\n",
        "    loss = nn.functional.cross_entropy(logits, target_ids, ignore_index=model.pad_token_id)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "def validation_step(input_ids, target_ids):\n",
        "    model.eval()\n",
        "    logits = model(input_ids)\n",
        "    logits = logits.reshape(-1, logits.shape[-1])\n",
        "    target_ids = target_ids.reshape(-1)\n",
        "    loss = nn.functional.cross_entropy(logits, target_ids, ignore_index=model.pad_token_id)\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "train_losses = []\n",
        "n_examples = 0\n",
        "step = 0\n",
        "while n_examples < max_examples:\n",
        "    for train_input_ids, train_target_ids in train_loader:\n",
        "        loss = train_step(train_input_ids.to(device), train_target_ids.to(device)) \n",
        "        train_losses.append(loss)\n",
        "        \n",
        "        if step % eval_every_steps == 0:\n",
        "            train_ppl = np.exp(np.average(train_losses))\n",
        "\n",
        "            with torch.no_grad():\n",
        "                valid_ppl = np.exp(np.average([\n",
        "                    validation_step(val_input_ids.to(device), val_target_ids.to(device))\n",
        "                    for val_input_ids, val_target_ids in validation_loader]))\n",
        "\n",
        "            print(f'{step} steps; {n_examples} examples so far; train ppl: {train_ppl:.2f}, valid ppl: {valid_ppl:.2f}')\n",
        "            train_losses = []\n",
        "\n",
        "        n_examples += len(train_input_ids)  # Increment of batch size\n",
        "        step += 1\n",
        "        if n_examples >= max_examples:\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 steps; 0 examples so far; train ppl: 30262.83, valid ppl: 29022.21\n",
            "1000 steps; 64000 examples so far; train ppl: 1318.33, valid ppl: 921.44\n",
            "2000 steps; 128000 examples so far; train ppl: 762.20, valid ppl: 674.43\n",
            "3000 steps; 192000 examples so far; train ppl: 591.41, valid ppl: 534.90\n",
            "4000 steps; 256000 examples so far; train ppl: 491.28, valid ppl: 458.66\n",
            "5000 steps; 320000 examples so far; train ppl: 435.20, valid ppl: 414.26\n",
            "6000 steps; 384000 examples so far; train ppl: 395.66, valid ppl: 381.50\n",
            "7000 steps; 448000 examples so far; train ppl: 371.79, valid ppl: 359.97\n",
            "8000 steps; 512000 examples so far; train ppl: 351.45, valid ppl: 343.97\n",
            "9000 steps; 576000 examples so far; train ppl: 338.41, valid ppl: 328.73\n",
            "10000 steps; 640000 examples so far; train ppl: 326.79, valid ppl: 317.31\n",
            "11000 steps; 704000 examples so far; train ppl: 317.30, valid ppl: 309.30\n",
            "12000 steps; 768000 examples so far; train ppl: 309.38, valid ppl: 302.05\n",
            "13000 steps; 832000 examples so far; train ppl: 301.61, valid ppl: 294.87\n",
            "14000 steps; 896000 examples so far; train ppl: 294.11, valid ppl: 289.01\n",
            "15000 steps; 960000 examples so far; train ppl: 288.83, valid ppl: 282.90\n",
            "16000 steps; 1024000 examples so far; train ppl: 287.07, valid ppl: 277.88\n",
            "17000 steps; 1088000 examples so far; train ppl: 280.60, valid ppl: 276.14\n",
            "18000 steps; 1152000 examples so far; train ppl: 276.60, valid ppl: 271.90\n",
            "19000 steps; 1216000 examples so far; train ppl: 273.30, valid ppl: 269.26\n",
            "20000 steps; 1280000 examples so far; train ppl: 269.90, valid ppl: 268.28\n",
            "21000 steps; 1344000 examples so far; train ppl: 268.66, valid ppl: 264.60\n",
            "22000 steps; 1408000 examples so far; train ppl: 262.05, valid ppl: 262.11\n",
            "23000 steps; 1472000 examples so far; train ppl: 263.66, valid ppl: 259.01\n",
            "24000 steps; 1536000 examples so far; train ppl: 258.35, valid ppl: 256.22\n",
            "25000 steps; 1600000 examples so far; train ppl: 258.29, valid ppl: 254.52\n",
            "26000 steps; 1664000 examples so far; train ppl: 254.15, valid ppl: 254.27\n",
            "27000 steps; 1728000 examples so far; train ppl: 254.56, valid ppl: 250.97\n",
            "28000 steps; 1792000 examples so far; train ppl: 251.48, valid ppl: 248.25\n",
            "29000 steps; 1856000 examples so far; train ppl: 251.89, valid ppl: 247.79\n",
            "30000 steps; 1920000 examples so far; train ppl: 249.67, valid ppl: 246.32\n",
            "31000 steps; 1984000 examples so far; train ppl: 247.68, valid ppl: 245.00\n",
            "32000 steps; 2048000 examples so far; train ppl: 248.17, valid ppl: 245.09\n",
            "33000 steps; 2112000 examples so far; train ppl: 246.24, valid ppl: 242.94\n",
            "34000 steps; 2176000 examples so far; train ppl: 243.69, valid ppl: 241.78\n",
            "35000 steps; 2240000 examples so far; train ppl: 244.55, valid ppl: 240.15\n",
            "36000 steps; 2304000 examples so far; train ppl: 242.49, valid ppl: 241.64\n",
            "37000 steps; 2368000 examples so far; train ppl: 242.07, valid ppl: 239.33\n",
            "38000 steps; 2432000 examples so far; train ppl: 240.82, valid ppl: 237.81\n",
            "39000 steps; 2496000 examples so far; train ppl: 240.22, valid ppl: 236.88\n",
            "40000 steps; 2560000 examples so far; train ppl: 238.67, valid ppl: 236.89\n",
            "41000 steps; 2624000 examples so far; train ppl: 238.29, valid ppl: 236.06\n",
            "42000 steps; 2688000 examples so far; train ppl: 236.13, valid ppl: 234.30\n",
            "43000 steps; 2752000 examples so far; train ppl: 238.96, valid ppl: 234.37\n",
            "44000 steps; 2816000 examples so far; train ppl: 235.53, valid ppl: 234.60\n",
            "45000 steps; 2880000 examples so far; train ppl: 235.16, valid ppl: 232.76\n",
            "46000 steps; 2944000 examples so far; train ppl: 233.82, valid ppl: 233.01\n",
            "47000 steps; 3008000 examples so far; train ppl: 234.47, valid ppl: 231.42\n",
            "48000 steps; 3072000 examples so far; train ppl: 233.28, valid ppl: 232.37\n",
            "49000 steps; 3136000 examples so far; train ppl: 231.65, valid ppl: 230.80\n",
            "50000 steps; 3200000 examples so far; train ppl: 232.48, valid ppl: 229.88\n",
            "51000 steps; 3264000 examples so far; train ppl: 231.57, valid ppl: 228.95\n",
            "52000 steps; 3328000 examples so far; train ppl: 229.77, valid ppl: 228.47\n",
            "53000 steps; 3392000 examples so far; train ppl: 230.86, valid ppl: 227.79\n",
            "54000 steps; 3456000 examples so far; train ppl: 228.67, valid ppl: 227.15\n",
            "55000 steps; 3520000 examples so far; train ppl: 228.55, valid ppl: 227.65\n",
            "56000 steps; 3584000 examples so far; train ppl: 229.02, valid ppl: 227.36\n",
            "57000 steps; 3648000 examples so far; train ppl: 228.12, valid ppl: 226.18\n",
            "58000 steps; 3712000 examples so far; train ppl: 228.24, valid ppl: 225.59\n",
            "59000 steps; 3776000 examples so far; train ppl: 226.50, valid ppl: 225.25\n",
            "60000 steps; 3840000 examples so far; train ppl: 226.12, valid ppl: 225.89\n",
            "61000 steps; 3904000 examples so far; train ppl: 225.24, valid ppl: 225.49\n",
            "62000 steps; 3968000 examples so far; train ppl: 225.88, valid ppl: 224.91\n",
            "63000 steps; 4032000 examples so far; train ppl: 224.23, valid ppl: 223.51\n",
            "64000 steps; 4096000 examples so far; train ppl: 223.25, valid ppl: 222.90\n",
            "65000 steps; 4160000 examples so far; train ppl: 224.46, valid ppl: 223.40\n",
            "66000 steps; 4224000 examples so far; train ppl: 223.68, valid ppl: 222.25\n",
            "67000 steps; 4288000 examples so far; train ppl: 223.53, valid ppl: 222.05\n",
            "68000 steps; 4352000 examples so far; train ppl: 223.64, valid ppl: 220.73\n",
            "69000 steps; 4416000 examples so far; train ppl: 222.44, valid ppl: 221.37\n",
            "70000 steps; 4480000 examples so far; train ppl: 222.21, valid ppl: 219.58\n",
            "71000 steps; 4544000 examples so far; train ppl: 221.97, valid ppl: 219.95\n",
            "72000 steps; 4608000 examples so far; train ppl: 221.20, valid ppl: 219.39\n",
            "73000 steps; 4672000 examples so far; train ppl: 219.77, valid ppl: 218.43\n",
            "74000 steps; 4736000 examples so far; train ppl: 220.44, valid ppl: 219.35\n",
            "75000 steps; 4800000 examples so far; train ppl: 217.86, valid ppl: 218.18\n",
            "76000 steps; 4864000 examples so far; train ppl: 217.34, valid ppl: 217.46\n",
            "77000 steps; 4928000 examples so far; train ppl: 219.96, valid ppl: 216.58\n",
            "78000 steps; 4992000 examples so far; train ppl: 218.61, valid ppl: 217.06\n",
            "79000 steps; 5056000 examples so far; train ppl: 216.91, valid ppl: 217.57\n",
            "80000 steps; 5120000 examples so far; train ppl: 208.58, valid ppl: 215.62\n",
            "81000 steps; 5184000 examples so far; train ppl: 207.14, valid ppl: 216.51\n",
            "82000 steps; 5248000 examples so far; train ppl: 206.94, valid ppl: 216.18\n",
            "83000 steps; 5312000 examples so far; train ppl: 207.75, valid ppl: 214.53\n",
            "84000 steps; 5376000 examples so far; train ppl: 205.93, valid ppl: 214.98\n",
            "85000 steps; 5440000 examples so far; train ppl: 207.40, valid ppl: 214.65\n",
            "86000 steps; 5504000 examples so far; train ppl: 206.40, valid ppl: 215.07\n",
            "87000 steps; 5568000 examples so far; train ppl: 205.11, valid ppl: 214.79\n",
            "88000 steps; 5632000 examples so far; train ppl: 206.13, valid ppl: 215.28\n",
            "89000 steps; 5696000 examples so far; train ppl: 205.42, valid ppl: 212.96\n",
            "90000 steps; 5760000 examples so far; train ppl: 204.91, valid ppl: 214.30\n",
            "91000 steps; 5824000 examples so far; train ppl: 206.43, valid ppl: 212.96\n",
            "92000 steps; 5888000 examples so far; train ppl: 204.61, valid ppl: 211.75\n",
            "93000 steps; 5952000 examples so far; train ppl: 204.15, valid ppl: 212.37\n",
            "94000 steps; 6016000 examples so far; train ppl: 205.90, valid ppl: 211.37\n",
            "95000 steps; 6080000 examples so far; train ppl: 204.61, valid ppl: 211.76\n",
            "96000 steps; 6144000 examples so far; train ppl: 204.18, valid ppl: 211.34\n",
            "97000 steps; 6208000 examples so far; train ppl: 203.70, valid ppl: 210.21\n",
            "98000 steps; 6272000 examples so far; train ppl: 204.32, valid ppl: 211.00\n",
            "99000 steps; 6336000 examples so far; train ppl: 203.10, valid ppl: 210.12\n",
            "100000 steps; 6400000 examples so far; train ppl: 204.07, valid ppl: 209.75\n",
            "101000 steps; 6464000 examples so far; train ppl: 203.39, valid ppl: 209.26\n",
            "102000 steps; 6528000 examples so far; train ppl: 203.63, valid ppl: 209.52\n",
            "103000 steps; 6592000 examples so far; train ppl: 202.73, valid ppl: 209.61\n",
            "104000 steps; 6656000 examples so far; train ppl: 204.48, valid ppl: 208.91\n",
            "105000 steps; 6720000 examples so far; train ppl: 202.20, valid ppl: 208.27\n",
            "106000 steps; 6784000 examples so far; train ppl: 202.52, valid ppl: 207.60\n",
            "107000 steps; 6848000 examples so far; train ppl: 202.00, valid ppl: 207.51\n",
            "108000 steps; 6912000 examples so far; train ppl: 201.15, valid ppl: 207.11\n",
            "109000 steps; 6976000 examples so far; train ppl: 201.54, valid ppl: 207.05\n",
            "110000 steps; 7040000 examples so far; train ppl: 201.42, valid ppl: 206.24\n",
            "111000 steps; 7104000 examples so far; train ppl: 202.04, valid ppl: 206.83\n",
            "112000 steps; 7168000 examples so far; train ppl: 202.28, valid ppl: 205.80\n",
            "113000 steps; 7232000 examples so far; train ppl: 199.78, valid ppl: 205.26\n",
            "114000 steps; 7296000 examples so far; train ppl: 201.22, valid ppl: 205.15\n",
            "115000 steps; 7360000 examples so far; train ppl: 200.89, valid ppl: 204.33\n",
            "116000 steps; 7424000 examples so far; train ppl: 200.61, valid ppl: 204.29\n",
            "117000 steps; 7488000 examples so far; train ppl: 200.80, valid ppl: 204.09\n",
            "118000 steps; 7552000 examples so far; train ppl: 199.10, valid ppl: 203.68\n",
            "119000 steps; 7616000 examples so far; train ppl: 199.16, valid ppl: 203.92\n",
            "120000 steps; 7680000 examples so far; train ppl: 200.29, valid ppl: 203.25\n",
            "121000 steps; 7744000 examples so far; train ppl: 198.64, valid ppl: 203.02\n",
            "122000 steps; 7808000 examples so far; train ppl: 200.53, valid ppl: 202.17\n",
            "123000 steps; 7872000 examples so far; train ppl: 198.82, valid ppl: 202.48\n",
            "124000 steps; 7936000 examples so far; train ppl: 198.71, valid ppl: 201.67\n",
            "125000 steps; 8000000 examples so far; train ppl: 198.17, valid ppl: 201.35\n",
            "126000 steps; 8064000 examples so far; train ppl: 198.36, valid ppl: 201.40\n",
            "127000 steps; 8128000 examples so far; train ppl: 197.49, valid ppl: 200.23\n",
            "128000 steps; 8192000 examples so far; train ppl: 197.60, valid ppl: 200.59\n",
            "129000 steps; 8256000 examples so far; train ppl: 195.89, valid ppl: 200.10\n",
            "130000 steps; 8320000 examples so far; train ppl: 197.74, valid ppl: 200.31\n",
            "131000 steps; 8384000 examples so far; train ppl: 196.16, valid ppl: 200.80\n",
            "132000 steps; 8448000 examples so far; train ppl: 196.14, valid ppl: 199.88\n",
            "133000 steps; 8512000 examples so far; train ppl: 196.52, valid ppl: 199.14\n",
            "134000 steps; 8576000 examples so far; train ppl: 197.59, valid ppl: 198.94\n",
            "135000 steps; 8640000 examples so far; train ppl: 197.09, valid ppl: 198.74\n",
            "136000 steps; 8704000 examples so far; train ppl: 195.23, valid ppl: 198.41\n",
            "137000 steps; 8768000 examples so far; train ppl: 195.45, valid ppl: 198.60\n",
            "138000 steps; 8832000 examples so far; train ppl: 194.45, valid ppl: 197.90\n",
            "139000 steps; 8896000 examples so far; train ppl: 194.89, valid ppl: 197.45\n",
            "140000 steps; 8960000 examples so far; train ppl: 195.10, valid ppl: 197.60\n",
            "141000 steps; 9024000 examples so far; train ppl: 193.99, valid ppl: 196.91\n",
            "142000 steps; 9088000 examples so far; train ppl: 194.34, valid ppl: 196.10\n",
            "143000 steps; 9152000 examples so far; train ppl: 194.65, valid ppl: 195.71\n",
            "144000 steps; 9216000 examples so far; train ppl: 194.91, valid ppl: 195.86\n",
            "145000 steps; 9280000 examples so far; train ppl: 193.74, valid ppl: 195.84\n",
            "146000 steps; 9344000 examples so far; train ppl: 193.65, valid ppl: 195.76\n",
            "147000 steps; 9408000 examples so far; train ppl: 193.66, valid ppl: 195.67\n",
            "148000 steps; 9472000 examples so far; train ppl: 193.19, valid ppl: 195.56\n",
            "149000 steps; 9536000 examples so far; train ppl: 192.84, valid ppl: 195.10\n",
            "150000 steps; 9600000 examples so far; train ppl: 192.96, valid ppl: 195.13\n",
            "151000 steps; 9664000 examples so far; train ppl: 191.60, valid ppl: 194.89\n",
            "152000 steps; 9728000 examples so far; train ppl: 192.03, valid ppl: 194.42\n",
            "153000 steps; 9792000 examples so far; train ppl: 191.27, valid ppl: 194.87\n",
            "154000 steps; 9856000 examples so far; train ppl: 191.26, valid ppl: 194.70\n",
            "155000 steps; 9920000 examples so far; train ppl: 191.26, valid ppl: 194.63\n",
            "156000 steps; 9984000 examples so far; train ppl: 190.84, valid ppl: 193.57\n",
            "157000 steps; 10048000 examples so far; train ppl: 190.91, valid ppl: 193.41\n",
            "158000 steps; 10112000 examples so far; train ppl: 191.61, valid ppl: 193.65\n",
            "159000 steps; 10176000 examples so far; train ppl: 185.45, valid ppl: 193.12\n",
            "160000 steps; 10240000 examples so far; train ppl: 182.52, valid ppl: 193.05\n",
            "161000 steps; 10304000 examples so far; train ppl: 182.94, valid ppl: 192.93\n",
            "162000 steps; 10368000 examples so far; train ppl: 181.86, valid ppl: 191.98\n",
            "163000 steps; 10432000 examples so far; train ppl: 181.91, valid ppl: 193.26\n",
            "164000 steps; 10496000 examples so far; train ppl: 181.76, valid ppl: 192.84\n",
            "165000 steps; 10560000 examples so far; train ppl: 182.42, valid ppl: 193.00\n",
            "166000 steps; 10624000 examples so far; train ppl: 181.92, valid ppl: 191.86\n",
            "167000 steps; 10688000 examples so far; train ppl: 182.88, valid ppl: 192.47\n",
            "168000 steps; 10752000 examples so far; train ppl: 181.40, valid ppl: 192.79\n",
            "169000 steps; 10816000 examples so far; train ppl: 182.05, valid ppl: 192.08\n",
            "170000 steps; 10880000 examples so far; train ppl: 182.81, valid ppl: 192.26\n",
            "171000 steps; 10944000 examples so far; train ppl: 181.76, valid ppl: 192.21\n",
            "172000 steps; 11008000 examples so far; train ppl: 180.76, valid ppl: 192.41\n",
            "173000 steps; 11072000 examples so far; train ppl: 183.18, valid ppl: 191.32\n",
            "174000 steps; 11136000 examples so far; train ppl: 182.10, valid ppl: 191.20\n",
            "175000 steps; 11200000 examples so far; train ppl: 182.65, valid ppl: 191.44\n",
            "176000 steps; 11264000 examples so far; train ppl: 182.65, valid ppl: 190.65\n",
            "177000 steps; 11328000 examples so far; train ppl: 181.03, valid ppl: 190.49\n",
            "178000 steps; 11392000 examples so far; train ppl: 181.80, valid ppl: 190.94\n",
            "179000 steps; 11456000 examples so far; train ppl: 182.01, valid ppl: 189.84\n",
            "180000 steps; 11520000 examples so far; train ppl: 181.74, valid ppl: 190.36\n",
            "181000 steps; 11584000 examples so far; train ppl: 181.45, valid ppl: 190.41\n",
            "182000 steps; 11648000 examples so far; train ppl: 180.83, valid ppl: 190.30\n",
            "183000 steps; 11712000 examples so far; train ppl: 181.43, valid ppl: 190.17\n",
            "184000 steps; 11776000 examples so far; train ppl: 180.43, valid ppl: 189.57\n",
            "185000 steps; 11840000 examples so far; train ppl: 180.40, valid ppl: 189.64\n",
            "186000 steps; 11904000 examples so far; train ppl: 182.19, valid ppl: 190.15\n",
            "187000 steps; 11968000 examples so far; train ppl: 180.74, valid ppl: 188.97\n",
            "188000 steps; 12032000 examples so far; train ppl: 180.71, valid ppl: 188.71\n",
            "189000 steps; 12096000 examples so far; train ppl: 181.98, valid ppl: 189.63\n",
            "190000 steps; 12160000 examples so far; train ppl: 182.99, valid ppl: 189.08\n",
            "191000 steps; 12224000 examples so far; train ppl: 180.73, valid ppl: 188.86\n",
            "192000 steps; 12288000 examples so far; train ppl: 181.11, valid ppl: 188.75\n",
            "193000 steps; 12352000 examples so far; train ppl: 179.99, valid ppl: 188.75\n",
            "194000 steps; 12416000 examples so far; train ppl: 182.26, valid ppl: 188.26\n",
            "195000 steps; 12480000 examples so far; train ppl: 180.53, valid ppl: 188.11\n",
            "196000 steps; 12544000 examples so far; train ppl: 180.50, valid ppl: 188.33\n",
            "197000 steps; 12608000 examples so far; train ppl: 180.24, valid ppl: 187.73\n",
            "198000 steps; 12672000 examples so far; train ppl: 180.87, valid ppl: 187.33\n",
            "199000 steps; 12736000 examples so far; train ppl: 180.52, valid ppl: 187.22\n",
            "200000 steps; 12800000 examples so far; train ppl: 180.00, valid ppl: 187.93\n",
            "201000 steps; 12864000 examples so far; train ppl: 180.08, valid ppl: 187.35\n",
            "202000 steps; 12928000 examples so far; train ppl: 180.45, valid ppl: 187.61\n",
            "203000 steps; 12992000 examples so far; train ppl: 181.12, valid ppl: 187.16\n",
            "204000 steps; 13056000 examples so far; train ppl: 179.79, valid ppl: 187.08\n",
            "205000 steps; 13120000 examples so far; train ppl: 179.12, valid ppl: 187.09\n",
            "206000 steps; 13184000 examples so far; train ppl: 180.83, valid ppl: 186.49\n",
            "207000 steps; 13248000 examples so far; train ppl: 179.74, valid ppl: 185.95\n",
            "208000 steps; 13312000 examples so far; train ppl: 179.37, valid ppl: 186.01\n",
            "209000 steps; 13376000 examples so far; train ppl: 179.60, valid ppl: 185.86\n",
            "210000 steps; 13440000 examples so far; train ppl: 179.68, valid ppl: 186.04\n",
            "211000 steps; 13504000 examples so far; train ppl: 179.63, valid ppl: 186.56\n",
            "212000 steps; 13568000 examples so far; train ppl: 179.12, valid ppl: 186.19\n",
            "213000 steps; 13632000 examples so far; train ppl: 178.47, valid ppl: 186.05\n",
            "214000 steps; 13696000 examples so far; train ppl: 179.56, valid ppl: 185.57\n",
            "215000 steps; 13760000 examples so far; train ppl: 179.98, valid ppl: 185.15\n",
            "216000 steps; 13824000 examples so far; train ppl: 181.04, valid ppl: 185.49\n",
            "217000 steps; 13888000 examples so far; train ppl: 178.69, valid ppl: 186.10\n",
            "218000 steps; 13952000 examples so far; train ppl: 178.26, valid ppl: 184.69\n",
            "219000 steps; 14016000 examples so far; train ppl: 179.42, valid ppl: 185.15\n",
            "220000 steps; 14080000 examples so far; train ppl: 178.08, valid ppl: 185.06\n",
            "221000 steps; 14144000 examples so far; train ppl: 179.24, valid ppl: 184.96\n",
            "222000 steps; 14208000 examples so far; train ppl: 179.11, valid ppl: 184.64\n",
            "223000 steps; 14272000 examples so far; train ppl: 179.77, valid ppl: 184.43\n",
            "224000 steps; 14336000 examples so far; train ppl: 177.44, valid ppl: 184.04\n",
            "225000 steps; 14400000 examples so far; train ppl: 178.50, valid ppl: 184.57\n",
            "226000 steps; 14464000 examples so far; train ppl: 178.84, valid ppl: 184.20\n",
            "227000 steps; 14528000 examples so far; train ppl: 179.35, valid ppl: 183.68\n",
            "228000 steps; 14592000 examples so far; train ppl: 177.65, valid ppl: 184.16\n",
            "229000 steps; 14656000 examples so far; train ppl: 178.25, valid ppl: 183.80\n",
            "230000 steps; 14720000 examples so far; train ppl: 178.70, valid ppl: 183.78\n",
            "231000 steps; 14784000 examples so far; train ppl: 178.56, valid ppl: 183.34\n",
            "232000 steps; 14848000 examples so far; train ppl: 177.54, valid ppl: 183.52\n",
            "233000 steps; 14912000 examples so far; train ppl: 178.56, valid ppl: 182.90\n",
            "234000 steps; 14976000 examples so far; train ppl: 179.06, valid ppl: 183.18\n",
            "235000 steps; 15040000 examples so far; train ppl: 176.99, valid ppl: 182.42\n",
            "236000 steps; 15104000 examples so far; train ppl: 178.35, valid ppl: 182.64\n",
            "237000 steps; 15168000 examples so far; train ppl: 178.12, valid ppl: 182.55\n",
            "238000 steps; 15232000 examples so far; train ppl: 174.30, valid ppl: 182.54\n",
            "239000 steps; 15296000 examples so far; train ppl: 170.41, valid ppl: 183.10\n",
            "240000 steps; 15360000 examples so far; train ppl: 169.22, valid ppl: 182.52\n",
            "241000 steps; 15424000 examples so far; train ppl: 169.50, valid ppl: 182.47\n",
            "242000 steps; 15488000 examples so far; train ppl: 170.16, valid ppl: 182.68\n",
            "243000 steps; 15552000 examples so far; train ppl: 171.51, valid ppl: 182.81\n",
            "244000 steps; 15616000 examples so far; train ppl: 170.35, valid ppl: 182.34\n",
            "245000 steps; 15680000 examples so far; train ppl: 171.43, valid ppl: 182.06\n",
            "246000 steps; 15744000 examples so far; train ppl: 170.11, valid ppl: 182.26\n",
            "247000 steps; 15808000 examples so far; train ppl: 170.41, valid ppl: 182.31\n",
            "248000 steps; 15872000 examples so far; train ppl: 171.05, valid ppl: 181.90\n",
            "249000 steps; 15936000 examples so far; train ppl: 170.63, valid ppl: 182.09\n",
            "250000 steps; 16000000 examples so far; train ppl: 169.90, valid ppl: 182.14\n",
            "251000 steps; 16064000 examples so far; train ppl: 171.00, valid ppl: 182.02\n",
            "252000 steps; 16128000 examples so far; train ppl: 170.49, valid ppl: 181.91\n",
            "253000 steps; 16192000 examples so far; train ppl: 172.13, valid ppl: 182.54\n",
            "254000 steps; 16256000 examples so far; train ppl: 172.42, valid ppl: 181.63\n",
            "255000 steps; 16320000 examples so far; train ppl: 172.28, valid ppl: 182.23\n",
            "256000 steps; 16384000 examples so far; train ppl: 171.03, valid ppl: 181.54\n",
            "257000 steps; 16448000 examples so far; train ppl: 171.57, valid ppl: 181.22\n",
            "258000 steps; 16512000 examples so far; train ppl: 170.27, valid ppl: 181.36\n",
            "259000 steps; 16576000 examples so far; train ppl: 170.72, valid ppl: 181.40\n",
            "260000 steps; 16640000 examples so far; train ppl: 170.28, valid ppl: 181.35\n",
            "261000 steps; 16704000 examples so far; train ppl: 170.49, valid ppl: 181.21\n",
            "262000 steps; 16768000 examples so far; train ppl: 170.79, valid ppl: 180.99\n",
            "263000 steps; 16832000 examples so far; train ppl: 170.25, valid ppl: 181.19\n",
            "264000 steps; 16896000 examples so far; train ppl: 170.53, valid ppl: 180.30\n",
            "265000 steps; 16960000 examples so far; train ppl: 171.31, valid ppl: 180.61\n",
            "266000 steps; 17024000 examples so far; train ppl: 170.94, valid ppl: 180.95\n",
            "267000 steps; 17088000 examples so far; train ppl: 172.01, valid ppl: 180.72\n",
            "268000 steps; 17152000 examples so far; train ppl: 171.30, valid ppl: 180.47\n",
            "269000 steps; 17216000 examples so far; train ppl: 170.40, valid ppl: 180.75\n",
            "270000 steps; 17280000 examples so far; train ppl: 171.27, valid ppl: 180.82\n",
            "271000 steps; 17344000 examples so far; train ppl: 170.83, valid ppl: 180.19\n",
            "272000 steps; 17408000 examples so far; train ppl: 170.46, valid ppl: 180.64\n",
            "273000 steps; 17472000 examples so far; train ppl: 170.88, valid ppl: 180.12\n",
            "274000 steps; 17536000 examples so far; train ppl: 171.30, valid ppl: 180.24\n",
            "275000 steps; 17600000 examples so far; train ppl: 171.44, valid ppl: 180.56\n",
            "276000 steps; 17664000 examples so far; train ppl: 171.91, valid ppl: 178.77\n",
            "277000 steps; 17728000 examples so far; train ppl: 170.67, valid ppl: 179.48\n",
            "278000 steps; 17792000 examples so far; train ppl: 170.43, valid ppl: 179.84\n",
            "279000 steps; 17856000 examples so far; train ppl: 170.90, valid ppl: 179.55\n",
            "280000 steps; 17920000 examples so far; train ppl: 170.52, valid ppl: 179.37\n",
            "281000 steps; 17984000 examples so far; train ppl: 170.54, valid ppl: 179.48\n",
            "282000 steps; 18048000 examples so far; train ppl: 170.49, valid ppl: 179.70\n",
            "283000 steps; 18112000 examples so far; train ppl: 171.03, valid ppl: 179.32\n",
            "284000 steps; 18176000 examples so far; train ppl: 170.79, valid ppl: 179.48\n",
            "285000 steps; 18240000 examples so far; train ppl: 170.90, valid ppl: 178.77\n",
            "286000 steps; 18304000 examples so far; train ppl: 171.25, valid ppl: 178.33\n",
            "287000 steps; 18368000 examples so far; train ppl: 170.93, valid ppl: 179.36\n",
            "288000 steps; 18432000 examples so far; train ppl: 170.70, valid ppl: 178.61\n",
            "289000 steps; 18496000 examples so far; train ppl: 171.06, valid ppl: 179.18\n",
            "290000 steps; 18560000 examples so far; train ppl: 168.88, valid ppl: 178.93\n",
            "291000 steps; 18624000 examples so far; train ppl: 170.79, valid ppl: 178.77\n",
            "292000 steps; 18688000 examples so far; train ppl: 171.06, valid ppl: 178.96\n",
            "293000 steps; 18752000 examples so far; train ppl: 170.88, valid ppl: 178.79\n",
            "294000 steps; 18816000 examples so far; train ppl: 170.29, valid ppl: 178.75\n",
            "295000 steps; 18880000 examples so far; train ppl: 171.24, valid ppl: 177.88\n",
            "296000 steps; 18944000 examples so far; train ppl: 170.11, valid ppl: 178.40\n",
            "297000 steps; 19008000 examples so far; train ppl: 170.47, valid ppl: 177.75\n",
            "298000 steps; 19072000 examples so far; train ppl: 171.06, valid ppl: 177.98\n",
            "299000 steps; 19136000 examples so far; train ppl: 169.12, valid ppl: 178.26\n",
            "300000 steps; 19200000 examples so far; train ppl: 169.54, valid ppl: 178.20\n",
            "301000 steps; 19264000 examples so far; train ppl: 169.75, valid ppl: 177.25\n",
            "302000 steps; 19328000 examples so far; train ppl: 170.21, valid ppl: 177.55\n",
            "303000 steps; 19392000 examples so far; train ppl: 170.01, valid ppl: 177.89\n",
            "304000 steps; 19456000 examples so far; train ppl: 169.31, valid ppl: 177.26\n",
            "305000 steps; 19520000 examples so far; train ppl: 171.22, valid ppl: 177.82\n",
            "306000 steps; 19584000 examples so far; train ppl: 168.81, valid ppl: 178.05\n",
            "307000 steps; 19648000 examples so far; train ppl: 169.40, valid ppl: 177.70\n",
            "308000 steps; 19712000 examples so far; train ppl: 169.26, valid ppl: 177.24\n",
            "309000 steps; 19776000 examples so far; train ppl: 170.73, valid ppl: 177.63\n",
            "310000 steps; 19840000 examples so far; train ppl: 169.83, valid ppl: 177.38\n",
            "311000 steps; 19904000 examples so far; train ppl: 171.14, valid ppl: 176.93\n",
            "312000 steps; 19968000 examples so far; train ppl: 170.54, valid ppl: 176.94\n",
            "313000 steps; 20032000 examples so far; train ppl: 169.48, valid ppl: 176.74\n",
            "314000 steps; 20096000 examples so far; train ppl: 169.97, valid ppl: 177.15\n",
            "315000 steps; 20160000 examples so far; train ppl: 168.78, valid ppl: 177.00\n",
            "316000 steps; 20224000 examples so far; train ppl: 169.90, valid ppl: 176.65\n",
            "317000 steps; 20288000 examples so far; train ppl: 167.41, valid ppl: 177.58\n",
            "318000 steps; 20352000 examples so far; train ppl: 163.02, valid ppl: 177.12\n",
            "319000 steps; 20416000 examples so far; train ppl: 163.50, valid ppl: 177.18\n",
            "320000 steps; 20480000 examples so far; train ppl: 164.82, valid ppl: 177.34\n",
            "321000 steps; 20544000 examples so far; train ppl: 163.55, valid ppl: 177.23\n",
            "322000 steps; 20608000 examples so far; train ppl: 163.75, valid ppl: 176.58\n",
            "323000 steps; 20672000 examples so far; train ppl: 163.47, valid ppl: 176.94\n",
            "324000 steps; 20736000 examples so far; train ppl: 163.76, valid ppl: 176.45\n",
            "325000 steps; 20800000 examples so far; train ppl: 163.75, valid ppl: 177.24\n",
            "326000 steps; 20864000 examples so far; train ppl: 164.11, valid ppl: 176.98\n",
            "327000 steps; 20928000 examples so far; train ppl: 163.91, valid ppl: 176.52\n",
            "328000 steps; 20992000 examples so far; train ppl: 164.87, valid ppl: 176.77\n",
            "329000 steps; 21056000 examples so far; train ppl: 165.32, valid ppl: 176.00\n",
            "330000 steps; 21120000 examples so far; train ppl: 164.22, valid ppl: 176.48\n",
            "331000 steps; 21184000 examples so far; train ppl: 163.66, valid ppl: 176.14\n",
            "332000 steps; 21248000 examples so far; train ppl: 165.85, valid ppl: 176.07\n",
            "333000 steps; 21312000 examples so far; train ppl: 164.51, valid ppl: 176.01\n",
            "334000 steps; 21376000 examples so far; train ppl: 164.80, valid ppl: 176.39\n",
            "335000 steps; 21440000 examples so far; train ppl: 163.69, valid ppl: 175.31\n",
            "336000 steps; 21504000 examples so far; train ppl: 165.45, valid ppl: 175.42\n",
            "337000 steps; 21568000 examples so far; train ppl: 164.86, valid ppl: 175.57\n",
            "338000 steps; 21632000 examples so far; train ppl: 165.31, valid ppl: 175.45\n",
            "339000 steps; 21696000 examples so far; train ppl: 164.03, valid ppl: 175.44\n",
            "340000 steps; 21760000 examples so far; train ppl: 164.18, valid ppl: 176.29\n",
            "341000 steps; 21824000 examples so far; train ppl: 165.52, valid ppl: 175.36\n",
            "342000 steps; 21888000 examples so far; train ppl: 163.78, valid ppl: 175.18\n",
            "343000 steps; 21952000 examples so far; train ppl: 163.89, valid ppl: 175.02\n",
            "344000 steps; 22016000 examples so far; train ppl: 163.47, valid ppl: 175.15\n",
            "345000 steps; 22080000 examples so far; train ppl: 164.84, valid ppl: 175.49\n",
            "346000 steps; 22144000 examples so far; train ppl: 164.75, valid ppl: 175.31\n",
            "347000 steps; 22208000 examples so far; train ppl: 165.47, valid ppl: 175.36\n",
            "348000 steps; 22272000 examples so far; train ppl: 165.05, valid ppl: 175.10\n",
            "349000 steps; 22336000 examples so far; train ppl: 165.39, valid ppl: 175.42\n",
            "350000 steps; 22400000 examples so far; train ppl: 164.56, valid ppl: 175.86\n",
            "351000 steps; 22464000 examples so far; train ppl: 164.94, valid ppl: 175.51\n",
            "352000 steps; 22528000 examples so far; train ppl: 164.28, valid ppl: 174.59\n",
            "353000 steps; 22592000 examples so far; train ppl: 165.30, valid ppl: 175.07\n",
            "354000 steps; 22656000 examples so far; train ppl: 165.05, valid ppl: 175.11\n",
            "355000 steps; 22720000 examples so far; train ppl: 164.31, valid ppl: 175.37\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-3478ae6ea791>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mn_examples\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_examples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target_ids\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-3478ae6ea791>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(input_ids, target_ids)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   1730\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1733\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   1730\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1733\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   1730\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1733\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   1730\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1733\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   1728\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training mode is expected to be boolean\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1730\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1731\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1732\u001b[0m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1224\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m                 \u001b[0mbuffers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_buffers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1226\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1227\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m                         raise TypeError(\"cannot assign '{}' as buffer '{}' \"\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliação final no dataset de teste\n",
        "\n",
        "\n",
        "Bonus: o modelo com menor perplexidade no dataset de testes ganhará 0.5 ponto na nota final."
      ],
      "metadata": {
        "id": "VgdNymJdNPXP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxN5YytzZ7Tn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "affcfad6-e9e0-4513-8601-d0c4ded65f09"
      },
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_ppl = np.exp(np.average([\n",
        "        validation_step(test_input_ids.to(device), test_target_ids.to(device))\n",
        "        for test_input_ids, test_target_ids in test_loader\n",
        "    ]))\n",
        "\n",
        "print(f'test perplexity: {test_ppl}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test perplexity: 178.48945769210718\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teste seu modelo com uma sentença\n",
        "\n",
        "Escolha uma sentença gerada pelo modelo que ache interessante."
      ],
      "metadata": {
        "id": "BHvEs8mPszy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text: str, tokenizer):\n",
        "    # Recomenda-se usar o tokenizer.batch_encode_plus pois é mais rápido.\n",
        "    return tokenizer(text, return_tensors=None, add_special_tokens=False).input_ids"
      ],
      "metadata": {
        "id": "jI65_f1hJlgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'Eu gosto de comer pizza pois me faz bem comer aos'\n",
        "max_output_tokens = 20\n",
        "model.eval()\n",
        "\n",
        "for _ in range(max_output_tokens):\n",
        "    input_ids = tokenize(text=prompt, tokenizer=tokenizer)\n",
        "    input_ids_truncated = input_ids[-max_seq_length:]  # Usamos apenas os últimos <max_seq_length> tokens como entrada para o modelo.\n",
        "    logits = model(torch.LongTensor([input_ids_truncated]).to(device))\n",
        "    logits = logits[:, -1, :]  # Usamos apenas o ultimo token da sequencia\n",
        "    # Ao usarmos o argmax, a saída do modelo em cada passo é o token de maior probabilidade.\n",
        "    # Isso se chama decodificação gulosa (greedy decoding).\n",
        "    predicted_id = torch.argmax(logits).item()\n",
        "    input_ids += [predicted_id]  # Concatenamos a entrada com o token escolhido nesse passo.\n",
        "    prompt = tokenizer.decode(input_ids)\n",
        "    print(prompt)"
      ],
      "metadata": {
        "id": "-CFElf4tsytW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc3c7b87-b1ec-49b0-9846-b42d38b6b368"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eu gosto de comer pizza pois me faz bem comer aos que\n",
            "Eu gosto de comer pizza pois me faz bem comer aos que a\n",
            "Eu gosto de comer pizza pois me faz bem comer aos que a minha\n",
            "Eu gosto de comer pizza pois me faz bem comer aos que a minhas\n",
            "Eu gosto de comer pizza pois me faz bem comer aos que a minhas,\n",
            "Eu gosto de comer pizza pois me faz bem comer aos que a minhas, a\n",
            "Eu gosto de comer pizza pois me faz bem comer aos que a minhas, a vida\n",
            "Eu gosto de comer pizza pois me faz bem comer aos que a minhas, a vidamel\n",
            "Eu gosto de comer pizza pois me faz bem comer aos que a minhas, a vidameli\n",
            "Eu gosto de comer pizza pois me faz bem comer aos que a minhas, a vidameli,\n",
            "Eu gosto de comer pizza pois me faz bem comer aos que a minhas, a vidameli, o\n",
            "Eu gosto de comer pizza pois me faz bem comer aos que a minhas, a vidameli, o que\n",
            "Eu gosto de comer pizza pois me faz bem comer aos que a minhas, a vidameli, o que a\n",
            "Eu gosto de comer pizza pois me faz bem comer aos que a minhas, a vidameli, o que ai\n",
            "Eu gosto de comer pizza pois me faz bem comer aos que a minhas, a vidameli, o que ai paro\n",
            "Eu gosto de comer pizza pois me faz bem comer aos que a minhas, a vidameli, o que ai paro,\n",
            "Eu gosto de comer pizza pois me faz bem comer aos que a minhas, a vidameli, o que ai paro, que\n",
            "Eu gosto de comer pizza pois me faz bem comer aos que a minhas, a vidameli, o que ai paro, que a\n",
            "Eu gosto de comer pizza pois me faz bem comer aos que a minhas, a vidameli, o que ai paro, que ai\n",
            "Eu gosto de comer pizza pois me faz bem comer aos que a minhas, a vidameli, o que ai paro, que ai,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bonus 1\n",
        "Quem conseguir a menor perplexidade no dataset de testes ganha 0.5 ponto na média final.\n",
        "\n",
        "## Bonus 2\n",
        "Qual é a complexidade (em notação O-grande) da função de geração de texto acima?\n",
        "\n",
        "Quem responder corretamente a pergunta acima e deixar a função com menor complexidade ganha 0.5 ponto na média final."
      ],
      "metadata": {
        "id": "nGdxlXhGq7Ua"
      }
    }
  ]
}