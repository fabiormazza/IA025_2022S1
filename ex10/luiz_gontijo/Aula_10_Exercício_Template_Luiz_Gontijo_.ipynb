{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unicamp-dl/IA025_2022S1/blob/main/ex10/luiz_gontijo/Aula_10_Exerci%CC%81cio_Template_Luiz_Gontijo_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOdQB41_4ZxG",
        "outputId": "68167f6d-ffb5-4b59-fa4d-73e64f67549a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meu nome é Luiz Fernando da Costa Gontijo\n"
          ]
        }
      ],
      "source": [
        "nome = 'Luiz Fernando da Costa Gontijo'\n",
        "print(f'Meu nome é {nome}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3PrMPH_pKQ1"
      },
      "source": [
        "# Sobre a execução do trabalho\n",
        "\n",
        "Tive certa dificuldade para a criação do modelo. A forma de criação das máscaras não estava muito clara para mim. Durante a aula da semana 10, pude observar os meus erros e consegui implementar a solução necessária. \n",
        "\n",
        "Nessa última versão consegui resolver o problema do overfitting e obter bons valores de PPL. \n",
        "\n",
        "Alterei a célula de treino e validação para salvar os melhores modelos e poder usar futuramente. \n",
        "\n",
        "Por fim, mantive alguns rascunhos no final do notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IbuChoAPMEn"
      },
      "source": [
        "#  Exercício: Modelo de Linguagem com auto-atenção"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_DBb0-Klwf2"
      },
      "source": [
        "Este exercício é similar ao da Aula 8, mas iremos agora treinar uma rede neural com **duas camadas** de auto-atenção **causais** para prever a próxima palavra de um texto, data as palavras anteriores como entrada. \n",
        "\n",
        "Iremos também trabalhar com sequencias de tamanho variável.\n",
        "\n",
        "Na camada de auto-atenção, não se esqueça de implementar:\n",
        "- Embeddings de posição\n",
        "- Projeções lineares (WQ, WK, WV, WO)\n",
        "- Conexões residuais\n",
        "- Camada de feed forward (2-layer MLP)\n",
        "\n",
        "\n",
        "O dataset usado neste exercício (BrWaC) possui um tamanho razoável e você vai precisar rodar seus experimentos com GPU.\n",
        "\n",
        "Alguns conselhos úteis:\n",
        "- **ATENÇÃO:** o dataset é bem grande. Não dê comando de imprimí-lo.\n",
        "- Durante a depuração, faça seu dataset ficar bem pequeno, para que a depuração seja mais rápida e não precise de GPU. Somente ligue a GPU quando o seu laço de treinamento já está funcionando\n",
        "- Não deixe para fazer esse exercício na véspera. Ele é trabalhoso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3twP0YJC4jmJ",
        "outputId": "dd7842f2-e2f5-4fa2-cc53-008dbb0e800a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.19.3-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 4.9 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 68.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 67.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.3\n"
          ]
        }
      ],
      "source": [
        "# iremos utilizar a biblioteca dos transformers para ter acesso ao tokenizador do BERT.\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnyhJZtTRNMx"
      },
      "source": [
        "## Importação dos pacotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qlIOVCajPWcU"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import itertools\n",
        "import functools\n",
        "import math\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm_notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9f3PfifAwpU",
        "outputId": "73235e15-c05c-4d51-b190-493ec1232ca5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jun 10 17:40:34 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Check which GPU we are using\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whTCe2i7AtoV",
        "outputId": "27f1f75e-f21a-4172-ade1-728052d184a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda:0\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available(): \n",
        "   dev = \"cuda:0\"\n",
        "else: \n",
        "   dev = \"cpu\"\n",
        "device = torch.device(dev)\n",
        "print('Using {}'.format(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZfxgV2DUk58"
      },
      "source": [
        "## Implementação do MyDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2FT5vJkCooWY"
      },
      "outputs": [],
      "source": [
        "# tentar esse dataset para verificar o overfitting\n",
        "\n",
        "from typing import List\n",
        "\n",
        "def tokenize(text: str, tokenizer):\n",
        "    return tokenizer(text, return_tensors=None, add_special_tokens=False).input_ids\n",
        "\n",
        "class MyDataset():\n",
        "    def __init__(self, texts: List[str], tokenizer, max_seq_length: int):\n",
        "        # Escreva seu código aqui\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.features = self._token_window(texts)\n",
        "\n",
        "    def _token_window(self, texts):\n",
        "        feat = []\n",
        "        y = []\n",
        "\n",
        "        # Dataloader inspirado no notebook do Pedro Gengo\n",
        "        for text in texts:\n",
        "          # tokeniza uma frase\n",
        "          tokens_from_text = tokenize(f'[CLS]{text}', self.tokenizer)\n",
        "          tokens_from_text +=  [tokenizer.vocab['[PAD]']] * max(0, 1 + self.max_seq_length - len(tokens_from_text))\n",
        "          for i in range(0, len(tokens_from_text)-1, self.max_seq_length): \n",
        "            if i+self.max_seq_length < len(tokens_from_text):\n",
        "              feat.append(tokens_from_text[i:i+self.max_seq_length+1])\n",
        "            else:\n",
        "              feat.append(tokens_from_text[-self.max_seq_length-1:])\n",
        "        return torch.tensor(feat).long()\n",
        "\n",
        "    def __len__(self):\n",
        "        # Escreva seu código aqui\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Escreva seu código aqui\n",
        "        out = self.features[idx]\n",
        "        return out[:-1], out[1:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wew-gFbWeBTq"
      },
      "source": [
        "## Testando se a implementação do MyDataset está correta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "34345ed91e7d42e8a5a631a78e990733",
            "5dfb37b6e5374efebae719ff60c20b32",
            "f2325dfa7e8f4bf38dc73bed2cb3ca43",
            "74e5468877bb409e9c3d854e25909827",
            "cb273013edb846a1adf0c04b50d5c750",
            "74192ef4bb86458691ddc300dec587c5",
            "ff798f4c79ac459a91ea7e8924800357",
            "17471c685ad547ed847d0e9b4d50feb7",
            "c673480b35184ab591979a86f1d3d09c",
            "ea79f297c20a49f295b0f053736b6704",
            "c9812a7a26224fb787360e66cfe28f50",
            "06c644e566ed4d549232f890d8362c5e",
            "2ddcc99c9b234a5f9ffecefb541751b6",
            "fe08ba36bb2f48f2af9b35bb22f1f922",
            "59c210337dec4322a56347bc29d80836",
            "4f7f5edc5cee4f76acc665aa530c87dd",
            "ee1842b970c644b5914a9818e20952c0",
            "3e6c9840802e44c7b07c3d836c398d3d",
            "d0294751f2894369863bd8c1666865ab",
            "dbdf1167b88b40388156530f532f30f0",
            "9d011294ab894ad4981ad7039dfb10fb",
            "90f820c59c27449f8014f44026f83513",
            "623de119c8734e6fa843af4daad601e7",
            "6c2c85cfb89a47ea86c6a9e66db3d680",
            "a4bdf619e8fa42719dd9b2e7495be732",
            "b4872d886fc1499d9dc0faea89bb6322",
            "b491bec49b794a8cb98e0a174a232785",
            "04d57cd72c4a4b07a811a72a15670e29",
            "7fb8aa2d9e4e4a43b4ede79aaab539f9",
            "a06fae4e66de465f9b1f5663785a2743",
            "929fba04df474f42be047489cfb2743a",
            "782577068c17402987da791bffbaca29",
            "3aa502b6289b4f549ea24ca6d33925d8",
            "164577bfcb364dd592e36579fef72268",
            "05e1a53ad1fe40c58aa51012f5d344ac",
            "bb35ff17aaf64175b9135394a7d2243a",
            "26a416fd73174286b33ffb0f7a749e3a",
            "44b36dfa5fa54562be22839b84b9fbb0",
            "088f0bd325564f54846b1f46613509ee",
            "f09fd2ce0a35491db034fef7413b9fcf",
            "a580de4c7ade41208439e5f92510f1e6",
            "b56020198dcb47f09c41caf147bce846",
            "460573203f054984b0ace792262de3aa",
            "a4df8f69d61a48808036dfd95b6b8e6c",
            "8fe96c74dbec49928fd3cb112d4748c3",
            "edf2e363dbf34646a9adf34a2aea8bc4",
            "9df9851b07df473fb03ff1f6444c7b6a",
            "05540359cbfc4fcdaadb6ac2dd38481d",
            "f00254862e3d4d2cb3670fc357e82506",
            "12feb18d58b249948e2175d2f242ebfb",
            "c97053bfd0264ee6baf02395a8544ad2",
            "6b3aff495f594900a427179809431a5f",
            "54ca432e71c7449fa27cf5a703256f6d",
            "c5b04da864b74f6b985ca054ca2de404",
            "b83d96ddd8fe45418d0547237d4f3c1b"
          ]
        },
        "id": "6Lczd7GfUwRK",
        "outputId": "674cd80f-c7f3-4a27-9ce6-c3836f09a3e0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/205k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34345ed91e7d42e8a5a631a78e990733"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06c644e566ed4d549232f890d8362c5e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "623de119c8734e6fa843af4daad601e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/43.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "164577bfcb364dd592e36579fef72268"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/647 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8fe96c74dbec49928fd3cb112d4748c3"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KW4gShbvLRlP",
        "outputId": "b50244c6-c81f-4deb-d470-b114489af812"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passou no assert de tamanho do dataset.\n",
            "first_batch_input: tensor([[  101,  3396, 10303,   125, 13239,     0,     0,     0,     0],\n",
            "        [  101,  1660,  5971,   785,   125,  1847, 13779, 15616,     0],\n",
            "        [  101,   787,   253,  2996, 22280,   221, 18165,   122,  1028],\n",
            "        [  221, 18165,   122,  1028,  4486,   123,   325,   864,  4486]])\n",
            "first_batch_target: tensor([[ 3396, 10303,   125, 13239,     0,     0,     0,     0,     0],\n",
            "        [ 1660,  5971,   785,   125,  1847, 13779, 15616,     0,     0],\n",
            "        [  787,   253,  2996, 22280,   221, 18165,   122,  1028,  4486],\n",
            "        [18165,   122,  1028,  4486,   123,   325,   864,  4486,  1755]])\n"
          ]
        }
      ],
      "source": [
        "dummy_texts = ['Eu gosto de correr', 'Ela gosta muito de comer pizza', 'Ele é feio para dormir e outras coisas a mais três coisas diferentes']\n",
        "\n",
        "dummy_dataset = MyDataset(texts=dummy_texts, tokenizer=tokenizer, max_seq_length=9)\n",
        "dummy_loader = DataLoader(dummy_dataset, batch_size=6, shuffle=False)\n",
        "#assert len(dummy_dataset) == 2\n",
        "print('Passou no assert de tamanho do dataset.')\n",
        "\n",
        "first_batch_input, first_batch_target = next(iter(dummy_loader))\n",
        "\n",
        "print(f'first_batch_input: {first_batch_input}')\n",
        "print(f'first_batch_target: {first_batch_target}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8r7jBFFUeApe",
        "outputId": "57c93eba-c924-43e0-8e44-695d1cf9aedc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passou no assert de tamanho do dataset.\n",
            "meu batch: torch.int64\n",
            "batch correto: torch.int64\n",
            "Passou no assert de dataset.\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
        "\n",
        "dummy_texts = ['Eu gosto de correr', 'Ela gosta muito de comer pizza']\n",
        "\n",
        "dummy_dataset = MyDataset(texts=dummy_texts, tokenizer=tokenizer, max_seq_length=9)\n",
        "dummy_loader = DataLoader(dummy_dataset, batch_size=6, shuffle=False)\n",
        "assert len(dummy_dataset) == 2\n",
        "print('Passou no assert de tamanho do dataset.')\n",
        "\n",
        "first_batch_input, first_batch_target = next(iter(dummy_loader))\n",
        "\n",
        "correct_first_batch_input = torch.LongTensor(\n",
        "    [[  101,  3396, 10303,   125, 13239,     0,     0,     0,     0],\n",
        "     [  101,  1660,  5971,   785,   125,  1847, 13779, 15616,     0]])\n",
        "\n",
        "correct_first_batch_target = torch.LongTensor(\n",
        "    [[ 3396, 10303,   125, 13239,     0,     0,     0,     0,     0],\n",
        "     [ 1660,  5971,   785,   125,  1847, 13779, 15616,     0,     0]])\n",
        "\n",
        "print(f'meu batch: {first_batch_input.dtype}')\n",
        "print(f'batch correto: {correct_first_batch_input.dtype}')\n",
        "\n",
        "assert torch.equal(first_batch_input, correct_first_batch_input)\n",
        "assert torch.equal(first_batch_target, correct_first_batch_target)\n",
        "\n",
        "print('Passou no assert de dataset.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LfrHHouleJ0"
      },
      "source": [
        "# Carregamento do dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2vFWjsSkmop"
      },
      "source": [
        "Iremos usar uma pequena amostra do dataset [BrWaC](https://www.inf.ufrgs.br/pln/wiki/index.php?title=BrWaC) para treinar e avaliar nosso modelo de linguagem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGlN1WqrXPA6",
        "outputId": "b8d1b97b-e6fa-4209-858b-1fa9813b3596"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-10 17:40:46--  https://storage.googleapis.com/unicamp-dl/ia025a_2022s1/aula9/sample-1gb.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.161.128, 142.250.152.128, 74.125.126.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.161.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1230909256 (1.1G) [text/plain]\n",
            "Saving to: ‘sample-1gb.txt’\n",
            "\n",
            "sample-1gb.txt      100%[===================>]   1.15G   151MB/s    in 7.6s    \n",
            "\n",
            "2022-06-10 17:40:54 (153 MB/s) - ‘sample-1gb.txt’ saved [1230909256/1230909256]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -nc https://storage.googleapis.com/unicamp-dl/ia025a_2022s1/aula9/sample-1gb.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxa_4gmiA-wE",
        "outputId": "d2a0cf54-ea4a-404f-f26a-32b338733e83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read 250000 lines.\n",
            "Truncating to 52000 lines.\n"
          ]
        }
      ],
      "source": [
        "# Load datasets\n",
        "max_seq_length = 9\n",
        "\n",
        "train_examples = 50000\n",
        "valid_examples = 1000\n",
        "test_examples = 1000\n",
        "\n",
        "texts = open('sample-1gb.txt').readlines()\n",
        "\n",
        "print(f'Read {len(texts)} lines.')\n",
        "\n",
        "max_lines = train_examples + valid_examples + test_examples\n",
        "print(f'Truncating to {max_lines} lines.')\n",
        "texts = texts[:max_lines]\n",
        "\n",
        "training_texts = texts[:-(valid_examples + test_examples)]\n",
        "valid_texts = texts[-(valid_examples + test_examples):-test_examples]\n",
        "test_texts = texts[-test_examples:]\n",
        "\n",
        "training_dataset = MyDataset(texts=training_texts, tokenizer=tokenizer, max_seq_length=max_seq_length)\n",
        "valid_dataset = MyDataset(texts=valid_texts, tokenizer=tokenizer, max_seq_length=max_seq_length)\n",
        "test_dataset = MyDataset(texts=test_texts, tokenizer=tokenizer, max_seq_length=max_seq_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCSGJ5m7py4c",
        "outputId": "160a59ee-cc27-4b51-9233-6118401f9339"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training examples: 6186062\n",
            "valid examples: 136756\n",
            "test examples: 125212\n"
          ]
        }
      ],
      "source": [
        "print(f'training examples: {len(training_dataset)}')\n",
        "print(f'valid examples: {len(valid_dataset)}')\n",
        "print(f'test examples: {len(test_dataset)}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# com algumas alterações\n",
        "\n",
        "class LanguageModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size: int, max_seq_length: int, dim: int, n_layers: int, pad_token_id: int):\n",
        "        \"\"\"\n",
        "        Implements the Self-attention, decoder-only.\"\n",
        "\n",
        "        Args:\n",
        "            vocab_size (int): Size of the input vocabulary.\n",
        "            max_seq_length (int): Size of the sequence to consider as context for prediction.\n",
        "            dim (int): Dimension of the embedding layer for each word in the context.\n",
        "            n_layers (int): number of self-attention layers.\n",
        "            pad_token_id (int): id of the pad token that will be ignored in the attention.\n",
        "        \"\"\"\n",
        "        # Escreva seu código aqui.\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.dim = dim\n",
        "        self.n_layers = n_layers\n",
        "        self.pad_token_id = pad_token_id\n",
        "\n",
        "        self.embedding_layer = torch.nn.Embedding(self.vocab_size, self.dim)\n",
        "        self.positional_embeddings = torch.nn.Linear(self.dim, self.max_seq_length, bias=False)\n",
        "\n",
        "        self.W_q = torch.nn.Linear(self.dim,self.dim,bias=False) \n",
        "        self.W_k = torch.nn.Linear(self.dim,self.dim,bias=False) \n",
        "        self.W_v = torch.nn.Linear(self.dim,self.dim,bias=False) \n",
        "        self.W_o = torch.nn.Linear(self.dim,self.dim,bias=False) \n",
        "        \n",
        "        #hidden_layer = 2*self.dim\n",
        "        hidden_layer = self.dim\n",
        "        #self.linear1 = nn.Linear(self.max_seq_length*self.dim, hidden_layer)\n",
        "        #self.linear2 = nn.Linear(hidden_layer, self.max_seq_length*self.vocab_size, bias=False)\n",
        "\n",
        "        self.linear1 = nn.Linear(self.dim, hidden_layer)\n",
        "        self.linear2 = nn.Linear(hidden_layer, self.vocab_size, bias=False)\n",
        "\n",
        "        self.tanh1 = nn.Tanh() # testar resultado\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "\n",
        "    #Auxílio do código do Gabriel Lopes\n",
        "    def Attention(self, q, k, v, mask_pad, mask_causal):\n",
        "      \n",
        "        scores = torch.matmul(q, k.transpose(2,1))# shape = B,L,L\n",
        "\n",
        "        scores = scores.masked_fill(~mask_pad[:, None], -1e9)\n",
        "\n",
        "        scores = scores.masked_fill(~mask_causal, -1e9)\n",
        "\n",
        "        probs = nn.functional.softmax(scores, dim = -1)  \n",
        "        output  = torch.matmul(probs, v) # shape = B,L,E\n",
        "\n",
        "        return output\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            inputs is a LongTensor of shape (batch_size, max_seq_length)\n",
        "            \n",
        "        Returns:\n",
        "            logits of shape (batch_size, vocab_size)\n",
        "        \"\"\"\n",
        "        # Escreva seu código aqui.\n",
        "        self.batch_size = inputs.shape[0]\n",
        "\n",
        "        X_emb = self.embedding_layer(inputs)\n",
        "        X = X_emb + self.positional_embeddings.weight\n",
        "\n",
        "        mask_pad = inputs != self.pad_token_id\n",
        "        mask_causal = torch.tril(torch.ones(self.max_seq_length, self.max_seq_length)).bool().to(device)\n",
        "\n",
        "\n",
        "        for i in range(self.n_layers):\n",
        "            q = self.W_q(X).to(device)\n",
        "            k = self.W_k(X).to(device)\n",
        "            v = self.W_v(X).to(device)\n",
        "\n",
        "            new_x = self.Attention(q, k, v, mask_pad, mask_causal)\n",
        "\n",
        "            new_x = self.W_o(new_x).to(device)  # shape = (B, L, D)\n",
        "            \n",
        "            X = self.W_o(new_x)\n",
        "            #print(f'X shape: {X.shape}')\n",
        "\n",
        "        #logits = self.linear1(X.view(self.batch_size,-1)) \n",
        "        logits = self.linear1(X) \n",
        "        logits = self.relu1(logits)\n",
        "        #print(f'logits shape: {logits.shape}')\n",
        "        logits = self.linear2(logits)\n",
        "\n",
        "        #logits = logits.reshape(X.shape[0], self.max_seq_length, self.vocab_size)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "rEVF4r0vbVDf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rm6_PTH2i98e"
      },
      "source": [
        "## Teste o modelo com um exemplo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwnxfZlrZoT_",
        "outputId": "52979068-4d3d-4af7-9d09-3d74c04f4ce1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_input.shape: torch.Size([1, 9])\n",
            "sample_output.shape: torch.Size([1, 9, 29794])\n"
          ]
        }
      ],
      "source": [
        "embedding_dim = 10\n",
        "batch_size = 1024\n",
        "\n",
        "model = LanguageModel(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    max_seq_length=max_seq_length,\n",
        "    dim=64,\n",
        "    n_layers=2,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        ").to(device)\n",
        "\n",
        "sample_input, _ = next(iter(DataLoader(training_dataset)))\n",
        "sample_input = sample_input.to(device)\n",
        "sample_output = model(sample_input)\n",
        "print(f'sample_input.shape: {sample_input.shape}')\n",
        "print(f'sample_output.shape: {sample_output.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1Ghr97MzeGF",
        "outputId": "d30e3320-5cf9-4dd8-a55e-a7427041df35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch de inputs: tensor([[  101, 20100,  2308,  3074,  1089,   481,   117,   146,  1189],\n",
            "        [  125, 13254,   143,   122, 18073, 22281,   179,   695,   923]])\n",
            "batch de targets: tensor([[20100,  2308,  3074,  1089,   481,   117,   146,  1189,   125],\n",
            "        [13254,   143,   122, 18073, 22281,   179,   695,   923,   320]])\n"
          ]
        }
      ],
      "source": [
        "train_input_ids, train_target_ids = next(iter(DataLoader(training_dataset, batch_size=2)))\n",
        "\n",
        "print(f'batch de inputs: {train_input_ids}')\n",
        "print(f'batch de targets: {train_target_ids}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3Vh6B-VkA01",
        "outputId": "8d91fecf-6152-4e43-f530-bdb4608b3a6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of model parameters: 3834752\n"
          ]
        }
      ],
      "source": [
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'Number of model parameters: {num_params}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nhbUVsYnVAp"
      },
      "source": [
        "## Assert da Perplexidade\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbMP8VAUncfX",
        "outputId": "e4cf3091-400b-4087-938c-73489bcbdaf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my perplexity:              29703\n",
            "correct initial perplexity: 29794\n",
            "Passou o no assert da perplexidade\n"
          ]
        }
      ],
      "source": [
        "random.seed(123)\n",
        "np.random.seed(123)\n",
        "torch.manual_seed(123)\n",
        "\n",
        "\n",
        "def perplexity(logits, target, ignore_token_id: int):\n",
        "    \"\"\"\n",
        "    Computes the perplexity.\n",
        "\n",
        "    Args:\n",
        "        logits: a FloatTensor of shape (batch_size, seq_length, vocab_size)\n",
        "        target: a LongTensor of shape (batch_size, seq_length)\n",
        "\n",
        "    Returns:\n",
        "        A float corresponding to the perplexity\n",
        "    \"\"\"\n",
        "    logits = logits.reshape(-1, logits.shape[-1])\n",
        "    target = target.reshape(-1)\n",
        "    loss = nn.functional.cross_entropy(logits, target, reduction='mean', ignore_index=ignore_token_id)\n",
        "    return torch.exp(loss)\n",
        "\n",
        "\n",
        "n_examples = 1000\n",
        "\n",
        "train_input_ids, train_target_ids = next(iter(DataLoader(training_dataset, batch_size=64)))\n",
        "train_input_ids = train_input_ids.to(device)\n",
        "train_target_ids = train_target_ids.to(device)\n",
        "\n",
        "logits = model(train_input_ids)\n",
        "\n",
        "my_perplexity = perplexity(logits=logits, target=train_target_ids, ignore_token_id=tokenizer.pad_token_id)\n",
        "\n",
        "print(f'my perplexity:              {int(my_perplexity)}')\n",
        "print(f'correct initial perplexity: {tokenizer.vocab_size}')\n",
        "\n",
        "assert math.isclose(my_perplexity, tokenizer.vocab_size, abs_tol=7000)\n",
        "print('Passou o no assert da perplexidade')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ53vnEWj6rv",
        "outputId": "e4cd4bfc-ecd3-4328-906b-02829b4fe67f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 9, 29794])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "train_target_ids.shape\n",
        "logits.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiJtrsqPnE_l"
      },
      "source": [
        "## Laço de Treinamento e Validação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13p6y-bXPzKK",
        "outputId": "f7c0fdba-8910-456a-a2eb-9b7308e504b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 steps; 0 examples so far; train ppl: 29746.66, valid ppl: 29702.04\n",
            "100 steps; 102400 examples so far; train ppl: 5286.43, valid ppl: 2423.91\n",
            "200 steps; 204800 examples so far; train ppl: 2238.57, valid ppl: 2171.50\n",
            "300 steps; 307200 examples so far; train ppl: 2021.82, valid ppl: 1957.76\n",
            "400 steps; 409600 examples so far; train ppl: 1865.29, valid ppl: 1854.06\n",
            "500 steps; 512000 examples so far; train ppl: 1787.00, valid ppl: 1798.81\n",
            "600 steps; 614400 examples so far; train ppl: 1754.95, valid ppl: 1758.86\n",
            "700 steps; 716800 examples so far; train ppl: 1712.38, valid ppl: 1725.25\n",
            "800 steps; 819200 examples so far; train ppl: 1683.36, valid ppl: 1681.86\n",
            "900 steps; 921600 examples so far; train ppl: 1629.30, valid ppl: 1603.72\n",
            "1000 steps; 1024000 examples so far; train ppl: 1552.43, valid ppl: 1530.84\n",
            "1100 steps; 1126400 examples so far; train ppl: 1463.71, valid ppl: 1429.65\n",
            "1200 steps; 1228800 examples so far; train ppl: 1378.48, valid ppl: 1364.60\n",
            "1300 steps; 1331200 examples so far; train ppl: 1332.38, valid ppl: 1309.95\n",
            "1400 steps; 1433600 examples so far; train ppl: 1276.24, valid ppl: 1257.20\n",
            "1500 steps; 1536000 examples so far; train ppl: 1222.19, valid ppl: 1211.64\n",
            "1600 steps; 1638400 examples so far; train ppl: 1180.44, valid ppl: 1169.67\n",
            "1700 steps; 1740800 examples so far; train ppl: 1145.03, valid ppl: 1125.46\n",
            "1800 steps; 1843200 examples so far; train ppl: 1096.29, valid ppl: 1079.30\n",
            "1900 steps; 1945600 examples so far; train ppl: 1048.98, valid ppl: 1031.37\n",
            "2000 steps; 2048000 examples so far; train ppl: 1005.91, valid ppl: 984.68\n",
            "2100 steps; 2150400 examples so far; train ppl: 960.12, valid ppl: 938.49\n",
            "2200 steps; 2252800 examples so far; train ppl: 908.61, valid ppl: 890.60\n",
            "2300 steps; 2355200 examples so far; train ppl: 868.74, valid ppl: 852.69\n",
            "2400 steps; 2457600 examples so far; train ppl: 828.25, valid ppl: 816.26\n",
            "2500 steps; 2560000 examples so far; train ppl: 795.36, valid ppl: 783.77\n",
            "2600 steps; 2662400 examples so far; train ppl: 769.05, valid ppl: 754.29\n",
            "2700 steps; 2764800 examples so far; train ppl: 739.18, valid ppl: 729.84\n",
            "2800 steps; 2867200 examples so far; train ppl: 715.88, valid ppl: 704.87\n",
            "2900 steps; 2969600 examples so far; train ppl: 690.83, valid ppl: 682.65\n",
            "3000 steps; 3072000 examples so far; train ppl: 673.28, valid ppl: 662.06\n",
            "3100 steps; 3174400 examples so far; train ppl: 649.12, valid ppl: 642.60\n",
            "3200 steps; 3276800 examples so far; train ppl: 632.45, valid ppl: 623.88\n",
            "3300 steps; 3379200 examples so far; train ppl: 612.56, valid ppl: 606.25\n",
            "3400 steps; 3481600 examples so far; train ppl: 596.69, valid ppl: 589.50\n",
            "3500 steps; 3584000 examples so far; train ppl: 581.59, valid ppl: 573.41\n",
            "3600 steps; 3686400 examples so far; train ppl: 563.57, valid ppl: 557.93\n",
            "3700 steps; 3788800 examples so far; train ppl: 549.01, valid ppl: 543.83\n",
            "3800 steps; 3891200 examples so far; train ppl: 533.63, valid ppl: 529.13\n",
            "3900 steps; 3993600 examples so far; train ppl: 521.46, valid ppl: 517.00\n",
            "4000 steps; 4096000 examples so far; train ppl: 509.17, valid ppl: 503.27\n",
            "4100 steps; 4198400 examples so far; train ppl: 497.26, valid ppl: 491.63\n",
            "4200 steps; 4300800 examples so far; train ppl: 487.07, valid ppl: 480.22\n",
            "4300 steps; 4403200 examples so far; train ppl: 474.67, valid ppl: 469.76\n",
            "4400 steps; 4505600 examples so far; train ppl: 464.90, valid ppl: 458.86\n",
            "4500 steps; 4608000 examples so far; train ppl: 453.19, valid ppl: 449.84\n",
            "4600 steps; 4710400 examples so far; train ppl: 444.23, valid ppl: 440.64\n",
            "4700 steps; 4812800 examples so far; train ppl: 436.26, valid ppl: 431.42\n",
            "4800 steps; 4915200 examples so far; train ppl: 426.64, valid ppl: 423.24\n",
            "4900 steps; 5017600 examples so far; train ppl: 417.66, valid ppl: 414.85\n",
            "5000 steps; 5120000 examples so far; train ppl: 409.49, valid ppl: 407.38\n",
            "5100 steps; 5222400 examples so far; train ppl: 405.78, valid ppl: 401.28\n",
            "5200 steps; 5324800 examples so far; train ppl: 398.45, valid ppl: 394.94\n",
            "5300 steps; 5427200 examples so far; train ppl: 391.15, valid ppl: 388.31\n",
            "5400 steps; 5529600 examples so far; train ppl: 385.71, valid ppl: 382.60\n",
            "5500 steps; 5632000 examples so far; train ppl: 380.09, valid ppl: 376.40\n",
            "5600 steps; 5734400 examples so far; train ppl: 373.43, valid ppl: 372.24\n",
            "5700 steps; 5836800 examples so far; train ppl: 370.83, valid ppl: 366.45\n",
            "5800 steps; 5939200 examples so far; train ppl: 364.74, valid ppl: 362.23\n",
            "5900 steps; 6041600 examples so far; train ppl: 361.18, valid ppl: 357.93\n",
            "6000 steps; 6144000 examples so far; train ppl: 356.54, valid ppl: 354.02\n",
            "6100 steps; 6246400 examples so far; train ppl: 350.92, valid ppl: 349.98\n",
            "6200 steps; 6348800 examples so far; train ppl: 344.34, valid ppl: 346.45\n",
            "6300 steps; 6451200 examples so far; train ppl: 340.51, valid ppl: 342.98\n",
            "6400 steps; 6553600 examples so far; train ppl: 338.63, valid ppl: 340.39\n",
            "6500 steps; 6656000 examples so far; train ppl: 334.64, valid ppl: 336.98\n",
            "6600 steps; 6758400 examples so far; train ppl: 333.25, valid ppl: 334.30\n",
            "6700 steps; 6860800 examples so far; train ppl: 327.71, valid ppl: 331.58\n",
            "6800 steps; 6963200 examples so far; train ppl: 327.34, valid ppl: 328.55\n",
            "6900 steps; 7065600 examples so far; train ppl: 323.85, valid ppl: 326.46\n",
            "7000 steps; 7168000 examples so far; train ppl: 321.50, valid ppl: 324.12\n",
            "7100 steps; 7270400 examples so far; train ppl: 319.20, valid ppl: 321.65\n",
            "7200 steps; 7372800 examples so far; train ppl: 315.62, valid ppl: 318.66\n",
            "7300 steps; 7475200 examples so far; train ppl: 314.58, valid ppl: 316.48\n",
            "7400 steps; 7577600 examples so far; train ppl: 312.80, valid ppl: 314.38\n",
            "7500 steps; 7680000 examples so far; train ppl: 310.83, valid ppl: 312.44\n",
            "7600 steps; 7782400 examples so far; train ppl: 309.61, valid ppl: 310.73\n",
            "7700 steps; 7884800 examples so far; train ppl: 306.69, valid ppl: 309.01\n",
            "7800 steps; 7987200 examples so far; train ppl: 306.31, valid ppl: 307.04\n",
            "7900 steps; 8089600 examples so far; train ppl: 303.09, valid ppl: 305.44\n",
            "8000 steps; 8192000 examples so far; train ppl: 299.98, valid ppl: 303.73\n",
            "8100 steps; 8294400 examples so far; train ppl: 301.72, valid ppl: 302.85\n",
            "8200 steps; 8396800 examples so far; train ppl: 300.71, valid ppl: 300.77\n",
            "8300 steps; 8499200 examples so far; train ppl: 298.69, valid ppl: 299.13\n",
            "8400 steps; 8601600 examples so far; train ppl: 297.41, valid ppl: 298.20\n",
            "8500 steps; 8704000 examples so far; train ppl: 294.34, valid ppl: 296.55\n",
            "8600 steps; 8806400 examples so far; train ppl: 293.60, valid ppl: 294.82\n",
            "8700 steps; 8908800 examples so far; train ppl: 292.10, valid ppl: 293.55\n",
            "8800 steps; 9011200 examples so far; train ppl: 291.71, valid ppl: 292.20\n",
            "8900 steps; 9113600 examples so far; train ppl: 289.37, valid ppl: 291.51\n",
            "9000 steps; 9216000 examples so far; train ppl: 289.72, valid ppl: 289.82\n",
            "9100 steps; 9318400 examples so far; train ppl: 287.52, valid ppl: 288.78\n",
            "9200 steps; 9420800 examples so far; train ppl: 287.07, valid ppl: 288.12\n",
            "9300 steps; 9523200 examples so far; train ppl: 285.99, valid ppl: 286.73\n",
            "9400 steps; 9625600 examples so far; train ppl: 283.87, valid ppl: 286.08\n",
            "9500 steps; 9728000 examples so far; train ppl: 284.57, valid ppl: 284.61\n",
            "9600 steps; 9830400 examples so far; train ppl: 283.68, valid ppl: 283.88\n",
            "9700 steps; 9932800 examples so far; train ppl: 282.33, valid ppl: 282.77\n",
            "9800 steps; 10035200 examples so far; train ppl: 280.66, valid ppl: 282.12\n",
            "9900 steps; 10137600 examples so far; train ppl: 280.24, valid ppl: 280.99\n",
            "10000 steps; 10240000 examples so far; train ppl: 280.25, valid ppl: 280.11\n",
            "10100 steps; 10342400 examples so far; train ppl: 279.60, valid ppl: 278.88\n",
            "10200 steps; 10444800 examples so far; train ppl: 276.81, valid ppl: 278.20\n",
            "10300 steps; 10547200 examples so far; train ppl: 276.28, valid ppl: 277.96\n",
            "10400 steps; 10649600 examples so far; train ppl: 274.34, valid ppl: 276.46\n",
            "10500 steps; 10752000 examples so far; train ppl: 274.78, valid ppl: 275.52\n",
            "10600 steps; 10854400 examples so far; train ppl: 274.47, valid ppl: 275.39\n",
            "10700 steps; 10956800 examples so far; train ppl: 276.10, valid ppl: 274.99\n",
            "10800 steps; 11059200 examples so far; train ppl: 274.48, valid ppl: 273.84\n",
            "10900 steps; 11161600 examples so far; train ppl: 272.16, valid ppl: 272.02\n",
            "11000 steps; 11264000 examples so far; train ppl: 272.00, valid ppl: 272.25\n",
            "11100 steps; 11366400 examples so far; train ppl: 271.59, valid ppl: 271.25\n",
            "11200 steps; 11468800 examples so far; train ppl: 270.29, valid ppl: 270.80\n",
            "11300 steps; 11571200 examples so far; train ppl: 270.20, valid ppl: 270.03\n",
            "11400 steps; 11673600 examples so far; train ppl: 268.41, valid ppl: 269.31\n",
            "11500 steps; 11776000 examples so far; train ppl: 268.49, valid ppl: 268.82\n",
            "11600 steps; 11878400 examples so far; train ppl: 268.57, valid ppl: 267.72\n",
            "11700 steps; 11980800 examples so far; train ppl: 268.26, valid ppl: 267.40\n",
            "11800 steps; 12083200 examples so far; train ppl: 265.66, valid ppl: 266.62\n",
            "11900 steps; 12185600 examples so far; train ppl: 265.68, valid ppl: 265.81\n",
            "12000 steps; 12288000 examples so far; train ppl: 266.33, valid ppl: 265.46\n",
            "12100 steps; 12390400 examples so far; train ppl: 265.39, valid ppl: 264.68\n",
            "12200 steps; 12492800 examples so far; train ppl: 257.91, valid ppl: 264.37\n",
            "12300 steps; 12595200 examples so far; train ppl: 258.76, valid ppl: 263.98\n",
            "12400 steps; 12697600 examples so far; train ppl: 257.52, valid ppl: 264.03\n",
            "12500 steps; 12800000 examples so far; train ppl: 257.20, valid ppl: 263.32\n",
            "12600 steps; 12902400 examples so far; train ppl: 256.66, valid ppl: 262.70\n",
            "12700 steps; 13004800 examples so far; train ppl: 256.91, valid ppl: 262.27\n",
            "12800 steps; 13107200 examples so far; train ppl: 257.27, valid ppl: 262.11\n",
            "12900 steps; 13209600 examples so far; train ppl: 257.30, valid ppl: 261.43\n",
            "13000 steps; 13312000 examples so far; train ppl: 256.57, valid ppl: 260.64\n",
            "13100 steps; 13414400 examples so far; train ppl: 255.56, valid ppl: 260.74\n",
            "13200 steps; 13516800 examples so far; train ppl: 255.53, valid ppl: 260.11\n",
            "13300 steps; 13619200 examples so far; train ppl: 254.52, valid ppl: 259.15\n",
            "13400 steps; 13721600 examples so far; train ppl: 254.34, valid ppl: 259.53\n",
            "13500 steps; 13824000 examples so far; train ppl: 254.71, valid ppl: 258.51\n",
            "13600 steps; 13926400 examples so far; train ppl: 253.56, valid ppl: 258.01\n",
            "13700 steps; 14028800 examples so far; train ppl: 254.14, valid ppl: 258.02\n",
            "13800 steps; 14131200 examples so far; train ppl: 253.82, valid ppl: 257.25\n",
            "13900 steps; 14233600 examples so far; train ppl: 253.90, valid ppl: 257.04\n",
            "14000 steps; 14336000 examples so far; train ppl: 253.71, valid ppl: 256.23\n",
            "14100 steps; 14438400 examples so far; train ppl: 252.66, valid ppl: 256.27\n",
            "14200 steps; 14540800 examples so far; train ppl: 252.76, valid ppl: 255.47\n",
            "14300 steps; 14643200 examples so far; train ppl: 252.64, valid ppl: 255.50\n",
            "14400 steps; 14745600 examples so far; train ppl: 250.87, valid ppl: 254.80\n",
            "14500 steps; 14848000 examples so far; train ppl: 250.96, valid ppl: 254.68\n",
            "14600 steps; 14950400 examples so far; train ppl: 250.56, valid ppl: 254.69\n",
            "14700 steps; 15052800 examples so far; train ppl: 251.99, valid ppl: 253.61\n",
            "14800 steps; 15155200 examples so far; train ppl: 249.92, valid ppl: 253.21\n",
            "14900 steps; 15257600 examples so far; train ppl: 249.44, valid ppl: 253.10\n",
            "15000 steps; 15360000 examples so far; train ppl: 249.07, valid ppl: 252.96\n",
            "15100 steps; 15462400 examples so far; train ppl: 249.74, valid ppl: 252.03\n",
            "15200 steps; 15564800 examples so far; train ppl: 250.06, valid ppl: 251.78\n",
            "15300 steps; 15667200 examples so far; train ppl: 248.62, valid ppl: 251.66\n",
            "15400 steps; 15769600 examples so far; train ppl: 248.12, valid ppl: 251.47\n",
            "15500 steps; 15872000 examples so far; train ppl: 248.53, valid ppl: 250.96\n",
            "15600 steps; 15974400 examples so far; train ppl: 248.31, valid ppl: 250.58\n",
            "15700 steps; 16076800 examples so far; train ppl: 247.30, valid ppl: 250.06\n",
            "15800 steps; 16179200 examples so far; train ppl: 248.02, valid ppl: 250.37\n",
            "15900 steps; 16281600 examples so far; train ppl: 247.12, valid ppl: 250.28\n",
            "16000 steps; 16384000 examples so far; train ppl: 246.07, valid ppl: 249.43\n",
            "16100 steps; 16486400 examples so far; train ppl: 246.66, valid ppl: 249.35\n",
            "16200 steps; 16588800 examples so far; train ppl: 247.02, valid ppl: 248.51\n",
            "16300 steps; 16691200 examples so far; train ppl: 246.27, valid ppl: 248.12\n",
            "16400 steps; 16793600 examples so far; train ppl: 245.57, valid ppl: 248.28\n",
            "16500 steps; 16896000 examples so far; train ppl: 245.41, valid ppl: 248.26\n",
            "16600 steps; 16998400 examples so far; train ppl: 245.72, valid ppl: 247.58\n",
            "16700 steps; 17100800 examples so far; train ppl: 245.08, valid ppl: 247.46\n",
            "16800 steps; 17203200 examples so far; train ppl: 245.13, valid ppl: 247.24\n",
            "16900 steps; 17305600 examples so far; train ppl: 244.71, valid ppl: 246.82\n",
            "17000 steps; 17408000 examples so far; train ppl: 244.82, valid ppl: 246.11\n",
            "17100 steps; 17510400 examples so far; train ppl: 245.31, valid ppl: 246.02\n",
            "17200 steps; 17612800 examples so far; train ppl: 243.80, valid ppl: 245.75\n",
            "17300 steps; 17715200 examples so far; train ppl: 243.41, valid ppl: 245.39\n",
            "17400 steps; 17817600 examples so far; train ppl: 243.66, valid ppl: 245.21\n",
            "17500 steps; 17920000 examples so far; train ppl: 241.97, valid ppl: 245.29\n",
            "17600 steps; 18022400 examples so far; train ppl: 242.29, valid ppl: 244.84\n",
            "17700 steps; 18124800 examples so far; train ppl: 241.21, valid ppl: 244.46\n",
            "17800 steps; 18227200 examples so far; train ppl: 243.15, valid ppl: 243.99\n",
            "17900 steps; 18329600 examples so far; train ppl: 241.50, valid ppl: 244.13\n",
            "18000 steps; 18432000 examples so far; train ppl: 242.02, valid ppl: 243.31\n",
            "18100 steps; 18534400 examples so far; train ppl: 241.35, valid ppl: 243.08\n",
            "18200 steps; 18636800 examples so far; train ppl: 237.06, valid ppl: 243.47\n",
            "18300 steps; 18739200 examples so far; train ppl: 236.53, valid ppl: 243.21\n",
            "18400 steps; 18841600 examples so far; train ppl: 235.53, valid ppl: 243.02\n",
            "18500 steps; 18944000 examples so far; train ppl: 236.85, valid ppl: 243.11\n",
            "18600 steps; 19046400 examples so far; train ppl: 235.40, valid ppl: 242.46\n",
            "18700 steps; 19148800 examples so far; train ppl: 235.75, valid ppl: 242.35\n",
            "18800 steps; 19251200 examples so far; train ppl: 235.19, valid ppl: 241.98\n",
            "18900 steps; 19353600 examples so far; train ppl: 236.23, valid ppl: 241.53\n",
            "19000 steps; 19456000 examples so far; train ppl: 234.97, valid ppl: 241.64\n",
            "19100 steps; 19558400 examples so far; train ppl: 235.69, valid ppl: 241.52\n",
            "19200 steps; 19660800 examples so far; train ppl: 235.07, valid ppl: 240.97\n",
            "19300 steps; 19763200 examples so far; train ppl: 235.01, valid ppl: 241.01\n",
            "19400 steps; 19865600 examples so far; train ppl: 235.66, valid ppl: 240.27\n",
            "19500 steps; 19968000 examples so far; train ppl: 233.30, valid ppl: 240.58\n",
            "19600 steps; 20070400 examples so far; train ppl: 234.58, valid ppl: 240.74\n",
            "19700 steps; 20172800 examples so far; train ppl: 235.09, valid ppl: 240.20\n",
            "19800 steps; 20275200 examples so far; train ppl: 233.58, valid ppl: 239.58\n",
            "19900 steps; 20377600 examples so far; train ppl: 233.97, valid ppl: 239.47\n",
            "20000 steps; 20480000 examples so far; train ppl: 235.22, valid ppl: 239.31\n",
            "20100 steps; 20582400 examples so far; train ppl: 233.88, valid ppl: 239.35\n",
            "20200 steps; 20684800 examples so far; train ppl: 234.24, valid ppl: 239.36\n",
            "20300 steps; 20787200 examples so far; train ppl: 233.63, valid ppl: 239.19\n",
            "20400 steps; 20889600 examples so far; train ppl: 232.76, valid ppl: 238.86\n",
            "20500 steps; 20992000 examples so far; train ppl: 232.55, valid ppl: 238.60\n",
            "20600 steps; 21094400 examples so far; train ppl: 233.65, valid ppl: 238.45\n",
            "20700 steps; 21196800 examples so far; train ppl: 233.32, valid ppl: 237.65\n",
            "20800 steps; 21299200 examples so far; train ppl: 234.08, valid ppl: 237.53\n",
            "20900 steps; 21401600 examples so far; train ppl: 232.70, valid ppl: 237.48\n",
            "21000 steps; 21504000 examples so far; train ppl: 232.66, valid ppl: 237.47\n",
            "21100 steps; 21606400 examples so far; train ppl: 232.80, valid ppl: 237.62\n",
            "21200 steps; 21708800 examples so far; train ppl: 231.88, valid ppl: 237.13\n",
            "21300 steps; 21811200 examples so far; train ppl: 232.57, valid ppl: 237.10\n",
            "21400 steps; 21913600 examples so far; train ppl: 230.96, valid ppl: 236.33\n",
            "21500 steps; 22016000 examples so far; train ppl: 231.27, valid ppl: 236.04\n",
            "21600 steps; 22118400 examples so far; train ppl: 230.68, valid ppl: 235.76\n",
            "21700 steps; 22220800 examples so far; train ppl: 232.91, valid ppl: 235.87\n",
            "21800 steps; 22323200 examples so far; train ppl: 230.52, valid ppl: 235.77\n",
            "21900 steps; 22425600 examples so far; train ppl: 233.16, valid ppl: 235.07\n",
            "22000 steps; 22528000 examples so far; train ppl: 231.92, valid ppl: 235.05\n",
            "22100 steps; 22630400 examples so far; train ppl: 231.71, valid ppl: 235.42\n",
            "22200 steps; 22732800 examples so far; train ppl: 231.17, valid ppl: 235.27\n",
            "22300 steps; 22835200 examples so far; train ppl: 230.39, valid ppl: 234.67\n",
            "22400 steps; 22937600 examples so far; train ppl: 231.53, valid ppl: 234.51\n",
            "22500 steps; 23040000 examples so far; train ppl: 229.43, valid ppl: 234.61\n",
            "22600 steps; 23142400 examples so far; train ppl: 230.48, valid ppl: 234.01\n",
            "22700 steps; 23244800 examples so far; train ppl: 231.12, valid ppl: 234.20\n",
            "22800 steps; 23347200 examples so far; train ppl: 229.43, valid ppl: 233.80\n",
            "22900 steps; 23449600 examples so far; train ppl: 229.49, valid ppl: 233.93\n",
            "23000 steps; 23552000 examples so far; train ppl: 230.80, valid ppl: 233.27\n",
            "23100 steps; 23654400 examples so far; train ppl: 228.94, valid ppl: 233.15\n",
            "23200 steps; 23756800 examples so far; train ppl: 229.21, valid ppl: 233.38\n",
            "23300 steps; 23859200 examples so far; train ppl: 229.58, valid ppl: 233.06\n",
            "23400 steps; 23961600 examples so far; train ppl: 228.78, valid ppl: 232.73\n",
            "23500 steps; 24064000 examples so far; train ppl: 229.82, valid ppl: 232.49\n",
            "23600 steps; 24166400 examples so far; train ppl: 228.50, valid ppl: 232.52\n",
            "23700 steps; 24268800 examples so far; train ppl: 229.14, valid ppl: 232.29\n",
            "23800 steps; 24371200 examples so far; train ppl: 229.45, valid ppl: 231.97\n",
            "23900 steps; 24473600 examples so far; train ppl: 228.31, valid ppl: 231.86\n",
            "24000 steps; 24576000 examples so far; train ppl: 227.72, valid ppl: 231.83\n",
            "24100 steps; 24678400 examples so far; train ppl: 228.38, valid ppl: 231.50\n",
            "24200 steps; 24780800 examples so far; train ppl: 225.92, valid ppl: 231.58\n",
            "24300 steps; 24883200 examples so far; train ppl: 223.72, valid ppl: 231.93\n",
            "24400 steps; 24985600 examples so far; train ppl: 222.80, valid ppl: 231.76\n",
            "24500 steps; 25088000 examples so far; train ppl: 222.55, valid ppl: 231.28\n",
            "24600 steps; 25190400 examples so far; train ppl: 223.36, valid ppl: 231.80\n",
            "24700 steps; 25292800 examples so far; train ppl: 222.63, valid ppl: 231.43\n",
            "24800 steps; 25395200 examples so far; train ppl: 224.04, valid ppl: 230.80\n",
            "24900 steps; 25497600 examples so far; train ppl: 223.76, valid ppl: 230.91\n",
            "25000 steps; 25600000 examples so far; train ppl: 222.82, valid ppl: 231.00\n",
            "25100 steps; 25702400 examples so far; train ppl: 223.83, valid ppl: 230.40\n",
            "25200 steps; 25804800 examples so far; train ppl: 223.27, valid ppl: 230.82\n",
            "25300 steps; 25907200 examples so far; train ppl: 222.74, valid ppl: 230.28\n",
            "25400 steps; 26009600 examples so far; train ppl: 223.31, valid ppl: 230.72\n",
            "25500 steps; 26112000 examples so far; train ppl: 222.11, valid ppl: 229.58\n",
            "25600 steps; 26214400 examples so far; train ppl: 222.65, valid ppl: 229.76\n",
            "25700 steps; 26316800 examples so far; train ppl: 221.98, valid ppl: 230.05\n",
            "25800 steps; 26419200 examples so far; train ppl: 222.12, valid ppl: 229.63\n",
            "25900 steps; 26521600 examples so far; train ppl: 222.44, valid ppl: 229.13\n",
            "26000 steps; 26624000 examples so far; train ppl: 221.84, valid ppl: 228.75\n",
            "26100 steps; 26726400 examples so far; train ppl: 222.49, valid ppl: 228.78\n",
            "26200 steps; 26828800 examples so far; train ppl: 222.81, valid ppl: 228.81\n",
            "26300 steps; 26931200 examples so far; train ppl: 223.49, valid ppl: 228.62\n",
            "26400 steps; 27033600 examples so far; train ppl: 221.84, valid ppl: 228.51\n",
            "26500 steps; 27136000 examples so far; train ppl: 223.04, valid ppl: 228.45\n",
            "26600 steps; 27238400 examples so far; train ppl: 221.35, valid ppl: 228.31\n",
            "26700 steps; 27340800 examples so far; train ppl: 222.80, valid ppl: 228.27\n",
            "26800 steps; 27443200 examples so far; train ppl: 222.00, valid ppl: 227.91\n",
            "26900 steps; 27545600 examples so far; train ppl: 222.04, valid ppl: 228.01\n",
            "27000 steps; 27648000 examples so far; train ppl: 221.79, valid ppl: 227.95\n",
            "27100 steps; 27750400 examples so far; train ppl: 221.43, valid ppl: 227.31\n",
            "27200 steps; 27852800 examples so far; train ppl: 221.91, valid ppl: 227.52\n",
            "27300 steps; 27955200 examples so far; train ppl: 222.19, valid ppl: 227.25\n",
            "27400 steps; 28057600 examples so far; train ppl: 220.11, valid ppl: 227.26\n",
            "27500 steps; 28160000 examples so far; train ppl: 221.20, valid ppl: 226.90\n",
            "27600 steps; 28262400 examples so far; train ppl: 221.05, valid ppl: 226.71\n",
            "27700 steps; 28364800 examples so far; train ppl: 219.89, valid ppl: 226.41\n",
            "27800 steps; 28467200 examples so far; train ppl: 221.61, valid ppl: 226.85\n",
            "27900 steps; 28569600 examples so far; train ppl: 221.16, valid ppl: 226.12\n",
            "28000 steps; 28672000 examples so far; train ppl: 221.01, valid ppl: 226.77\n",
            "28100 steps; 28774400 examples so far; train ppl: 221.33, valid ppl: 225.77\n",
            "28200 steps; 28876800 examples so far; train ppl: 220.23, valid ppl: 225.97\n",
            "28300 steps; 28979200 examples so far; train ppl: 220.03, valid ppl: 225.91\n",
            "28400 steps; 29081600 examples so far; train ppl: 221.18, valid ppl: 225.74\n",
            "28500 steps; 29184000 examples so far; train ppl: 219.80, valid ppl: 225.04\n",
            "28600 steps; 29286400 examples so far; train ppl: 220.05, valid ppl: 225.15\n",
            "28700 steps; 29388800 examples so far; train ppl: 220.36, valid ppl: 225.16\n",
            "28800 steps; 29491200 examples so far; train ppl: 220.38, valid ppl: 225.30\n",
            "28900 steps; 29593600 examples so far; train ppl: 220.47, valid ppl: 225.24\n",
            "29000 steps; 29696000 examples so far; train ppl: 219.93, valid ppl: 225.06\n",
            "29100 steps; 29798400 examples so far; train ppl: 219.00, valid ppl: 224.71\n",
            "29200 steps; 29900800 examples so far; train ppl: 220.01, valid ppl: 224.50\n",
            "29300 steps; 30003200 examples so far; train ppl: 219.33, valid ppl: 224.34\n",
            "29400 steps; 30105600 examples so far; train ppl: 219.80, valid ppl: 224.49\n",
            "29500 steps; 30208000 examples so far; train ppl: 219.55, valid ppl: 224.41\n",
            "29600 steps; 30310400 examples so far; train ppl: 220.06, valid ppl: 223.68\n",
            "29700 steps; 30412800 examples so far; train ppl: 220.53, valid ppl: 224.04\n",
            "29800 steps; 30515200 examples so far; train ppl: 220.14, valid ppl: 223.81\n",
            "29900 steps; 30617600 examples so far; train ppl: 219.04, valid ppl: 223.18\n",
            "30000 steps; 30720000 examples so far; train ppl: 218.55, valid ppl: 224.06\n",
            "30100 steps; 30822400 examples so far; train ppl: 218.36, valid ppl: 223.26\n",
            "30200 steps; 30924800 examples so far; train ppl: 218.44, valid ppl: 223.46\n",
            "30300 steps; 31027200 examples so far; train ppl: 213.54, valid ppl: 223.37\n",
            "30400 steps; 31129600 examples so far; train ppl: 214.56, valid ppl: 223.35\n",
            "30500 steps; 31232000 examples so far; train ppl: 213.69, valid ppl: 223.28\n",
            "30600 steps; 31334400 examples so far; train ppl: 213.41, valid ppl: 222.97\n",
            "30700 steps; 31436800 examples so far; train ppl: 215.07, valid ppl: 223.62\n",
            "30800 steps; 31539200 examples so far; train ppl: 213.51, valid ppl: 223.06\n",
            "30900 steps; 31641600 examples so far; train ppl: 213.68, valid ppl: 222.92\n",
            "31000 steps; 31744000 examples so far; train ppl: 216.49, valid ppl: 222.94\n",
            "31100 steps; 31846400 examples so far; train ppl: 213.41, valid ppl: 222.42\n",
            "31200 steps; 31948800 examples so far; train ppl: 213.24, valid ppl: 222.91\n",
            "31300 steps; 32051200 examples so far; train ppl: 214.18, valid ppl: 222.21\n",
            "31400 steps; 32153600 examples so far; train ppl: 214.07, valid ppl: 222.70\n",
            "31500 steps; 32256000 examples so far; train ppl: 214.04, valid ppl: 221.95\n",
            "31600 steps; 32358400 examples so far; train ppl: 214.66, valid ppl: 222.06\n",
            "31700 steps; 32460800 examples so far; train ppl: 215.00, valid ppl: 222.06\n",
            "31800 steps; 32563200 examples so far; train ppl: 215.35, valid ppl: 222.30\n",
            "31900 steps; 32665600 examples so far; train ppl: 214.19, valid ppl: 221.90\n",
            "32000 steps; 32768000 examples so far; train ppl: 213.80, valid ppl: 221.69\n",
            "32100 steps; 32870400 examples so far; train ppl: 214.91, valid ppl: 221.18\n",
            "32200 steps; 32972800 examples so far; train ppl: 214.27, valid ppl: 221.53\n",
            "32300 steps; 33075200 examples so far; train ppl: 213.79, valid ppl: 221.35\n",
            "32400 steps; 33177600 examples so far; train ppl: 213.36, valid ppl: 221.20\n",
            "32500 steps; 33280000 examples so far; train ppl: 212.87, valid ppl: 221.03\n",
            "32600 steps; 33382400 examples so far; train ppl: 214.79, valid ppl: 220.70\n",
            "32700 steps; 33484800 examples so far; train ppl: 213.83, valid ppl: 220.68\n",
            "32800 steps; 33587200 examples so far; train ppl: 213.62, valid ppl: 220.86\n",
            "32900 steps; 33689600 examples so far; train ppl: 212.70, valid ppl: 220.55\n",
            "33000 steps; 33792000 examples so far; train ppl: 212.95, valid ppl: 220.10\n",
            "33100 steps; 33894400 examples so far; train ppl: 213.20, valid ppl: 220.28\n",
            "33200 steps; 33996800 examples so far; train ppl: 214.20, valid ppl: 220.15\n",
            "33300 steps; 34099200 examples so far; train ppl: 214.17, valid ppl: 219.81\n",
            "33400 steps; 34201600 examples so far; train ppl: 213.26, valid ppl: 220.14\n",
            "33500 steps; 34304000 examples so far; train ppl: 212.56, valid ppl: 219.86\n",
            "33600 steps; 34406400 examples so far; train ppl: 212.49, valid ppl: 220.21\n",
            "33700 steps; 34508800 examples so far; train ppl: 212.00, valid ppl: 219.43\n",
            "33800 steps; 34611200 examples so far; train ppl: 212.38, valid ppl: 219.18\n",
            "33900 steps; 34713600 examples so far; train ppl: 213.25, valid ppl: 219.43\n",
            "34000 steps; 34816000 examples so far; train ppl: 211.65, valid ppl: 219.08\n",
            "34100 steps; 34918400 examples so far; train ppl: 214.00, valid ppl: 218.99\n",
            "34200 steps; 35020800 examples so far; train ppl: 213.23, valid ppl: 219.01\n",
            "34300 steps; 35123200 examples so far; train ppl: 211.92, valid ppl: 218.84\n",
            "34400 steps; 35225600 examples so far; train ppl: 211.81, valid ppl: 218.55\n",
            "34500 steps; 35328000 examples so far; train ppl: 212.99, valid ppl: 218.51\n",
            "34600 steps; 35430400 examples so far; train ppl: 213.54, valid ppl: 218.35\n",
            "34700 steps; 35532800 examples so far; train ppl: 212.34, valid ppl: 218.28\n",
            "34800 steps; 35635200 examples so far; train ppl: 211.18, valid ppl: 218.14\n",
            "34900 steps; 35737600 examples so far; train ppl: 213.59, valid ppl: 217.83\n",
            "35000 steps; 35840000 examples so far; train ppl: 211.13, valid ppl: 217.86\n",
            "35100 steps; 35942400 examples so far; train ppl: 212.04, valid ppl: 217.46\n",
            "35200 steps; 36044800 examples so far; train ppl: 211.38, valid ppl: 218.21\n",
            "35300 steps; 36147200 examples so far; train ppl: 212.05, valid ppl: 217.90\n",
            "35400 steps; 36249600 examples so far; train ppl: 210.79, valid ppl: 217.44\n",
            "35500 steps; 36352000 examples so far; train ppl: 212.45, valid ppl: 217.16\n",
            "35600 steps; 36454400 examples so far; train ppl: 212.39, valid ppl: 217.28\n",
            "35700 steps; 36556800 examples so far; train ppl: 211.11, valid ppl: 217.14\n",
            "35800 steps; 36659200 examples so far; train ppl: 211.29, valid ppl: 217.66\n",
            "35900 steps; 36761600 examples so far; train ppl: 211.59, valid ppl: 217.18\n",
            "36000 steps; 36864000 examples so far; train ppl: 212.00, valid ppl: 216.96\n",
            "36100 steps; 36966400 examples so far; train ppl: 211.29, valid ppl: 217.45\n",
            "36200 steps; 37068800 examples so far; train ppl: 211.58, valid ppl: 216.63\n",
            "36300 steps; 37171200 examples so far; train ppl: 208.48, valid ppl: 216.71\n",
            "36400 steps; 37273600 examples so far; train ppl: 206.05, valid ppl: 216.68\n",
            "36500 steps; 37376000 examples so far; train ppl: 206.72, valid ppl: 217.03\n",
            "36600 steps; 37478400 examples so far; train ppl: 205.99, valid ppl: 216.88\n",
            "36700 steps; 37580800 examples so far; train ppl: 208.26, valid ppl: 216.76\n",
            "36800 steps; 37683200 examples so far; train ppl: 207.28, valid ppl: 216.49\n",
            "36900 steps; 37785600 examples so far; train ppl: 207.20, valid ppl: 216.80\n",
            "37000 steps; 37888000 examples so far; train ppl: 207.72, valid ppl: 216.94\n",
            "37100 steps; 37990400 examples so far; train ppl: 207.14, valid ppl: 216.25\n",
            "37200 steps; 38092800 examples so far; train ppl: 207.32, valid ppl: 216.80\n",
            "37300 steps; 38195200 examples so far; train ppl: 207.58, valid ppl: 216.48\n",
            "37400 steps; 38297600 examples so far; train ppl: 206.41, valid ppl: 216.09\n",
            "37500 steps; 38400000 examples so far; train ppl: 207.42, valid ppl: 216.25\n",
            "37600 steps; 38502400 examples so far; train ppl: 206.84, valid ppl: 216.06\n",
            "37700 steps; 38604800 examples so far; train ppl: 206.83, valid ppl: 216.25\n",
            "37800 steps; 38707200 examples so far; train ppl: 206.69, valid ppl: 215.85\n",
            "37900 steps; 38809600 examples so far; train ppl: 207.23, valid ppl: 215.93\n",
            "38000 steps; 38912000 examples so far; train ppl: 207.77, valid ppl: 215.71\n",
            "38100 steps; 39014400 examples so far; train ppl: 207.04, valid ppl: 215.68\n",
            "38200 steps; 39116800 examples so far; train ppl: 207.32, valid ppl: 215.59\n",
            "38300 steps; 39219200 examples so far; train ppl: 207.37, valid ppl: 215.58\n",
            "38400 steps; 39321600 examples so far; train ppl: 207.93, valid ppl: 215.40\n",
            "38500 steps; 39424000 examples so far; train ppl: 207.97, valid ppl: 215.51\n",
            "38600 steps; 39526400 examples so far; train ppl: 208.13, valid ppl: 215.22\n",
            "38700 steps; 39628800 examples so far; train ppl: 207.06, valid ppl: 215.02\n",
            "38800 steps; 39731200 examples so far; train ppl: 206.70, valid ppl: 214.99\n",
            "38900 steps; 39833600 examples so far; train ppl: 205.96, valid ppl: 214.90\n",
            "39000 steps; 39936000 examples so far; train ppl: 206.52, valid ppl: 214.54\n",
            "39100 steps; 40038400 examples so far; train ppl: 206.85, valid ppl: 214.71\n",
            "39200 steps; 40140800 examples so far; train ppl: 207.92, valid ppl: 214.36\n",
            "39300 steps; 40243200 examples so far; train ppl: 206.46, valid ppl: 214.94\n",
            "39400 steps; 40345600 examples so far; train ppl: 206.55, valid ppl: 214.13\n",
            "39500 steps; 40448000 examples so far; train ppl: 206.96, valid ppl: 213.99\n",
            "39600 steps; 40550400 examples so far; train ppl: 206.69, valid ppl: 213.77\n",
            "39700 steps; 40652800 examples so far; train ppl: 205.35, valid ppl: 213.76\n",
            "39800 steps; 40755200 examples so far; train ppl: 207.00, valid ppl: 214.04\n",
            "39900 steps; 40857600 examples so far; train ppl: 207.10, valid ppl: 213.56\n",
            "40000 steps; 40960000 examples so far; train ppl: 207.51, valid ppl: 213.44\n",
            "40100 steps; 41062400 examples so far; train ppl: 204.95, valid ppl: 213.58\n",
            "40200 steps; 41164800 examples so far; train ppl: 205.52, valid ppl: 213.36\n",
            "40300 steps; 41267200 examples so far; train ppl: 206.70, valid ppl: 213.27\n",
            "40400 steps; 41369600 examples so far; train ppl: 206.53, valid ppl: 213.38\n",
            "40500 steps; 41472000 examples so far; train ppl: 206.85, valid ppl: 213.22\n",
            "40600 steps; 41574400 examples so far; train ppl: 206.54, valid ppl: 212.84\n",
            "40700 steps; 41676800 examples so far; train ppl: 205.69, valid ppl: 213.10\n",
            "40800 steps; 41779200 examples so far; train ppl: 205.87, valid ppl: 213.07\n",
            "40900 steps; 41881600 examples so far; train ppl: 205.96, valid ppl: 212.83\n",
            "41000 steps; 41984000 examples so far; train ppl: 205.46, valid ppl: 212.89\n",
            "41100 steps; 42086400 examples so far; train ppl: 206.92, valid ppl: 212.80\n",
            "41200 steps; 42188800 examples so far; train ppl: 206.38, valid ppl: 212.78\n",
            "41300 steps; 42291200 examples so far; train ppl: 206.57, valid ppl: 212.93\n",
            "41400 steps; 42393600 examples so far; train ppl: 206.57, valid ppl: 212.24\n",
            "41500 steps; 42496000 examples so far; train ppl: 206.20, valid ppl: 212.37\n",
            "41600 steps; 42598400 examples so far; train ppl: 205.24, valid ppl: 212.18\n",
            "41700 steps; 42700800 examples so far; train ppl: 206.20, valid ppl: 211.95\n",
            "41800 steps; 42803200 examples so far; train ppl: 205.64, valid ppl: 212.16\n",
            "41900 steps; 42905600 examples so far; train ppl: 205.76, valid ppl: 211.99\n",
            "42000 steps; 43008000 examples so far; train ppl: 205.03, valid ppl: 211.85\n",
            "42100 steps; 43110400 examples so far; train ppl: 205.62, valid ppl: 211.60\n",
            "42200 steps; 43212800 examples so far; train ppl: 205.54, valid ppl: 211.45\n",
            "42300 steps; 43315200 examples so far; train ppl: 204.68, valid ppl: 211.09\n",
            "42400 steps; 43417600 examples so far; train ppl: 200.87, valid ppl: 211.95\n",
            "42500 steps; 43520000 examples so far; train ppl: 199.20, valid ppl: 211.61\n",
            "42600 steps; 43622400 examples so far; train ppl: 200.53, valid ppl: 212.37\n",
            "42700 steps; 43724800 examples so far; train ppl: 201.51, valid ppl: 211.86\n",
            "42800 steps; 43827200 examples so far; train ppl: 200.84, valid ppl: 211.52\n",
            "42900 steps; 43929600 examples so far; train ppl: 201.61, valid ppl: 211.52\n",
            "43000 steps; 44032000 examples so far; train ppl: 202.82, valid ppl: 211.28\n",
            "43100 steps; 44134400 examples so far; train ppl: 201.02, valid ppl: 211.20\n",
            "43200 steps; 44236800 examples so far; train ppl: 201.28, valid ppl: 211.35\n",
            "43300 steps; 44339200 examples so far; train ppl: 202.74, valid ppl: 211.18\n",
            "43400 steps; 44441600 examples so far; train ppl: 201.78, valid ppl: 211.82\n",
            "43500 steps; 44544000 examples so far; train ppl: 202.03, valid ppl: 211.33\n",
            "43600 steps; 44646400 examples so far; train ppl: 201.76, valid ppl: 211.17\n",
            "43700 steps; 44748800 examples so far; train ppl: 200.50, valid ppl: 211.30\n",
            "43800 steps; 44851200 examples so far; train ppl: 202.41, valid ppl: 211.05\n",
            "43900 steps; 44953600 examples so far; train ppl: 202.08, valid ppl: 210.92\n",
            "44000 steps; 45056000 examples so far; train ppl: 201.76, valid ppl: 211.12\n",
            "44100 steps; 45158400 examples so far; train ppl: 201.09, valid ppl: 210.80\n",
            "44200 steps; 45260800 examples so far; train ppl: 201.68, valid ppl: 210.72\n",
            "44300 steps; 45363200 examples so far; train ppl: 201.14, valid ppl: 210.32\n",
            "44400 steps; 45465600 examples so far; train ppl: 202.22, valid ppl: 210.27\n",
            "44500 steps; 45568000 examples so far; train ppl: 202.09, valid ppl: 210.30\n",
            "44600 steps; 45670400 examples so far; train ppl: 200.52, valid ppl: 210.17\n",
            "44700 steps; 45772800 examples so far; train ppl: 202.22, valid ppl: 210.38\n",
            "44800 steps; 45875200 examples so far; train ppl: 202.50, valid ppl: 209.93\n",
            "44900 steps; 45977600 examples so far; train ppl: 201.13, valid ppl: 210.18\n",
            "45000 steps; 46080000 examples so far; train ppl: 201.42, valid ppl: 210.06\n",
            "45100 steps; 46182400 examples so far; train ppl: 202.48, valid ppl: 210.14\n",
            "45200 steps; 46284800 examples so far; train ppl: 200.90, valid ppl: 209.65\n",
            "45300 steps; 46387200 examples so far; train ppl: 201.17, valid ppl: 209.37\n",
            "45400 steps; 46489600 examples so far; train ppl: 201.48, valid ppl: 209.51\n",
            "45500 steps; 46592000 examples so far; train ppl: 201.16, valid ppl: 209.36\n",
            "45600 steps; 46694400 examples so far; train ppl: 201.16, valid ppl: 209.38\n",
            "45700 steps; 46796800 examples so far; train ppl: 201.75, valid ppl: 209.24\n",
            "45800 steps; 46899200 examples so far; train ppl: 201.74, valid ppl: 209.21\n",
            "45900 steps; 47001600 examples so far; train ppl: 201.45, valid ppl: 209.18\n",
            "46000 steps; 47104000 examples so far; train ppl: 200.82, valid ppl: 208.75\n",
            "46100 steps; 47206400 examples so far; train ppl: 201.05, valid ppl: 208.57\n",
            "46200 steps; 47308800 examples so far; train ppl: 200.88, valid ppl: 208.47\n",
            "46300 steps; 47411200 examples so far; train ppl: 201.47, valid ppl: 208.67\n",
            "46400 steps; 47513600 examples so far; train ppl: 200.82, valid ppl: 208.65\n",
            "46500 steps; 47616000 examples so far; train ppl: 201.33, valid ppl: 208.47\n",
            "46600 steps; 47718400 examples so far; train ppl: 202.45, valid ppl: 208.48\n",
            "46700 steps; 47820800 examples so far; train ppl: 200.78, valid ppl: 208.18\n",
            "46800 steps; 47923200 examples so far; train ppl: 202.02, valid ppl: 208.37\n",
            "46900 steps; 48025600 examples so far; train ppl: 199.73, valid ppl: 208.33\n",
            "47000 steps; 48128000 examples so far; train ppl: 201.18, valid ppl: 208.26\n",
            "47100 steps; 48230400 examples so far; train ppl: 200.58, valid ppl: 208.07\n",
            "47200 steps; 48332800 examples so far; train ppl: 200.44, valid ppl: 207.68\n",
            "47300 steps; 48435200 examples so far; train ppl: 200.68, valid ppl: 207.96\n",
            "47400 steps; 48537600 examples so far; train ppl: 201.00, valid ppl: 207.96\n",
            "47500 steps; 48640000 examples so far; train ppl: 200.40, valid ppl: 207.59\n",
            "47600 steps; 48742400 examples so far; train ppl: 200.87, valid ppl: 207.62\n",
            "47700 steps; 48844800 examples so far; train ppl: 201.97, valid ppl: 207.72\n",
            "47800 steps; 48947200 examples so far; train ppl: 199.82, valid ppl: 207.67\n",
            "47900 steps; 49049600 examples so far; train ppl: 198.91, valid ppl: 207.48\n",
            "48000 steps; 49152000 examples so far; train ppl: 199.67, valid ppl: 207.25\n",
            "48100 steps; 49254400 examples so far; train ppl: 199.25, valid ppl: 206.84\n",
            "48200 steps; 49356800 examples so far; train ppl: 200.68, valid ppl: 206.99\n",
            "48300 steps; 49459200 examples so far; train ppl: 200.42, valid ppl: 207.04\n",
            "48400 steps; 49561600 examples so far; train ppl: 195.48, valid ppl: 207.19\n",
            "48500 steps; 49664000 examples so far; train ppl: 196.27, valid ppl: 207.63\n",
            "48600 steps; 49766400 examples so far; train ppl: 195.86, valid ppl: 207.08\n",
            "48700 steps; 49868800 examples so far; train ppl: 195.54, valid ppl: 207.05\n",
            "48800 steps; 49971200 examples so far; train ppl: 196.62, valid ppl: 207.13\n"
          ]
        }
      ],
      "source": [
        "# com gpu\n",
        "# laço com save \n",
        "\n",
        "compare=float('inf')\n",
        "\n",
        "max_examples = 50_000_000\n",
        "eval_every_steps = 100\n",
        "lr = 3e-4\n",
        "\n",
        "embedding_dim = 256\n",
        "batch_size = 1024\n",
        "model = LanguageModel(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    max_seq_length=max_seq_length,\n",
        "    dim=embedding_dim,\n",
        "    n_layers=2,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        ").to(device)\n",
        "\n",
        "train_loader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "validation_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "def train_step(input_ids, target_ids):\n",
        "    model.train()\n",
        "    model.zero_grad()\n",
        "    logits = model(input_ids)\n",
        "    logits = logits.reshape(-1, logits.shape[-1])\n",
        "    target_ids = target_ids.reshape(-1)\n",
        "    loss = nn.functional.cross_entropy(logits, target_ids, ignore_index=model.pad_token_id)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "def validation_step(input_ids, target_ids):\n",
        "    model.eval()\n",
        "    logits = model(input_ids)\n",
        "    logits = logits.reshape(-1, logits.shape[-1])\n",
        "    target_ids = target_ids.reshape(-1)\n",
        "    loss = nn.functional.cross_entropy(logits, target_ids, ignore_index=model.pad_token_id)\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "train_losses = []\n",
        "n_examples = 0\n",
        "step = 0\n",
        "while n_examples < max_examples:\n",
        "    for input, target in train_loader:\n",
        "        loss = train_step(input.to(device), target.to(device)) \n",
        "        train_losses.append(loss)\n",
        "        \n",
        "        if step % eval_every_steps == 0:\n",
        "            train_ppl = np.exp(np.average(train_losses))\n",
        "\n",
        "            with torch.no_grad():\n",
        "                valid_ppl = np.exp(np.average([\n",
        "                    validation_step(input.to(device), target.to(device))\n",
        "                    for input, target in validation_loader]))\n",
        "                \n",
        "                if valid_ppl<compare:\n",
        "                    compare=valid_ppl\n",
        "                    torch.save(model, \"/content/drive/MyDrive/Intro ao Aprendizado Profundo/Trabalho10/modelos_salvos/\"+f\"model_{max_examples/1000000}ex_{embedding_dim}embdim.pt\")\n",
        "                    with open(\"/content/drive/MyDrive/Intro ao Aprendizado Profundo/Trabalho10/modelos_salvos/\"+f\"model_{max_examples/1000000}ex_{embedding_dim}embdim.txt\", 'w') as f:\n",
        "                      lines = [f'batch size = {batch_size}', \n",
        "                                f'embedding dim = {embedding_dim}', \n",
        "                                f'max examples = {max_examples}', \n",
        "                                f'learning rate = {lr}', \n",
        "                                f'max_examples = {max_examples}', \n",
        "                                f'train PPL = {train_ppl}',\n",
        "                                f'validation PPL = {valid_ppl}',\n",
        "                                f'best values at {n_examples} examples']\n",
        "                      f.writelines('\\n'.join(lines))\n",
        "                    f.close()\n",
        "\n",
        "            print(f'{step} steps; {n_examples} examples so far; train ppl: {train_ppl:.2f}, valid ppl: {valid_ppl:.2f}')\n",
        "            train_losses = []\n",
        "\n",
        "        n_examples += len(input)  # Increment of batch size\n",
        "        step += 1\n",
        "        if n_examples >= max_examples:\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgdNymJdNPXP"
      },
      "source": [
        "## Avaliação final no dataset de teste\n",
        "\n",
        "\n",
        "Bonus: o modelo com menor perplexidade no dataset de testes ganhará 0.5 ponto na nota final."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxN5YytzZ7Tn",
        "outputId": "828f3f49-4395-408c-d7bf-e5f6d8007122"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test perplexity: 212.12948271223058\n"
          ]
        }
      ],
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_ppl = np.exp(np.average([\n",
        "        validation_step(test_input_ids.to(device), test_target_ids.to(device))\n",
        "        for test_input_ids, test_target_ids in test_loader\n",
        "    ]))\n",
        "\n",
        "print(f'test perplexity: {test_ppl}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHvEs8mPszy_"
      },
      "source": [
        "## Teste seu modelo com uma sentença\n",
        "\n",
        "Escolha uma sentença gerada pelo modelo que ache interessante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CFElf4tsytW",
        "outputId": "ea6b73cf-e073-403e-e739-b2bf14db442c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eu gosto de comer pizza pois me faz parte\n",
            "Eu gosto de comer pizza pois me faz parte do\n",
            "Eu gosto de comer pizza pois me faz parte do que\n",
            "Eu gosto de comer pizza pois me faz parte do que o\n",
            "Eu gosto de comer pizza pois me faz parte do que o governo\n",
            "Eu gosto de comer pizza pois me faz parte do que o governo,\n",
            "Eu gosto de comer pizza pois me faz parte do que o governo, a\n",
            "Eu gosto de comer pizza pois me faz parte do que o governo, a partir\n",
            "Eu gosto de comer pizza pois me faz parte do que o governo, a partir de\n",
            "Eu gosto de comer pizza pois me faz parte do que o governo, a partir de um\n",
            "Eu gosto de comer pizza pois me faz parte do que o governo, a partir de um ano\n",
            "Eu gosto de comer pizza pois me faz parte do que o governo, a partir de um ano,\n",
            "Eu gosto de comer pizza pois me faz parte do que o governo, a partir de um ano, o\n",
            "Eu gosto de comer pizza pois me faz parte do que o governo, a partir de um ano, o que\n",
            "Eu gosto de comer pizza pois me faz parte do que o governo, a partir de um ano, o que é\n",
            "Eu gosto de comer pizza pois me faz parte do que o governo, a partir de um ano, o que é que\n",
            "Eu gosto de comer pizza pois me faz parte do que o governo, a partir de um ano, o que é que o\n",
            "Eu gosto de comer pizza pois me faz parte do que o governo, a partir de um ano, o que é que o que\n",
            "Eu gosto de comer pizza pois me faz parte do que o governo, a partir de um ano, o que é que o que é\n",
            "Eu gosto de comer pizza pois me faz parte do que o governo, a partir de um ano, o que é que o que é que\n"
          ]
        }
      ],
      "source": [
        "prompt = 'Eu gosto de comer pizza pois me faz'\n",
        "max_output_tokens = 20\n",
        "model.eval()\n",
        "\n",
        "for _ in range(max_output_tokens):\n",
        "    input_ids = tokenize(text=prompt, tokenizer=tokenizer)\n",
        "    input_ids_truncated = input_ids[-max_seq_length:]  # Usamos apenas os últimos <max_seq_length> tokens como entrada para o modelo.\n",
        "    logits = model(torch.LongTensor([input_ids_truncated]).to(device))\n",
        "    logits = logits[:, -1, :]  # Usamos apenas o ultimo token da sequencia\n",
        "    # Ao usarmos o argmax, a saída do modelo em cada passo é o token de maior probabilidade.\n",
        "    # Isso se chama decodificação gulosa (greedy decoding).\n",
        "    predicted_id = torch.argmax(logits).item()\n",
        "    input_ids += [predicted_id]  # Concatenamos a entrada com o token escolhido nesse passo.\n",
        "    prompt = tokenizer.decode(input_ids)\n",
        "    print(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGdxlXhGq7Ua"
      },
      "source": [
        "## Bonus 1\n",
        "Quem conseguir a menor perplexidade no dataset de testes ganha 0.5 ponto na média final.\n",
        "\n",
        "## Bonus 2\n",
        "Qual é a complexidade (em notação O-grande) da função de geração de texto acima?\n",
        "\n",
        "Quem responder corretamente a pergunta acima e deixar a função com menor complexidade ganha 0.5 ponto na média final."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKGcXeZVP36Q",
        "outputId": "7ee27e6f-bbc0-4339-e0a4-b2403ad36b52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzX4bYXRFRZd"
      },
      "source": [
        "# Rascunhos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DcY3AwQFSxs"
      },
      "outputs": [],
      "source": [
        "rint(f'token de PAD do BERT:{tokenizer.pad_token}')\n",
        "\n",
        "pad = '[PAD]'\n",
        "print(f'número que indica o toke de PAD: {tokenizer.vocab[pad]}')\n",
        "\n",
        "dummy_texts = ['Eu gosto de correr', 'Ela gosta muito de comer pizza']\n",
        "print(f'dummy_texts: {dummy_texts}')\n",
        "max_seq_length = 3\n",
        "dummy_dataset = MyDataset(texts=dummy_texts, tokenizer=tokenizer, max_seq_length=max_seq_length)\n",
        "dummy_loader = DataLoader(dummy_dataset, batch_size=6, shuffle=False)\n",
        "\n",
        "print(f'dummy_dataset: {dummy_dataset}')\n",
        "print(f'dummy_loader: {dummy_loader}')\n",
        "\n",
        "first_batch_input, first_batch_target = next(iter(dummy_loader))\n",
        "print(f'batch_input: {first_batch_input}')\n",
        "print(f'batch_target: {first_batch_target}')\n",
        "\n",
        "tokens_ids = tokenize(dummy_texts[0], tokenizer)\n",
        "tensor_empty = torch.zeros(max_seq_length, dtype=torch.int32)\n",
        "print(f'empty tensor: {tensor_empty}')\n",
        "\n",
        "after_sum = tensor_empty + first_batch_input[0] \n",
        "print(f'tensor depois da soma: {after_sum}')\n",
        "\n",
        "\n",
        "#def __init__(self, texts: List[str], tokenizer, max_seq_length: int):\n",
        "#self.tokensIds_n = []\n",
        "#self.y = []\n",
        "\n",
        "texts = dummy_texts\n",
        "tokensIds_n = []\n",
        "max_seq_length = 9\n",
        "token_cls = torch.tensor(tokenizer.vocab['[CLS]'], dtype=torch.int32)\n",
        "for text in tqdm_notebook(texts):\n",
        "  tokens_ids = tokenize(text, tokenizer)\n",
        "  # desconsiderar parte que tira tamanhos diferentes\n",
        "  print(f'len token_ids:{len(tokens_ids)}')\n",
        "  print(f'tokens_ids do texto {text}: {tokens_ids}')\n",
        "  #if len(tokens_ids) < max_seq_length:\n",
        "   # for i in range(max_seq_length):\n",
        "   #   tokensIds_n_temp = []\n",
        "   #   tokensIds_n_temp.append(tokens_ids[i:max_seq_length])\n",
        "   #   p1d = (0, max_seq_length - len(tokensIds_n_temp))\n",
        "   #   out = nn.functional.pad(tokensIds_n_temp, p1d, \"constant\", 0)\n",
        "   #   tokensIds_n.append(out)\n",
        "\n",
        "  if len(tokens_ids) < max_seq_length:\n",
        "    #tokenid_temp = torch.tensor(tokens_ids[0:max_seq_length])\n",
        "    tokenid_temp_cat = torch.cat((token_cls.unsqueeze(dim=-1), torch.tensor(tokens_ids[0:max_seq_length])))\n",
        "    print(f'tokenid_temp_cat: {torch.cat((token_cls.unsqueeze(dim=-1), tokenid_temp_cat))}')\n",
        "    tokensIds_n.append(tokenid_temp_cat)\n",
        "\n",
        "  else:\n",
        "    for i in range(max_seq_length):\n",
        "      tokenid_temp = torch.tensor(tokens_ids[i:max_seq_length])\n",
        "      #tokenid_temp_cat = torch.cat(token_cls,tokenid_temp), dim=0)\n",
        "      #tokenid_temp_cat = torch.cat((token_cls.unsqueeze(dim=-1), tokenid_temp))\n",
        "      tokensIds_n.append(torch.cat((token_cls.unsqueeze(dim=-1), tokenid_temp)))\n",
        "      print(f'tokenid_temp_cat: {torch.cat((token_cls.unsqueeze(dim=-1), tokenid_temp))}')\n",
        "      #tokensIds_n.append(torch.cat((token_cls.unsqueeze(dim=-1), tokenid_temp)))\n",
        "\n",
        "print(f'lista de tokens ids: {tokensIds_n}')\n",
        "for j, s in enumerate(tokensIds_n):\n",
        "  #print(f'j: {j}')\n",
        "  #print(f's: {s}')\n",
        "  if len(s) < max_seq_length:\n",
        "    s_torch = torch.tensor(s)\n",
        "    p1d = (0, max_seq_length - len(s))\n",
        "    #padded = nn.functional.pad(s_torch, p1d, \"constant\", 0)\n",
        "    #print(f'padded: {padded}')\n",
        "    tokensIds_n[j] = nn.functional.pad(s_torch, p1d, \"constant\", 0)\n",
        "          #self.y.append(tokens_ids[i+context_size])\n",
        "\n",
        "tokensIds_n = torch.stack(tokensIds_n, 0)\n",
        "print(f'token ids batch: {tokensIds_n}')\n",
        "\n",
        "# definir batch de target\n",
        "tensor_zero = torch.tensor(0)\n",
        "token_ids_target = torch.empty(len(texts), max_seq_length, dtype=torch.int32)\n",
        "j=0\n",
        "for i in tokensIds_n:\n",
        "  #token_tensor = i[1:]\n",
        "  #print(f'tonken shifted: {token_tensor}')\n",
        "  tokenid_temp_cat = torch.cat((i[1:], tensor_zero.unsqueeze(dim=-1)))\n",
        "  token_ids_target[j] = tokenid_temp_cat\n",
        "  j+=1\n",
        "  #target = torch.stack((tokenid_temp_cat, tokenid_temp_cat))\n",
        "\n",
        "#print(f'tokens id: {tokensIds_n}')\n",
        "#print(f'token ids target: {token_ids_target}')\n",
        "\n",
        "#traget = torch.LongTensor(token_ids_target)\n",
        "print(f'target: {token_ids_target}')\n",
        "print(f'texts: {texts}')\n",
        "#print(f'tokens id: {tokensIds_n}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Aula_10_Exercício_Template_Luiz_Gontijo.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "34345ed91e7d42e8a5a631a78e990733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5dfb37b6e5374efebae719ff60c20b32",
              "IPY_MODEL_f2325dfa7e8f4bf38dc73bed2cb3ca43",
              "IPY_MODEL_74e5468877bb409e9c3d854e25909827"
            ],
            "layout": "IPY_MODEL_cb273013edb846a1adf0c04b50d5c750"
          }
        },
        "5dfb37b6e5374efebae719ff60c20b32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74192ef4bb86458691ddc300dec587c5",
            "placeholder": "​",
            "style": "IPY_MODEL_ff798f4c79ac459a91ea7e8924800357",
            "value": "Downloading: 100%"
          }
        },
        "f2325dfa7e8f4bf38dc73bed2cb3ca43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17471c685ad547ed847d0e9b4d50feb7",
            "max": 209528,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c673480b35184ab591979a86f1d3d09c",
            "value": 209528
          }
        },
        "74e5468877bb409e9c3d854e25909827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea79f297c20a49f295b0f053736b6704",
            "placeholder": "​",
            "style": "IPY_MODEL_c9812a7a26224fb787360e66cfe28f50",
            "value": " 205k/205k [00:00&lt;00:00, 1.57MB/s]"
          }
        },
        "cb273013edb846a1adf0c04b50d5c750": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74192ef4bb86458691ddc300dec587c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff798f4c79ac459a91ea7e8924800357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17471c685ad547ed847d0e9b4d50feb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c673480b35184ab591979a86f1d3d09c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea79f297c20a49f295b0f053736b6704": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9812a7a26224fb787360e66cfe28f50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06c644e566ed4d549232f890d8362c5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ddcc99c9b234a5f9ffecefb541751b6",
              "IPY_MODEL_fe08ba36bb2f48f2af9b35bb22f1f922",
              "IPY_MODEL_59c210337dec4322a56347bc29d80836"
            ],
            "layout": "IPY_MODEL_4f7f5edc5cee4f76acc665aa530c87dd"
          }
        },
        "2ddcc99c9b234a5f9ffecefb541751b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee1842b970c644b5914a9818e20952c0",
            "placeholder": "​",
            "style": "IPY_MODEL_3e6c9840802e44c7b07c3d836c398d3d",
            "value": "Downloading: 100%"
          }
        },
        "fe08ba36bb2f48f2af9b35bb22f1f922": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0294751f2894369863bd8c1666865ab",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dbdf1167b88b40388156530f532f30f0",
            "value": 2
          }
        },
        "59c210337dec4322a56347bc29d80836": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d011294ab894ad4981ad7039dfb10fb",
            "placeholder": "​",
            "style": "IPY_MODEL_90f820c59c27449f8014f44026f83513",
            "value": " 2.00/2.00 [00:00&lt;00:00, 26.1B/s]"
          }
        },
        "4f7f5edc5cee4f76acc665aa530c87dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee1842b970c644b5914a9818e20952c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e6c9840802e44c7b07c3d836c398d3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0294751f2894369863bd8c1666865ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbdf1167b88b40388156530f532f30f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d011294ab894ad4981ad7039dfb10fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90f820c59c27449f8014f44026f83513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "623de119c8734e6fa843af4daad601e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c2c85cfb89a47ea86c6a9e66db3d680",
              "IPY_MODEL_a4bdf619e8fa42719dd9b2e7495be732",
              "IPY_MODEL_b4872d886fc1499d9dc0faea89bb6322"
            ],
            "layout": "IPY_MODEL_b491bec49b794a8cb98e0a174a232785"
          }
        },
        "6c2c85cfb89a47ea86c6a9e66db3d680": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04d57cd72c4a4b07a811a72a15670e29",
            "placeholder": "​",
            "style": "IPY_MODEL_7fb8aa2d9e4e4a43b4ede79aaab539f9",
            "value": "Downloading: 100%"
          }
        },
        "a4bdf619e8fa42719dd9b2e7495be732": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a06fae4e66de465f9b1f5663785a2743",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_929fba04df474f42be047489cfb2743a",
            "value": 112
          }
        },
        "b4872d886fc1499d9dc0faea89bb6322": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_782577068c17402987da791bffbaca29",
            "placeholder": "​",
            "style": "IPY_MODEL_3aa502b6289b4f549ea24ca6d33925d8",
            "value": " 112/112 [00:00&lt;00:00, 1.50kB/s]"
          }
        },
        "b491bec49b794a8cb98e0a174a232785": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04d57cd72c4a4b07a811a72a15670e29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fb8aa2d9e4e4a43b4ede79aaab539f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a06fae4e66de465f9b1f5663785a2743": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "929fba04df474f42be047489cfb2743a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "782577068c17402987da791bffbaca29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aa502b6289b4f549ea24ca6d33925d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "164577bfcb364dd592e36579fef72268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05e1a53ad1fe40c58aa51012f5d344ac",
              "IPY_MODEL_bb35ff17aaf64175b9135394a7d2243a",
              "IPY_MODEL_26a416fd73174286b33ffb0f7a749e3a"
            ],
            "layout": "IPY_MODEL_44b36dfa5fa54562be22839b84b9fbb0"
          }
        },
        "05e1a53ad1fe40c58aa51012f5d344ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_088f0bd325564f54846b1f46613509ee",
            "placeholder": "​",
            "style": "IPY_MODEL_f09fd2ce0a35491db034fef7413b9fcf",
            "value": "Downloading: 100%"
          }
        },
        "bb35ff17aaf64175b9135394a7d2243a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a580de4c7ade41208439e5f92510f1e6",
            "max": 43,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b56020198dcb47f09c41caf147bce846",
            "value": 43
          }
        },
        "26a416fd73174286b33ffb0f7a749e3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_460573203f054984b0ace792262de3aa",
            "placeholder": "​",
            "style": "IPY_MODEL_a4df8f69d61a48808036dfd95b6b8e6c",
            "value": " 43.0/43.0 [00:00&lt;00:00, 393B/s]"
          }
        },
        "44b36dfa5fa54562be22839b84b9fbb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "088f0bd325564f54846b1f46613509ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f09fd2ce0a35491db034fef7413b9fcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a580de4c7ade41208439e5f92510f1e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b56020198dcb47f09c41caf147bce846": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "460573203f054984b0ace792262de3aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4df8f69d61a48808036dfd95b6b8e6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fe96c74dbec49928fd3cb112d4748c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_edf2e363dbf34646a9adf34a2aea8bc4",
              "IPY_MODEL_9df9851b07df473fb03ff1f6444c7b6a",
              "IPY_MODEL_05540359cbfc4fcdaadb6ac2dd38481d"
            ],
            "layout": "IPY_MODEL_f00254862e3d4d2cb3670fc357e82506"
          }
        },
        "edf2e363dbf34646a9adf34a2aea8bc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12feb18d58b249948e2175d2f242ebfb",
            "placeholder": "​",
            "style": "IPY_MODEL_c97053bfd0264ee6baf02395a8544ad2",
            "value": "Downloading: 100%"
          }
        },
        "9df9851b07df473fb03ff1f6444c7b6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b3aff495f594900a427179809431a5f",
            "max": 647,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54ca432e71c7449fa27cf5a703256f6d",
            "value": 647
          }
        },
        "05540359cbfc4fcdaadb6ac2dd38481d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5b04da864b74f6b985ca054ca2de404",
            "placeholder": "​",
            "style": "IPY_MODEL_b83d96ddd8fe45418d0547237d4f3c1b",
            "value": " 647/647 [00:00&lt;00:00, 7.50kB/s]"
          }
        },
        "f00254862e3d4d2cb3670fc357e82506": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12feb18d58b249948e2175d2f242ebfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c97053bfd0264ee6baf02395a8544ad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b3aff495f594900a427179809431a5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54ca432e71c7449fa27cf5a703256f6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5b04da864b74f6b985ca054ca2de404": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b83d96ddd8fe45418d0547237d4f3c1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}