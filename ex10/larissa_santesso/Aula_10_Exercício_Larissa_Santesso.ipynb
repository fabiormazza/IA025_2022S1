{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unicamp-dl/IA025_2022S1/blob/main/ex10/larissa_santesso/Aula_10_Exerc%C3%ADcio_Larissa_Santesso.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOdQB41_4ZxG",
        "outputId": "25ca28e1-02e1-481c-8407-4a6783f3291f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Meu nome é Larissa Antonelli Santesso\n"
          ]
        }
      ],
      "source": [
        "nome = \"Larissa Antonelli Santesso\"\n",
        "print(f'Meu nome é {nome}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAytoDJGEg77",
        "outputId": "995216b1-d2da-42b6-d150-67a9ea1ad56b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IbuChoAPMEn"
      },
      "source": [
        "#  Exercício: Modelo de Linguagem com auto-atenção"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_DBb0-Klwf2"
      },
      "source": [
        "Este exercício é similar ao da Aula 8, mas iremos agora treinar uma rede neural com **duas camadas** de auto-atenção **causais** para prever a próxima palavra de um texto, data as palavras anteriores como entrada. \n",
        "\n",
        "Iremos também trabalhar com sequencias de tamanho variável.\n",
        "\n",
        "Na camada de auto-atenção, não se esqueça de implementar:\n",
        "- Embeddings de posição\n",
        "- Projeções lineares (WQ, WK, WV, WO)\n",
        "- Conexões residuais\n",
        "- Camada de feed forward (2-layer MLP)\n",
        "\n",
        "\n",
        "O dataset usado neste exercício (BrWaC) possui um tamanho razoável e você vai precisar rodar seus experimentos com GPU.\n",
        "\n",
        "Alguns conselhos úteis:\n",
        "- **ATENÇÃO:** o dataset é bem grande. Não dê comando de imprimí-lo.\n",
        "- Durante a depuração, faça seu dataset ficar bem pequeno, para que a depuração seja mais rápida e não precise de GPU. Somente ligue a GPU quando o seu laço de treinamento já está funcionando\n",
        "- Não deixe para fazer esse exercício na véspera. Ele é trabalhoso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3twP0YJC4jmJ",
        "outputId": "c0f4ed03-7e34-4682-c2c4-e098789c60e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 5.1 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 59.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 60.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"
          ]
        }
      ],
      "source": [
        "# iremos utilizar a biblioteca dos transformers para ter acesso ao tokenizador do BERT.\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnyhJZtTRNMx"
      },
      "source": [
        "## Importação dos pacotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlIOVCajPWcU"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import itertools\n",
        "import functools\n",
        "import math\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm_notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9f3PfifAwpU",
        "outputId": "c510204d-02e9-4b06-e46b-4d2d735b6c2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jun  8 17:43:19 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Check which GPU we are using\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whTCe2i7AtoV",
        "outputId": "cfe25c7e-c663-4cb4-865b-cfa36152bc6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda:0\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available(): \n",
        "   dev = \"cuda:0\"\n",
        "else: \n",
        "   dev = \"cpu\"\n",
        "device = torch.device(dev)\n",
        "print('Using {}'.format(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZfxgV2DUk58"
      },
      "source": [
        "## Implementação do MyDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3aNsOi0yaIJ"
      },
      "source": [
        "Mais sobre` batch_encode_plus`: https://huggingface.co/docs/transformers/internal/tokenization_utils#transformers.tokenization_utils_base.PreTrainedTokenizerBase.batch_encode_plus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6Fh1-166lQs"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "\n",
        "def tokenize(text: str, tokenizer):\n",
        "    # Recomenda-se usar o tokenizer.batch_encode_plus pois é mais rápido.\n",
        "    return tokenizer.batch_encode_plus(text, return_tensors='pt', add_special_tokens= False,  padding=\"longest\").input_ids\n",
        "\n",
        "\n",
        "class MyDataset():\n",
        "    def __init__(self, texts: List[str], tokenizer, max_seq_length: int, folder_name: str, data_type=\"train\", iter_texts=1000, i_init=0):\n",
        "        path = \"/content/gdrive/MyDrive/Colab Notebooks/modelos_Aula09/\"+folder_name\n",
        "        self.tokens_ids =[]\n",
        "        for i in range(i_init,len(texts), iter_texts):\n",
        "            # Ideia de salvar os dados para aproveitar melhor a RAM baseada no exercício da Aula 08 do aluno Patrick Ferreira\n",
        "            try:\n",
        "                self.load_x = np.load(path+\"x_\"+ str(i) + \"_\"+ str(i+iter_texts) +\"_\" + data_type + \".npy\", mmap_mode=\"r\", allow_pickle=True)\n",
        "                self.tokens_ids.append(torch.tensor(self.load_x))\n",
        "                print(str(i) + \" to \"+ str(i+iter_texts)+\" lines loaded\")\n",
        "\n",
        "            except Exception as e:\n",
        "                output_tokenize = tokenize(texts[i:i+iter_texts], tokenizer)\n",
        "                output_tokenize = torch.nn.functional.pad(output_tokenize, (0,max((max_seq_length-int(output_tokenize.shape[1]),1))))\n",
        "                self.tokens_ids =[]\n",
        "                shape_iter = output_tokenize.shape[1]\n",
        "                for j in range(0,shape_iter-1, max_seq_length-1):    # Ideia do slicing baseada no notebook do Pedro Gengo   \n",
        "                    if (j + max_seq_length) < int(shape_iter):\n",
        "                        batch_seq = output_tokenize[:,j:j+max_seq_length]\n",
        "\n",
        "                    else:\n",
        "                        batch_seq = output_tokenize[:,-max_seq_length:]\n",
        "                    \n",
        "                    batch_seq = batch_seq[torch.sum(batch_seq, dim=1)!=0]\n",
        "                    self.tokens_ids.extend(torch.cat([torch.tensor(tokenizer.cls_token_id).long().repeat(batch_seq.shape[0])[:, None],batch_seq], axis=1))\n",
        "                \n",
        "                self.tokens_ids = torch.stack(self.tokens_ids)\n",
        "                \n",
        "                print(f\"Saving: {i} to {i+iter_texts} lines - shape ={self.tokens_ids.shape}\")\n",
        "                np.save(path+\"x_\"+ str(i) + \"_\"+ str(i+iter_texts) + \"_\" + data_type + \".npy\", np.array(self.tokens_ids))\n",
        "\n",
        "        try:\n",
        "            self.tokens_ids = torch.vstack(self.tokens_ids)\n",
        "        \n",
        "        except:\n",
        "            print(\"Don't need to stack tensor\")\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.tokens_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.tokens_ids[idx,:-1].long(), self.tokens_ids[idx,1:].long()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wew-gFbWeBTq"
      },
      "source": [
        "## Testando se a implementação do MyDataset está correta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_lLQSTckYtS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "b160268ee9184673a5af67fbdd277210",
            "d61f33cdc8dc4cc6ac1852942828a9f2",
            "e7664fe0eef643cf83ece5d61d0db020",
            "6a45294fc535451ea06481b49844cdfb",
            "2032fa80b3584988973b37cdccbd4bec",
            "ada03ada630f4c6c90a11bcafa376733",
            "18a8f1f08c6240e9b416e0e71906596d",
            "8651d43af93a444482958556a0ae9cc2",
            "e862a9f434aa48a9bd5a6a496aa71007",
            "d32b7e0b486540c081f66609b042aba6",
            "efeb989417554746abe6142d22a752d8",
            "fa5e195a6bf442a2a0d9af5000c3bc67",
            "a1bd0703fa844af69bea267fc7d7ed20",
            "0a9d58e1afcb469e88b3aa78a27e6301",
            "89dc84ac3e6d4b7db6beb5df3dda732d",
            "5b30b0b561b240ef9c4ab75daed71744",
            "80a8c5d87573490487a52ac33b3d50d4",
            "3c24d13cce0042e0ada9fec8fda48d53",
            "cbdc70cecaa54aeaae4aefbfc2c3a7a6",
            "339e6ea512644f3b90622b86c4dc2b23",
            "887bbde8ac2a4e43895e61d2904a2e8e",
            "a55f320634424c00afb294fd091b64e9",
            "f4ee344004e441608c5520b130484348",
            "851c16fdfd9f419eb85dd15cd8244620",
            "81cb41f86e1247979080b3ca3e90bbed",
            "00ecaf3d00974580b0312be789718c86",
            "2d4b6fb5c0f848a4b52f63014c64dc30",
            "b260a2086d354cc587c78c499e155e5a",
            "4b1812f8f01740f3b50697a280250d34",
            "e51de0e3ef8049daa64f0bb97b06a012",
            "24417af2102942d0bd05bb0716c159e8",
            "20acac1478694f2e98c1332bdc46c359",
            "2d3c955fc5c84656b0e4061eb7e7db94",
            "20e856ae07d54cfeab0a45a98634d32a",
            "a95357d0de0e42aa8ac27ab7584597d2",
            "39aa805788f34bbd801e6caedf9773be",
            "171a01c096904e98bd08fa66250fa9ef",
            "71f26d4978fe4823aa1ac593db10de99",
            "61ba23a6b46a4fa3ade72c9892f087c1",
            "eedb1e8dec86420a869527c5ff7cbc57",
            "e32a73b9ff934053b4022d249a524888",
            "8f31dd8d1b024d359f4c4b2e1c00d7d2",
            "98ac99a30dc14112b84b33dc300e7d27",
            "d172a310ca0949febfbd4d112cad6aeb",
            "819655885f2c4e22a3ef13ad8e58ad73",
            "4a913ed626934ed9a50bd4a9ac53b096",
            "0488fdfbbcf64be8afa6cbd3d6bdc0ca",
            "c62b605811c34d1399aa31f13aa74690",
            "ee8041110a704573bbcc432c7447e08e",
            "7f41738f55eb4d02b6b6609eb8b56223",
            "477b25b95a6f41d081bb4b97dd225ef7",
            "490dfde34c1742e08a278b9116b14c63",
            "9ab3c508898843d8ab1de8f58e851fdc",
            "9c1c9c952a0848e9add0166ae6c05f08",
            "ef08e270e7ee4b4b9f92c9f2464226ed"
          ]
        },
        "outputId": "1b808561-ae9a-4857-a5f2-93bbd681ac4b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/205k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b160268ee9184673a5af67fbdd277210"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa5e195a6bf442a2a0d9af5000c3bc67"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4ee344004e441608c5520b130484348"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/43.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "20e856ae07d54cfeab0a45a98634d32a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/647 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "819655885f2c4e22a3ef13ad8e58ad73"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246,
          "referenced_widgets": [
            "808222214af941c893294da96a772bee",
            "256a05b035cf4a8f9026c40c40fa2533",
            "6b5a5a4f60d24620a0d3f0e71e247feb",
            "8618356df359482e9ac05904028f7a6b",
            "79b3bb230afd40edbbbb088dd65d8cd8",
            "f38445c2cd384a5aa1e8f0ef8bd78af5",
            "fa92cd199c5748c29a0c6ab07306c5bf",
            "66d13388a75e4b859306f27cba04d811",
            "8157b5198bc64f0498de31adb83adadc",
            "ebbf26f106404d35b83492c3771ebc94",
            "c8b7aad8114b43a18e773bde64168426",
            "821f9feae43647d086e0a0837b2e6d06",
            "a9c85083f7914ab0a2bdaa1242d003f2",
            "434fbe96891943b49d237a2addff4c17",
            "db0a162ee68f4a239e42a2c04b145680",
            "61636a51e79d4d31afa127d5f88ee96f",
            "0c6a9589cf4b48e49cbf14654ad727e0",
            "30a1a8b11f694c3d992e13d5db8fbbf9",
            "4449d2ab3153428287f56670d9cf862c",
            "0fe10e810ab14298b6268f9c600bf6a1",
            "3a8b7e55cf2b4cd6adc506ae6f7f78c7",
            "f2bdc3a338dd4e27a8c9de7770eaef06",
            "bf85a3de3dd3477fa686844d9a661a15",
            "318bcef4a3494900b015b1c1172a2f68",
            "d90c277107c04d26ac2bbb259ce9302a",
            "c66af7b29ee540c295f59aa1403f2f6c",
            "15d869d0525e42d997b8bec90f263805",
            "ee35fefddff0489394481f0548cda87c",
            "29afa218da0547409216e581ff86d90f",
            "188f5509eaa14ef5a150656a31510a4e",
            "a8fe031081964e2f99d1901af1c7fdb0",
            "026da411b2e24e58a5bcf486f509c190",
            "13f67f3e57b84f47879d2d49e409a82c",
            "1c7ed902ba19455194c9bd72405f2ebd",
            "5e5cb419a27b4a2ebd43964ca44efcf1",
            "df088b4fe5be4bdcbc6111d5fa4b2e3f",
            "7a443a1dad7f4d88a44b9f9db50c534b",
            "e1a9eaeea65d46208652ecb49f68434a",
            "40b991bbe3474b7384c8b404710cb883",
            "76712bd22ec14118b74d8dc7dd586857",
            "dedd452453a942dfb1ab83a82fb51be1",
            "2f5eb3f6d1bb44999e1529834fa348f7",
            "c88ff51b761a4e6bb8d07d27eec12ed0",
            "a0c561b4fa5a479a8198d97c8b7c2315",
            "eb6fc5c62cfb4b58b0be787f8829ebc1",
            "576576a4bcee48cf9aae481235ecae4e",
            "240928fe31894a9e87fddb9526c44552",
            "6d28bb02b56d4cdf821d3714308f7427",
            "c5f0ba1405f64f7f808b9b982bfd3081",
            "e264487111dc44f38704b5d05ceda1d4",
            "498f310ce5794ffdbf62421623d92393",
            "cfd09cc242584f89940d9b15792d8d71",
            "511221767f3f4780a7a9828ce76f1a30",
            "c16618845876426b9d2afc1a1344fec8",
            "747769302bed441e8634bbabe31d9083"
          ]
        },
        "outputId": "80a8271b-3fa9-4b93-d028-a60c9e2bbb56",
        "id": "cyV34ojQ8hAu"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/205k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "808222214af941c893294da96a772bee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "821f9feae43647d086e0a0837b2e6d06"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf85a3de3dd3477fa686844d9a661a15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/43.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c7ed902ba19455194c9bd72405f2ebd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/647 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb6fc5c62cfb4b58b0be787f8829ebc1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving: 0 to 1000 lines - shape =torch.Size([2, 10])\n",
            "Don't need to stack tensor\n",
            "Passou no assert de tamanho do dataset.\n",
            "Passou no assert de dataset.\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
        "\n",
        "dummy_texts = ['Eu gosto de correr', 'Ela gosta muito de comer pizza']\n",
        "\n",
        "dummy_dataset = MyDataset(texts=dummy_texts, tokenizer=tokenizer, max_seq_length=9)\n",
        "dummy_loader = DataLoader(dummy_dataset, batch_size=6, shuffle=False)\n",
        "assert len(dummy_dataset) == 2\n",
        "print('Passou no assert de tamanho do dataset.')\n",
        "\n",
        "first_batch_input, first_batch_target = next(iter(dummy_loader))\n",
        "\n",
        "correct_first_batch_input = torch.LongTensor(\n",
        "    [[  101,  3396, 10303,   125, 13239,     0,     0,     0,     0],\n",
        "     [  101,  1660,  5971,   785,   125,  1847, 13779, 15616,     0]])\n",
        "\n",
        "correct_first_batch_target = torch.LongTensor(\n",
        "    [[ 3396, 10303,   125, 13239,     0,     0,     0,     0,     0],\n",
        "     [ 1660,  5971,   785,   125,  1847, 13779, 15616,     0,     0]])\n",
        "\n",
        "assert torch.equal(first_batch_input, correct_first_batch_input)\n",
        "assert torch.equal(first_batch_target, correct_first_batch_target)\n",
        "\n",
        "print('Passou no assert de dataset.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dummy_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvZlKCyGUnEn",
        "outputId": "27640b10-cd52-484f-ad40-c4bc55b795e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_batch_input, correct_first_batch_input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVtui4nzShTD",
        "outputId": "5cf4f588-930f-4d1b-dc5b-e30290e7c10e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[  101,  3396, 10303,   125, 13239,     0,     0,     0,     0],\n",
              "         [  101,  1660,  5971,   785,   125,  1847, 13779, 15616,     0]]),\n",
              " tensor([[  101,  3396, 10303,   125, 13239,     0,     0,     0,     0],\n",
              "         [  101,  1660,  5971,   785,   125,  1847, 13779, 15616,     0]]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_batch_target, correct_first_batch_target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaOPWb1Pjj_E",
        "outputId": "d58b027b-7240-4608-ce80-9462829b24da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 3396, 10303,   125, 13239,     0,     0,     0,     0,     0],\n",
              "         [ 1660,  5971,   785,   125,  1847, 13779, 15616,     0,     0]]),\n",
              " tensor([[ 3396, 10303,   125, 13239,     0,     0,     0,     0,     0],\n",
              "         [ 1660,  5971,   785,   125,  1847, 13779, 15616,     0,     0]]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_dataset = MyDataset(texts=dummy_texts, tokenizer=tokenizer, max_seq_length=3,folder_name=\"dataset_04/\")\n",
        "dummy_loader = DataLoader(dummy_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "next(iter(dummy_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rZdkVWEiIr1",
        "outputId": "9828e29a-b5d4-4ec4-c9dd-6170bbb2b70e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving: 0 to 1000 lines - shape =torch.Size([6, 4])\n",
            "Don't need to stack tensor\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[  101,  3396, 10303]]), tensor([[ 3396, 10303,   125]])]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_loader = DataLoader(dummy_dataset, batch_size=10, shuffle=False)\n",
        "\n",
        "next(iter(dummy_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_i3HRDiHWoKG",
        "outputId": "3064ba7e-cf4a-48d2-c624-c9cb772bf659"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[  101,  3396, 10303],\n",
              "         [  101,  1660,  5971],\n",
              "         [  101,   125, 13239],\n",
              "         [  101,   785,   125],\n",
              "         [  101,  1847, 13779],\n",
              "         [  101, 13779, 15616]]), tensor([[ 3396, 10303,   125],\n",
              "         [ 1660,  5971,   785],\n",
              "         [  125, 13239,     0],\n",
              "         [  785,   125,  1847],\n",
              "         [ 1847, 13779, 15616],\n",
              "         [13779, 15616,     0]])]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LfrHHouleJ0"
      },
      "source": [
        "# Carregamento do dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2vFWjsSkmop"
      },
      "source": [
        "Iremos usar uma pequena amostra do dataset [BrWaC](https://www.inf.ufrgs.br/pln/wiki/index.php?title=BrWaC) para treinar e avaliar nosso modelo de linguagem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGlN1WqrXPA6",
        "outputId": "4f24451b-1b73-4918-8cab-3d62c8ac8db0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-08 21:40:45--  https://storage.googleapis.com/unicamp-dl/ia025a_2022s1/aula9/sample-1gb.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.214.128, 173.194.215.128, 173.194.216.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.214.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1230909256 (1.1G) [text/plain]\n",
            "Saving to: ‘sample-1gb.txt’\n",
            "\n",
            "sample-1gb.txt      100%[===================>]   1.15G  89.6MB/s    in 12s     \n",
            "\n",
            "2022-06-08 21:40:57 (100 MB/s) - ‘sample-1gb.txt’ saved [1230909256/1230909256]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -nc https://storage.googleapis.com/unicamp-dl/ia025a_2022s1/aula9/sample-1gb.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Salvando o dataset em uma pasta da Drive"
      ],
      "metadata": {
        "id": "VDMe0UAfPvtx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zD7giuVMkdsR",
        "outputId": "febd8531-aaa4-4980-cd8a-126d034bb418"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read 250000 lines.\n",
            "Saving: 0 to 1000 lines - shape =torch.Size([106473, 13])\n",
            "Saving: 1000 to 2000 lines - shape =torch.Size([103069, 13])\n",
            "Saving: 2000 to 3000 lines - shape =torch.Size([119189, 13])\n",
            "Saving: 3000 to 4000 lines - shape =torch.Size([113051, 13])\n",
            "Saving: 4000 to 5000 lines - shape =torch.Size([94192, 13])\n",
            "Saving: 5000 to 6000 lines - shape =torch.Size([113454, 13])\n",
            "Saving: 6000 to 7000 lines - shape =torch.Size([108846, 13])\n",
            "Saving: 7000 to 8000 lines - shape =torch.Size([91483, 13])\n",
            "Saving: 8000 to 9000 lines - shape =torch.Size([118739, 13])\n",
            "Saving: 9000 to 10000 lines - shape =torch.Size([113324, 13])\n",
            "Saving: 10000 to 11000 lines - shape =torch.Size([103453, 13])\n",
            "Saving: 11000 to 12000 lines - shape =torch.Size([98252, 13])\n",
            "Saving: 12000 to 13000 lines - shape =torch.Size([97600, 13])\n",
            "Saving: 13000 to 14000 lines - shape =torch.Size([92441, 13])\n",
            "Saving: 14000 to 15000 lines - shape =torch.Size([108823, 13])\n",
            "Saving: 15000 to 16000 lines - shape =torch.Size([97246, 13])\n",
            "Saving: 16000 to 17000 lines - shape =torch.Size([88443, 13])\n",
            "Saving: 17000 to 18000 lines - shape =torch.Size([98587, 13])\n",
            "Saving: 18000 to 19000 lines - shape =torch.Size([92111, 13])\n",
            "Saving: 19000 to 20000 lines - shape =torch.Size([95336, 13])\n",
            "Saving: 20000 to 21000 lines - shape =torch.Size([103901, 13])\n",
            "Saving: 21000 to 22000 lines - shape =torch.Size([87425, 13])\n",
            "Saving: 22000 to 23000 lines - shape =torch.Size([118549, 13])\n",
            "Saving: 23000 to 24000 lines - shape =torch.Size([103882, 13])\n",
            "Saving: 24000 to 25000 lines - shape =torch.Size([102496, 13])\n",
            "Saving: 25000 to 26000 lines - shape =torch.Size([100898, 13])\n",
            "Saving: 26000 to 27000 lines - shape =torch.Size([95521, 13])\n",
            "Saving: 27000 to 28000 lines - shape =torch.Size([87805, 13])\n",
            "Saving: 28000 to 29000 lines - shape =torch.Size([97677, 13])\n",
            "Saving: 29000 to 30000 lines - shape =torch.Size([106377, 13])\n",
            "Saving: 30000 to 31000 lines - shape =torch.Size([102283, 13])\n",
            "Saving: 31000 to 32000 lines - shape =torch.Size([108911, 13])\n",
            "Saving: 32000 to 33000 lines - shape =torch.Size([99061, 13])\n",
            "Saving: 33000 to 34000 lines - shape =torch.Size([108903, 13])\n",
            "Saving: 34000 to 35000 lines - shape =torch.Size([95053, 13])\n",
            "Saving: 35000 to 36000 lines - shape =torch.Size([90119, 13])\n",
            "Saving: 36000 to 37000 lines - shape =torch.Size([98184, 13])\n",
            "Saving: 37000 to 38000 lines - shape =torch.Size([98054, 13])\n",
            "Saving: 38000 to 39000 lines - shape =torch.Size([100247, 13])\n",
            "Saving: 39000 to 40000 lines - shape =torch.Size([96810, 13])\n",
            "Saving: 40000 to 41000 lines - shape =torch.Size([100891, 13])\n",
            "Saving: 41000 to 42000 lines - shape =torch.Size([93614, 13])\n",
            "Saving: 42000 to 43000 lines - shape =torch.Size([94631, 13])\n",
            "Saving: 43000 to 44000 lines - shape =torch.Size([95224, 13])\n",
            "Saving: 44000 to 45000 lines - shape =torch.Size([107506, 13])\n",
            "Saving: 45000 to 46000 lines - shape =torch.Size([91071, 13])\n",
            "Saving: 46000 to 47000 lines - shape =torch.Size([96179, 13])\n",
            "Saving: 47000 to 48000 lines - shape =torch.Size([114378, 13])\n",
            "Saving: 48000 to 49000 lines - shape =torch.Size([107138, 13])\n",
            "Saving: 49000 to 50000 lines - shape =torch.Size([108873, 13])\n",
            "Saving: 50000 to 51000 lines - shape =torch.Size([112012, 13])\n",
            "Saving: 51000 to 52000 lines - shape =torch.Size([102533, 13])\n",
            "Saving: 52000 to 53000 lines - shape =torch.Size([96845, 13])\n",
            "Saving: 53000 to 54000 lines - shape =torch.Size([96578, 13])\n",
            "Saving: 54000 to 55000 lines - shape =torch.Size([94034, 13])\n",
            "Saving: 55000 to 56000 lines - shape =torch.Size([104610, 13])\n",
            "Saving: 56000 to 57000 lines - shape =torch.Size([114085, 13])\n",
            "Saving: 57000 to 58000 lines - shape =torch.Size([112127, 13])\n",
            "Saving: 58000 to 59000 lines - shape =torch.Size([83022, 13])\n",
            "Saving: 59000 to 60000 lines - shape =torch.Size([119518, 13])\n",
            "Saving: 60000 to 61000 lines - shape =torch.Size([106722, 13])\n",
            "Saving: 61000 to 62000 lines - shape =torch.Size([107657, 13])\n",
            "Saving: 62000 to 63000 lines - shape =torch.Size([99661, 13])\n",
            "Saving: 63000 to 64000 lines - shape =torch.Size([103527, 13])\n",
            "Saving: 64000 to 65000 lines - shape =torch.Size([107096, 13])\n",
            "Saving: 65000 to 66000 lines - shape =torch.Size([90636, 13])\n",
            "Saving: 66000 to 67000 lines - shape =torch.Size([100211, 13])\n",
            "Saving: 67000 to 68000 lines - shape =torch.Size([98976, 13])\n",
            "Saving: 68000 to 69000 lines - shape =torch.Size([112961, 13])\n",
            "Saving: 69000 to 70000 lines - shape =torch.Size([96582, 13])\n",
            "Saving: 70000 to 71000 lines - shape =torch.Size([100967, 13])\n",
            "Saving: 71000 to 72000 lines - shape =torch.Size([101328, 13])\n",
            "Saving: 72000 to 73000 lines - shape =torch.Size([94133, 13])\n",
            "Saving: 73000 to 74000 lines - shape =torch.Size([92852, 13])\n",
            "Saving: 74000 to 75000 lines - shape =torch.Size([97954, 13])\n",
            "Saving: 75000 to 76000 lines - shape =torch.Size([104529, 13])\n",
            "Saving: 76000 to 77000 lines - shape =torch.Size([98615, 13])\n",
            "Saving: 77000 to 78000 lines - shape =torch.Size([107992, 13])\n",
            "Saving: 78000 to 79000 lines - shape =torch.Size([105269, 13])\n",
            "Saving: 79000 to 80000 lines - shape =torch.Size([103304, 13])\n",
            "Saving: 80000 to 81000 lines - shape =torch.Size([103213, 13])\n",
            "Saving: 81000 to 82000 lines - shape =torch.Size([107553, 13])\n",
            "Saving: 82000 to 83000 lines - shape =torch.Size([103759, 13])\n",
            "Saving: 83000 to 84000 lines - shape =torch.Size([103324, 13])\n",
            "Saving: 84000 to 85000 lines - shape =torch.Size([104003, 13])\n",
            "Saving: 85000 to 86000 lines - shape =torch.Size([108252, 13])\n",
            "Saving: 86000 to 87000 lines - shape =torch.Size([98096, 13])\n",
            "Saving: 87000 to 88000 lines - shape =torch.Size([105379, 13])\n",
            "Saving: 88000 to 89000 lines - shape =torch.Size([97997, 13])\n",
            "Saving: 89000 to 90000 lines - shape =torch.Size([106419, 13])\n",
            "Saving: 90000 to 91000 lines - shape =torch.Size([92380, 13])\n",
            "Saving: 91000 to 92000 lines - shape =torch.Size([114559, 13])\n",
            "Saving: 92000 to 93000 lines - shape =torch.Size([117106, 13])\n",
            "Saving: 93000 to 94000 lines - shape =torch.Size([102386, 13])\n",
            "Saving: 94000 to 95000 lines - shape =torch.Size([95452, 13])\n",
            "Saving: 95000 to 96000 lines - shape =torch.Size([105749, 13])\n",
            "Saving: 96000 to 97000 lines - shape =torch.Size([95091, 13])\n",
            "Saving: 97000 to 98000 lines - shape =torch.Size([102360, 13])\n",
            "Saving: 98000 to 99000 lines - shape =torch.Size([105267, 13])\n",
            "Saving: 99000 to 100000 lines - shape =torch.Size([116232, 13])\n",
            "Saving: 100000 to 101000 lines - shape =torch.Size([104027, 13])\n",
            "Saving: 101000 to 102000 lines - shape =torch.Size([104512, 13])\n",
            "Saving: 102000 to 103000 lines - shape =torch.Size([107755, 13])\n",
            "Saving: 103000 to 104000 lines - shape =torch.Size([119730, 13])\n",
            "Saving: 104000 to 105000 lines - shape =torch.Size([86951, 13])\n",
            "Saving: 105000 to 106000 lines - shape =torch.Size([118070, 13])\n",
            "Saving: 106000 to 107000 lines - shape =torch.Size([100044, 13])\n",
            "Saving: 107000 to 108000 lines - shape =torch.Size([103423, 13])\n",
            "Saving: 108000 to 109000 lines - shape =torch.Size([94728, 13])\n",
            "Saving: 109000 to 110000 lines - shape =torch.Size([111112, 13])\n",
            "Saving: 110000 to 111000 lines - shape =torch.Size([93743, 13])\n",
            "Saving: 111000 to 112000 lines - shape =torch.Size([112362, 13])\n",
            "Saving: 112000 to 113000 lines - shape =torch.Size([98985, 13])\n",
            "Saving: 113000 to 114000 lines - shape =torch.Size([109892, 13])\n",
            "Saving: 114000 to 115000 lines - shape =torch.Size([105294, 13])\n",
            "Saving: 115000 to 116000 lines - shape =torch.Size([99156, 13])\n",
            "Saving: 116000 to 117000 lines - shape =torch.Size([97156, 13])\n",
            "Saving: 117000 to 118000 lines - shape =torch.Size([101788, 13])\n",
            "Saving: 118000 to 119000 lines - shape =torch.Size([92744, 13])\n",
            "Saving: 119000 to 120000 lines - shape =torch.Size([87853, 13])\n",
            "Saving: 120000 to 121000 lines - shape =torch.Size([107047, 13])\n",
            "Saving: 121000 to 122000 lines - shape =torch.Size([99789, 13])\n",
            "Saving: 122000 to 123000 lines - shape =torch.Size([92868, 13])\n",
            "Saving: 123000 to 124000 lines - shape =torch.Size([94131, 13])\n",
            "Saving: 124000 to 125000 lines - shape =torch.Size([95719, 13])\n",
            "Saving: 125000 to 126000 lines - shape =torch.Size([102691, 13])\n",
            "Saving: 126000 to 127000 lines - shape =torch.Size([113472, 13])\n",
            "Saving: 127000 to 128000 lines - shape =torch.Size([107096, 13])\n",
            "Saving: 128000 to 129000 lines - shape =torch.Size([92973, 13])\n",
            "Saving: 129000 to 130000 lines - shape =torch.Size([102542, 13])\n",
            "Saving: 130000 to 131000 lines - shape =torch.Size([103619, 13])\n",
            "Saving: 131000 to 132000 lines - shape =torch.Size([102641, 13])\n",
            "Saving: 132000 to 133000 lines - shape =torch.Size([92346, 13])\n",
            "Saving: 133000 to 134000 lines - shape =torch.Size([98770, 13])\n",
            "Saving: 134000 to 135000 lines - shape =torch.Size([107653, 13])\n",
            "Saving: 135000 to 136000 lines - shape =torch.Size([75937, 13])\n",
            "Saving: 136000 to 137000 lines - shape =torch.Size([91406, 13])\n",
            "Saving: 137000 to 138000 lines - shape =torch.Size([119228, 13])\n",
            "Saving: 138000 to 139000 lines - shape =torch.Size([103948, 13])\n",
            "Saving: 139000 to 140000 lines - shape =torch.Size([106905, 13])\n",
            "Saving: 140000 to 141000 lines - shape =torch.Size([97071, 13])\n",
            "Saving: 141000 to 142000 lines - shape =torch.Size([91263, 13])\n",
            "Saving: 142000 to 143000 lines - shape =torch.Size([92987, 13])\n",
            "Saving: 143000 to 144000 lines - shape =torch.Size([101463, 13])\n",
            "Saving: 144000 to 145000 lines - shape =torch.Size([100970, 13])\n",
            "Saving: 145000 to 146000 lines - shape =torch.Size([95860, 13])\n",
            "Saving: 146000 to 147000 lines - shape =torch.Size([94968, 13])\n",
            "Saving: 147000 to 148000 lines - shape =torch.Size([100090, 13])\n",
            "Saving: 148000 to 149000 lines - shape =torch.Size([88199, 13])\n",
            "Saving: 149000 to 150000 lines - shape =torch.Size([108077, 13])\n",
            "Saving: 150000 to 151000 lines - shape =torch.Size([89262, 13])\n",
            "Saving: 151000 to 152000 lines - shape =torch.Size([110964, 13])\n",
            "Saving: 152000 to 153000 lines - shape =torch.Size([118077, 13])\n",
            "Saving: 153000 to 154000 lines - shape =torch.Size([98578, 13])\n",
            "Saving: 154000 to 155000 lines - shape =torch.Size([100466, 13])\n",
            "Saving: 155000 to 156000 lines - shape =torch.Size([109135, 13])\n",
            "Saving: 156000 to 157000 lines - shape =torch.Size([102195, 13])\n",
            "Saving: 157000 to 158000 lines - shape =torch.Size([108113, 13])\n",
            "Saving: 158000 to 159000 lines - shape =torch.Size([101280, 13])\n",
            "Saving: 159000 to 160000 lines - shape =torch.Size([104810, 13])\n",
            "Saving: 160000 to 161000 lines - shape =torch.Size([109881, 13])\n",
            "Saving: 161000 to 162000 lines - shape =torch.Size([106645, 13])\n",
            "Saving: 162000 to 163000 lines - shape =torch.Size([112066, 13])\n",
            "Saving: 163000 to 164000 lines - shape =torch.Size([93821, 13])\n",
            "Saving: 164000 to 165000 lines - shape =torch.Size([118655, 13])\n",
            "Saving: 165000 to 166000 lines - shape =torch.Size([102630, 13])\n",
            "Saving: 166000 to 167000 lines - shape =torch.Size([92615, 13])\n",
            "Saving: 167000 to 168000 lines - shape =torch.Size([100279, 13])\n",
            "Saving: 168000 to 169000 lines - shape =torch.Size([93312, 13])\n",
            "Saving: 169000 to 170000 lines - shape =torch.Size([96911, 13])\n",
            "Saving: 170000 to 171000 lines - shape =torch.Size([99157, 13])\n",
            "Saving: 171000 to 172000 lines - shape =torch.Size([111891, 13])\n",
            "Saving: 172000 to 173000 lines - shape =torch.Size([97669, 13])\n",
            "Saving: 173000 to 174000 lines - shape =torch.Size([101442, 13])\n",
            "Saving: 174000 to 175000 lines - shape =torch.Size([96613, 13])\n",
            "Saving: 175000 to 176000 lines - shape =torch.Size([105400, 13])\n",
            "Saving: 176000 to 177000 lines - shape =torch.Size([107308, 13])\n",
            "Saving: 177000 to 178000 lines - shape =torch.Size([110431, 13])\n",
            "Saving: 178000 to 179000 lines - shape =torch.Size([132533, 13])\n",
            "Saving: 179000 to 180000 lines - shape =torch.Size([92997, 13])\n",
            "Saving: 180000 to 181000 lines - shape =torch.Size([96061, 13])\n",
            "Saving: 181000 to 182000 lines - shape =torch.Size([120477, 13])\n",
            "Saving: 182000 to 183000 lines - shape =torch.Size([93031, 13])\n",
            "Saving: 183000 to 184000 lines - shape =torch.Size([91850, 13])\n",
            "Saving: 184000 to 185000 lines - shape =torch.Size([96941, 13])\n",
            "Saving: 185000 to 186000 lines - shape =torch.Size([111055, 13])\n",
            "Saving: 186000 to 187000 lines - shape =torch.Size([106359, 13])\n",
            "Saving: 187000 to 188000 lines - shape =torch.Size([103386, 13])\n",
            "Saving: 188000 to 189000 lines - shape =torch.Size([103998, 13])\n",
            "Saving: 189000 to 190000 lines - shape =torch.Size([120150, 13])\n",
            "Saving: 190000 to 191000 lines - shape =torch.Size([100143, 13])\n",
            "Saving: 191000 to 192000 lines - shape =torch.Size([91806, 13])\n",
            "Saving: 192000 to 193000 lines - shape =torch.Size([105797, 13])\n",
            "Saving: 193000 to 194000 lines - shape =torch.Size([95468, 13])\n",
            "Saving: 194000 to 195000 lines - shape =torch.Size([96141, 13])\n",
            "Saving: 195000 to 196000 lines - shape =torch.Size([101482, 13])\n",
            "Saving: 196000 to 197000 lines - shape =torch.Size([105892, 13])\n",
            "Saving: 197000 to 198000 lines - shape =torch.Size([101041, 13])\n",
            "Saving: 198000 to 199000 lines - shape =torch.Size([102245, 13])\n",
            "Saving: 199000 to 200000 lines - shape =torch.Size([116401, 13])\n",
            "Saving: 200000 to 201000 lines - shape =torch.Size([87304, 13])\n",
            "Saving: 201000 to 202000 lines - shape =torch.Size([97574, 13])\n",
            "Saving: 202000 to 203000 lines - shape =torch.Size([100351, 13])\n",
            "Saving: 203000 to 204000 lines - shape =torch.Size([105918, 13])\n",
            "Saving: 204000 to 205000 lines - shape =torch.Size([90943, 13])\n",
            "Saving: 205000 to 206000 lines - shape =torch.Size([99123, 13])\n",
            "Saving: 206000 to 207000 lines - shape =torch.Size([103027, 13])\n",
            "Saving: 207000 to 208000 lines - shape =torch.Size([91710, 13])\n",
            "Saving: 208000 to 209000 lines - shape =torch.Size([111677, 13])\n",
            "Saving: 209000 to 210000 lines - shape =torch.Size([102317, 13])\n",
            "Saving: 210000 to 211000 lines - shape =torch.Size([110059, 13])\n",
            "Saving: 211000 to 212000 lines - shape =torch.Size([97035, 13])\n",
            "Saving: 212000 to 213000 lines - shape =torch.Size([106323, 13])\n",
            "Saving: 213000 to 214000 lines - shape =torch.Size([108791, 13])\n",
            "Saving: 214000 to 215000 lines - shape =torch.Size([119723, 13])\n",
            "Saving: 215000 to 216000 lines - shape =torch.Size([99168, 13])\n",
            "Saving: 216000 to 217000 lines - shape =torch.Size([93127, 13])\n",
            "Saving: 217000 to 218000 lines - shape =torch.Size([95305, 13])\n",
            "Saving: 218000 to 219000 lines - shape =torch.Size([93054, 13])\n",
            "Saving: 219000 to 220000 lines - shape =torch.Size([89709, 13])\n",
            "Saving: 220000 to 221000 lines - shape =torch.Size([104003, 13])\n",
            "Saving: 221000 to 222000 lines - shape =torch.Size([103370, 13])\n",
            "Saving: 222000 to 223000 lines - shape =torch.Size([97385, 13])\n",
            "Saving: 223000 to 224000 lines - shape =torch.Size([97161, 13])\n",
            "Saving: 224000 to 225000 lines - shape =torch.Size([111733, 13])\n",
            "Saving: 225000 to 226000 lines - shape =torch.Size([105174, 13])\n",
            "Saving: 226000 to 227000 lines - shape =torch.Size([94816, 13])\n",
            "Saving: 227000 to 228000 lines - shape =torch.Size([119445, 13])\n",
            "Saving: 228000 to 229000 lines - shape =torch.Size([124400, 13])\n",
            "Saving: 229000 to 230000 lines - shape =torch.Size([98765, 13])\n",
            "Saving: 230000 to 231000 lines - shape =torch.Size([105138, 13])\n",
            "Saving: 231000 to 232000 lines - shape =torch.Size([98053, 13])\n",
            "Saving: 232000 to 233000 lines - shape =torch.Size([107035, 13])\n",
            "Saving: 233000 to 234000 lines - shape =torch.Size([119358, 13])\n",
            "Saving: 234000 to 235000 lines - shape =torch.Size([102410, 13])\n",
            "Saving: 235000 to 236000 lines - shape =torch.Size([108680, 13])\n",
            "Saving: 236000 to 237000 lines - shape =torch.Size([98393, 13])\n",
            "Saving: 237000 to 238000 lines - shape =torch.Size([107531, 13])\n",
            "Saving: 238000 to 239000 lines - shape =torch.Size([109250, 13])\n",
            "Saving: 239000 to 240000 lines - shape =torch.Size([99523, 13])\n",
            "Saving: 240000 to 241000 lines - shape =torch.Size([98978, 13])\n",
            "Saving: 241000 to 242000 lines - shape =torch.Size([112253, 13])\n",
            "Saving: 242000 to 243000 lines - shape =torch.Size([104124, 13])\n",
            "Saving: 243000 to 244000 lines - shape =torch.Size([107367, 13])\n",
            "Saving: 244000 to 245000 lines - shape =torch.Size([107235, 13])\n",
            "Saving: 245000 to 246000 lines - shape =torch.Size([91178, 13])\n",
            "Saving: 246000 to 247000 lines - shape =torch.Size([89485, 13])\n",
            "Saving: 247000 to 248000 lines - shape =torch.Size([92529, 13])\n",
            "Saving: 248000 to 249000 lines - shape =torch.Size([97733, 13])\n",
            "Saving: 249000 to 250000 lines - shape =torch.Size([68340, 13])\n",
            "Don't need to stack tensor\n",
            "Saving: 0 to 100 lines - shape =torch.Size([12081, 13])\n",
            "Don't need to stack tensor\n",
            "Saving: 0 to 100 lines - shape =torch.Size([6803, 13])\n",
            "Don't need to stack tensor\n"
          ]
        }
      ],
      "source": [
        "# Load datasets\n",
        "max_seq_length = 12\n",
        "\n",
        "train_examples = 500\n",
        "valid_examples = 100\n",
        "test_examples = 100\n",
        "\n",
        "texts = open('sample-1gb.txt').readlines()\n",
        "\n",
        "print(f'Read {len(texts)} lines.')\n",
        "\n",
        "#max_lines = train_examples + valid_examples + test_examples\n",
        "#print(f'Truncating to {max_lines} lines.')\n",
        "#texts = texts[:max_lines]  \n",
        "\n",
        "training_texts = texts[:-(valid_examples + test_examples)]\n",
        "valid_texts = texts[-(valid_examples + test_examples):-test_examples]\n",
        "test_texts = texts[-test_examples:]\n",
        "\n",
        "folder_save=\"dataset_04/\"\n",
        "training_dataset = MyDataset(texts=training_texts, tokenizer=tokenizer, max_seq_length=max_seq_length, folder_name=folder_save)\n",
        "valid_dataset = MyDataset(texts=valid_texts, tokenizer=tokenizer, max_seq_length=max_seq_length, folder_name=folder_save, data_type=\"val\", iter_texts=100)\n",
        "test_dataset = MyDataset(texts=test_texts, tokenizer=tokenizer, max_seq_length=max_seq_length, folder_name=folder_save, data_type=\"test\", iter_texts=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carregando Dataset salvo na pasta do Drive"
      ],
      "metadata": {
        "id": "t7EfB_n7PqhW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f89b960d-6154-41f6-ac3e-c83564c59ae1",
        "id": "QSvbquSu8272"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read 250000 lines.\n",
            "0 to 1000 lines loaded\n",
            "1000 to 2000 lines loaded\n",
            "2000 to 3000 lines loaded\n",
            "3000 to 4000 lines loaded\n",
            "4000 to 5000 lines loaded\n",
            "5000 to 6000 lines loaded\n",
            "6000 to 7000 lines loaded\n",
            "7000 to 8000 lines loaded\n",
            "8000 to 9000 lines loaded\n",
            "9000 to 10000 lines loaded\n",
            "10000 to 11000 lines loaded\n",
            "11000 to 12000 lines loaded\n",
            "12000 to 13000 lines loaded\n",
            "13000 to 14000 lines loaded\n",
            "14000 to 15000 lines loaded\n",
            "15000 to 16000 lines loaded\n",
            "16000 to 17000 lines loaded\n",
            "17000 to 18000 lines loaded\n",
            "18000 to 19000 lines loaded\n",
            "19000 to 20000 lines loaded\n",
            "20000 to 21000 lines loaded\n",
            "21000 to 22000 lines loaded\n",
            "22000 to 23000 lines loaded\n",
            "23000 to 24000 lines loaded\n",
            "24000 to 25000 lines loaded\n",
            "25000 to 26000 lines loaded\n",
            "26000 to 27000 lines loaded\n",
            "27000 to 28000 lines loaded\n",
            "28000 to 29000 lines loaded\n",
            "29000 to 30000 lines loaded\n",
            "30000 to 31000 lines loaded\n",
            "31000 to 32000 lines loaded\n",
            "32000 to 33000 lines loaded\n",
            "33000 to 34000 lines loaded\n",
            "34000 to 35000 lines loaded\n",
            "35000 to 36000 lines loaded\n",
            "36000 to 37000 lines loaded\n",
            "37000 to 38000 lines loaded\n",
            "38000 to 39000 lines loaded\n",
            "39000 to 40000 lines loaded\n",
            "40000 to 41000 lines loaded\n",
            "41000 to 42000 lines loaded\n",
            "42000 to 43000 lines loaded\n",
            "43000 to 44000 lines loaded\n",
            "44000 to 45000 lines loaded\n",
            "45000 to 46000 lines loaded\n",
            "46000 to 47000 lines loaded\n",
            "47000 to 48000 lines loaded\n",
            "48000 to 49000 lines loaded\n",
            "49000 to 50000 lines loaded\n",
            "50000 to 51000 lines loaded\n",
            "51000 to 52000 lines loaded\n",
            "52000 to 53000 lines loaded\n",
            "53000 to 54000 lines loaded\n",
            "54000 to 55000 lines loaded\n",
            "55000 to 56000 lines loaded\n",
            "56000 to 57000 lines loaded\n",
            "57000 to 58000 lines loaded\n",
            "58000 to 59000 lines loaded\n",
            "59000 to 60000 lines loaded\n",
            "60000 to 61000 lines loaded\n",
            "61000 to 62000 lines loaded\n",
            "62000 to 63000 lines loaded\n",
            "63000 to 64000 lines loaded\n",
            "64000 to 65000 lines loaded\n",
            "65000 to 66000 lines loaded\n",
            "66000 to 67000 lines loaded\n",
            "67000 to 68000 lines loaded\n",
            "68000 to 69000 lines loaded\n",
            "69000 to 70000 lines loaded\n",
            "70000 to 71000 lines loaded\n",
            "71000 to 72000 lines loaded\n",
            "72000 to 73000 lines loaded\n",
            "73000 to 74000 lines loaded\n",
            "74000 to 75000 lines loaded\n",
            "75000 to 76000 lines loaded\n",
            "76000 to 77000 lines loaded\n",
            "77000 to 78000 lines loaded\n",
            "78000 to 79000 lines loaded\n",
            "79000 to 80000 lines loaded\n",
            "80000 to 81000 lines loaded\n",
            "81000 to 82000 lines loaded\n",
            "82000 to 83000 lines loaded\n",
            "83000 to 84000 lines loaded\n",
            "84000 to 85000 lines loaded\n",
            "85000 to 86000 lines loaded\n",
            "86000 to 87000 lines loaded\n",
            "87000 to 88000 lines loaded\n",
            "88000 to 89000 lines loaded\n",
            "89000 to 90000 lines loaded\n",
            "90000 to 91000 lines loaded\n",
            "91000 to 92000 lines loaded\n",
            "92000 to 93000 lines loaded\n",
            "93000 to 94000 lines loaded\n",
            "94000 to 95000 lines loaded\n",
            "95000 to 96000 lines loaded\n",
            "96000 to 97000 lines loaded\n",
            "97000 to 98000 lines loaded\n",
            "98000 to 99000 lines loaded\n",
            "99000 to 100000 lines loaded\n",
            "100000 to 101000 lines loaded\n",
            "101000 to 102000 lines loaded\n",
            "102000 to 103000 lines loaded\n",
            "103000 to 104000 lines loaded\n",
            "104000 to 105000 lines loaded\n",
            "105000 to 106000 lines loaded\n",
            "106000 to 107000 lines loaded\n",
            "107000 to 108000 lines loaded\n",
            "108000 to 109000 lines loaded\n",
            "109000 to 110000 lines loaded\n",
            "110000 to 111000 lines loaded\n",
            "111000 to 112000 lines loaded\n",
            "112000 to 113000 lines loaded\n",
            "113000 to 114000 lines loaded\n",
            "114000 to 115000 lines loaded\n",
            "115000 to 116000 lines loaded\n",
            "116000 to 117000 lines loaded\n",
            "117000 to 118000 lines loaded\n",
            "118000 to 119000 lines loaded\n",
            "119000 to 120000 lines loaded\n",
            "120000 to 121000 lines loaded\n",
            "121000 to 122000 lines loaded\n",
            "122000 to 123000 lines loaded\n",
            "123000 to 124000 lines loaded\n",
            "124000 to 125000 lines loaded\n",
            "125000 to 126000 lines loaded\n",
            "126000 to 127000 lines loaded\n",
            "127000 to 128000 lines loaded\n",
            "128000 to 129000 lines loaded\n",
            "129000 to 130000 lines loaded\n",
            "130000 to 131000 lines loaded\n",
            "131000 to 132000 lines loaded\n",
            "132000 to 133000 lines loaded\n",
            "133000 to 134000 lines loaded\n",
            "134000 to 135000 lines loaded\n",
            "135000 to 136000 lines loaded\n",
            "136000 to 137000 lines loaded\n",
            "137000 to 138000 lines loaded\n",
            "138000 to 139000 lines loaded\n",
            "139000 to 140000 lines loaded\n",
            "140000 to 141000 lines loaded\n",
            "141000 to 142000 lines loaded\n",
            "142000 to 143000 lines loaded\n",
            "143000 to 144000 lines loaded\n",
            "144000 to 145000 lines loaded\n",
            "145000 to 146000 lines loaded\n",
            "146000 to 147000 lines loaded\n",
            "147000 to 148000 lines loaded\n",
            "148000 to 149000 lines loaded\n",
            "149000 to 150000 lines loaded\n",
            "150000 to 151000 lines loaded\n",
            "151000 to 152000 lines loaded\n",
            "152000 to 153000 lines loaded\n",
            "153000 to 154000 lines loaded\n",
            "154000 to 155000 lines loaded\n",
            "155000 to 156000 lines loaded\n",
            "156000 to 157000 lines loaded\n",
            "157000 to 158000 lines loaded\n",
            "158000 to 159000 lines loaded\n",
            "159000 to 160000 lines loaded\n",
            "160000 to 161000 lines loaded\n",
            "161000 to 162000 lines loaded\n",
            "162000 to 163000 lines loaded\n",
            "163000 to 164000 lines loaded\n",
            "164000 to 165000 lines loaded\n",
            "165000 to 166000 lines loaded\n",
            "166000 to 167000 lines loaded\n",
            "167000 to 168000 lines loaded\n",
            "168000 to 169000 lines loaded\n",
            "169000 to 170000 lines loaded\n",
            "170000 to 171000 lines loaded\n",
            "171000 to 172000 lines loaded\n",
            "172000 to 173000 lines loaded\n",
            "173000 to 174000 lines loaded\n",
            "174000 to 175000 lines loaded\n",
            "175000 to 176000 lines loaded\n",
            "176000 to 177000 lines loaded\n",
            "177000 to 178000 lines loaded\n",
            "178000 to 179000 lines loaded\n",
            "179000 to 180000 lines loaded\n",
            "180000 to 181000 lines loaded\n",
            "181000 to 182000 lines loaded\n",
            "182000 to 183000 lines loaded\n",
            "183000 to 184000 lines loaded\n",
            "184000 to 185000 lines loaded\n",
            "185000 to 186000 lines loaded\n",
            "186000 to 187000 lines loaded\n",
            "187000 to 188000 lines loaded\n",
            "188000 to 189000 lines loaded\n",
            "189000 to 190000 lines loaded\n",
            "190000 to 191000 lines loaded\n",
            "191000 to 192000 lines loaded\n",
            "192000 to 193000 lines loaded\n",
            "193000 to 194000 lines loaded\n",
            "194000 to 195000 lines loaded\n",
            "195000 to 196000 lines loaded\n",
            "196000 to 197000 lines loaded\n",
            "197000 to 198000 lines loaded\n",
            "198000 to 199000 lines loaded\n",
            "199000 to 200000 lines loaded\n",
            "200000 to 201000 lines loaded\n",
            "201000 to 202000 lines loaded\n",
            "202000 to 203000 lines loaded\n",
            "203000 to 204000 lines loaded\n",
            "204000 to 205000 lines loaded\n",
            "205000 to 206000 lines loaded\n",
            "206000 to 207000 lines loaded\n",
            "207000 to 208000 lines loaded\n",
            "208000 to 209000 lines loaded\n",
            "209000 to 210000 lines loaded\n",
            "210000 to 211000 lines loaded\n",
            "211000 to 212000 lines loaded\n",
            "212000 to 213000 lines loaded\n",
            "213000 to 214000 lines loaded\n",
            "214000 to 215000 lines loaded\n",
            "215000 to 216000 lines loaded\n",
            "216000 to 217000 lines loaded\n",
            "217000 to 218000 lines loaded\n",
            "218000 to 219000 lines loaded\n",
            "219000 to 220000 lines loaded\n",
            "220000 to 221000 lines loaded\n",
            "221000 to 222000 lines loaded\n",
            "222000 to 223000 lines loaded\n",
            "223000 to 224000 lines loaded\n",
            "224000 to 225000 lines loaded\n",
            "225000 to 226000 lines loaded\n",
            "226000 to 227000 lines loaded\n",
            "227000 to 228000 lines loaded\n",
            "228000 to 229000 lines loaded\n",
            "229000 to 230000 lines loaded\n",
            "230000 to 231000 lines loaded\n",
            "231000 to 232000 lines loaded\n",
            "232000 to 233000 lines loaded\n",
            "233000 to 234000 lines loaded\n",
            "234000 to 235000 lines loaded\n",
            "235000 to 236000 lines loaded\n",
            "236000 to 237000 lines loaded\n",
            "237000 to 238000 lines loaded\n",
            "238000 to 239000 lines loaded\n",
            "239000 to 240000 lines loaded\n",
            "240000 to 241000 lines loaded\n",
            "241000 to 242000 lines loaded\n",
            "242000 to 243000 lines loaded\n",
            "243000 to 244000 lines loaded\n",
            "244000 to 245000 lines loaded\n",
            "245000 to 246000 lines loaded\n",
            "246000 to 247000 lines loaded\n",
            "247000 to 248000 lines loaded\n",
            "248000 to 249000 lines loaded\n",
            "249000 to 250000 lines loaded\n",
            "0 to 100 lines loaded\n",
            "0 to 100 lines loaded\n"
          ]
        }
      ],
      "source": [
        "# Load datasets\n",
        "max_seq_length = 12\n",
        "\n",
        "train_examples = 500\n",
        "valid_examples = 100\n",
        "test_examples = 100\n",
        "\n",
        "texts = open('sample-1gb.txt').readlines()\n",
        "\n",
        "print(f'Read {len(texts)} lines.')\n",
        "\n",
        "#max_lines = train_examples + valid_examples + test_examples\n",
        "#print(f'Truncating to {max_lines} lines.')\n",
        "#texts = texts[:max_lines]  \n",
        "\n",
        "training_texts = texts[:-(valid_examples + test_examples)]\n",
        "valid_texts = texts[-(valid_examples + test_examples):-test_examples]\n",
        "test_texts = texts[-test_examples:]\n",
        "\n",
        "folder_save=\"dataset_04/\"\n",
        "training_dataset = MyDataset(texts=training_texts, tokenizer=tokenizer, max_seq_length=max_seq_length, folder_name=folder_save)\n",
        "valid_dataset = MyDataset(texts=valid_texts, tokenizer=tokenizer, max_seq_length=max_seq_length, folder_name=folder_save, data_type=\"val\", iter_texts=100)\n",
        "test_dataset = MyDataset(texts=test_texts, tokenizer=tokenizer, max_seq_length=max_seq_length, folder_name=folder_save, data_type=\"test\", iter_texts=100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaLXR51JBhco",
        "outputId": "b51c1c84-1e2e-4122-e6d7-be42806b69ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([  101, 20100,  2308,  3074,  1089,   481,   117,   146,  1189,   125,\n",
              "         13254,   143]),\n",
              " tensor([20100,  2308,  3074,  1089,   481,   117,   146,  1189,   125, 13254,\n",
              "           143,   122]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCSGJ5m7py4c",
        "outputId": "d64e6cfe-9215-4960-aec6-0a1b1a62f8b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training examples: 25515683\n",
            "valid examples: 12081\n",
            "test examples: 6803\n"
          ]
        }
      ],
      "source": [
        "print(f'training examples: {len(training_dataset)}')\n",
        "print(f'valid examples: {len(valid_dataset)}')\n",
        "print(f'test examples: {len(test_dataset)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Arquitetura do modelo"
      ],
      "metadata": {
        "id": "WgdO2IM8hpmS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkJ_XyI5t1Y0"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(torch.nn.Module):\n",
        "    def __init__(self, dim: int, n_heads: int):\n",
        "        \"\"\"\n",
        "        Implements the Multi-Head Self-attention.\"\n",
        "\n",
        "        Args:on.\n",
        "            dim (int): Dimension of the embedding layer for each word in the context.\n",
        "            n_heads (int): number of heads.\n",
        "            mask(bool): if applies mask or not\n",
        "        \"\"\"\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        \n",
        "        self.dim = dim\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "        self.W_q = nn.Linear(dim, dim, bias = False)    # shape = (D, D)\n",
        "        self.W_k = nn.Linear(dim, dim, bias = False)    # shape = (D, D)   \n",
        "        self.W_v = nn.Linear(dim, dim, bias = False)    # shape = (D, D)\n",
        "        self.W_o = nn.Linear(dim, dim, bias = False)    # shape = (D, D)\n",
        "\n",
        "    def attention(self, q, k, v, mask=None):\n",
        "        scores = torch.bmm(q, k.transpose(1,2)) #shape: (B*H, L, D/H) * (B*H, D/H, L) = (B*H, L, L)\n",
        "        scores = scores/math.sqrt(self.dim) # scale by 1/sqrt(D)\n",
        "\n",
        "        if mask is not None:\n",
        "            # retornando escores para o shape (B, H, L, L) para aplicar a mascara\n",
        "            scores = scores.view(self.batch_size, self.n_heads, self.context_size, self.context_size).masked_fill(mask == 0, float('-inf'))\n",
        "            scores = scores.view(self.batch_size*self.n_heads, self.context_size, self.context_size)\n",
        "\n",
        "        # retornando escores para o shape (B*H, L, L) para seguir os cálculos\n",
        "        \n",
        "        probs = torch.nn.functional.softmax(scores, dim=-1) # shape:   (B*H, L, L)\n",
        "        out = torch.bmm(probs, v).view(self.batch_size, self.n_heads, self.context_size, int(self.dim/self.n_heads)) # shape:   (B, H, L, D/H)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def forward(self, inputs, mask):\n",
        "        self.batch_size = inputs.shape[0]   # shape = B\n",
        "        self.context_size = inputs.shape[1] # shape = L\n",
        "\n",
        "        q = self.W_q(inputs).reshape(self.batch_size, self.context_size, self.n_heads, self.dim//self.n_heads)  # shape = (B, L, H, D/H)\n",
        "        k = self.W_k(inputs).reshape(self.batch_size, self.context_size, self.n_heads, self.dim//self.n_heads)  # shape = (B, L, H, D/H)\n",
        "        v = self.W_v(inputs).reshape(self.batch_size, self.context_size, self.n_heads, self.dim//self.n_heads)  # shape = (B, L, H, D/H)\n",
        "\n",
        "        # Changing shapes for: (B, H, L, D/H)\n",
        "        q = q.transpose(1,2).contiguous().view(int(self.batch_size*self.n_heads), self.context_size, self.dim//self.n_heads) # shape = (B*H, L, D/H) \n",
        "        k = k.transpose(1,2).contiguous().view(int(self.batch_size*self.n_heads), self.context_size, self.dim//self.n_heads) # shape = (B*H, L, D/H) \n",
        "        v = v.transpose(1,2).contiguous().view(int(self.batch_size*self.n_heads), self.context_size, self.dim//self.n_heads) # shape = (B*H, L, D/H) \n",
        "\n",
        "        E = self.attention(q, k, v, mask)  # shape = (B, H, L, D/H)\n",
        "        E = E.transpose(1,2).contiguous() # shape = (B, L, H, D/H)\n",
        "        \n",
        "        E = E.reshape(self.batch_size, self.context_size, self.dim) # shape = (B, L, D)\n",
        "\n",
        "        E = self.W_o(E)  # shape = (B, L, D)\n",
        "\n",
        "        return E"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(torch.nn.Module):\n",
        "    def __init__(self, dim: int, hid_dim: int):\n",
        "        \"\"\"\n",
        "        Implements the Multi-Head Self-attention.\"\n",
        "\n",
        "        Args:on.\n",
        "            dim (int): Dimension of the embedding layer for each word in the context.\n",
        "            hid_dim (int): dimension of the hidden layer\n",
        "        \"\"\"\n",
        "        super(FeedForward, self).__init__()\n",
        "        \n",
        "        self.dim = dim\n",
        "        self.hid_dim = hid_dim\n",
        "\n",
        "        self.linear1 = nn.Linear(self.dim, hid_dim)\n",
        "        self.relu =  nn.ReLU()\n",
        "        self.linear2 =  nn.Linear(hid_dim, self.dim)\n",
        "        self.drop =  nn.Dropout(p=0.1)\n",
        "        \n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        out = self.relu(self.linear1(inputs))\n",
        "        out = self.drop(self.linear2(out))\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "lfK-4dTRce8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerDecoder(torch.nn.Module):\n",
        "    def __init__(self, dim: int, hid_dim: int, n_heads: int):\n",
        "        \"\"\"\n",
        "        Implements the Multi-Head Self-attention.\"\n",
        "\n",
        "        Args:on.\n",
        "            dim (int): Dimension of the embedding layer for each word in the context.\n",
        "            hid_dim (int): dimension of the hidden layer\n",
        "            drop_rate (float): rate of the dropout to apply\n",
        "        \"\"\"\n",
        "        super(LayerDecoder, self).__init__()\n",
        "        \n",
        "        self.dim = dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "\n",
        "        self.multihead_attention = MultiHeadAttention(self.dim, self.n_heads)\n",
        "        self.feedforward = FeedForward(self.dim, self.hid_dim)\n",
        "        self.drop =  nn.Dropout(p=0.1)\n",
        "\n",
        "        # Layer Norms\n",
        "        self.layer_norm1 = nn.LayerNorm(self.dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(self.dim)\n",
        "\n",
        "    def forward(self, inputs, mask=None):\n",
        "\n",
        "        # Multi Head Attention Block\n",
        "        out = self.multihead_attention(inputs, mask)\n",
        "        out = self.drop(out)\n",
        "        out = self.layer_norm1(out+inputs)\n",
        "\n",
        "        # Feed Forward Block\n",
        "        out_ff = self.feedforward(out)\n",
        "        out_ff = self.layer_norm2(out_ff+out)\n",
        "\n",
        "        return out_ff"
      ],
      "metadata": {
        "id": "2P6NpzyPelEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGaAjYDfWdd1"
      },
      "outputs": [],
      "source": [
        "class LanguageModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size: int, max_seq_length: int, dim: int, n_layers: int, pad_token_id: int):\n",
        "        \"\"\"\n",
        "        Implements the Self-attention, decoder-only.\"\n",
        "\n",
        "        Args:\n",
        "            vocab_size (int): Size of the input vocabulary.\n",
        "            max_seq_length (int): Size of the sequence to consider as context for prediction.\n",
        "            dim (int): Dimension of the embedding layer for each word in the context.\n",
        "            n_layers (int): number of self-attention layers.\n",
        "            pad_token_id (int): id of the pad token that will be ignored in the attention.\n",
        "        \"\"\"\n",
        "        super(LanguageModel, self).__init__()\n",
        "\n",
        "        self.context_size = max_seq_length\n",
        "        self.dim = dim\n",
        "        self.n_heads = 4\n",
        "        self.hidden_dim = 2*self.dim\n",
        "        self.pad_token_id = pad_token_id\n",
        "\n",
        "        # Embedding of the words\n",
        "        self.embeddings_C = nn.Embedding(vocab_size, self.dim, padding_idx=self.pad_token_id)\n",
        "\n",
        "        # Embedding of the words positions\n",
        "        self.embeddings_P = nn.Embedding(self.context_size, self.dim)\n",
        "\n",
        "        # Causal Mask\n",
        "        self.causal_mask = torch.tril(torch.ones((self.context_size, self.context_size))).bool().to(device) # shape: (L, L)\n",
        "        \n",
        "        # Applying n_layers of the DecoderLayer\n",
        "        self.layers_decoder = nn.ModuleList([\n",
        "            LayerDecoder(self.dim, self.hidden_dim, self.n_heads)\n",
        "            for _ in range(n_layers)])\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "\n",
        "        # Output layer\n",
        "        self.dense = nn.Linear(self.dim, vocab_size, bias = False)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            inputs is a LongTensor of shape (batch_size, max_seq_length)\n",
        "            \n",
        "        Returns:\n",
        "            logits of shape (batch_size, max_seq_length, vocab_size)\n",
        "        \"\"\"\n",
        "        embeds = self.embeddings_C(inputs) # embeds shape: (B, L, D)\n",
        "        # self.embeddings_P.weight shape: (L, D)\n",
        "\n",
        "        X = embeds + self.embeddings_P.weight # X shape: (B, L, D) \n",
        "        X = self.dropout(X)\n",
        "\n",
        "        pad_mask = (inputs != self.pad_token_id).unsqueeze(1).unsqueeze(2) # shape: (B, 1, 1,  L)\n",
        "        \n",
        "        mask_padc = pad_mask & self.causal_mask  # (B, 1, L, L)\n",
        "\n",
        "        for layer in self.layers_decoder:\n",
        "            # X shape: (B, L, D)\n",
        "            X = layer(X, mask = mask_padc)\n",
        "        \n",
        "        logits = self.dense(X) # logits shape: (B, L, V)\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo da criação da máscara de padding e \"no peak\":"
      ],
      "metadata": {
        "id": "1kUBvcY0CZvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.tril(torch.ones((9, 9))).bool()\n",
        "t1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8fb5058-921e-46ce-fad8-514a248147dd",
        "id": "_L8joQOekRfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ True, False, False, False, False, False, False, False, False],\n",
              "        [ True,  True, False, False, False, False, False, False, False],\n",
              "        [ True,  True,  True, False, False, False, False, False, False],\n",
              "        [ True,  True,  True,  True, False, False, False, False, False],\n",
              "        [ True,  True,  True,  True,  True, False, False, False, False],\n",
              "        [ True,  True,  True,  True,  True,  True, False, False, False],\n",
              "        [ True,  True,  True,  True,  True,  True,  True, False, False],\n",
              "        [ True,  True,  True,  True,  True,  True,  True,  True, False],\n",
              "        [ True,  True,  True,  True,  True,  True,  True,  True,  True]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t2 = torch.tensor([[True, True, True, True, True, True, False, False, False],\n",
        "                  [True, True, True, True, True, True, True, True, True],\n",
        "                  [True, True, True, True, True, True, True, True, False], \n",
        "                  [True, True, True, True, True, True, True, False, False],\n",
        "                  [True, True, True, True, False, False,False, False, False]]).unsqueeze(1).unsqueeze(2)\n",
        "t2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsyNjvZOkSlz",
        "outputId": "c26fb9ab-035a-49db-ccb3-c93147c0b0fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ True,  True,  True,  True,  True,  True, False, False, False]]],\n",
              "\n",
              "\n",
              "        [[[ True,  True,  True,  True,  True,  True,  True,  True,  True]]],\n",
              "\n",
              "\n",
              "        [[[ True,  True,  True,  True,  True,  True,  True,  True, False]]],\n",
              "\n",
              "\n",
              "        [[[ True,  True,  True,  True,  True,  True,  True, False, False]]],\n",
              "\n",
              "\n",
              "        [[[ True,  True,  True,  True, False, False, False, False, False]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8n8qwIIlH3E",
        "outputId": "b3b205a7-9a55-49cf-8c2d-1e610fc1e5a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([9, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_ry16dClI9s",
        "outputId": "0d7bc0ac-7d88-44c7-a03a-54c6decbd200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 1, 1, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1_t2 = t1&t2"
      ],
      "metadata": {
        "id": "KBOqB9MBCvq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(t1_t2).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1l1T9sclKxT",
        "outputId": "eca28437-882b-4d91-e6f4-17c8e23032a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 1, 9, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rm6_PTH2i98e"
      },
      "source": [
        "## Teste o modelo com um exemplo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwnxfZlrZoT_",
        "outputId": "8880f728-3a62-4689-8137-311b543c4870"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_input.shape: torch.Size([5, 12])\n",
            "sample_output.shape: torch.Size([5, 12, 29794])\n"
          ]
        }
      ],
      "source": [
        "model = LanguageModel(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    max_seq_length=max_seq_length,\n",
        "    dim=512,\n",
        "    n_layers=2,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        ").to(device)\n",
        "\n",
        "sample_input, _ = next(iter(DataLoader(training_dataset, batch_size=5)))\n",
        "sample_input = sample_input.to(device)\n",
        "sample_output = model(sample_input)\n",
        "print(f'sample_input.shape: {sample_input.shape}')\n",
        "print(f'sample_output.shape: {sample_output.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3Vh6B-VkA01",
        "outputId": "e35a2ea3-e51e-4454-81b2-e3f7f9e737c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of model parameters: 34716672\n"
          ]
        }
      ],
      "source": [
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'Number of model parameters: {num_params}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nhbUVsYnVAp"
      },
      "source": [
        "## Assert da Perplexidade\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(123)\n",
        "np.random.seed(123)\n",
        "torch.manual_seed(123)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lB6tNEvb7WvZ",
        "outputId": "761825cf-8f4e-4361-b108-0ad7d11f2313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f7fc4d7d6b0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbMP8VAUncfX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e87b429f-a690-4059-ed6e-6fba3073ca33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my perplexity:              34018\n",
            "correct initial perplexity: 29794\n",
            "Passou o no assert da perplexidade\n"
          ]
        }
      ],
      "source": [
        "random.seed(123)\n",
        "np.random.seed(123)\n",
        "torch.manual_seed(123)\n",
        "\n",
        "\n",
        "def perplexity(logits, target, ignore_token_id: int):\n",
        "    \"\"\"\n",
        "    Computes the perplexity.\n",
        "\n",
        "    Args:\n",
        "        logits: a FloatTensor of shape (batch_size, seq_len, vocab_size)\n",
        "        target: a LongTensor of shape (batch_size, seq_len)\n",
        "\n",
        "    Returns:\n",
        "        A float corresponding to the perplexity\n",
        "    \"\"\"\n",
        "    logits = logits.reshape(-1, logits.shape[-1])\n",
        "    target = target.reshape(-1)\n",
        "    loss = nn.functional.cross_entropy(logits, target, reduction='mean', ignore_index=ignore_token_id)\n",
        "    return torch.exp(loss)\n",
        "\n",
        "\n",
        "n_examples = 1000\n",
        "\n",
        "train_input_ids, train_target_ids = next(iter(DataLoader(training_dataset, batch_size=n_examples)))\n",
        "train_input_ids = train_input_ids.to(device)\n",
        "train_target_ids = train_target_ids.to(device)\n",
        "\n",
        "logits = model(train_input_ids)\n",
        "\n",
        "my_perplexity = perplexity(logits=logits, target=train_target_ids, ignore_token_id=tokenizer.pad_token_id)\n",
        "\n",
        "print(f'my perplexity:              {int(my_perplexity)}')\n",
        "print(f'correct initial perplexity: {tokenizer.vocab_size}')\n",
        "\n",
        "assert math.isclose(my_perplexity, tokenizer.vocab_size, abs_tol=7000)\n",
        "print('Passou o no assert da perplexidade')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiJtrsqPnE_l"
      },
      "source": [
        "## Laço de Treinamento e Validação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97a6bfc2-efa0-440d-f14d-7f3205d20420",
        "id": "WEJSfGtCvxZI"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 steps; 0 examples so far; train ppl: 34451.10, valid ppl: 26226.82\n",
            "10000 steps; 10240000 examples so far; train ppl: 237.18, valid ppl: 180.02\n"
          ]
        }
      ],
      "source": [
        "max_examples = 150_000_000\n",
        "eval_every_steps = 10000\n",
        "lr = 3e-4\n",
        "compare=float('inf')\n",
        "\n",
        "model = LanguageModel(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    max_seq_length=max_seq_length,\n",
        "    dim=512,\n",
        "    n_layers=2,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        ").to(device)\n",
        "\n",
        "train_loader = DataLoader(training_dataset, batch_size=1024, shuffle=True, drop_last=True)\n",
        "validation_loader = DataLoader(valid_dataset, batch_size=1024)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "def train_step(input_ids, target_ids):\n",
        "    model.train()\n",
        "    model.zero_grad()\n",
        "    logits = model(input_ids)\n",
        "    logits = logits.reshape(-1, logits.shape[-1])\n",
        "    target_ids = target_ids.reshape(-1)\n",
        "    loss = nn.functional.cross_entropy(logits, target_ids, ignore_index=model.pad_token_id)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "def validation_step(input_ids, target_ids):\n",
        "    model.eval()\n",
        "    logits = model(input_ids)\n",
        "    logits = logits.reshape(-1, logits.shape[-1])\n",
        "    target_ids = target_ids.reshape(-1)\n",
        "    loss = nn.functional.cross_entropy(logits, target_ids, ignore_index=model.pad_token_id)\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "train_losses = []\n",
        "n_examples = 0\n",
        "step = 0\n",
        "while n_examples < max_examples:\n",
        "    for train_input_ids, train_target_ids in train_loader:\n",
        "        loss = train_step(train_input_ids.to(device), train_target_ids.to(device)) \n",
        "        train_losses.append(loss)\n",
        "        \n",
        "        if step % eval_every_steps == 0:\n",
        "            train_ppl = np.exp(np.average(train_losses))\n",
        "\n",
        "            with torch.no_grad():\n",
        "                valid_ppl = np.exp(np.average([\n",
        "                    validation_step(val_input_ids.to(device), val_target_ids.to(device))\n",
        "                    for val_input_ids, val_target_ids in validation_loader]))\n",
        "\n",
        "            if valid_ppl<compare:\n",
        "                compare=valid_ppl\n",
        "                torch.save(model, \"/content/gdrive/MyDrive/Colab Notebooks/modelos_Aula09/\"+\"model_v12.pt\")\n",
        "                with open(\"/content/gdrive/MyDrive/Colab Notebooks/modelos_Aula09/\"+\"valid_ppl_model_v12.txt\", 'w') as f:\n",
        "                    f.write(\"%s\\n\" % valid_ppl)\n",
        "                f.close()\n",
        "                \n",
        "            print(f'{step} steps; {n_examples} examples so far; train ppl: {train_ppl:.2f}, valid ppl: {valid_ppl:.2f}')\n",
        "            train_losses = []\n",
        "\n",
        "        n_examples += len(train_input_ids)  # Increment of batch size\n",
        "        step += 1\n",
        "        if n_examples >= max_examples:\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/gdrive/MyDrive/Colab Notebooks/modelos_Aula09/\"+\"valid_ppl_model_v12.txt\") as f:\n",
        "    txt = list(f)\n",
        "    compare = float(txt[-1])\n",
        "    f.close()\n"
      ],
      "metadata": {
        "id": "M1UDy0v9rWfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLZjV4i67_Pd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ced4c0a4-583e-4fa4-8b14-e2b0d6d396b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180.01938340763607\n",
            "0 steps; 0 examples so far; train ppl: 176.08, valid ppl: 180.94\n",
            "10000 steps; 10240000 examples so far; train ppl: 158.80, valid ppl: 160.14\n",
            "20000 steps; 20480000 examples so far; train ppl: 148.55, valid ppl: 150.26\n",
            "30000 steps; 30720000 examples so far; train ppl: 140.60, valid ppl: 144.65\n"
          ]
        }
      ],
      "source": [
        "max_examples = 150_000_000\n",
        "eval_every_steps = 10000\n",
        "lr = 3e-4\n",
        "print(compare)\n",
        "\n",
        "model = LanguageModel(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    max_seq_length=max_seq_length,\n",
        "    dim=512,\n",
        "    n_layers=2,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        ").to(device)\n",
        "\n",
        "\n",
        "model = torch.load(\"/content/gdrive/MyDrive/Colab Notebooks/modelos_Aula09/\"+\"model_v12.pt\")\n",
        "model.to(device)\n",
        "\n",
        "train_loader = DataLoader(training_dataset, batch_size=1024, shuffle=True, drop_last=True)\n",
        "validation_loader = DataLoader(valid_dataset, batch_size=1024)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "def train_step(input_ids, target_ids):\n",
        "    model.train()\n",
        "    model.zero_grad()\n",
        "    logits = model(input_ids)\n",
        "    logits = logits.reshape(-1, logits.shape[-1])\n",
        "    target_ids = target_ids.reshape(-1)\n",
        "    loss = nn.functional.cross_entropy(logits, target_ids, ignore_index=model.pad_token_id)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "def validation_step(input_ids, target_ids):\n",
        "    model.eval()\n",
        "    logits = model(input_ids)\n",
        "    logits = logits.reshape(-1, logits.shape[-1])\n",
        "    target_ids = target_ids.reshape(-1)\n",
        "    loss = nn.functional.cross_entropy(logits, target_ids, ignore_index=model.pad_token_id)\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "train_losses = []\n",
        "n_examples = 0\n",
        "step = 0\n",
        "while n_examples < max_examples:\n",
        "    for train_input_ids, train_target_ids in train_loader:\n",
        "        loss = train_step(train_input_ids.to(device), train_target_ids.to(device)) \n",
        "        train_losses.append(loss)\n",
        "        \n",
        "        if step % eval_every_steps == 0:\n",
        "            train_ppl = np.exp(np.average(train_losses))\n",
        "\n",
        "            with torch.no_grad():\n",
        "                valid_ppl = np.exp(np.average([\n",
        "                    validation_step(val_input_ids.to(device), val_target_ids.to(device))\n",
        "                    for val_input_ids, val_target_ids in validation_loader]))\n",
        "\n",
        "            if valid_ppl<compare:\n",
        "                compare=valid_ppl\n",
        "                torch.save(model, \"/content/gdrive/MyDrive/Colab Notebooks/modelos_Aula09/\"+\"model_v12_run02.pt\")\n",
        "                with open(\"/content/gdrive/MyDrive/Colab Notebooks/modelos_Aula09/\"+\"valid_ppl_model_v12_run02.txt\", 'w') as f:\n",
        "                    f.write(\"%s\\n\" % valid_ppl)\n",
        "                f.close()\n",
        "                \n",
        "            print(f'{step} steps; {n_examples} examples so far; train ppl: {train_ppl:.2f}, valid ppl: {valid_ppl:.2f}')\n",
        "            train_losses = []\n",
        "\n",
        "        n_examples += len(train_input_ids)  # Increment of batch size\n",
        "        step += 1\n",
        "        if n_examples >= max_examples:\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/gdrive/MyDrive/Colab Notebooks/modelos_Aula09/\"+\"valid_ppl_model_v12_run02.txt\") as f:\n",
        "    txt = list(f)\n",
        "    compare = float(txt[-1])\n",
        "    f.close()\n"
      ],
      "metadata": {
        "id": "U8UTKfuzauej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59af394e-de89-4099-eb0e-07cab4903c9c",
        "id": "yDgjjrl1auek"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "144.64617235144226\n",
            "0 steps; 0 examples so far; train ppl: 141.90, valid ppl: 144.98\n",
            "10000 steps; 10240000 examples so far; train ppl: 135.09, valid ppl: 141.29\n",
            "20000 steps; 20480000 examples so far; train ppl: 132.56, valid ppl: 138.56\n"
          ]
        }
      ],
      "source": [
        "max_examples = 150_000_000\n",
        "eval_every_steps = 10000\n",
        "lr = 3e-4\n",
        "print(compare)\n",
        "\n",
        "model = LanguageModel(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    max_seq_length=max_seq_length,\n",
        "    dim=512,\n",
        "    n_layers=2,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        ").to(device)\n",
        "\n",
        "\n",
        "model = torch.load(\"/content/gdrive/MyDrive/Colab Notebooks/modelos_Aula09/\"+\"model_v12_run02.pt\")\n",
        "model.to(device)\n",
        "\n",
        "train_loader = DataLoader(training_dataset, batch_size=1024, shuffle=True, drop_last=True)\n",
        "validation_loader = DataLoader(valid_dataset, batch_size=1024)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "def train_step(input_ids, target_ids):\n",
        "    model.train()\n",
        "    model.zero_grad()\n",
        "    logits = model(input_ids)\n",
        "    logits = logits.reshape(-1, logits.shape[-1])\n",
        "    target_ids = target_ids.reshape(-1)\n",
        "    loss = nn.functional.cross_entropy(logits, target_ids, ignore_index=model.pad_token_id)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "def validation_step(input_ids, target_ids):\n",
        "    model.eval()\n",
        "    logits = model(input_ids)\n",
        "    logits = logits.reshape(-1, logits.shape[-1])\n",
        "    target_ids = target_ids.reshape(-1)\n",
        "    loss = nn.functional.cross_entropy(logits, target_ids, ignore_index=model.pad_token_id)\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "train_losses = []\n",
        "n_examples = 0\n",
        "step = 0\n",
        "while n_examples < max_examples:\n",
        "    for train_input_ids, train_target_ids in train_loader:\n",
        "        loss = train_step(train_input_ids.to(device), train_target_ids.to(device)) \n",
        "        train_losses.append(loss)\n",
        "        \n",
        "        if step % eval_every_steps == 0:\n",
        "            train_ppl = np.exp(np.average(train_losses))\n",
        "\n",
        "            with torch.no_grad():\n",
        "                valid_ppl = np.exp(np.average([\n",
        "                    validation_step(val_input_ids.to(device), val_target_ids.to(device))\n",
        "                    for val_input_ids, val_target_ids in validation_loader]))\n",
        "\n",
        "            if valid_ppl<compare:\n",
        "                compare=valid_ppl\n",
        "                torch.save(model, \"/content/gdrive/MyDrive/Colab Notebooks/modelos_Aula09/\"+\"model_v12_run03.pt\")\n",
        "                with open(\"/content/gdrive/MyDrive/Colab Notebooks/modelos_Aula09/\"+\"valid_ppl_model_v12_run03.txt\", 'w') as f:\n",
        "                    f.write(\"%s\\n\" % valid_ppl)\n",
        "                f.close()\n",
        "                \n",
        "            print(f'{step} steps; {n_examples} examples so far; train ppl: {train_ppl:.2f}, valid ppl: {valid_ppl:.2f}')\n",
        "            train_losses = []\n",
        "\n",
        "        n_examples += len(train_input_ids)  # Increment of batch size\n",
        "        step += 1\n",
        "        if n_examples >= max_examples:\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgdNymJdNPXP"
      },
      "source": [
        "## Avaliação final no dataset de teste\n",
        "\n",
        "\n",
        "Bonus: o modelo com menor perplexidade no dataset de testes ganhará 0.5 ponto na nota final."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load(\"/content/gdrive/MyDrive/Colab Notebooks/modelos_Aula09/\"+\"model_v12_run03.pt\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5snrNfAeTVy",
        "outputId": "283836ab-f9bc-4828-9c17-4d2eceb77b0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageModel(\n",
              "  (embeddings_C): Embedding(29794, 512, padding_idx=0)\n",
              "  (embeddings_P): Embedding(12, 512)\n",
              "  (layers_decoder): ModuleList(\n",
              "    (0): LayerDecoder(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (W_k): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (W_v): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (W_o): Linear(in_features=512, out_features=512, bias=False)\n",
              "      )\n",
              "      (feedforward): FeedForward(\n",
              "        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
              "        (relu): ReLU()\n",
              "        (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
              "        (drop): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (drop): Dropout(p=0.1, inplace=False)\n",
              "      (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (1): LayerDecoder(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (W_k): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (W_v): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (W_o): Linear(in_features=512, out_features=512, bias=False)\n",
              "      )\n",
              "      (feedforward): FeedForward(\n",
              "        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
              "        (relu): ReLU()\n",
              "        (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
              "        (drop): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (drop): Dropout(p=0.1, inplace=False)\n",
              "      (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (dense): Linear(in_features=512, out_features=29794, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxN5YytzZ7Tn",
        "outputId": "ab07ee00-4242-454f-986d-4d39e15a4f86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test perplexity: 112.10454591695101\n"
          ]
        }
      ],
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "def validation_step(input_ids, target_ids):\n",
        "    model.eval()\n",
        "    logits = model(input_ids)\n",
        "    logits = logits.reshape(-1, logits.shape[-1])\n",
        "    target_ids = target_ids.reshape(-1)\n",
        "    loss = nn.functional.cross_entropy(logits, target_ids, ignore_index=model.pad_token_id)\n",
        "    return loss.item()\n",
        "    \n",
        "with torch.no_grad():\n",
        "    test_ppl = np.exp(np.average([\n",
        "        validation_step(test_input_ids.to(device), test_target_ids.to(device))\n",
        "        for test_input_ids, test_target_ids in test_loader\n",
        "    ]))\n",
        "\n",
        "print(f'test perplexity: {test_ppl}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHvEs8mPszy_"
      },
      "source": [
        "## Teste seu modelo com uma sentença\n",
        "\n",
        "Escolha uma sentença gerada pelo modelo que ache interessante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QQ-1x0ADpf9"
      },
      "outputs": [],
      "source": [
        "def tokenize(text: str, tokenizer):\n",
        "\n",
        "    return tokenizer.encode_plus(text, return_tensors=None, add_special_tokens= False).input_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CFElf4tsytW",
        "outputId": "7aeaee8b-dca8-49cc-a91b-88803a546793"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eu gosto de comer muita pizza aos domingos pois me faz a\n",
            "Eu gosto de comer muita pizza aos domingos pois me faz a diferença\n",
            "Eu gosto de comer muita pizza aos domingos pois me faz a diferença ser\n",
            "Eu gosto de comer muita pizza aos domingos pois me faz a diferença ser mais\n",
            "Eu gosto de comer muita pizza aos domingos pois me faz a diferença ser mais uma\n",
            "Eu gosto de comer muita pizza aos domingos pois me faz a diferença ser mais uma coisa\n",
            "Eu gosto de comer muita pizza aos domingos pois me faz a diferença ser mais uma coisa,\n",
            "Eu gosto de comer muita pizza aos domingos pois me faz a diferença ser mais uma coisa, mas\n",
            "Eu gosto de comer muita pizza aos domingos pois me faz a diferença ser mais uma coisa, mas não\n",
            "Eu gosto de comer muita pizza aos domingos pois me faz a diferença ser mais uma coisa, mas não é\n",
            "Eu gosto de comer muita pizza aos domingos pois me faz a diferença ser mais uma coisa, mas não é uma\n",
            "Eu gosto de comer muita pizza aos domingos pois me faz a diferença ser mais uma coisa, mas não é uma coisa\n",
            "Eu gosto de comer muita pizza aos domingos pois me faz a diferença ser mais uma coisa, mas não é uma coisa que\n",
            "Eu gosto de comer muita pizza aos domingos pois me faz a diferença ser mais uma coisa, mas não é uma coisa que eu\n",
            "Eu gosto de comer muita pizza aos domingos pois me faz a diferença ser mais uma coisa, mas não é uma coisa que eu quero\n",
            "Eu gosto de comer muita pizza aos domingos pois me faz a diferença ser mais uma coisa, mas não é uma coisa que eu quero fazer\n",
            "Eu gosto de comer muita pizza aos domingos pois me faz a diferença ser mais uma coisa, mas não é uma coisa que eu quero fazer,\n",
            "Eu gosto de comer muita pizza aos domingos pois me faz a diferença ser mais uma coisa, mas não é uma coisa que eu quero fazer, mas\n",
            "Eu gosto de comer muita pizza aos domingos pois me faz a diferença ser mais uma coisa, mas não é uma coisa que eu quero fazer, mas não\n",
            "Eu gosto de comer muita pizza aos domingos pois me faz a diferença ser mais uma coisa, mas não é uma coisa que eu quero fazer, mas não é\n"
          ]
        }
      ],
      "source": [
        "prompt = 'Eu gosto de comer muita pizza aos domingos pois me faz '\n",
        "max_output_tokens = 20\n",
        "model.eval()\n",
        "\n",
        "for _ in range(max_output_tokens):\n",
        "    input_ids = tokenize(text=prompt, tokenizer=tokenizer)\n",
        "    input_ids_truncated = input_ids[-max_seq_length:]  # Usamos apenas os últimos <max_seq_length> tokens como entrada para o modelo.\n",
        "    logits = model(torch.LongTensor([input_ids_truncated]).to(device))\n",
        "    logits = logits[:, -1, :]  # Usamos apenas o ultimo token da sequencia\n",
        "    # Ao usarmos o argmax, a saída do modelo em cada passo é o token de maior probabilidade.\n",
        "    # Isso se chama decodificação gulosa (greedy decoding).\n",
        "    predicted_id = torch.argmax(logits).item()\n",
        "    input_ids += [predicted_id]  # Concatenamos a entrada com o token escolhido nesse passo.\n",
        "    prompt = tokenizer.decode(input_ids)\n",
        "    print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2321397-1c3b-4d98-c6e6-95e5b3421295",
        "id": "2cfMjZS--fDg"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Temos que pensar no futuro e guardar o que aprendemos na prática\n",
            "Temos que pensar no futuro e guardar o que aprendemos na prática.\n",
            "Temos que pensar no futuro e guardar o que aprendemos na prática. O\n",
            "Temos que pensar no futuro e guardar o que aprendemos na prática. O que\n",
            "Temos que pensar no futuro e guardar o que aprendemos na prática. O que é\n",
            "Temos que pensar no futuro e guardar o que aprendemos na prática. O que é que\n",
            "Temos que pensar no futuro e guardar o que aprendemos na prática. O que é que o\n",
            "Temos que pensar no futuro e guardar o que aprendemos na prática. O que é que o homem\n",
            "Temos que pensar no futuro e guardar o que aprendemos na prática. O que é que o homem não\n",
            "Temos que pensar no futuro e guardar o que aprendemos na prática. O que é que o homem não tem\n",
            "Temos que pensar no futuro e guardar o que aprendemos na prática. O que é que o homem não tem a\n",
            "Temos que pensar no futuro e guardar o que aprendemos na prática. O que é que o homem não tem a ver\n",
            "Temos que pensar no futuro e guardar o que aprendemos na prática. O que é que o homem não tem a ver com\n",
            "Temos que pensar no futuro e guardar o que aprendemos na prática. O que é que o homem não tem a ver com o\n",
            "Temos que pensar no futuro e guardar o que aprendemos na prática. O que é que o homem não tem a ver com o que\n",
            "Temos que pensar no futuro e guardar o que aprendemos na prática. O que é que o homem não tem a ver com o que se\n",
            "Temos que pensar no futuro e guardar o que aprendemos na prática. O que é que o homem não tem a ver com o que se vê\n",
            "Temos que pensar no futuro e guardar o que aprendemos na prática. O que é que o homem não tem a ver com o que se vê é\n",
            "Temos que pensar no futuro e guardar o que aprendemos na prática. O que é que o homem não tem a ver com o que se vê é a\n",
            "Temos que pensar no futuro e guardar o que aprendemos na prática. O que é que o homem não tem a ver com o que se vê é a sua\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Temos que pensar no futuro e guardar o que aprendemos na\"\n",
        "max_output_tokens = 20\n",
        "model.eval()\n",
        "\n",
        "for _ in range(max_output_tokens):\n",
        "    input_ids = tokenize(text=prompt, tokenizer=tokenizer)\n",
        "    input_ids_truncated = input_ids[-max_seq_length:]  # Usamos apenas os últimos <max_seq_length> tokens como entrada para o modelo.\n",
        "    logits = model(torch.LongTensor([input_ids_truncated]).to(device))\n",
        "    logits = logits[:, -1, :]  # Usamos apenas o ultimo token da sequencia\n",
        "    # Ao usarmos o argmax, a saída do modelo em cada passo é o token de maior probabilidade.\n",
        "    # Isso se chama decodificação gulosa (greedy decoding).\n",
        "    predicted_id = torch.argmax(logits).item()\n",
        "    input_ids += [predicted_id]  # Concatenamos a entrada com o token escolhido nesse passo.\n",
        "    prompt = tokenizer.decode(input_ids)\n",
        "    print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"A exposição dos quadros da Tarsila do Amaral ocorreu na\"\n",
        "max_output_tokens = 20\n",
        "model.eval()\n",
        "\n",
        "for _ in range(max_output_tokens):\n",
        "    input_ids = tokenize(text=prompt, tokenizer=tokenizer)\n",
        "    input_ids_truncated = input_ids[-max_seq_length:]  # Usamos apenas os últimos <max_seq_length> tokens como entrada para o modelo.\n",
        "    logits = model(torch.LongTensor([input_ids_truncated]).to(device))\n",
        "    logits = logits[:, -1, :]  # Usamos apenas o ultimo token da sequencia\n",
        "    # Ao usarmos o argmax, a saída do modelo em cada passo é o token de maior probabilidade.\n",
        "    # Isso se chama decodificação gulosa (greedy decoding).\n",
        "    predicted_id = torch.argmax(logits).item()\n",
        "    input_ids += [predicted_id]  # Concatenamos a entrada com o token escolhido nesse passo.\n",
        "    prompt = tokenizer.decode(input_ids)\n",
        "    print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGa21ip-fEjG",
        "outputId": "a0791c3f-08e8-4be8-effa-dbced8b81c42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A exposição dos quadros da Tarsila do Amaral ocorreu na sexta\n",
            "A exposição dos quadros da Tarsila do Amaral ocorreu na sexta -\n",
            "A exposição dos quadros da Tarsila do Amaral ocorreu na sexta - feira\n",
            "A exposição dos quadros da Tarsila do Amaral ocorreu na sexta - feira,\n",
            "A exposição dos quadros da Tarsila do Amaral ocorreu na sexta - feira, o\n",
            "A exposição dos quadros da Tarsila do Amaral ocorreu na sexta - feira, o presidente\n",
            "A exposição dos quadros da Tarsila do Amaral ocorreu na sexta - feira, o presidente da\n",
            "A exposição dos quadros da Tarsila do Amaral ocorreu na sexta - feira, o presidente da Associação\n",
            "A exposição dos quadros da Tarsila do Amaral ocorreu na sexta - feira, o presidente da Associação dos\n",
            "A exposição dos quadros da Tarsila do Amaral ocorreu na sexta - feira, o presidente da Associação dos Mag\n",
            "A exposição dos quadros da Tarsila do Amaral ocorreu na sexta - feira, o presidente da Associação dos Magist\n",
            "A exposição dos quadros da Tarsila do Amaral ocorreu na sexta - feira, o presidente da Associação dos Magistrados\n",
            "A exposição dos quadros da Tarsila do Amaral ocorreu na sexta - feira, o presidente da Associação dos Magistrados de\n",
            "A exposição dos quadros da Tarsila do Amaral ocorreu na sexta - feira, o presidente da Associação dos Magistrados de São\n",
            "A exposição dos quadros da Tarsila do Amaral ocorreu na sexta - feira, o presidente da Associação dos Magistrados de São Paulo\n",
            "A exposição dos quadros da Tarsila do Amaral ocorreu na sexta - feira, o presidente da Associação dos Magistrados de São Paulo,\n",
            "A exposição dos quadros da Tarsila do Amaral ocorreu na sexta - feira, o presidente da Associação dos Magistrados de São Paulo, o\n",
            "A exposição dos quadros da Tarsila do Amaral ocorreu na sexta - feira, o presidente da Associação dos Magistrados de São Paulo, o que\n",
            "A exposição dos quadros da Tarsila do Amaral ocorreu na sexta - feira, o presidente da Associação dos Magistrados de São Paulo, o que é\n",
            "A exposição dos quadros da Tarsila do Amaral ocorreu na sexta - feira, o presidente da Associação dos Magistrados de São Paulo, o que é o\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aplicando modelo em textos do treino"
      ],
      "metadata": {
        "id": "NgdMhryTiTFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts[1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "feInz92-TE7h",
        "outputId": "6fb2ae57-4a9a-440d-d98e-f97a6ac0ec39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Palestra traz resultados de 10 anos de estudo sobre o tratamento da Esclerose Múltipla O Ciclo de Conferências do Instituto de Ciências Biológicas (ICB) Marc Jeannerod começa, nessa terça-feira, 6, trazendo como palestrantes, pesquisadores da UFJF cujos trabalhos se destacam pela excelência em suas respectivas áreas. Servindo como forma de divulgação e discussão do conhecimento, o evento — aberto a toda a comunidade acadêmica — oferece aos participantes uma oportunidade de se atualizarem em relação às principais pesquisas desenvolvidas na área. Com duração de 50 minutos, as conferências serão realizadas no Anfiteatro A do ICB, às 16h das primeiras terças-feiras de cada mês. Abrindo o Ciclo, a professora Ana Paula Ferreira irá tratar de seus trabalhos realizados na área da Imunologia, durante a palestra \"Mecanismos imunoregulatórios envolvidos na Encelafalomielite Autoimune Experimental\". Em sua fala, Ana Paula irá compartilhar os resultados obtidos ao longo de 10 anos de estudo sobre o tratamento da Esclerose Múltipla. Em sequência, no dia 04 de outubro, o professor Cláudio Galuppo Diniz conduzirá a apresentação \"Sexo, drogas e rock\\'n roll: o desafio da medicina no século XXI\". No dia 1º de novembro, a palestra \"Remodelamento cardíaco elétrico provocado pelo uso de esteroides anabólicos\" será ministrada pelo professor Moacir Marocolo Júnior . O encerramento do Ciclo, no dia 6 de dezembro, será marcado pela apresentação do professor Henrique Teixeira : \"30 anos de pesquisa: perguntas, agruras e resultados\".\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Palestra traz resultados de 10 anos de estudo sobre o tratamento\"\n",
        "max_output_tokens = 20\n",
        "model.eval()\n",
        "\n",
        "for _ in range(max_output_tokens):\n",
        "    input_ids = tokenize(text=prompt, tokenizer=tokenizer)\n",
        "    input_ids_truncated = input_ids[-max_seq_length:]  # Usamos apenas os últimos <max_seq_length> tokens como entrada para o modelo.\n",
        "    logits = model(torch.LongTensor([input_ids_truncated]).to(device))\n",
        "    logits = logits[:, -1, :]  # Usamos apenas o ultimo token da sequencia\n",
        "    # Ao usarmos o argmax, a saída do modelo em cada passo é o token de maior probabilidade.\n",
        "    # Isso se chama decodificação gulosa (greedy decoding).\n",
        "    predicted_id = torch.argmax(logits).item()\n",
        "    input_ids += [predicted_id]  # Concatenamos a entrada com o token escolhido nesse passo.\n",
        "    prompt = tokenizer.decode(input_ids)\n",
        "    print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZqamWClhzBG",
        "outputId": "1d8ef151-c03c-4513-be7b-47bcbfa23b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palestra traz resultados de 10 anos de estudo sobre o tratamento de\n",
            "Palestra traz resultados de 10 anos de estudo sobre o tratamento de um\n",
            "Palestra traz resultados de 10 anos de estudo sobre o tratamento de um paciente\n",
            "Palestra traz resultados de 10 anos de estudo sobre o tratamento de um paciente,\n",
            "Palestra traz resultados de 10 anos de estudo sobre o tratamento de um paciente, que\n",
            "Palestra traz resultados de 10 anos de estudo sobre o tratamento de um paciente, que é\n",
            "Palestra traz resultados de 10 anos de estudo sobre o tratamento de um paciente, que é a\n",
            "Palestra traz resultados de 10 anos de estudo sobre o tratamento de um paciente, que é a primeira\n",
            "Palestra traz resultados de 10 anos de estudo sobre o tratamento de um paciente, que é a primeira vez\n",
            "Palestra traz resultados de 10 anos de estudo sobre o tratamento de um paciente, que é a primeira vez que\n",
            "Palestra traz resultados de 10 anos de estudo sobre o tratamento de um paciente, que é a primeira vez que o\n",
            "Palestra traz resultados de 10 anos de estudo sobre o tratamento de um paciente, que é a primeira vez que o paciente\n",
            "Palestra traz resultados de 10 anos de estudo sobre o tratamento de um paciente, que é a primeira vez que o paciente se\n",
            "Palestra traz resultados de 10 anos de estudo sobre o tratamento de um paciente, que é a primeira vez que o paciente se sente\n",
            "Palestra traz resultados de 10 anos de estudo sobre o tratamento de um paciente, que é a primeira vez que o paciente se sente bem\n",
            "Palestra traz resultados de 10 anos de estudo sobre o tratamento de um paciente, que é a primeira vez que o paciente se sente bem,\n",
            "Palestra traz resultados de 10 anos de estudo sobre o tratamento de um paciente, que é a primeira vez que o paciente se sente bem, é\n",
            "Palestra traz resultados de 10 anos de estudo sobre o tratamento de um paciente, que é a primeira vez que o paciente se sente bem, é o\n",
            "Palestra traz resultados de 10 anos de estudo sobre o tratamento de um paciente, que é a primeira vez que o paciente se sente bem, é o que\n",
            "Palestra traz resultados de 10 anos de estudo sobre o tratamento de um paciente, que é a primeira vez que o paciente se sente bem, é o que se\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts[10000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "uNAu_iTMUHlf",
        "outputId": "3a73d970-e014-49b4-9f9f-6a6f6ab1506c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"Escrito por professores e profissionais da área de Alimentação Coletiva, o livro aborda os desafios enfrentados por nutricionistas no dia a dia. Na obra, ressalta-se a importância da aplicação de conceitos teóricos à realidade prática de uma Unidade Produtora de Refeições, termo aplicado a serviços de alimentação externo ao domicílio.Levando em conta a crescente demanda por esse tipo de serviço no País, Administração de Unidades Produtoras de Refeições: Desafios e Perspectivas discorre sobre algumas perspectivas para a área, como a aplicação de novas tecnologias no setor e a importância da ergonomia para a saúde do manipulador de alimentos. Abrange, ainda, temas relacionados com administração e planejamento dessas unidades, aplicação da técnica dietética, gastronomia, ergonomia e segurança no trabalho, gestão de resíduos, controle de custos, treinamentos e consultoria na área de alimentação coletiva. Assim, esta publicação traz novas contribuições para acadêmicos e profissionais ao aliar conteúdos teórico-práticos formulados por colaboradores com vivência na área.\"\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Escrito por professores e profissionais da área de Alimentação Coletiva, o livro aborda\"\n",
        "max_output_tokens = 20\n",
        "model.eval()\n",
        "\n",
        "for _ in range(max_output_tokens):\n",
        "    input_ids = tokenize(text=prompt, tokenizer=tokenizer)\n",
        "    input_ids_truncated = input_ids[-max_seq_length:]  # Usamos apenas os últimos <max_seq_length> tokens como entrada para o modelo.\n",
        "    logits = model(torch.LongTensor([input_ids_truncated]).to(device))\n",
        "    logits = logits[:, -1, :]  # Usamos apenas o ultimo token da sequencia\n",
        "    # Ao usarmos o argmax, a saída do modelo em cada passo é o token de maior probabilidade.\n",
        "    # Isso se chama decodificação gulosa (greedy decoding).\n",
        "    predicted_id = torch.argmax(logits).item()\n",
        "    input_ids += [predicted_id]  # Concatenamos a entrada com o token escolhido nesse passo.\n",
        "    prompt = tokenizer.decode(input_ids)\n",
        "    print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMQuYIiMi0u9",
        "outputId": "d73156f5-df29-42a5-af95-d61e171c72a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Escrito por professores e profissionais da área de Alimentação Coletiva, o livro aborda a\n",
            "Escrito por professores e profissionais da área de Alimentação Coletiva, o livro aborda a questão\n",
            "Escrito por professores e profissionais da área de Alimentação Coletiva, o livro aborda a questão da\n",
            "Escrito por professores e profissionais da área de Alimentação Coletiva, o livro aborda a questão da \"\n",
            "Escrito por professores e profissionais da área de Alimentação Coletiva, o livro aborda a questão da \" \"\n",
            "Escrito por professores e profissionais da área de Alimentação Coletiva, o livro aborda a questão da \" \" História\n",
            "Escrito por professores e profissionais da área de Alimentação Coletiva, o livro aborda a questão da \" \" História da\n",
            "Escrito por professores e profissionais da área de Alimentação Coletiva, o livro aborda a questão da \" \" História da Vida\n",
            "Escrito por professores e profissionais da área de Alimentação Coletiva, o livro aborda a questão da \" \" História da Vida \"\n",
            "Escrito por professores e profissionais da área de Alimentação Coletiva, o livro aborda a questão da \" \" História da Vida \",\n",
            "Escrito por professores e profissionais da área de Alimentação Coletiva, o livro aborda a questão da \" \" História da Vida \", que\n",
            "Escrito por professores e profissionais da área de Alimentação Coletiva, o livro aborda a questão da \" \" História da Vida \", que é\n",
            "Escrito por professores e profissionais da área de Alimentação Coletiva, o livro aborda a questão da \" \" História da Vida \", que é o\n",
            "Escrito por professores e profissionais da área de Alimentação Coletiva, o livro aborda a questão da \" \" História da Vida \", que é o primeiro\n",
            "Escrito por professores e profissionais da área de Alimentação Coletiva, o livro aborda a questão da \" \" História da Vida \", que é o primeiro \"\n",
            "Escrito por professores e profissionais da área de Alimentação Coletiva, o livro aborda a questão da \" \" História da Vida \", que é o primeiro \",\n",
            "Escrito por professores e profissionais da área de Alimentação Coletiva, o livro aborda a questão da \" \" História da Vida \", que é o primeiro \", diz\n",
            "Escrito por professores e profissionais da área de Alimentação Coletiva, o livro aborda a questão da \" \" História da Vida \", que é o primeiro \", diz o\n",
            "Escrito por professores e profissionais da área de Alimentação Coletiva, o livro aborda a questão da \" \" História da Vida \", que é o primeiro \", diz o diretor\n",
            "Escrito por professores e profissionais da área de Alimentação Coletiva, o livro aborda a questão da \" \" História da Vida \", que é o primeiro \", diz o diretor.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts[490]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "tw_F0j59UUqS",
        "outputId": "5f7679c7-27bd-4889-eb39-f2015fdb5f61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Na estreia de Tite, o Brasil derrotou o Equador, por 3 a 0. A partida, válida pelas Eliminatórias da Copa do Mundo, foi disputada no início da noite desta quinta-feira, no Estádio Olímpico Atahualpa, em Quito. Os gols da Seleção Brasileira foram anotados por Neymar e Gabriel Jesus (2). A vitória conquistada fora de casa deixou o Brasil com 12 pontos, dentro da zona de classificação para o Mundial da Rússia de 2018. Na próxima terça-feira, dia 6, a Seleção Brasileira recebe a Colômbia na Arena da Amazônia, em Manaus (AM), às 21h45min. O jogo A etapa inicial da partida foi marcada por poucas chances de gol. O Equador começou melhor, mas o Brasil igualou as ações nos minutos seguintes. Aos 15, Gabriel Jesus chutou forte e mandou rente a trave. Já o time da casa, depois de uma saída de bola errada de Renato Augusto, ameaçou a meta defendida por Alisson, com Noboa, aos 35 minutos. No primeiro minuto do segundo tempo, Neymar chutou com perigo e mandou a bola perto da trave. Aos 24 minutos, o Brasil abriu o caminho para sua vitória. Gabriel Jesus, em jogada de velocidade, foi derrubado pelo goleiro dentro da área. Neymar foi para a cobrança do pênalti e mandou a bola na rede. Pouco tempo depois, o lateral Paredes deu uma entrada forte em Renato Augusto e recebeu o segundo cartão amarelo. Com um jogador a mais em campo o jogo ficou mais fácil para o Brasil. Aos 41, Marcelo cruzou da ponta esquerda e Gabriel Jesus, de calcanhar, ampliou a vantagem sobre o Equador. Nos acréscimos, Gabriel Jesus recebeu de Neymar, fez o giro, e mandou a bola no ângulo fechando a vitória da Seleção Brasileira. O Brasil fez 3 a 0 no Equador jogando com a seguinte escalação: Alisson; Daniel Alves, Marquinhos, Miranda e Marcelo; Paulinho, Casemiro, Renato Augusto e Willian (Philippe Coutinho); Neymar e Gabriel Jesus.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Na estreia de Tite, o Brasil derrotou o Equador, por \"\n",
        "max_output_tokens = 20\n",
        "model.eval()\n",
        "\n",
        "for _ in range(max_output_tokens):\n",
        "    input_ids = tokenize(text=prompt, tokenizer=tokenizer)\n",
        "    input_ids_truncated = input_ids[-max_seq_length:]  # Usamos apenas os últimos <max_seq_length> tokens como entrada para o modelo.\n",
        "    logits = model(torch.LongTensor([input_ids_truncated]).to(device))\n",
        "    logits = logits[:, -1, :]  # Usamos apenas o ultimo token da sequencia\n",
        "    # Ao usarmos o argmax, a saída do modelo em cada passo é o token de maior probabilidade.\n",
        "    # Isso se chama decodificação gulosa (greedy decoding).\n",
        "    predicted_id = torch.argmax(logits).item()\n",
        "    input_ids += [predicted_id]  # Concatenamos a entrada com o token escolhido nesse passo.\n",
        "    prompt = tokenizer.decode(input_ids)\n",
        "    print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "205db8c9-edfa-4f94-fa64-96eac23da11c",
        "id": "aL4-pM43U4Jv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Na estreia de Tite, o Brasil derrotou o Equador, por exemplo\n",
            "Na estreia de Tite, o Brasil derrotou o Equador, por exemplo,\n",
            "Na estreia de Tite, o Brasil derrotou o Equador, por exemplo, que\n",
            "Na estreia de Tite, o Brasil derrotou o Equador, por exemplo, que o\n",
            "Na estreia de Tite, o Brasil derrotou o Equador, por exemplo, que o Brasil\n",
            "Na estreia de Tite, o Brasil derrotou o Equador, por exemplo, que o Brasil não\n",
            "Na estreia de Tite, o Brasil derrotou o Equador, por exemplo, que o Brasil não tem\n",
            "Na estreia de Tite, o Brasil derrotou o Equador, por exemplo, que o Brasil não tem o\n",
            "Na estreia de Tite, o Brasil derrotou o Equador, por exemplo, que o Brasil não tem o direito\n",
            "Na estreia de Tite, o Brasil derrotou o Equador, por exemplo, que o Brasil não tem o direito de\n",
            "Na estreia de Tite, o Brasil derrotou o Equador, por exemplo, que o Brasil não tem o direito de ser\n",
            "Na estreia de Tite, o Brasil derrotou o Equador, por exemplo, que o Brasil não tem o direito de ser um\n",
            "Na estreia de Tite, o Brasil derrotou o Equador, por exemplo, que o Brasil não tem o direito de ser um país\n",
            "Na estreia de Tite, o Brasil derrotou o Equador, por exemplo, que o Brasil não tem o direito de ser um país de\n",
            "Na estreia de Tite, o Brasil derrotou o Equador, por exemplo, que o Brasil não tem o direito de ser um país de origem\n",
            "Na estreia de Tite, o Brasil derrotou o Equador, por exemplo, que o Brasil não tem o direito de ser um país de origem,\n",
            "Na estreia de Tite, o Brasil derrotou o Equador, por exemplo, que o Brasil não tem o direito de ser um país de origem, mas\n",
            "Na estreia de Tite, o Brasil derrotou o Equador, por exemplo, que o Brasil não tem o direito de ser um país de origem, mas sim\n",
            "Na estreia de Tite, o Brasil derrotou o Equador, por exemplo, que o Brasil não tem o direito de ser um país de origem, mas sim de\n",
            "Na estreia de Tite, o Brasil derrotou o Equador, por exemplo, que o Brasil não tem o direito de ser um país de origem, mas sim de uma\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Na estreia de Tite o Brasil derrotou o Equador por 3\"\n",
        "max_output_tokens = 20\n",
        "model.eval()\n",
        "\n",
        "for _ in range(max_output_tokens):\n",
        "    input_ids = tokenize(text=prompt, tokenizer=tokenizer)\n",
        "    input_ids_truncated = input_ids[-max_seq_length:]  # Usamos apenas os últimos <max_seq_length> tokens como entrada para o modelo.\n",
        "    logits = model(torch.LongTensor([input_ids_truncated]).to(device))\n",
        "    logits = logits[:, -1, :]  # Usamos apenas o ultimo token da sequencia\n",
        "    # Ao usarmos o argmax, a saída do modelo em cada passo é o token de maior probabilidade.\n",
        "    # Isso se chama decodificação gulosa (greedy decoding).\n",
        "    predicted_id = torch.argmax(logits).item()\n",
        "    input_ids += [predicted_id]  # Concatenamos a entrada com o token escolhido nesse passo.\n",
        "    prompt = tokenizer.decode(input_ids)\n",
        "    print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dk2eErytiMPi",
        "outputId": "2f19d309-6384-4594-bb24-5f11785d09bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Na estreia de Tite o Brasil derrotou o Equador por 3 a\n",
            "Na estreia de Tite o Brasil derrotou o Equador por 3 a 1\n",
            "Na estreia de Tite o Brasil derrotou o Equador por 3 a 1.\n",
            "Na estreia de Tite o Brasil derrotou o Equador por 3 a 1. 0\n",
            "Na estreia de Tite o Brasil derrotou o Equador por 3 a 1. 0.\n",
            "Na estreia de Tite o Brasil derrotou o Equador por 3 a 1. 0. O\n",
            "Na estreia de Tite o Brasil derrotou o Equador por 3 a 1. 0. O time\n",
            "Na estreia de Tite o Brasil derrotou o Equador por 3 a 1. 0. O time do\n",
            "Na estreia de Tite o Brasil derrotou o Equador por 3 a 1. 0. O time do Grêmio\n",
            "Na estreia de Tite o Brasil derrotou o Equador por 3 a 1. 0. O time do Grêmio,\n",
            "Na estreia de Tite o Brasil derrotou o Equador por 3 a 1. 0. O time do Grêmio, que\n",
            "Na estreia de Tite o Brasil derrotou o Equador por 3 a 1. 0. O time do Grêmio, que venceu\n",
            "Na estreia de Tite o Brasil derrotou o Equador por 3 a 1. 0. O time do Grêmio, que venceu o\n",
            "Na estreia de Tite o Brasil derrotou o Equador por 3 a 1. 0. O time do Grêmio, que venceu o time\n",
            "Na estreia de Tite o Brasil derrotou o Equador por 3 a 1. 0. O time do Grêmio, que venceu o time do\n",
            "Na estreia de Tite o Brasil derrotou o Equador por 3 a 1. 0. O time do Grêmio, que venceu o time do técnico\n",
            "Na estreia de Tite o Brasil derrotou o Equador por 3 a 1. 0. O time do Grêmio, que venceu o time do técnico Tit\n",
            "Na estreia de Tite o Brasil derrotou o Equador por 3 a 1. 0. O time do Grêmio, que venceu o time do técnico Tit?\n",
            "Na estreia de Tite o Brasil derrotou o Equador por 3 a 1. 0. O time do Grêmio, que venceu o time do técnico Tit??\n",
            "Na estreia de Tite o Brasil derrotou o Equador por 3 a 1. 0. O time do Grêmio, que venceu o time do técnico Tit???\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Na estreia de Tite, o Brasil derrotou o Equador por \"\n",
        "max_output_tokens = 20\n",
        "model.eval()\n",
        "\n",
        "for _ in range(max_output_tokens):\n",
        "    input_ids = tokenize(text=prompt, tokenizer=tokenizer)\n",
        "    input_ids_truncated = input_ids[-max_seq_length:]  # Usamos apenas os últimos <max_seq_length> tokens como entrada para o modelo.\n",
        "    logits = model(torch.LongTensor([input_ids_truncated]).to(device))\n",
        "    logits = logits[:, -1, :]  # Usamos apenas o ultimo token da sequencia\n",
        "    # Ao usarmos o argmax, a saída do modelo em cada passo é o token de maior probabilidade.\n",
        "    # Isso se chama decodificação gulosa (greedy decoding).\n",
        "    predicted_id = torch.argmax(logits).item()\n",
        "    input_ids += [predicted_id]  # Concatenamos a entrada com o token escolhido nesse passo.\n",
        "    prompt = tokenizer.decode(input_ids)\n",
        "    print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "369e7944-1ea6-4f91-b15d-6da151665b33",
        "id": "cP_vZf_xUrrv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Na estreia de Tite, o Brasil derrotou o Equador por 3\n",
            "Na estreia de Tite, o Brasil derrotou o Equador por 3 a\n",
            "Na estreia de Tite, o Brasil derrotou o Equador por 3 a 1\n",
            "Na estreia de Tite, o Brasil derrotou o Equador por 3 a 1,\n",
            "Na estreia de Tite, o Brasil derrotou o Equador por 3 a 1, em\n",
            "Na estreia de Tite, o Brasil derrotou o Equador por 3 a 1, em São\n",
            "Na estreia de Tite, o Brasil derrotou o Equador por 3 a 1, em São Paulo\n",
            "Na estreia de Tite, o Brasil derrotou o Equador por 3 a 1, em São Paulo,\n",
            "Na estreia de Tite, o Brasil derrotou o Equador por 3 a 1, em São Paulo, no\n",
            "Na estreia de Tite, o Brasil derrotou o Equador por 3 a 1, em São Paulo, no Rio\n",
            "Na estreia de Tite, o Brasil derrotou o Equador por 3 a 1, em São Paulo, no Rio de\n",
            "Na estreia de Tite, o Brasil derrotou o Equador por 3 a 1, em São Paulo, no Rio de Janeiro\n",
            "Na estreia de Tite, o Brasil derrotou o Equador por 3 a 1, em São Paulo, no Rio de Janeiro,\n",
            "Na estreia de Tite, o Brasil derrotou o Equador por 3 a 1, em São Paulo, no Rio de Janeiro, em\n",
            "Na estreia de Tite, o Brasil derrotou o Equador por 3 a 1, em São Paulo, no Rio de Janeiro, em São\n",
            "Na estreia de Tite, o Brasil derrotou o Equador por 3 a 1, em São Paulo, no Rio de Janeiro, em São Paulo\n",
            "Na estreia de Tite, o Brasil derrotou o Equador por 3 a 1, em São Paulo, no Rio de Janeiro, em São Paulo.\n",
            "Na estreia de Tite, o Brasil derrotou o Equador por 3 a 1, em São Paulo, no Rio de Janeiro, em São Paulo. O\n",
            "Na estreia de Tite, o Brasil derrotou o Equador por 3 a 1, em São Paulo, no Rio de Janeiro, em São Paulo. O evento\n",
            "Na estreia de Tite, o Brasil derrotou o Equador por 3 a 1, em São Paulo, no Rio de Janeiro, em São Paulo. O evento contou\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGdxlXhGq7Ua"
      },
      "source": [
        "## Bonus 1\n",
        "Quem conseguir a menor perplexidade no dataset de testes ganha 0.5 ponto na média final.\n",
        "\n",
        "## Bonus 2\n",
        "Qual é a complexidade (em notação O-grande) da função de geração de texto acima?\n",
        "\n",
        "Quem responder corretamente a pergunta acima e deixar a função com menor complexidade ganha 0.5 ponto na média final."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "VDMe0UAfPvtx",
        "1kUBvcY0CZvk"
      ],
      "name": "Aula 10 - Exercício - Larissa Santesso",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "808222214af941c893294da96a772bee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_256a05b035cf4a8f9026c40c40fa2533",
              "IPY_MODEL_6b5a5a4f60d24620a0d3f0e71e247feb",
              "IPY_MODEL_8618356df359482e9ac05904028f7a6b"
            ],
            "layout": "IPY_MODEL_79b3bb230afd40edbbbb088dd65d8cd8"
          }
        },
        "256a05b035cf4a8f9026c40c40fa2533": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f38445c2cd384a5aa1e8f0ef8bd78af5",
            "placeholder": "​",
            "style": "IPY_MODEL_fa92cd199c5748c29a0c6ab07306c5bf",
            "value": "Downloading: 100%"
          }
        },
        "6b5a5a4f60d24620a0d3f0e71e247feb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66d13388a75e4b859306f27cba04d811",
            "max": 209528,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8157b5198bc64f0498de31adb83adadc",
            "value": 209528
          }
        },
        "8618356df359482e9ac05904028f7a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebbf26f106404d35b83492c3771ebc94",
            "placeholder": "​",
            "style": "IPY_MODEL_c8b7aad8114b43a18e773bde64168426",
            "value": " 205k/205k [00:00&lt;00:00, 273kB/s]"
          }
        },
        "79b3bb230afd40edbbbb088dd65d8cd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f38445c2cd384a5aa1e8f0ef8bd78af5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa92cd199c5748c29a0c6ab07306c5bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66d13388a75e4b859306f27cba04d811": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8157b5198bc64f0498de31adb83adadc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ebbf26f106404d35b83492c3771ebc94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8b7aad8114b43a18e773bde64168426": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "821f9feae43647d086e0a0837b2e6d06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a9c85083f7914ab0a2bdaa1242d003f2",
              "IPY_MODEL_434fbe96891943b49d237a2addff4c17",
              "IPY_MODEL_db0a162ee68f4a239e42a2c04b145680"
            ],
            "layout": "IPY_MODEL_61636a51e79d4d31afa127d5f88ee96f"
          }
        },
        "a9c85083f7914ab0a2bdaa1242d003f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c6a9589cf4b48e49cbf14654ad727e0",
            "placeholder": "​",
            "style": "IPY_MODEL_30a1a8b11f694c3d992e13d5db8fbbf9",
            "value": "Downloading: 100%"
          }
        },
        "434fbe96891943b49d237a2addff4c17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4449d2ab3153428287f56670d9cf862c",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0fe10e810ab14298b6268f9c600bf6a1",
            "value": 2
          }
        },
        "db0a162ee68f4a239e42a2c04b145680": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a8b7e55cf2b4cd6adc506ae6f7f78c7",
            "placeholder": "​",
            "style": "IPY_MODEL_f2bdc3a338dd4e27a8c9de7770eaef06",
            "value": " 2.00/2.00 [00:00&lt;00:00, 61.2B/s]"
          }
        },
        "61636a51e79d4d31afa127d5f88ee96f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c6a9589cf4b48e49cbf14654ad727e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30a1a8b11f694c3d992e13d5db8fbbf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4449d2ab3153428287f56670d9cf862c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fe10e810ab14298b6268f9c600bf6a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a8b7e55cf2b4cd6adc506ae6f7f78c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2bdc3a338dd4e27a8c9de7770eaef06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf85a3de3dd3477fa686844d9a661a15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_318bcef4a3494900b015b1c1172a2f68",
              "IPY_MODEL_d90c277107c04d26ac2bbb259ce9302a",
              "IPY_MODEL_c66af7b29ee540c295f59aa1403f2f6c"
            ],
            "layout": "IPY_MODEL_15d869d0525e42d997b8bec90f263805"
          }
        },
        "318bcef4a3494900b015b1c1172a2f68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee35fefddff0489394481f0548cda87c",
            "placeholder": "​",
            "style": "IPY_MODEL_29afa218da0547409216e581ff86d90f",
            "value": "Downloading: 100%"
          }
        },
        "d90c277107c04d26ac2bbb259ce9302a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_188f5509eaa14ef5a150656a31510a4e",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8fe031081964e2f99d1901af1c7fdb0",
            "value": 112
          }
        },
        "c66af7b29ee540c295f59aa1403f2f6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_026da411b2e24e58a5bcf486f509c190",
            "placeholder": "​",
            "style": "IPY_MODEL_13f67f3e57b84f47879d2d49e409a82c",
            "value": " 112/112 [00:00&lt;00:00, 3.40kB/s]"
          }
        },
        "15d869d0525e42d997b8bec90f263805": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee35fefddff0489394481f0548cda87c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29afa218da0547409216e581ff86d90f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "188f5509eaa14ef5a150656a31510a4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8fe031081964e2f99d1901af1c7fdb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "026da411b2e24e58a5bcf486f509c190": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13f67f3e57b84f47879d2d49e409a82c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c7ed902ba19455194c9bd72405f2ebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e5cb419a27b4a2ebd43964ca44efcf1",
              "IPY_MODEL_df088b4fe5be4bdcbc6111d5fa4b2e3f",
              "IPY_MODEL_7a443a1dad7f4d88a44b9f9db50c534b"
            ],
            "layout": "IPY_MODEL_e1a9eaeea65d46208652ecb49f68434a"
          }
        },
        "5e5cb419a27b4a2ebd43964ca44efcf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40b991bbe3474b7384c8b404710cb883",
            "placeholder": "​",
            "style": "IPY_MODEL_76712bd22ec14118b74d8dc7dd586857",
            "value": "Downloading: 100%"
          }
        },
        "df088b4fe5be4bdcbc6111d5fa4b2e3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dedd452453a942dfb1ab83a82fb51be1",
            "max": 43,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f5eb3f6d1bb44999e1529834fa348f7",
            "value": 43
          }
        },
        "7a443a1dad7f4d88a44b9f9db50c534b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c88ff51b761a4e6bb8d07d27eec12ed0",
            "placeholder": "​",
            "style": "IPY_MODEL_a0c561b4fa5a479a8198d97c8b7c2315",
            "value": " 43.0/43.0 [00:00&lt;00:00, 1.33kB/s]"
          }
        },
        "e1a9eaeea65d46208652ecb49f68434a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40b991bbe3474b7384c8b404710cb883": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76712bd22ec14118b74d8dc7dd586857": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dedd452453a942dfb1ab83a82fb51be1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f5eb3f6d1bb44999e1529834fa348f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c88ff51b761a4e6bb8d07d27eec12ed0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0c561b4fa5a479a8198d97c8b7c2315": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb6fc5c62cfb4b58b0be787f8829ebc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_576576a4bcee48cf9aae481235ecae4e",
              "IPY_MODEL_240928fe31894a9e87fddb9526c44552",
              "IPY_MODEL_6d28bb02b56d4cdf821d3714308f7427"
            ],
            "layout": "IPY_MODEL_c5f0ba1405f64f7f808b9b982bfd3081"
          }
        },
        "576576a4bcee48cf9aae481235ecae4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e264487111dc44f38704b5d05ceda1d4",
            "placeholder": "​",
            "style": "IPY_MODEL_498f310ce5794ffdbf62421623d92393",
            "value": "Downloading: 100%"
          }
        },
        "240928fe31894a9e87fddb9526c44552": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfd09cc242584f89940d9b15792d8d71",
            "max": 647,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_511221767f3f4780a7a9828ce76f1a30",
            "value": 647
          }
        },
        "6d28bb02b56d4cdf821d3714308f7427": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c16618845876426b9d2afc1a1344fec8",
            "placeholder": "​",
            "style": "IPY_MODEL_747769302bed441e8634bbabe31d9083",
            "value": " 647/647 [00:00&lt;00:00, 16.9kB/s]"
          }
        },
        "c5f0ba1405f64f7f808b9b982bfd3081": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e264487111dc44f38704b5d05ceda1d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "498f310ce5794ffdbf62421623d92393": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfd09cc242584f89940d9b15792d8d71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "511221767f3f4780a7a9828ce76f1a30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c16618845876426b9d2afc1a1344fec8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "747769302bed441e8634bbabe31d9083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b160268ee9184673a5af67fbdd277210": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d61f33cdc8dc4cc6ac1852942828a9f2",
              "IPY_MODEL_e7664fe0eef643cf83ece5d61d0db020",
              "IPY_MODEL_6a45294fc535451ea06481b49844cdfb"
            ],
            "layout": "IPY_MODEL_2032fa80b3584988973b37cdccbd4bec"
          }
        },
        "d61f33cdc8dc4cc6ac1852942828a9f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ada03ada630f4c6c90a11bcafa376733",
            "placeholder": "​",
            "style": "IPY_MODEL_18a8f1f08c6240e9b416e0e71906596d",
            "value": "Downloading: 100%"
          }
        },
        "e7664fe0eef643cf83ece5d61d0db020": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8651d43af93a444482958556a0ae9cc2",
            "max": 209528,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e862a9f434aa48a9bd5a6a496aa71007",
            "value": 209528
          }
        },
        "6a45294fc535451ea06481b49844cdfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d32b7e0b486540c081f66609b042aba6",
            "placeholder": "​",
            "style": "IPY_MODEL_efeb989417554746abe6142d22a752d8",
            "value": " 205k/205k [00:00&lt;00:00, 2.25MB/s]"
          }
        },
        "2032fa80b3584988973b37cdccbd4bec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ada03ada630f4c6c90a11bcafa376733": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18a8f1f08c6240e9b416e0e71906596d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8651d43af93a444482958556a0ae9cc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e862a9f434aa48a9bd5a6a496aa71007": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d32b7e0b486540c081f66609b042aba6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efeb989417554746abe6142d22a752d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa5e195a6bf442a2a0d9af5000c3bc67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1bd0703fa844af69bea267fc7d7ed20",
              "IPY_MODEL_0a9d58e1afcb469e88b3aa78a27e6301",
              "IPY_MODEL_89dc84ac3e6d4b7db6beb5df3dda732d"
            ],
            "layout": "IPY_MODEL_5b30b0b561b240ef9c4ab75daed71744"
          }
        },
        "a1bd0703fa844af69bea267fc7d7ed20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80a8c5d87573490487a52ac33b3d50d4",
            "placeholder": "​",
            "style": "IPY_MODEL_3c24d13cce0042e0ada9fec8fda48d53",
            "value": "Downloading: 100%"
          }
        },
        "0a9d58e1afcb469e88b3aa78a27e6301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbdc70cecaa54aeaae4aefbfc2c3a7a6",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_339e6ea512644f3b90622b86c4dc2b23",
            "value": 2
          }
        },
        "89dc84ac3e6d4b7db6beb5df3dda732d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_887bbde8ac2a4e43895e61d2904a2e8e",
            "placeholder": "​",
            "style": "IPY_MODEL_a55f320634424c00afb294fd091b64e9",
            "value": " 2.00/2.00 [00:00&lt;00:00, 63.8B/s]"
          }
        },
        "5b30b0b561b240ef9c4ab75daed71744": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80a8c5d87573490487a52ac33b3d50d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c24d13cce0042e0ada9fec8fda48d53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbdc70cecaa54aeaae4aefbfc2c3a7a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "339e6ea512644f3b90622b86c4dc2b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "887bbde8ac2a4e43895e61d2904a2e8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a55f320634424c00afb294fd091b64e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4ee344004e441608c5520b130484348": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_851c16fdfd9f419eb85dd15cd8244620",
              "IPY_MODEL_81cb41f86e1247979080b3ca3e90bbed",
              "IPY_MODEL_00ecaf3d00974580b0312be789718c86"
            ],
            "layout": "IPY_MODEL_2d4b6fb5c0f848a4b52f63014c64dc30"
          }
        },
        "851c16fdfd9f419eb85dd15cd8244620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b260a2086d354cc587c78c499e155e5a",
            "placeholder": "​",
            "style": "IPY_MODEL_4b1812f8f01740f3b50697a280250d34",
            "value": "Downloading: 100%"
          }
        },
        "81cb41f86e1247979080b3ca3e90bbed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e51de0e3ef8049daa64f0bb97b06a012",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24417af2102942d0bd05bb0716c159e8",
            "value": 112
          }
        },
        "00ecaf3d00974580b0312be789718c86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20acac1478694f2e98c1332bdc46c359",
            "placeholder": "​",
            "style": "IPY_MODEL_2d3c955fc5c84656b0e4061eb7e7db94",
            "value": " 112/112 [00:00&lt;00:00, 3.37kB/s]"
          }
        },
        "2d4b6fb5c0f848a4b52f63014c64dc30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b260a2086d354cc587c78c499e155e5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b1812f8f01740f3b50697a280250d34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e51de0e3ef8049daa64f0bb97b06a012": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24417af2102942d0bd05bb0716c159e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20acac1478694f2e98c1332bdc46c359": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d3c955fc5c84656b0e4061eb7e7db94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20e856ae07d54cfeab0a45a98634d32a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a95357d0de0e42aa8ac27ab7584597d2",
              "IPY_MODEL_39aa805788f34bbd801e6caedf9773be",
              "IPY_MODEL_171a01c096904e98bd08fa66250fa9ef"
            ],
            "layout": "IPY_MODEL_71f26d4978fe4823aa1ac593db10de99"
          }
        },
        "a95357d0de0e42aa8ac27ab7584597d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61ba23a6b46a4fa3ade72c9892f087c1",
            "placeholder": "​",
            "style": "IPY_MODEL_eedb1e8dec86420a869527c5ff7cbc57",
            "value": "Downloading: 100%"
          }
        },
        "39aa805788f34bbd801e6caedf9773be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e32a73b9ff934053b4022d249a524888",
            "max": 43,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f31dd8d1b024d359f4c4b2e1c00d7d2",
            "value": 43
          }
        },
        "171a01c096904e98bd08fa66250fa9ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98ac99a30dc14112b84b33dc300e7d27",
            "placeholder": "​",
            "style": "IPY_MODEL_d172a310ca0949febfbd4d112cad6aeb",
            "value": " 43.0/43.0 [00:00&lt;00:00, 1.22kB/s]"
          }
        },
        "71f26d4978fe4823aa1ac593db10de99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61ba23a6b46a4fa3ade72c9892f087c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eedb1e8dec86420a869527c5ff7cbc57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e32a73b9ff934053b4022d249a524888": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f31dd8d1b024d359f4c4b2e1c00d7d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "98ac99a30dc14112b84b33dc300e7d27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d172a310ca0949febfbd4d112cad6aeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "819655885f2c4e22a3ef13ad8e58ad73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a913ed626934ed9a50bd4a9ac53b096",
              "IPY_MODEL_0488fdfbbcf64be8afa6cbd3d6bdc0ca",
              "IPY_MODEL_c62b605811c34d1399aa31f13aa74690"
            ],
            "layout": "IPY_MODEL_ee8041110a704573bbcc432c7447e08e"
          }
        },
        "4a913ed626934ed9a50bd4a9ac53b096": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f41738f55eb4d02b6b6609eb8b56223",
            "placeholder": "​",
            "style": "IPY_MODEL_477b25b95a6f41d081bb4b97dd225ef7",
            "value": "Downloading: 100%"
          }
        },
        "0488fdfbbcf64be8afa6cbd3d6bdc0ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_490dfde34c1742e08a278b9116b14c63",
            "max": 647,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ab3c508898843d8ab1de8f58e851fdc",
            "value": 647
          }
        },
        "c62b605811c34d1399aa31f13aa74690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c1c9c952a0848e9add0166ae6c05f08",
            "placeholder": "​",
            "style": "IPY_MODEL_ef08e270e7ee4b4b9f92c9f2464226ed",
            "value": " 647/647 [00:00&lt;00:00, 8.94kB/s]"
          }
        },
        "ee8041110a704573bbcc432c7447e08e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f41738f55eb4d02b6b6609eb8b56223": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "477b25b95a6f41d081bb4b97dd225ef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "490dfde34c1742e08a278b9116b14c63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ab3c508898843d8ab1de8f58e851fdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c1c9c952a0848e9add0166ae6c05f08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef08e270e7ee4b4b9f92c9f2464226ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}