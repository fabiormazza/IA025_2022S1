{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "toc": {
      "nav_menu": {
        "height": "318px",
        "width": "252px"
      },
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "Aula 5 - Exercício - Marcus Borela",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unicamp-dl/IA025_2022S1/blob/main/ex05/Marcus_Vinicius_Borela_de_Castro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nome = 'Marcus Vinícius Borela de CAstro'\n",
        "\n",
        "print(f'Meu nome é {nome}')"
      ],
      "metadata": {
        "id": "CdORg7oe68oq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bae01930-d0b9-42b0-a3a9-384b6ae22ade"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meu nome é Marcus Vinícius Borela de CAstro\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkfGTqMVQT1u"
      },
      "source": [
        "Este exercicío consiste em treinar no MNIST um modelo de duas camadas, sendo a primeira uma camada convolucional e a segunda uma camada linear de classificação.\n",
        "\n",
        "Não podemos usar as funções torch.nn.Conv{1,2,3}d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFNf4RPxQT1w"
      },
      "source": [
        "## Importação das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-21T14:08:14.033692Z",
          "start_time": "2018-08-21T14:08:11.179981Z"
        },
        "id": "-fLUSHaCQT1x"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fixando as seeds"
      ],
      "metadata": {
        "id": "achvQ78sa3p3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkETIyWGkbOf"
      },
      "source": [
        "def inicializa_seed(num_semente:int=123):\n",
        "  \"\"\"\n",
        "  É recomendado reiniciar as seeds antes de inicializar o modelo, pois assim\n",
        "  garantimos que os pesos vao ser sempre os mesmos.\n",
        "  fontes de apoio: \n",
        "      http://nlp.seas.harvard.edu/2018/04/03/attention.html\n",
        "      https://github.com/CyberZHG/torch-multi-head-attention/blob/master/torch_multi_head_attention/multi_head_attention.py#L15\n",
        "  \"\"\"\n",
        "  random.seed(num_semente)\n",
        "  np.random.seed(num_semente)\n",
        "  torch.manual_seed(num_semente)\n",
        "  #torch.cuda.manual_seed(num_semente)\n",
        "  #Cuda algorithms\n",
        "  #torch.backends.cudnn.deterministic = True "
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViMcw_kVkbOf"
      },
      "source": [
        "inicializa_seed(123)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define pesos iniciais"
      ],
      "metadata": {
        "id": "fzurMVpHxcNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_channels = 1\n",
        "out_channels = 2\n",
        "kernel_size = 5\n",
        "stride = 3\n",
        "\n",
        "# Input image size\n",
        "height_in = 28  \n",
        "width_in = 28\n",
        "\n",
        "# Image size after the first convolutional layer.\n",
        "height_out = (height_in - kernel_size - 1) // stride + 1\n",
        "width_out = (width_in - kernel_size - 1) // stride + 1\n",
        "\n",
        "initial_conv_weight = torch.FloatTensor(in_channels, out_channels, kernel_size, kernel_size).uniform_(-0.01, 0.01)\n",
        "initial_conv_bias = torch.FloatTensor(out_channels,).uniform_(-0.01, 0.01)\n",
        "\n",
        "initial_classification_weight = torch.FloatTensor(10, out_channels * height_out * width_out).uniform_(-0.01, 0.01)\n",
        "initial_classification_bias = torch.FloatTensor(10,).uniform_(-0.01, 0.01)"
      ],
      "metadata": {
        "id": "9a6jQJLLlfF3"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\" height_out {height_out}, width_out {width_out}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Y2-ILXqbE1d",
        "outputId": "77489fbf-20b2-4d36-cb7d-4b56153723d7"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " height_out 8, width_out 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEMUsfJpQT11"
      },
      "source": [
        "## Dataset e dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHoQjDs_QT12"
      },
      "source": [
        "### Definição do tamanho do minibatch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-21T14:08:20.282474Z",
          "start_time": "2018-08-21T14:08:20.275450Z"
        },
        "id": "tEQYUr4TQT13"
      },
      "source": [
        "batch_size = 50"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc7Rv_2BQT16"
      },
      "source": [
        "### Carregamento, criação dataset e do dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-21T14:10:45.430605Z",
          "start_time": "2018-08-21T14:10:04.953051Z"
        },
        "id": "G0dEKCn-QT17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd345ded-0f74-4810-d4b7-46fcf8636ae7"
      },
      "source": [
        "dataset_dir = '../data/'\n",
        "\n",
        "dataset_train_full = MNIST(dataset_dir, train=True, download=True,\n",
        "                           transform=torchvision.transforms.ToTensor())\n",
        "print(dataset_train_full.data.shape)\n",
        "print(dataset_train_full.targets.shape)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60000, 28, 28])\n",
            "torch.Size([60000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rOy9ntrQT2D"
      },
      "source": [
        "### Usando apenas 1000 amostras do MNIST\n",
        "\n",
        "Neste exercício utilizaremos 1000 amostras de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNF2XjLBWWe7"
      },
      "source": [
        "indices = torch.randperm(len(dataset_train_full))[:1000]\n",
        "dataset_train = torch.utils.data.Subset(dataset_train_full, indices)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define os pesos iniciais"
      ],
      "metadata": {
        "id": "wYqj_oeSliYj"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSNLD2JyA2e-"
      },
      "source": [
        "loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-21T13:30:35.209157Z",
          "start_time": "2018-08-21T13:30:34.757103Z"
        },
        "id": "w52KGYlIQT2A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96dcaf5c-90b0-4b41-c724-2989243df1d6"
      },
      "source": [
        "print('Número de minibatches de trenamento:', len(loader_train))\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de minibatches de trenamento: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = next(iter(loader_train))\n",
        "print(\"\\nDimensões dos dados de um minibatch:\", x_train.size())\n",
        "print(\"Valores mínimo e máximo dos pixels: \", torch.min(x_train), torch.max(x_train))\n",
        "print(\"Tipo dos dados das imagens:         \", type(x_train))\n",
        "print(\"Tipo das classes das imagens:       \", type(y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7vPdWoIbwht",
        "outputId": "081dad0e-ee64-4615-cba0-2b8bc879fe85"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dimensões dos dados de um minibatch: torch.Size([50, 1, 28, 28])\n",
            "Valores mínimo e máximo dos pixels:  tensor(0.) tensor(1.)\n",
            "Tipo dos dados das imagens:          <class 'torch.Tensor'>\n",
            "Tipo das classes das imagens:        <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYw9dR89b3Is",
        "outputId": "d881bcfc-51c0-4b10-8506-9b8504cae9af"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([50, 1, 28, 28]), torch.Size([50]))"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0, 0, 0, ] # 1a linha da 1a amostra"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6g_7GhLcJak",
        "outputId": "b446d77b-da2e-4bae-d2e1-2e8e3e8d2338"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0, 0,] # 28 linhas da 1a amostra"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7J64G0oDcYed",
        "outputId": "3f540d8e-5fa3-4a52-e5e5-0a32bbddea25"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2980, 0.9922, 0.9922, 0.6235,\n",
              "         0.3373, 0.0431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0667, 0.0196, 0.0353, 0.3608, 0.4824, 0.8745,\n",
              "         0.9882, 0.7569, 0.1490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.3255, 0.8196, 0.4196, 0.0000, 0.0000, 0.0000, 0.0980,\n",
              "         0.6784, 0.9922, 0.9412, 0.3216, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0667, 0.8196, 0.6902, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.4588, 0.9882, 0.9412, 0.1451, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.2902, 0.9176, 0.9882, 0.4235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0118, 0.4588, 0.9882, 0.7529, 0.0431, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4980,\n",
              "         1.0000, 0.9765, 0.4510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.1686, 0.9686, 0.9922, 0.3373, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9569,\n",
              "         0.9765, 0.4588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.4353, 0.9882, 0.5373, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3255, 0.9412, 0.9882,\n",
              "         0.4510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0745, 0.8588, 0.8667, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1490, 0.9412, 0.9882, 0.6157,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.8118, 0.9882, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5922, 0.9882, 0.9882, 0.1255,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.8118, 0.9882, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.3412, 0.9922, 0.9922, 0.1804, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.2745, 0.9922, 0.9529, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.5412, 0.9882, 0.8157, 0.0667, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.3569, 0.9882, 0.5373, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.5412, 0.9882, 0.5922, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.1333, 0.9176, 0.9882, 0.4157, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.5412, 0.9882, 0.2706, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0353, 0.4784, 0.9882, 0.8549, 0.0549, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.9529, 0.8235, 0.0235, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.5020, 0.9882, 0.9882, 0.2196, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.8275, 0.0275, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0353,\n",
              "         0.5020, 1.0000, 0.9765, 0.4510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.7059, 0.9882, 0.6039, 0.0353, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2588, 0.7608,\n",
              "         0.9882, 0.8941, 0.4588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.3961, 0.8902, 0.9882, 0.6039, 0.2745,\n",
              "         0.2510, 0.1255, 0.2000, 0.2745, 0.2745, 0.5176, 0.7216, 0.9176, 0.9882,\n",
              "         0.7412, 0.1255, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1961, 0.6275, 0.9255, 0.9882,\n",
              "         0.9765, 0.8941, 0.9412, 0.9882, 0.9882, 0.9922, 0.9216, 0.6275, 0.2588,\n",
              "         0.0157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0745, 0.0863,\n",
              "         0.5373, 0.5373, 0.6588, 0.8235, 0.5373, 0.2941, 0.0706, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape[1] # canais"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yo8ov5QdUNk",
        "outputId": "4cffd5db-910c-45bf-92e4-2db751afaf0b"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Camada Convolucional"
      ],
      "metadata": {
        "id": "dfU_v7aPfq40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.zeros((4,1,4,5),  dtype=torch.float, requires_grad=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWnT39vv2UFk",
        "outputId": "da94d111-14f5-4b32-9494-dbd46e5d84c8"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "        [[[0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "        [[[0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "        [[[0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.]]]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saida = torch.empty((4,1,4,5),  dtype=torch.float, requires_grad=True)"
      ],
      "metadata": {
        "id": "uR3td8Fn7KZZ"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saida.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BwNMw6q7Q6I",
        "outputId": "6f4f5773-54ff-4abf-e164-8173ededf6ac"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 1, 4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saida[0,0,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8PB0cWe92X-",
        "outputId": "b8e021d1-fbb7-4d9d-fdaf-f7478a770564"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.4613e-35, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.cat((saida[0,0,0], torch.tensor([[12]])), dim=-1)"
      ],
      "metadata": {
        "id": "-FebDt7c__d1"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saida"
      ],
      "metadata": {
        "id": "1Qi-eoW97Sp_"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyConv2d(torch.nn.Module):\n",
        "  def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int):\n",
        "    super(MyConv2d, self).__init__()\n",
        "\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.kernel_size = kernel_size  # The same for height and width.\n",
        "    self.stride = stride  # The same for height and width.\n",
        "    self.weight = torch.nn.Parameter(torch.FloatTensor(in_channels, out_channels, kernel_size, kernel_size).uniform_(-0.01, 0.01))\n",
        "    self.bias = torch.nn.Parameter(torch.FloatTensor(out_channels,).uniform_(-0.01, 0.01))\n",
        "    print(f\"Inicializado MyConv2d\")\n",
        "    print(f\"in_channels: {self.in_channels} \")\n",
        "    print(f\"out_channels: {self.out_channels} \")\n",
        "    print(f\"kernel_size: {self.kernel_size} \")\n",
        "    print(f\"stride: {self.stride} \")\n",
        "    print(f\"weight.shape: {self.weight.shape} \")\n",
        "    print(f\"weight: {self.weight} \")\n",
        "    print(f\"bias.shape: {self.bias.shape} \")\n",
        "    print(f\"bias: {self.bias} \")\n",
        "\n",
        "  def forward(self, x):\n",
        "    assert x.dim() == 4, f'x must have 4 dimensions, not {x.shape}'\n",
        "    assert x.shape[1] == 1, f'x must have only 1 channel, not {x.shape[1]}' # Num_canais sempre 1 (mnist, preto/branco)\n",
        "\n",
        "    # print(f\"kernel.shape: {self.weight.shape}, kernel: {self.weight}\")\n",
        "    # Escreva seu código aqui.\n",
        "    # versão com for nas dimensões de X\n",
        "    num_amostras = x.shape[0]\n",
        "    num_linhas_entrada = x.shape[2]\n",
        "    num_colunas_entrada = x.shape[3]\n",
        "    num_linhas_saida = (num_linhas_entrada - self.kernel_size) // self.stride + 1\n",
        "    num_colunas_saida = (num_colunas_entrada - self.kernel_size) // self.stride + 1\n",
        "    print(f\" num_amostras: {num_amostras}, self.out_channels: {self.out_channels}, num_linhas_entrada: {num_linhas_entrada}, num_colunas_entrada: {num_colunas_entrada}, num_linhas_saida: {num_linhas_saida}, num_colunas_saida: {num_colunas_saida}\")\n",
        "    saida = torch.zeros((num_amostras,self.out_channels,num_linhas_saida,num_colunas_saida), dtype=torch.float, requires_grad=False)        \n",
        "    print(f\"saida.shape: {saida.shape}\")\n",
        "    for ndx_amostra in range(num_amostras):\n",
        "      print(f\"\\nndx_amostra: {ndx_amostra}\")\n",
        "      for ndx_in_channels in range(self.in_channels):\n",
        "        print(f\"\\nndx_in_channels: {ndx_in_channels}\")\n",
        "        for ndx_linhas_saida in range(num_linhas_saida):\n",
        "          for ndx_colunas_saida in range(num_colunas_saida):\n",
        "            print(f\"\\nndx_linhas_saida, ndx_colunas_saida: {ndx_linhas_saida}, {ndx_colunas_saida}\")\n",
        "            print(f\" alvo do kernel em x: x[{ndx_amostra},{ndx_in_channels},{ndx_linhas_saida}:{ndx_linhas_saida+self.kernel_size}, {ndx_colunas_saida}:{ndx_colunas_saida+self.kernel_size}]\")\n",
        "            print(f\" \\n {x[ndx_amostra, ndx_in_channels, ndx_linhas_saida:ndx_linhas_saida+self.kernel_size, ndx_colunas_saida:ndx_colunas_saida+self.kernel_size]}\")\n",
        "            produto = torch.mul(x[ndx_amostra, ndx_in_channels, ndx_linhas_saida:ndx_linhas_saida+self.kernel_size, ndx_colunas_saida:ndx_colunas_saida+self.kernel_size], self.weight)\n",
        "            print(f\" produto: {produto}\")\n",
        "            soma = torch.sum(produto, dim=(2,3), keepdim=True )\n",
        "            print(f\" soma: {soma}\")\n",
        "            valor_soma = soma.squeeze()\n",
        "            print(f\" valor_soma: {valor_soma}\")\n",
        "\n",
        "            # saida = torch.cat((saida, soma))\n",
        "            if self.out_channels > 1:  # soma é um com dimensões, como em torch.tensor([[[[ 46.]], [[134.]]]])\n",
        "              for ndx_out_channels in range(self.out_channels):\n",
        "                saida[ndx_amostra, ndx_out_channels, ndx_linhas_saida, ndx_colunas_saida] += valor_soma[ndx_out_channels]\n",
        "                print(f\" somado na saída em [{ndx_amostra}, {ndx_out_channels}, {ndx_linhas_saida}, {ndx_colunas_saida}] = {saida[ndx_amostra, ndx_out_channels, ndx_linhas_saida, ndx_colunas_saida]}\")\n",
        "            else: # soma é um tensor escalar, como em tensor(34.)\n",
        "                saida[ndx_amostra, 0, ndx_linhas_saida, ndx_colunas_saida] += valor_soma\n",
        "                print(f\" somado na saída em [{ndx_amostra}, 0, {ndx_linhas_saida}, {ndx_colunas_saida}] = {saida[ndx_amostra, 0, ndx_linhas_saida, ndx_colunas_saida]}\")\n",
        "\n",
        "            ndx_colunas_saida += self.stride\n",
        "          ndx_linhas_saida += self.stride\n",
        "    print(f\" saida: {saida}\")\n",
        "    # somando bias\n",
        "    for ndx_amostra in range(num_amostras):\n",
        "      print(f\"\\nndx_amostra: {ndx_amostra}\")\n",
        "      for ndx_out_channels in range(self.out_channels):\n",
        "        saida[ndx_amostra, ndx_out_channels] += self.bias[ndx_out_channels]\n",
        "    print(f\" saida apos somar bias: {saida}\")\n",
        "    # versão com for no kernel\n",
        "\n",
        "    return saida"
      ],
      "metadata": {
        "id": "wRtpLJSFfsf8"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare se sua implementação está igual à do pytorch usando um exemplo simples"
      ],
      "metadata": {
        "id": "ROizI33sqE79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_channels_dummy = 1\n",
        "out_channels_dummy = 1\n",
        "kernel_size_dummy = 2\n",
        "stride_dummy = 1\n",
        "x = torch.arange(30).float().reshape(1, 1, 5, 6)"
      ],
      "metadata": {
        "id": "i1TuxWbkqMJc"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-FSsEC9icLX",
        "outputId": "5ff142d2-0a3a-4d18-911a-8e795b87b052"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
            "          [ 6.,  7.,  8.,  9., 10., 11.],\n",
            "          [12., 13., 14., 15., 16., 17.],\n",
            "          [18., 19., 20., 21., 22., 23.],\n",
            "          [24., 25., 26., 27., 28., 29.]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "conv_layer = MyConv2d(in_channels=in_channels_dummy, out_channels=out_channels_dummy, kernel_size=kernel_size_dummy, stride=stride_dummy)\n",
        "\n",
        "# Usa os mesmos pesos para minha implementação e a do pytorch\n",
        "initial_weights_dummy = torch.arange(in_channels_dummy * out_channels_dummy * kernel_size_dummy * kernel_size_dummy).float()\n",
        "initial_weights_dummy = initial_weights_dummy.reshape(in_channels_dummy, out_channels_dummy, kernel_size_dummy, kernel_size_dummy)\n",
        "initial_bias_dummy = torch.arange(out_channels_dummy,).float()\n",
        "\n",
        "conv_layer.weight.data = initial_weights_dummy\n",
        "conv_layer.bias.data = initial_bias_dummy\n",
        "\n",
        "out = conv_layer(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASbzrpDHiaxm",
        "outputId": "9459b727-9c33-4cbb-cd04-3ddfb0b855e9"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inicializado MyConv2d\n",
            "in_channels: 1 \n",
            "out_channels: 1 \n",
            "kernel_size: 2 \n",
            "stride: 1 \n",
            "weight.shape: torch.Size([1, 1, 2, 2]) \n",
            "weight: Parameter containing:\n",
            "tensor([[[[0.0012, 0.0035],\n",
            "          [0.0021, 0.0039]]]], requires_grad=True) \n",
            "bias.shape: torch.Size([1]) \n",
            "bias: Parameter containing:\n",
            "tensor([-0.0098], requires_grad=True) \n",
            " num_amostras: 1, self.out_channels: 1, num_linhas_entrada: 5, num_colunas_entrada: 6, num_linhas_saida: 4, num_colunas_saida: 5\n",
            "saida.shape: torch.Size([1, 1, 4, 5])\n",
            "\n",
            "ndx_amostra: 0\n",
            "\n",
            "ndx_in_channels: 0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 0\n",
            " alvo do kernel em x: x[0,0,0:2, 0:2]\n",
            " \n",
            " tensor([[0., 1.],\n",
            "        [6., 7.]])\n",
            " produto: tensor([[[[ 0.,  1.],\n",
            "          [12., 21.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[34.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 34.0\n",
            " somado na saída em [0, 0, 0, 0] = 34.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 1\n",
            " alvo do kernel em x: x[0,0,0:2, 1:3]\n",
            " \n",
            " tensor([[1., 2.],\n",
            "        [7., 8.]])\n",
            " produto: tensor([[[[ 0.,  2.],\n",
            "          [14., 24.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[40.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 40.0\n",
            " somado na saída em [0, 0, 0, 1] = 40.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 2\n",
            " alvo do kernel em x: x[0,0,0:2, 2:4]\n",
            " \n",
            " tensor([[2., 3.],\n",
            "        [8., 9.]])\n",
            " produto: tensor([[[[ 0.,  3.],\n",
            "          [16., 27.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[46.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 46.0\n",
            " somado na saída em [0, 0, 0, 2] = 46.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 3\n",
            " alvo do kernel em x: x[0,0,0:2, 3:5]\n",
            " \n",
            " tensor([[ 3.,  4.],\n",
            "        [ 9., 10.]])\n",
            " produto: tensor([[[[ 0.,  4.],\n",
            "          [18., 30.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[52.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 52.0\n",
            " somado na saída em [0, 0, 0, 3] = 52.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 4\n",
            " alvo do kernel em x: x[0,0,0:2, 4:6]\n",
            " \n",
            " tensor([[ 4.,  5.],\n",
            "        [10., 11.]])\n",
            " produto: tensor([[[[ 0.,  5.],\n",
            "          [20., 33.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[58.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 58.0\n",
            " somado na saída em [0, 0, 0, 4] = 58.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 0\n",
            " alvo do kernel em x: x[0,0,1:3, 0:2]\n",
            " \n",
            " tensor([[ 6.,  7.],\n",
            "        [12., 13.]])\n",
            " produto: tensor([[[[ 0.,  7.],\n",
            "          [24., 39.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[70.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 70.0\n",
            " somado na saída em [0, 0, 1, 0] = 70.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 1\n",
            " alvo do kernel em x: x[0,0,1:3, 1:3]\n",
            " \n",
            " tensor([[ 7.,  8.],\n",
            "        [13., 14.]])\n",
            " produto: tensor([[[[ 0.,  8.],\n",
            "          [26., 42.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[76.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 76.0\n",
            " somado na saída em [0, 0, 1, 1] = 76.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 2\n",
            " alvo do kernel em x: x[0,0,1:3, 2:4]\n",
            " \n",
            " tensor([[ 8.,  9.],\n",
            "        [14., 15.]])\n",
            " produto: tensor([[[[ 0.,  9.],\n",
            "          [28., 45.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[82.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 82.0\n",
            " somado na saída em [0, 0, 1, 2] = 82.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 3\n",
            " alvo do kernel em x: x[0,0,1:3, 3:5]\n",
            " \n",
            " tensor([[ 9., 10.],\n",
            "        [15., 16.]])\n",
            " produto: tensor([[[[ 0., 10.],\n",
            "          [30., 48.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[88.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 88.0\n",
            " somado na saída em [0, 0, 1, 3] = 88.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 4\n",
            " alvo do kernel em x: x[0,0,1:3, 4:6]\n",
            " \n",
            " tensor([[10., 11.],\n",
            "        [16., 17.]])\n",
            " produto: tensor([[[[ 0., 11.],\n",
            "          [32., 51.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[94.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 94.0\n",
            " somado na saída em [0, 0, 1, 4] = 94.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 0\n",
            " alvo do kernel em x: x[0,0,2:4, 0:2]\n",
            " \n",
            " tensor([[12., 13.],\n",
            "        [18., 19.]])\n",
            " produto: tensor([[[[ 0., 13.],\n",
            "          [36., 57.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[106.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 106.0\n",
            " somado na saída em [0, 0, 2, 0] = 106.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 1\n",
            " alvo do kernel em x: x[0,0,2:4, 1:3]\n",
            " \n",
            " tensor([[13., 14.],\n",
            "        [19., 20.]])\n",
            " produto: tensor([[[[ 0., 14.],\n",
            "          [38., 60.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[112.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 112.0\n",
            " somado na saída em [0, 0, 2, 1] = 112.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 2\n",
            " alvo do kernel em x: x[0,0,2:4, 2:4]\n",
            " \n",
            " tensor([[14., 15.],\n",
            "        [20., 21.]])\n",
            " produto: tensor([[[[ 0., 15.],\n",
            "          [40., 63.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[118.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 118.0\n",
            " somado na saída em [0, 0, 2, 2] = 118.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 3\n",
            " alvo do kernel em x: x[0,0,2:4, 3:5]\n",
            " \n",
            " tensor([[15., 16.],\n",
            "        [21., 22.]])\n",
            " produto: tensor([[[[ 0., 16.],\n",
            "          [42., 66.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[124.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 124.0\n",
            " somado na saída em [0, 0, 2, 3] = 124.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 4\n",
            " alvo do kernel em x: x[0,0,2:4, 4:6]\n",
            " \n",
            " tensor([[16., 17.],\n",
            "        [22., 23.]])\n",
            " produto: tensor([[[[ 0., 17.],\n",
            "          [44., 69.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[130.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 130.0\n",
            " somado na saída em [0, 0, 2, 4] = 130.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 0\n",
            " alvo do kernel em x: x[0,0,3:5, 0:2]\n",
            " \n",
            " tensor([[18., 19.],\n",
            "        [24., 25.]])\n",
            " produto: tensor([[[[ 0., 19.],\n",
            "          [48., 75.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[142.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 142.0\n",
            " somado na saída em [0, 0, 3, 0] = 142.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 1\n",
            " alvo do kernel em x: x[0,0,3:5, 1:3]\n",
            " \n",
            " tensor([[19., 20.],\n",
            "        [25., 26.]])\n",
            " produto: tensor([[[[ 0., 20.],\n",
            "          [50., 78.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[148.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 148.0\n",
            " somado na saída em [0, 0, 3, 1] = 148.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 2\n",
            " alvo do kernel em x: x[0,0,3:5, 2:4]\n",
            " \n",
            " tensor([[20., 21.],\n",
            "        [26., 27.]])\n",
            " produto: tensor([[[[ 0., 21.],\n",
            "          [52., 81.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[154.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 154.0\n",
            " somado na saída em [0, 0, 3, 2] = 154.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 3\n",
            " alvo do kernel em x: x[0,0,3:5, 3:5]\n",
            " \n",
            " tensor([[21., 22.],\n",
            "        [27., 28.]])\n",
            " produto: tensor([[[[ 0., 22.],\n",
            "          [54., 84.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[160.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 160.0\n",
            " somado na saída em [0, 0, 3, 3] = 160.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 4\n",
            " alvo do kernel em x: x[0,0,3:5, 4:6]\n",
            " \n",
            " tensor([[22., 23.],\n",
            "        [28., 29.]])\n",
            " produto: tensor([[[[ 0., 23.],\n",
            "          [56., 87.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[166.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 166.0\n",
            " somado na saída em [0, 0, 3, 4] = 166.0\n",
            " saida: tensor([[[[ 34.,  40.,  46.,  52.,  58.],\n",
            "          [ 70.,  76.,  82.,  88.,  94.],\n",
            "          [106., 112., 118., 124., 130.],\n",
            "          [142., 148., 154., 160., 166.]]]], grad_fn=<CopySlices>)\n",
            "\n",
            "ndx_amostra: 0\n",
            " saida apos somar bias: tensor([[[[ 34.,  40.,  46.,  52.,  58.],\n",
            "          [ 70.,  76.,  82.,  88.,  94.],\n",
            "          [106., 112., 118., 124., 130.],\n",
            "          [142., 148., 154., 160., 166.]]]], grad_fn=<CopySlices>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pytorch_conv_layer = torch.nn.Conv2d(in_channels=in_channels_dummy, out_channels=out_channels_dummy, kernel_size=kernel_size_dummy, stride=stride_dummy, padding=0)\n",
        "pytorch_conv_layer.load_state_dict(dict(weight=initial_weights_dummy, bias=initial_bias_dummy))\n",
        "target_out = pytorch_conv_layer(x)"
      ],
      "metadata": {
        "id": "xN--jid1fn-p"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blRMn_9hgIGZ",
        "outputId": "05e3cf2e-7f86-44d3-90c2-01712b755d87"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert torch.allclose(out, target_out, atol=1e-6)"
      ],
      "metadata": {
        "id": "FUgUwtXPgGaD"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare se sua implementação está igual à do pytorch usando um exemplo aleatório"
      ],
      "metadata": {
        "id": "_75UnRhdd_MW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2, in_channels, height_in, width_in)\n",
        "print(f\"x.shape: {x.shape}, x:{x}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7X_A2jeDs4f",
        "outputId": "00d6781e-f484-4362-ce9f-2a102402f308"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.shape: torch.Size([2, 1, 28, 28]), x:tensor([[[[0.0019, 0.0367, 0.7613,  ..., 0.2969, 0.0473, 0.2650],\n",
            "          [0.9732, 0.9548, 0.3147,  ..., 0.9224, 0.9866, 0.6201],\n",
            "          [0.3382, 0.2053, 0.6846,  ..., 0.2486, 0.9031, 0.8282],\n",
            "          ...,\n",
            "          [0.7676, 0.2166, 0.2992,  ..., 0.3895, 0.1751, 0.4259],\n",
            "          [0.2837, 0.1579, 0.7146,  ..., 0.1176, 0.0715, 0.4455],\n",
            "          [0.9980, 0.9825, 0.5886,  ..., 0.7503, 0.4703, 0.4557]]],\n",
            "\n",
            "\n",
            "        [[[0.1217, 0.4824, 0.2845,  ..., 0.3949, 0.0027, 0.6096],\n",
            "          [0.9385, 0.3673, 0.1423,  ..., 0.9886, 0.8045, 0.1761],\n",
            "          [0.5097, 0.4730, 0.5628,  ..., 0.1195, 0.2930, 0.6708],\n",
            "          ...,\n",
            "          [0.0356, 0.0520, 0.2423,  ..., 0.3978, 0.4956, 0.2159],\n",
            "          [0.0028, 0.4573, 0.1822,  ..., 0.5037, 0.4497, 0.7135],\n",
            "          [0.3006, 0.8984, 0.7966,  ..., 0.9287, 0.6528, 0.0585]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_layer = MyConv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride)\n",
        "conv_layer.weight.data = initial_conv_weight\n",
        "conv_layer.bias.data = initial_conv_bias\n",
        "out = conv_layer(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPL18MC-Ed9x",
        "outputId": "64af666d-e384-45f8-e62f-f3b7499ad349"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inicializado MyConv2d\n",
            "in_channels: 1 \n",
            "out_channels: 2 \n",
            "kernel_size: 5 \n",
            "stride: 3 \n",
            "weight.shape: torch.Size([1, 2, 5, 5]) \n",
            "weight: Parameter containing:\n",
            "tensor([[[[ 0.0098, -0.0064, -0.0045, -0.0048,  0.0016],\n",
            "          [ 0.0090,  0.0054, -0.0048, -0.0077,  0.0080],\n",
            "          [ 0.0046, -0.0087,  0.0081, -0.0053,  0.0079],\n",
            "          [ 0.0076, -0.0046,  0.0062, -0.0013, -0.0061],\n",
            "          [-0.0079, -0.0043,  0.0016, -0.0034,  0.0097]],\n",
            "\n",
            "         [[ 0.0042,  0.0026, -0.0078,  0.0061,  0.0053],\n",
            "          [ 0.0081,  0.0038,  0.0020,  0.0093,  0.0006],\n",
            "          [-0.0085, -0.0025, -0.0086,  0.0023,  0.0061],\n",
            "          [ 0.0079, -0.0034,  0.0076, -0.0092, -0.0092],\n",
            "          [ 0.0030,  0.0016,  0.0022, -0.0034, -0.0084]]]], requires_grad=True) \n",
            "bias.shape: torch.Size([2]) \n",
            "bias: Parameter containing:\n",
            "tensor([0.0021, 0.0065], requires_grad=True) \n",
            " num_amostras: 2, self.out_channels: 2, num_linhas_entrada: 28, num_colunas_entrada: 28, num_linhas_saida: 8, num_colunas_saida: 8\n",
            "saida.shape: torch.Size([2, 2, 8, 8])\n",
            "\n",
            "ndx_amostra: 0\n",
            "\n",
            "ndx_in_channels: 0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 0\n",
            " alvo do kernel em x: x[0,0,0:5, 0:5]\n",
            " \n",
            " tensor([[0.0019, 0.0367, 0.7613, 0.1013, 0.6424],\n",
            "        [0.9732, 0.9548, 0.3147, 0.6628, 0.1707],\n",
            "        [0.3382, 0.2053, 0.6846, 0.0996, 0.7510],\n",
            "        [0.8094, 0.5871, 0.3559, 0.7117, 0.3087],\n",
            "        [0.4166, 0.5816, 0.0036, 0.6798, 0.2174]])\n",
            " produto: tensor([[[[-7.9172e-06,  1.2149e-05, -3.7809e-03,  3.8199e-04, -5.4737e-03],\n",
            "          [ 7.1337e-03, -6.9396e-03, -2.5019e-03, -4.1879e-03,  7.7326e-04],\n",
            "          [-1.2495e-03,  7.6843e-04, -5.8102e-03, -6.0426e-04, -2.7573e-03],\n",
            "          [-1.5907e-03, -4.4786e-03,  2.3305e-03, -1.6785e-03,  9.9092e-04],\n",
            "          [ 2.9461e-03,  1.0836e-03,  9.8480e-06,  6.5621e-03, -9.8040e-04]],\n",
            "\n",
            "         [[ 6.1499e-06, -1.6318e-04,  5.4404e-03,  8.0899e-04, -5.9228e-03],\n",
            "          [ 8.3073e-03,  4.5591e-03,  1.3713e-03,  2.7284e-03,  1.4193e-03],\n",
            "          [-4.4653e-04, -1.7366e-03, -1.9644e-03, -7.0141e-04,  4.9643e-04],\n",
            "          [-1.5112e-03, -3.1490e-03, -3.2361e-04,  6.7431e-03, -2.4350e-04],\n",
            "          [ 1.3228e-04, -9.0712e-04,  5.6616e-06,  6.0574e-03,  1.3293e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0190]],\n",
            "\n",
            "         [[ 0.0223]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0190,  0.0223], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 0] = -0.01904863491654396\n",
            " somado na saída em [0, 1, 0, 0] = 0.02233579382300377\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 1\n",
            " alvo do kernel em x: x[0,0,0:5, 1:6]\n",
            " \n",
            " tensor([[0.0367, 0.7613, 0.1013, 0.6424, 0.2690],\n",
            "        [0.9548, 0.3147, 0.6628, 0.1707, 0.3211],\n",
            "        [0.2053, 0.6846, 0.0996, 0.7510, 0.6047],\n",
            "        [0.5871, 0.3559, 0.7117, 0.3087, 0.7022],\n",
            "        [0.5816, 0.0036, 0.6798, 0.2174, 0.8950]])\n",
            " produto: tensor([[[[-1.4956e-04,  2.5217e-04, -5.0308e-04,  2.4226e-03, -2.2921e-03],\n",
            "          [ 6.9989e-03, -2.2873e-03, -5.2692e-03, -1.0789e-03,  1.4540e-03],\n",
            "          [-7.5873e-04,  2.5618e-03, -8.4528e-04, -4.5562e-03, -2.2204e-03],\n",
            "          [-1.1537e-03, -2.7152e-03,  4.6604e-03, -7.2803e-04,  2.2541e-03],\n",
            "          [ 4.1130e-03,  6.7096e-06,  1.8590e-03,  2.0983e-03, -4.0367e-03]],\n",
            "\n",
            "         [[ 1.1617e-04, -3.3870e-03,  7.2389e-04,  5.1306e-03, -2.4802e-03],\n",
            "          [ 8.1503e-03,  1.5027e-03,  2.8881e-03,  7.0288e-04,  2.6689e-03],\n",
            "          [-2.7114e-04, -5.7895e-03, -2.8578e-04, -5.2888e-03,  3.9976e-04],\n",
            "          [-1.0961e-03, -1.9091e-03, -6.4713e-04,  2.9247e-03, -5.5390e-04],\n",
            "          [ 1.8467e-04, -5.6167e-06,  1.0687e-03,  1.9369e-03,  5.4731e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[8.6621e-05]],\n",
            "\n",
            "         [[1.2157e-02]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([8.6621e-05, 1.2157e-02], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 1] = 8.662138134241104e-05\n",
            " somado na saída em [0, 1, 0, 1] = 0.012157204560935497\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 2\n",
            " alvo do kernel em x: x[0,0,0:5, 2:7]\n",
            " \n",
            " tensor([[0.7613, 0.1013, 0.6424, 0.2690, 0.7972],\n",
            "        [0.3147, 0.6628, 0.1707, 0.3211, 0.7584],\n",
            "        [0.6846, 0.0996, 0.7510, 0.6047, 0.8701],\n",
            "        [0.3559, 0.7117, 0.3087, 0.7022, 0.1311],\n",
            "        [0.0036, 0.6798, 0.2174, 0.8950, 0.4227]])\n",
            " produto: tensor([[[[-3.1043e-03,  3.3553e-05, -3.1906e-03,  1.0145e-03, -6.7928e-03],\n",
            "          [ 2.3068e-03, -4.8172e-03, -1.3574e-03, -2.0287e-03,  3.4350e-03],\n",
            "          [-2.5295e-03,  3.7269e-04, -6.3735e-03, -3.6690e-03, -3.1947e-03],\n",
            "          [-6.9946e-04, -5.4296e-03,  2.0214e-03, -1.6561e-03,  4.2070e-04],\n",
            "          [ 2.5467e-05,  1.2666e-03,  5.9442e-04,  8.6394e-03, -1.9063e-03]],\n",
            "\n",
            "         [[ 2.4113e-03, -4.5067e-04,  4.5910e-03,  2.1485e-03, -7.3502e-03],\n",
            "          [ 2.6863e-03,  3.1648e-03,  7.4402e-04,  1.3217e-03,  6.3050e-03],\n",
            "          [-9.0392e-04, -8.4226e-04, -2.1548e-03, -4.2589e-03,  5.7518e-04],\n",
            "          [-6.6453e-04, -3.8177e-03, -2.8068e-04,  6.6531e-03, -1.0338e-04],\n",
            "          [ 1.1434e-06, -1.0603e-03,  3.4173e-04,  7.9749e-03,  2.5846e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0266]],\n",
            "\n",
            "         [[ 0.0196]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0266,  0.0196], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 2] = -0.02661876380443573\n",
            " somado na saída em [0, 1, 0, 2] = 0.01961587369441986\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 3\n",
            " alvo do kernel em x: x[0,0,0:5, 3:8]\n",
            " \n",
            " tensor([[0.1013, 0.6424, 0.2690, 0.7972, 0.4132],\n",
            "        [0.6628, 0.1707, 0.3211, 0.7584, 0.0487],\n",
            "        [0.0996, 0.7510, 0.6047, 0.8701, 0.2930],\n",
            "        [0.7117, 0.3087, 0.7022, 0.1311, 0.7808],\n",
            "        [0.6798, 0.2174, 0.8950, 0.4227, 0.7595]])\n",
            " produto: tensor([[[[-0.0004,  0.0002, -0.0013,  0.0030, -0.0035],\n",
            "          [ 0.0049, -0.0012, -0.0026, -0.0048,  0.0002],\n",
            "          [-0.0004,  0.0028, -0.0051, -0.0053, -0.0011],\n",
            "          [-0.0014, -0.0024,  0.0046, -0.0003,  0.0025],\n",
            "          [ 0.0048,  0.0004,  0.0024,  0.0041, -0.0034]],\n",
            "\n",
            "         [[ 0.0003, -0.0029,  0.0019,  0.0064, -0.0038],\n",
            "          [ 0.0057,  0.0008,  0.0014,  0.0031,  0.0004],\n",
            "          [-0.0001, -0.0064, -0.0017, -0.0061,  0.0002],\n",
            "          [-0.0013, -0.0017, -0.0006,  0.0012, -0.0006],\n",
            "          [ 0.0002, -0.0003,  0.0014,  0.0038,  0.0046]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0032]],\n",
            "\n",
            "         [[ 0.0059]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0032,  0.0059], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 3] = -0.003246808424592018\n",
            " somado na saída em [0, 1, 0, 3] = 0.00588702317327261\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 4\n",
            " alvo do kernel em x: x[0,0,0:5, 4:9]\n",
            " \n",
            " tensor([[0.6424, 0.2690, 0.7972, 0.4132, 0.6962],\n",
            "        [0.1707, 0.3211, 0.7584, 0.0487, 0.1954],\n",
            "        [0.7510, 0.6047, 0.8701, 0.2930, 0.3102],\n",
            "        [0.3087, 0.7022, 0.1311, 0.7808, 0.7739],\n",
            "        [0.2174, 0.8950, 0.4227, 0.7595, 0.9195]])\n",
            " produto: tensor([[[[-2.6196e-03,  8.9109e-05, -3.9595e-03,  1.5581e-03, -5.9319e-03],\n",
            "          [ 1.2516e-03, -2.3335e-03, -6.0300e-03, -3.0755e-04,  8.8486e-04],\n",
            "          [-2.7747e-03,  2.2629e-03, -7.3847e-03, -1.7779e-03, -1.1390e-03],\n",
            "          [-6.0668e-04, -5.3572e-03,  8.5819e-04, -1.8414e-03,  2.4843e-03],\n",
            "          [ 1.5372e-03,  1.6675e-03,  1.1558e-03,  7.3311e-03, -4.1470e-03]],\n",
            "\n",
            "         [[ 2.0348e-03, -1.1969e-03,  5.6974e-03,  3.2998e-03, -6.4187e-03],\n",
            "          [ 1.4575e-03,  1.5331e-03,  3.3051e-03,  2.0037e-04,  1.6242e-03],\n",
            "          [-9.9155e-04, -5.1141e-03, -2.4967e-03, -2.0638e-03,  2.0506e-04],\n",
            "          [-5.7639e-04, -3.7667e-03, -1.1916e-04,  7.3973e-03, -6.1045e-04],\n",
            "          [ 6.9018e-05, -1.3959e-03,  6.6447e-04,  6.7672e-03,  5.6226e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0251]],\n",
            "\n",
            "         [[ 0.0151]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0251,  0.0151], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 4] = -0.025129875168204308\n",
            " somado na saída em [0, 1, 0, 4] = 0.015127552673220634\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 5\n",
            " alvo do kernel em x: x[0,0,0:5, 5:10]\n",
            " \n",
            " tensor([[0.2690, 0.7972, 0.4132, 0.6962, 0.4461],\n",
            "        [0.3211, 0.7584, 0.0487, 0.1954, 0.6941],\n",
            "        [0.6047, 0.8701, 0.2930, 0.3102, 0.8282],\n",
            "        [0.7022, 0.1311, 0.7808, 0.7739, 0.5650],\n",
            "        [0.8950, 0.4227, 0.7595, 0.9195, 0.9969]])\n",
            " produto: tensor([[[[-0.0011,  0.0003, -0.0021,  0.0026, -0.0038],\n",
            "          [ 0.0024, -0.0055, -0.0004, -0.0012,  0.0031],\n",
            "          [-0.0022,  0.0033, -0.0025, -0.0019, -0.0030],\n",
            "          [-0.0014, -0.0010,  0.0051, -0.0018,  0.0018],\n",
            "          [ 0.0063,  0.0008,  0.0021,  0.0089, -0.0045]],\n",
            "\n",
            "         [[ 0.0009, -0.0035,  0.0030,  0.0056, -0.0041],\n",
            "          [ 0.0027,  0.0036,  0.0002,  0.0008,  0.0058],\n",
            "          [-0.0008, -0.0074, -0.0008, -0.0022,  0.0005],\n",
            "          [-0.0013, -0.0007, -0.0007,  0.0073, -0.0004],\n",
            "          [ 0.0003, -0.0007,  0.0012,  0.0082,  0.0061]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[0.0042]],\n",
            "\n",
            "         [[0.0235]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([0.0042, 0.0235], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 5] = 0.004208043683320284\n",
            " somado na saída em [0, 1, 0, 5] = 0.023489277809858322\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 6\n",
            " alvo do kernel em x: x[0,0,0:5, 6:11]\n",
            " \n",
            " tensor([[0.7972, 0.4132, 0.6962, 0.4461, 0.6978],\n",
            "        [0.7584, 0.0487, 0.1954, 0.6941, 0.4569],\n",
            "        [0.8701, 0.2930, 0.3102, 0.8282, 0.5365],\n",
            "        [0.1311, 0.7808, 0.7739, 0.5650, 0.5079],\n",
            "        [0.4227, 0.7595, 0.9195, 0.9969, 0.0508]])\n",
            " produto: tensor([[[[-0.0033,  0.0001, -0.0035,  0.0017, -0.0059],\n",
            "          [ 0.0056, -0.0004, -0.0016, -0.0044,  0.0021],\n",
            "          [-0.0032,  0.0011, -0.0026, -0.0050, -0.0020],\n",
            "          [-0.0003, -0.0060,  0.0051, -0.0013,  0.0016],\n",
            "          [ 0.0030,  0.0014,  0.0025,  0.0096, -0.0002]],\n",
            "\n",
            "         [[ 0.0025, -0.0018,  0.0050,  0.0036, -0.0064],\n",
            "          [ 0.0065,  0.0002,  0.0009,  0.0029,  0.0038],\n",
            "          [-0.0011, -0.0025, -0.0009, -0.0058,  0.0004],\n",
            "          [-0.0002, -0.0042, -0.0007,  0.0054, -0.0004],\n",
            "          [ 0.0001, -0.0012,  0.0014,  0.0089,  0.0003]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0058]],\n",
            "\n",
            "         [[ 0.0164]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0058,  0.0164], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 6] = -0.005781738553196192\n",
            " somado na saída em [0, 1, 0, 6] = 0.016413941979408264\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 7\n",
            " alvo do kernel em x: x[0,0,0:5, 7:12]\n",
            " \n",
            " tensor([[0.4132, 0.6962, 0.4461, 0.6978, 0.4535],\n",
            "        [0.0487, 0.1954, 0.6941, 0.4569, 0.6867],\n",
            "        [0.2930, 0.3102, 0.8282, 0.5365, 0.4530],\n",
            "        [0.7808, 0.7739, 0.5650, 0.5079, 0.1426],\n",
            "        [0.7595, 0.9195, 0.9969, 0.0508, 0.8124]])\n",
            " produto: tensor([[[[-0.0017,  0.0002, -0.0022,  0.0026, -0.0039],\n",
            "          [ 0.0004, -0.0014, -0.0055, -0.0029,  0.0031],\n",
            "          [-0.0011,  0.0012, -0.0070, -0.0033, -0.0017],\n",
            "          [-0.0015, -0.0059,  0.0037, -0.0012,  0.0005],\n",
            "          [ 0.0054,  0.0017,  0.0027,  0.0005, -0.0037]],\n",
            "\n",
            "         [[ 0.0013, -0.0031,  0.0032,  0.0056, -0.0042],\n",
            "          [ 0.0004,  0.0009,  0.0030,  0.0019,  0.0057],\n",
            "          [-0.0004, -0.0026, -0.0024, -0.0038,  0.0003],\n",
            "          [-0.0015, -0.0042, -0.0005,  0.0048, -0.0001],\n",
            "          [ 0.0002, -0.0014,  0.0016,  0.0005,  0.0050]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0210]],\n",
            "\n",
            "         [[ 0.0103]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0210,  0.0103], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 7] = -0.02097209170460701\n",
            " somado na saída em [0, 1, 0, 7] = 0.010259551927447319\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 0\n",
            " alvo do kernel em x: x[0,0,1:6, 0:5]\n",
            " \n",
            " tensor([[0.9732, 0.9548, 0.3147, 0.6628, 0.1707],\n",
            "        [0.3382, 0.2053, 0.6846, 0.0996, 0.7510],\n",
            "        [0.8094, 0.5871, 0.3559, 0.7117, 0.3087],\n",
            "        [0.4166, 0.5816, 0.0036, 0.6798, 0.2174],\n",
            "        [0.3212, 0.3049, 0.5938, 0.9811, 0.6770]])\n",
            " produto: tensor([[[[-3.9683e-03,  3.1626e-04, -1.5629e-03,  2.4994e-03, -1.4548e-03],\n",
            "          [ 2.4790e-03, -1.4925e-03, -5.4427e-03, -6.2932e-04,  3.4010e-03],\n",
            "          [-2.9907e-03,  2.1969e-03, -3.0208e-03, -4.3183e-03, -1.1335e-03],\n",
            "          [-8.1875e-04, -4.4371e-03,  2.3581e-05, -1.6033e-03,  6.9776e-04],\n",
            "          [ 2.2717e-03,  5.6801e-04,  1.6236e-03,  9.4701e-03, -3.0535e-03]],\n",
            "\n",
            "         [[ 3.0825e-03, -4.2479e-03,  2.2489e-03,  5.2932e-03, -1.5742e-03],\n",
            "          [ 2.8868e-03,  9.8055e-04,  2.9832e-03,  4.1000e-04,  6.2427e-03],\n",
            "          [-1.0687e-03, -4.9649e-03, -1.0213e-03, -5.0126e-03,  2.0408e-04],\n",
            "          [-7.7787e-04, -3.1198e-03, -3.2744e-06,  6.4408e-03, -1.7146e-04],\n",
            "          [ 1.0200e-04, -4.7549e-04,  9.3343e-04,  8.7416e-03,  4.1400e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0104]],\n",
            "\n",
            "         [[ 0.0223]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0104,  0.0223], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 0] = -0.010379176586866379\n",
            " somado na saída em [0, 1, 1, 0] = 0.022252157330513\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 1\n",
            " alvo do kernel em x: x[0,0,1:6, 1:6]\n",
            " \n",
            " tensor([[0.9548, 0.3147, 0.6628, 0.1707, 0.3211],\n",
            "        [0.2053, 0.6846, 0.0996, 0.7510, 0.6047],\n",
            "        [0.5871, 0.3559, 0.7117, 0.3087, 0.7022],\n",
            "        [0.5816, 0.0036, 0.6798, 0.2174, 0.8950],\n",
            "        [0.3049, 0.5938, 0.9811, 0.6770, 0.6254]])\n",
            " produto: tensor([[[[-3.8933e-03,  1.0424e-04, -3.2917e-03,  6.4387e-04, -2.7355e-03],\n",
            "          [ 1.5053e-03, -4.9758e-03, -7.9181e-04, -4.7452e-03,  2.7387e-03],\n",
            "          [-2.1692e-03,  1.3319e-03, -6.0408e-03, -1.8730e-03, -2.5785e-03],\n",
            "          [-1.1430e-03, -2.7474e-05,  4.4515e-03, -5.1265e-04,  2.8729e-03],\n",
            "          [ 2.1559e-03,  1.1062e-03,  2.6828e-03,  6.5351e-03, -2.8208e-03]],\n",
            "\n",
            "         [[ 3.0242e-03, -1.4001e-03,  4.7364e-03,  1.3636e-03, -2.9600e-03],\n",
            "          [ 1.7529e-03,  3.2690e-03,  4.3400e-04,  3.0915e-03,  5.0270e-03],\n",
            "          [-7.7517e-04, -3.0100e-03, -2.0423e-03, -2.1742e-03,  4.6423e-04],\n",
            "          [-1.0860e-03, -1.9317e-05, -6.1811e-04,  2.0595e-03, -7.0596e-04],\n",
            "          [ 9.6799e-05, -9.2603e-04,  1.5423e-03,  6.0324e-03,  3.8245e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0115]],\n",
            "\n",
            "         [[ 0.0210]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0115,  0.0210], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 1] = -0.011470207944512367\n",
            " somado na saída em [0, 1, 1, 1] = 0.02100122533738613\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 2\n",
            " alvo do kernel em x: x[0,0,1:6, 2:7]\n",
            " \n",
            " tensor([[0.3147, 0.6628, 0.1707, 0.3211, 0.7584],\n",
            "        [0.6846, 0.0996, 0.7510, 0.6047, 0.8701],\n",
            "        [0.3559, 0.7117, 0.3087, 0.7022, 0.1311],\n",
            "        [0.0036, 0.6798, 0.2174, 0.8950, 0.4227],\n",
            "        [0.5938, 0.9811, 0.6770, 0.6254, 0.1409]])\n",
            " produto: tensor([[[[-1.2832e-03,  2.1954e-04, -8.4798e-04,  1.2107e-03, -6.4624e-03],\n",
            "          [ 5.0183e-03, -7.2388e-04, -5.9704e-03, -3.8212e-03,  3.9406e-03],\n",
            "          [-1.3151e-03,  2.6634e-03, -2.6201e-03, -4.2607e-03, -4.8123e-04],\n",
            "          [-7.0774e-06, -5.1862e-03,  1.4234e-03, -2.1108e-03,  1.3567e-03],\n",
            "          [ 4.1987e-03,  1.8278e-03,  1.8513e-03,  6.0371e-03, -6.3538e-04]],\n",
            "\n",
            "         [[ 9.9677e-04, -2.9487e-03,  1.2202e-03,  2.5641e-03, -6.9927e-03],\n",
            "          [ 5.8439e-03,  4.7557e-04,  3.2724e-03,  2.4895e-03,  7.2330e-03],\n",
            "          [-4.6996e-04, -6.0192e-03, -8.8584e-04, -4.9458e-03,  8.6641e-05],\n",
            "          [-6.7240e-06, -3.6465e-03, -1.9764e-04,  8.4796e-03, -3.3339e-04],\n",
            "          [ 1.8852e-04, -1.5301e-03,  1.0643e-03,  5.5727e-03,  8.6147e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0060]],\n",
            "\n",
            "         [[ 0.0124]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0060,  0.0124], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 2] = -0.005977960303425789\n",
            " somado na saída em [0, 1, 1, 2] = 0.012372156605124474\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 3\n",
            " alvo do kernel em x: x[0,0,1:6, 3:8]\n",
            " \n",
            " tensor([[0.6628, 0.1707, 0.3211, 0.7584, 0.0487],\n",
            "        [0.0996, 0.7510, 0.6047, 0.8701, 0.2930],\n",
            "        [0.7117, 0.3087, 0.7022, 0.1311, 0.7808],\n",
            "        [0.6798, 0.2174, 0.8950, 0.4227, 0.7595],\n",
            "        [0.9811, 0.6770, 0.6254, 0.1409, 0.0744]])\n",
            " produto: tensor([[[[-2.7026e-03,  5.6556e-05, -1.5945e-03,  2.8602e-03, -4.1472e-04],\n",
            "          [ 7.3006e-04, -5.4582e-03, -4.8078e-03, -5.4980e-03,  1.3271e-03],\n",
            "          [-2.6298e-03,  1.1552e-03, -5.9602e-03, -7.9519e-04, -2.8669e-03],\n",
            "          [-1.3360e-03, -1.6583e-03,  5.8606e-03, -9.9680e-04,  2.4379e-03],\n",
            "          [ 6.9377e-03,  1.2613e-03,  1.7103e-03,  1.3598e-03, -3.3565e-04]],\n",
            "\n",
            "         [[ 2.0993e-03, -7.5964e-04,  2.2944e-03,  6.0574e-03, -4.4875e-04],\n",
            "          [ 8.5017e-04,  3.5859e-03,  2.6352e-03,  3.5819e-03,  2.4360e-03],\n",
            "          [-9.3978e-04, -2.6108e-03, -2.0151e-03, -9.2304e-04,  5.1616e-04],\n",
            "          [-1.2693e-03, -1.1660e-03, -8.1378e-04,  4.0044e-03, -5.9906e-04],\n",
            "          [ 3.1150e-04, -1.0559e-03,  9.8323e-04,  1.2553e-03,  4.5508e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0114]],\n",
            "\n",
            "         [[ 0.0185]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0114,  0.0185], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 3] = -0.011357760988175869\n",
            " somado na saída em [0, 1, 1, 3] = 0.01846480555832386\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 4\n",
            " alvo do kernel em x: x[0,0,1:6, 4:9]\n",
            " \n",
            " tensor([[0.1707, 0.3211, 0.7584, 0.0487, 0.1954],\n",
            "        [0.7510, 0.6047, 0.8701, 0.2930, 0.3102],\n",
            "        [0.3087, 0.7022, 0.1311, 0.7808, 0.7739],\n",
            "        [0.2174, 0.8950, 0.4227, 0.7595, 0.9195],\n",
            "        [0.6770, 0.6254, 0.1409, 0.0744, 0.0681]])\n",
            " produto: tensor([[[[-0.0007,  0.0001, -0.0038,  0.0002, -0.0017],\n",
            "          [ 0.0055, -0.0044, -0.0069, -0.0019,  0.0014],\n",
            "          [-0.0011,  0.0026, -0.0011, -0.0047, -0.0028],\n",
            "          [-0.0004, -0.0068,  0.0028, -0.0018,  0.0030],\n",
            "          [ 0.0048,  0.0012,  0.0004,  0.0007, -0.0003]],\n",
            "\n",
            "         [[ 0.0005, -0.0014,  0.0054,  0.0004, -0.0018],\n",
            "          [ 0.0064,  0.0029,  0.0038,  0.0012,  0.0026],\n",
            "          [-0.0004, -0.0059, -0.0004, -0.0055,  0.0005],\n",
            "          [-0.0004, -0.0048, -0.0004,  0.0072, -0.0007],\n",
            "          [ 0.0002, -0.0010,  0.0002,  0.0007,  0.0004]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0159]],\n",
            "\n",
            "         [[ 0.0097]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0159,  0.0097], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 4] = -0.015874797478318214\n",
            " somado na saída em [0, 1, 1, 4] = 0.009704525582492352\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 5\n",
            " alvo do kernel em x: x[0,0,1:6, 5:10]\n",
            " \n",
            " tensor([[3.2105e-01, 7.5845e-01, 4.8672e-02, 1.9538e-01, 6.9405e-01],\n",
            "        [6.0472e-01, 8.7009e-01, 2.9303e-01, 3.1020e-01, 8.2819e-01],\n",
            "        [7.0225e-01, 1.3106e-01, 7.8080e-01, 7.7394e-01, 5.6502e-01],\n",
            "        [8.9503e-01, 4.2267e-01, 7.5950e-01, 9.1949e-01, 9.9687e-01],\n",
            "        [6.2544e-01, 1.4088e-01, 7.4422e-02, 6.8094e-02, 4.5097e-04]])\n",
            " produto: tensor([[[[-1.3092e-03,  2.5123e-04, -2.4174e-04,  7.3680e-04, -5.9137e-03],\n",
            "          [ 4.4329e-03, -6.3241e-03, -2.3297e-03, -1.9601e-03,  3.7508e-03],\n",
            "          [-2.5947e-03,  4.9045e-04, -6.6268e-03, -4.6957e-03, -2.0746e-03],\n",
            "          [-1.7589e-03, -3.2244e-03,  4.9731e-03, -2.1685e-03,  3.1998e-03],\n",
            "          [ 4.4228e-03,  2.6247e-04,  2.0351e-04,  6.5729e-04, -2.0339e-06]],\n",
            "\n",
            "         [[ 1.0169e-03, -3.3745e-03,  3.4784e-04,  1.5604e-03, -6.3990e-03],\n",
            "          [ 5.1622e-03,  4.1548e-03,  1.2769e-03,  1.2770e-03,  6.8847e-03],\n",
            "          [-9.2724e-04, -1.1084e-03, -2.2405e-03, -5.4507e-03,  3.7351e-04],\n",
            "          [-1.6711e-03, -2.2672e-03, -6.9055e-04,  8.7113e-03, -7.8629e-04],\n",
            "          [ 1.9858e-04, -2.1972e-04,  1.1700e-04,  6.0673e-04,  2.7576e-06]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0178]],\n",
            "\n",
            "         [[ 0.0066]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0178,  0.0066], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 5] = -0.01784316450357437\n",
            " somado na saída em [0, 1, 1, 5] = 0.006555669475346804\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 6\n",
            " alvo do kernel em x: x[0,0,1:6, 6:11]\n",
            " \n",
            " tensor([[7.5845e-01, 4.8672e-02, 1.9538e-01, 6.9405e-01, 4.5693e-01],\n",
            "        [8.7009e-01, 2.9303e-01, 3.1020e-01, 8.2819e-01, 5.3646e-01],\n",
            "        [1.3106e-01, 7.8080e-01, 7.7394e-01, 5.6502e-01, 5.0786e-01],\n",
            "        [4.2267e-01, 7.5950e-01, 9.1949e-01, 9.9687e-01, 5.0818e-02],\n",
            "        [1.4088e-01, 7.4422e-02, 6.8094e-02, 4.5097e-04, 2.7528e-01]])\n",
            " produto: tensor([[[[-3.0928e-03,  1.6123e-05, -9.7037e-04,  2.6174e-03, -3.8933e-03],\n",
            "          [ 6.3781e-03, -2.1299e-03, -2.4662e-03, -5.2332e-03,  2.4296e-03],\n",
            "          [-4.8427e-04,  2.9218e-03, -6.5687e-03, -3.4281e-03, -1.8648e-03],\n",
            "          [-8.3064e-04, -5.7939e-03,  6.0208e-03, -2.3509e-03,  1.6312e-04],\n",
            "          [ 9.9622e-04,  1.3865e-04,  1.8620e-04,  4.3530e-06, -1.2416e-03]],\n",
            "\n",
            "         [[ 2.4024e-03, -2.1655e-04,  1.3963e-03,  5.5431e-03, -4.2128e-03],\n",
            "          [ 7.4274e-03,  1.3993e-03,  1.3517e-03,  3.4094e-03,  4.4596e-03],\n",
            "          [-1.7305e-04, -6.6032e-03, -2.2208e-03, -3.9793e-03,  3.3573e-04],\n",
            "          [-7.8916e-04, -4.0738e-03, -8.3602e-04,  9.4444e-03, -4.0083e-05],\n",
            "          [ 4.4729e-05, -1.1607e-04,  1.0705e-04,  4.0182e-06,  1.6833e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0185]],\n",
            "\n",
            "         [[ 0.0157]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0185,  0.0157], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 6] = -0.018476203083992004\n",
            " somado na saída em [0, 1, 1, 6] = 0.015747740864753723\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 7\n",
            " alvo do kernel em x: x[0,0,1:6, 7:12]\n",
            " \n",
            " tensor([[4.8672e-02, 1.9538e-01, 6.9405e-01, 4.5693e-01, 6.8672e-01],\n",
            "        [2.9303e-01, 3.1020e-01, 8.2819e-01, 5.3646e-01, 4.5296e-01],\n",
            "        [7.8080e-01, 7.7394e-01, 5.6502e-01, 5.0786e-01, 1.4265e-01],\n",
            "        [7.5950e-01, 9.1949e-01, 9.9687e-01, 5.0818e-02, 8.1244e-01],\n",
            "        [7.4422e-02, 6.8094e-02, 4.5097e-04, 2.7528e-01, 1.6445e-01]])\n",
            " produto: tensor([[[[-1.9847e-04,  6.4718e-05, -3.4471e-03,  1.7231e-03, -5.8513e-03],\n",
            "          [ 2.1481e-03, -2.2547e-03, -6.5844e-03, -3.3898e-03,  2.0514e-03],\n",
            "          [-2.8850e-03,  2.8962e-03, -4.7955e-03, -3.0813e-03, -5.2377e-04],\n",
            "          [-1.4926e-03, -7.0145e-03,  6.5274e-03, -1.1985e-04,  2.6078e-03],\n",
            "          [ 5.2627e-04,  1.2686e-04,  1.2332e-06,  2.6572e-03, -7.4169e-04]],\n",
            "\n",
            "         [[ 1.5417e-04, -8.6927e-04,  4.9600e-03,  3.6493e-03, -6.3314e-03],\n",
            "          [ 2.5015e-03,  1.4812e-03,  3.6090e-03,  2.2085e-03,  3.7655e-03],\n",
            "          [-1.0310e-03, -6.5452e-03, -1.6213e-03, -3.5768e-03,  9.4299e-05],\n",
            "          [-1.4180e-03, -4.9320e-03, -9.0637e-04,  4.8145e-04, -6.4082e-04],\n",
            "          [ 2.3629e-05, -1.0620e-04,  7.0895e-07,  2.4528e-03,  1.0056e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0210]],\n",
            "\n",
            "         [[-0.0016]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0210, -0.0016], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 7] = -0.021049480885267258\n",
            " somado na saída em [0, 1, 1, 7] = -0.0015907646156847477\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 0\n",
            " alvo do kernel em x: x[0,0,2:7, 0:5]\n",
            " \n",
            " tensor([[0.3382, 0.2053, 0.6846, 0.0996, 0.7510],\n",
            "        [0.8094, 0.5871, 0.3559, 0.7117, 0.3087],\n",
            "        [0.4166, 0.5816, 0.0036, 0.6798, 0.2174],\n",
            "        [0.3212, 0.3049, 0.5938, 0.9811, 0.6770],\n",
            "        [0.8693, 0.5654, 0.1892, 0.7047, 0.9982]])\n",
            " produto: tensor([[[[-1.3790e-03,  6.8020e-05, -3.4000e-03,  3.7558e-04, -6.3985e-03],\n",
            "          [ 5.9333e-03, -4.2671e-03, -2.8297e-03, -4.4974e-03,  1.3981e-03],\n",
            "          [-1.5394e-03,  2.1765e-03, -3.0566e-05, -4.1247e-03, -7.9816e-04],\n",
            "          [-6.3132e-04, -2.3258e-03,  3.8879e-03, -2.3137e-03,  2.1732e-03],\n",
            "          [ 6.1472e-03,  1.0533e-03,  5.1727e-04,  6.8018e-03, -4.5021e-03]],\n",
            "\n",
            "         [[ 1.0712e-03, -9.1361e-04,  4.8923e-03,  7.9541e-04, -6.9236e-03],\n",
            "          [ 6.9095e-03,  2.8034e-03,  1.5510e-03,  2.9301e-03,  2.5663e-03],\n",
            "          [-5.5011e-04, -4.9189e-03, -1.0334e-05, -4.7879e-03,  1.4370e-04],\n",
            "          [-5.9979e-04, -1.6353e-03, -5.3985e-04,  9.2949e-03, -5.3401e-04],\n",
            "          [ 2.7600e-04, -8.8172e-04,  2.9738e-04,  6.2786e-03,  6.1040e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0085]],\n",
            "\n",
            "         [[ 0.0236]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0085,  0.0236], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 0] = -0.008505359292030334\n",
            " somado na saída em [0, 1, 2, 0] = 0.023618698120117188\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 1\n",
            " alvo do kernel em x: x[0,0,2:7, 1:6]\n",
            " \n",
            " tensor([[0.2053, 0.6846, 0.0996, 0.7510, 0.6047],\n",
            "        [0.5871, 0.3559, 0.7117, 0.3087, 0.7022],\n",
            "        [0.5816, 0.0036, 0.6798, 0.2174, 0.8950],\n",
            "        [0.3049, 0.5938, 0.9811, 0.6770, 0.6254],\n",
            "        [0.5654, 0.1892, 0.7047, 0.9982, 0.9563]])\n",
            " produto: tensor([[[[-8.3735e-04,  2.2676e-04, -4.9464e-04,  2.8319e-03, -5.1526e-03],\n",
            "          [ 4.3035e-03, -2.5870e-03, -5.6586e-03, -1.9507e-03,  3.1804e-03],\n",
            "          [-2.1491e-03,  1.3477e-05, -5.7699e-03, -1.3189e-03, -3.2864e-03],\n",
            "          [-5.9914e-04, -4.5296e-03,  6.4241e-03, -1.5966e-03,  2.0076e-03],\n",
            "          [ 3.9978e-03,  3.5243e-04,  1.9269e-03,  9.6354e-03, -4.3130e-03]],\n",
            "\n",
            "         [[ 6.5043e-04, -3.0458e-03,  7.1174e-04,  5.9975e-03, -5.5754e-03],\n",
            "          [ 5.0115e-03,  1.6996e-03,  3.1015e-03,  1.2709e-03,  5.8378e-03],\n",
            "          [-7.6799e-04, -3.0457e-05, -1.9508e-03, -1.5309e-03,  5.9168e-04],\n",
            "          [-5.6923e-04, -3.1848e-03, -8.9202e-04,  6.4142e-03, -4.9332e-04],\n",
            "          [ 1.7950e-04, -2.9502e-04,  1.1078e-03,  8.8943e-03,  5.8477e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0053]],\n",
            "\n",
            "         [[ 0.0290]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0053,  0.0290], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 1] = -0.005343128927052021\n",
            " somado na saída em [0, 1, 2, 1] = 0.028980351984500885\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 2\n",
            " alvo do kernel em x: x[0,0,2:7, 2:7]\n",
            " \n",
            " tensor([[0.6846, 0.0996, 0.7510, 0.6047, 0.8701],\n",
            "        [0.3559, 0.7117, 0.3087, 0.7022, 0.1311],\n",
            "        [0.0036, 0.6798, 0.2174, 0.8950, 0.4227],\n",
            "        [0.5938, 0.9811, 0.6770, 0.6254, 0.1409],\n",
            "        [0.1892, 0.7047, 0.9982, 0.9563, 0.6654]])\n",
            " produto: tensor([[[[-2.7916e-03,  3.2990e-05, -3.7297e-03,  2.2805e-03, -7.4136e-03],\n",
            "          [ 2.6091e-03, -5.1732e-03, -2.4544e-03, -4.4374e-03,  5.9358e-04],\n",
            "          [-1.3307e-05,  2.5440e-03, -1.8450e-03, -5.4304e-03, -1.5520e-03],\n",
            "          [-1.1668e-03, -7.4844e-03,  4.4331e-03, -1.4750e-03,  4.5220e-04],\n",
            "          [ 1.3377e-03,  1.3128e-03,  2.7296e-03,  9.2308e-03, -3.0009e-03]],\n",
            "\n",
            "         [[ 2.1684e-03, -4.4311e-04,  5.3667e-03,  4.8296e-03, -8.0219e-03],\n",
            "          [ 3.0383e-03,  3.3987e-03,  1.3453e-03,  2.8910e-03,  1.0895e-03],\n",
            "          [-4.7552e-06, -5.7493e-03, -6.2377e-04, -6.3035e-03,  2.7942e-04],\n",
            "          [-1.1086e-03, -5.2624e-03, -6.1556e-04,  5.9254e-03, -1.1112e-04],\n",
            "          [ 6.0060e-05, -1.0990e-03,  1.5693e-03,  8.5207e-03,  4.0687e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0204]],\n",
            "\n",
            "         [[ 0.0152]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0204,  0.0152], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 2] = -0.02041122317314148\n",
            " somado na saída em [0, 1, 2, 2] = 0.015208043158054352\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 3\n",
            " alvo do kernel em x: x[0,0,2:7, 3:8]\n",
            " \n",
            " tensor([[0.0996, 0.7510, 0.6047, 0.8701, 0.2930],\n",
            "        [0.7117, 0.3087, 0.7022, 0.1311, 0.7808],\n",
            "        [0.6798, 0.2174, 0.8950, 0.4227, 0.7595],\n",
            "        [0.9811, 0.6770, 0.6254, 0.1409, 0.0744],\n",
            "        [0.7047, 0.9982, 0.9563, 0.6654, 0.7445]])\n",
            " produto: tensor([[[[-4.0612e-04,  2.4875e-04, -3.0034e-03,  3.2812e-03, -2.4968e-03],\n",
            "          [ 5.2174e-03, -2.2438e-03, -5.5832e-03, -8.2817e-04,  3.5362e-03],\n",
            "          [-2.5119e-03,  8.1346e-04, -7.5964e-03, -2.5645e-03, -2.7887e-03],\n",
            "          [-1.9280e-03, -5.1648e-03,  4.0953e-03, -3.3224e-04,  2.3888e-04],\n",
            "          [ 4.9829e-03,  1.8597e-03,  2.6150e-03,  6.4226e-03, -3.3576e-03]],\n",
            "\n",
            "         [[ 3.1546e-04, -3.3411e-03,  4.3216e-03,  6.9490e-03, -2.7017e-03],\n",
            "          [ 6.0758e-03,  1.4741e-03,  3.0602e-03,  5.3955e-04,  6.4907e-03],\n",
            "          [-8.9765e-04, -1.8384e-03, -2.5683e-03, -2.9768e-03,  5.0208e-04],\n",
            "          [-1.8318e-03, -3.6315e-03, -5.6866e-04,  1.3347e-03, -5.8700e-05],\n",
            "          [ 2.2373e-04, -1.5568e-03,  1.5034e-03,  5.9286e-03,  4.5523e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0075]],\n",
            "\n",
            "         [[ 0.0213]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0075,  0.0213], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 3] = -0.0074941301718354225\n",
            " somado na saída em [0, 1, 2, 3] = 0.021299919113516808\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 4\n",
            " alvo do kernel em x: x[0,0,2:7, 4:9]\n",
            " \n",
            " tensor([[0.7510, 0.6047, 0.8701, 0.2930, 0.3102],\n",
            "        [0.3087, 0.7022, 0.1311, 0.7808, 0.7739],\n",
            "        [0.2174, 0.8950, 0.4227, 0.7595, 0.9195],\n",
            "        [0.6770, 0.6254, 0.1409, 0.0744, 0.0681],\n",
            "        [0.9982, 0.9563, 0.6654, 0.7445, 0.7968]])\n",
            " produto: tensor([[[[-3.0622e-03,  2.0031e-04, -4.3214e-03,  1.1051e-03, -2.6431e-03],\n",
            "          [ 2.2630e-03, -5.1042e-03, -1.0420e-03, -4.9337e-03,  3.5051e-03],\n",
            "          [-8.0320e-04,  3.3493e-03, -3.5874e-03, -4.6080e-03, -3.3762e-03],\n",
            "          [-1.3305e-03, -4.7712e-03,  9.2246e-04, -1.7551e-04,  2.1857e-04],\n",
            "          [ 7.0589e-03,  1.7816e-03,  1.8195e-03,  7.1859e-03, -3.5936e-03]],\n",
            "\n",
            "         [[ 2.3786e-03, -2.6905e-03,  6.2181e-03,  2.3403e-03, -2.8600e-03],\n",
            "          [ 2.6353e-03,  3.3533e-03,  5.7113e-04,  3.2143e-03,  6.4338e-03],\n",
            "          [-2.8703e-04, -7.5693e-03, -1.2129e-03, -5.3489e-03,  6.0785e-04],\n",
            "          [-1.2641e-03, -3.3548e-03, -1.2809e-04,  7.0507e-04, -5.3710e-05],\n",
            "          [ 3.1694e-04, -1.4915e-03,  1.0460e-03,  6.6332e-03,  4.8723e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0139]],\n",
            "\n",
            "         [[ 0.0151]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0139,  0.0151], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 4] = -0.013942391611635685\n",
            " somado na saída em [0, 1, 2, 4] = 0.015065622515976429\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 5\n",
            " alvo do kernel em x: x[0,0,2:7, 5:10]\n",
            " \n",
            " tensor([[6.0472e-01, 8.7009e-01, 2.9303e-01, 3.1020e-01, 8.2819e-01],\n",
            "        [7.0225e-01, 1.3106e-01, 7.8080e-01, 7.7394e-01, 5.6502e-01],\n",
            "        [8.9503e-01, 4.2267e-01, 7.5950e-01, 9.1949e-01, 9.9687e-01],\n",
            "        [6.2544e-01, 1.4088e-01, 7.4422e-02, 6.8094e-02, 4.5097e-04],\n",
            "        [9.5630e-01, 6.6538e-01, 7.4446e-01, 7.9679e-01, 9.2493e-01]])\n",
            " produto: tensor([[[[-2.4659e-03,  2.8821e-04, -1.4554e-03,  1.1698e-03, -7.0566e-03],\n",
            "          [ 5.1478e-03, -9.5262e-04, -6.2076e-03, -4.8904e-03,  2.5589e-03],\n",
            "          [-3.3071e-03,  1.5817e-03, -6.4461e-03, -5.5788e-03, -3.6603e-03],\n",
            "          [-1.2291e-03, -1.0747e-03,  4.8731e-04, -1.6059e-04,  1.4476e-06],\n",
            "          [ 6.7624e-03,  1.2396e-03,  2.0357e-03,  7.6910e-03, -4.1715e-03]],\n",
            "\n",
            "         [[ 1.9155e-03, -3.8711e-03,  2.0942e-03,  2.4774e-03, -7.6357e-03],\n",
            "          [ 5.9947e-03,  6.2584e-04,  3.4024e-03,  3.1861e-03,  4.6970e-03],\n",
            "          [-1.1818e-03, -3.5745e-03, -2.1794e-03, -6.4758e-03,  6.5900e-04],\n",
            "          [-1.1677e-03, -7.5565e-04, -6.7665e-05,  6.4513e-04, -3.5570e-07],\n",
            "          [ 3.0363e-04, -1.0377e-03,  1.1703e-03,  7.0995e-03,  5.6559e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0197]],\n",
            "\n",
            "         [[ 0.0120]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0197,  0.0120], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 5] = -0.019692756235599518\n",
            " somado na saída em [0, 1, 2, 5] = 0.01197919063270092\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 6\n",
            " alvo do kernel em x: x[0,0,2:7, 6:11]\n",
            " \n",
            " tensor([[8.7009e-01, 2.9303e-01, 3.1020e-01, 8.2819e-01, 5.3646e-01],\n",
            "        [1.3106e-01, 7.8080e-01, 7.7394e-01, 5.6502e-01, 5.0786e-01],\n",
            "        [4.2267e-01, 7.5950e-01, 9.1949e-01, 9.9687e-01, 5.0818e-02],\n",
            "        [1.4088e-01, 7.4422e-02, 6.8094e-02, 4.5097e-04, 2.7528e-01],\n",
            "        [6.6538e-01, 7.4446e-01, 7.9679e-01, 9.2493e-01, 3.7752e-01]])\n",
            " produto: tensor([[[[-3.5480e-03,  9.7066e-05, -1.5406e-03,  3.1232e-03, -4.5709e-03],\n",
            "          [ 9.6075e-04, -5.6751e-03, -6.1532e-03, -3.5703e-03,  2.3001e-03],\n",
            "          [-1.5617e-03,  2.8421e-03, -7.8040e-03, -6.0483e-03, -1.8659e-04],\n",
            "          [-2.7686e-04, -5.6774e-04,  4.4587e-04, -1.0635e-06,  8.8362e-04],\n",
            "          [ 4.7052e-03,  1.3870e-03,  2.1788e-03,  8.9280e-03, -1.7027e-03]],\n",
            "\n",
            "         [[ 2.7560e-03, -1.3037e-03,  2.2168e-03,  6.6144e-03, -4.9460e-03],\n",
            "          [ 1.1188e-03,  3.7284e-03,  3.3726e-03,  2.3260e-03,  4.2219e-03],\n",
            "          [-5.5810e-04, -6.4231e-03, -2.6385e-03, -7.0207e-03,  3.3594e-05],\n",
            "          [-2.6303e-04, -3.9919e-04, -6.1912e-05,  4.2725e-06, -2.1713e-04],\n",
            "          [ 2.1126e-04, -1.1611e-03,  1.2526e-03,  8.2413e-03,  2.3085e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0154]],\n",
            "\n",
            "         [[ 0.0134]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0154,  0.0134], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 6] = -0.015355363488197327\n",
            " somado na saída em [0, 1, 2, 6] = 0.013414006680250168\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 7\n",
            " alvo do kernel em x: x[0,0,2:7, 7:12]\n",
            " \n",
            " tensor([[2.9303e-01, 3.1020e-01, 8.2819e-01, 5.3646e-01, 4.5296e-01],\n",
            "        [7.8080e-01, 7.7394e-01, 5.6502e-01, 5.0786e-01, 1.4265e-01],\n",
            "        [7.5950e-01, 9.1949e-01, 9.9687e-01, 5.0818e-02, 8.1244e-01],\n",
            "        [7.4422e-02, 6.8094e-02, 4.5097e-04, 2.7528e-01, 1.6445e-01],\n",
            "        [7.4446e-01, 7.9679e-01, 9.2493e-01, 3.7752e-01, 5.8573e-01]])\n",
            " produto: tensor([[[[-1.1949e-03,  1.0275e-04, -4.1133e-03,  2.0231e-03, -3.8595e-03],\n",
            "          [ 5.7236e-03, -5.6253e-03, -4.4921e-03, -3.2091e-03,  6.4604e-04],\n",
            "          [-2.8063e-03,  3.4409e-03, -8.4607e-03, -3.0833e-04, -2.9831e-03],\n",
            "          [-1.4625e-04, -5.1947e-04,  2.9529e-06, -6.4920e-04,  5.2787e-04],\n",
            "          [ 5.2644e-03,  1.4845e-03,  2.5292e-03,  3.6441e-03, -2.6417e-03]],\n",
            "\n",
            "         [[ 9.2818e-04, -1.3801e-03,  5.9186e-03,  4.2845e-03, -4.1762e-03],\n",
            "          [ 6.6652e-03,  3.6957e-03,  2.4622e-03,  2.0907e-03,  1.1858e-03],\n",
            "          [-1.0028e-03, -7.7761e-03, -2.8605e-03, -3.5790e-04,  5.3708e-04],\n",
            "          [-1.3895e-04, -3.6525e-04, -4.1003e-07,  2.6080e-03, -1.2971e-04],\n",
            "          [ 2.3637e-04, -1.2427e-03,  1.4541e-03,  3.3638e-03,  3.5817e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0156]],\n",
            "\n",
            "         [[ 0.0196]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0156,  0.0196], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 7] = -0.015619980171322823\n",
            " somado na saída em [0, 1, 2, 7] = 0.019581248983740807\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 0\n",
            " alvo do kernel em x: x[0,0,3:8, 0:5]\n",
            " \n",
            " tensor([[0.8094, 0.5871, 0.3559, 0.7117, 0.3087],\n",
            "        [0.4166, 0.5816, 0.0036, 0.6798, 0.2174],\n",
            "        [0.3212, 0.3049, 0.5938, 0.9811, 0.6770],\n",
            "        [0.8693, 0.5654, 0.1892, 0.7047, 0.9982],\n",
            "        [0.9398, 0.3753, 0.9446, 0.4064, 0.9276]])\n",
            " produto: tensor([[[[-3.3006e-03,  1.9447e-04, -1.7677e-03,  2.6841e-03, -2.6304e-03],\n",
            "          [ 3.0541e-03, -4.2275e-03, -2.8632e-05, -4.2958e-03,  9.8449e-04],\n",
            "          [-1.1870e-03,  1.1409e-03, -5.0394e-03, -5.9525e-03, -2.4859e-03],\n",
            "          [-1.7083e-03, -4.3128e-03,  1.2386e-03, -1.6618e-03,  3.2042e-03],\n",
            "          [ 6.6460e-03,  6.9927e-04,  2.5831e-03,  3.9227e-03, -4.1836e-03]],\n",
            "\n",
            "         [[ 2.5638e-03, -2.6120e-03,  2.5436e-03,  5.6844e-03, -2.8462e-03],\n",
            "          [ 3.5565e-03,  2.7774e-03,  1.5694e-05,  2.7987e-03,  1.8071e-03],\n",
            "          [-4.2417e-04, -2.5783e-03, -1.7038e-03, -6.9096e-03,  4.4756e-04],\n",
            "          [-1.6230e-03, -3.0325e-03, -1.7199e-04,  6.6760e-03, -7.8735e-04],\n",
            "          [ 2.9840e-04, -5.8537e-04,  1.4850e-03,  3.6210e-03,  5.6723e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0164]],\n",
            "\n",
            "         [[ 0.0167]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0164,  0.0167], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 0] = -0.016430027782917023\n",
            " somado na saída em [0, 1, 3, 0] = 0.016673116013407707\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 1\n",
            " alvo do kernel em x: x[0,0,3:8, 1:6]\n",
            " \n",
            " tensor([[0.5871, 0.3559, 0.7117, 0.3087, 0.7022],\n",
            "        [0.5816, 0.0036, 0.6798, 0.2174, 0.8950],\n",
            "        [0.3049, 0.5938, 0.9811, 0.6770, 0.6254],\n",
            "        [0.5654, 0.1892, 0.7047, 0.9982, 0.9563],\n",
            "        [0.3753, 0.9446, 0.4064, 0.9276, 0.7929]])\n",
            " produto: tensor([[[[-2.3939e-03,  1.1790e-04, -3.5349e-03,  1.1642e-03, -5.9835e-03],\n",
            "          [ 4.2636e-03, -2.6176e-05, -5.4050e-03, -1.3736e-03,  4.0536e-03],\n",
            "          [-1.1265e-03,  2.2219e-03, -8.3268e-03, -4.1077e-03, -2.2965e-03],\n",
            "          [-1.1110e-03, -1.4431e-03,  4.6140e-03, -2.3541e-03,  3.0696e-03],\n",
            "          [ 2.6542e-03,  1.7599e-03,  1.1113e-03,  8.9539e-03, -3.5761e-03]],\n",
            "\n",
            "         [[ 1.8596e-03, -1.5836e-03,  5.0865e-03,  2.4655e-03, -6.4745e-03],\n",
            "          [ 4.9651e-03,  1.7197e-05,  2.9625e-03,  8.9489e-04,  7.4404e-03],\n",
            "          [-4.0256e-04, -5.0214e-03, -2.8152e-03, -4.7681e-03,  4.1346e-04],\n",
            "          [-1.0556e-03, -1.0147e-03, -6.4068e-04,  9.4572e-03, -7.5429e-04],\n",
            "          [ 1.1917e-04, -1.4733e-03,  6.3888e-04,  8.2651e-03,  4.8486e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0091]],\n",
            "\n",
            "         [[ 0.0234]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0091,  0.0234], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 1] = -0.009074833244085312\n",
            " somado na saída em [0, 1, 3, 1] = 0.023430198431015015\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 2\n",
            " alvo do kernel em x: x[0,0,3:8, 2:7]\n",
            " \n",
            " tensor([[0.3559, 0.7117, 0.3087, 0.7022, 0.1311],\n",
            "        [0.0036, 0.6798, 0.2174, 0.8950, 0.4227],\n",
            "        [0.5938, 0.9811, 0.6770, 0.6254, 0.1409],\n",
            "        [0.1892, 0.7047, 0.9982, 0.9563, 0.6654],\n",
            "        [0.9446, 0.4064, 0.9276, 0.7929, 0.4814]])\n",
            " produto: tensor([[[[-1.4514e-03,  2.3576e-04, -1.5332e-03,  2.6483e-03, -1.1167e-03],\n",
            "          [ 2.6400e-05, -4.9413e-03, -1.7283e-03, -5.6556e-03,  1.9143e-03],\n",
            "          [-2.1939e-03,  3.6714e-03, -5.7461e-03, -3.7947e-03, -5.1727e-04],\n",
            "          [-3.7175e-04, -5.3756e-03,  6.5363e-03, -2.2553e-03,  2.1358e-03],\n",
            "          [ 6.6800e-03,  7.5714e-04,  2.5366e-03,  7.6536e-03, -2.1712e-03]],\n",
            "\n",
            "         [[ 1.1274e-03, -3.1667e-03,  2.2062e-03,  5.6085e-03, -1.2084e-03],\n",
            "          [ 3.0743e-05,  3.2463e-03,  9.4726e-04,  3.6846e-03,  3.5137e-03],\n",
            "          [-7.8399e-04, -8.2971e-03, -1.9427e-03, -4.4048e-03,  9.3131e-05],\n",
            "          [-3.5318e-04, -3.7797e-03, -9.0760e-04,  9.0600e-03, -5.2482e-04],\n",
            "          [ 2.9992e-04, -6.3381e-04,  1.4583e-03,  7.0649e-03,  2.9438e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0041]],\n",
            "\n",
            "         [[ 0.0153]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0041,  0.0153], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 2] = -0.00405686441808939\n",
            " somado na saída em [0, 1, 3, 2] = 0.015282053500413895\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 3\n",
            " alvo do kernel em x: x[0,0,3:8, 3:8]\n",
            " \n",
            " tensor([[0.7117, 0.3087, 0.7022, 0.1311, 0.7808],\n",
            "        [0.6798, 0.2174, 0.8950, 0.4227, 0.7595],\n",
            "        [0.9811, 0.6770, 0.6254, 0.1409, 0.0744],\n",
            "        [0.7047, 0.9982, 0.9563, 0.6654, 0.7445],\n",
            "        [0.4064, 0.9276, 0.7929, 0.4814, 0.8254]])\n",
            " produto: tensor([[[[-2.9023e-03,  1.0226e-04, -3.4878e-03,  4.9426e-04, -6.6528e-03],\n",
            "          [ 4.9835e-03, -1.5800e-03, -7.1159e-03, -2.6708e-03,  3.4397e-03],\n",
            "          [-3.6251e-03,  2.5335e-03, -5.3083e-03, -8.5475e-04, -2.7326e-04],\n",
            "          [-1.3848e-03, -7.6151e-03,  6.2618e-03, -1.5692e-03,  2.3896e-03],\n",
            "          [ 2.8738e-03,  1.7282e-03,  2.1682e-03,  4.6468e-03, -3.7227e-03]],\n",
            "\n",
            "         [[ 2.2545e-03, -1.3735e-03,  5.0186e-03,  1.0467e-03, -7.1987e-03],\n",
            "          [ 5.8034e-03,  1.0380e-03,  3.9003e-03,  1.7400e-03,  6.3137e-03],\n",
            "          [-1.2954e-03, -5.7256e-03, -1.7947e-03, -9.9218e-04,  4.9198e-05],\n",
            "          [-1.3156e-03, -5.3543e-03, -8.6948e-04,  6.3038e-03, -5.8719e-04],\n",
            "          [ 1.2903e-04, -1.4467e-03,  1.2465e-03,  4.2894e-03,  5.0473e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0171]],\n",
            "\n",
            "         [[ 0.0162]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0171,  0.0162], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 3] = -0.01714102178812027\n",
            " somado na saída em [0, 1, 3, 3] = 0.016227027401328087\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 4\n",
            " alvo do kernel em x: x[0,0,3:8, 4:9]\n",
            " \n",
            " tensor([[0.3087, 0.7022, 0.1311, 0.7808, 0.7739],\n",
            "        [0.2174, 0.8950, 0.4227, 0.7595, 0.9195],\n",
            "        [0.6770, 0.6254, 0.1409, 0.0744, 0.0681],\n",
            "        [0.9982, 0.9563, 0.6654, 0.7445, 0.7968],\n",
            "        [0.9276, 0.7929, 0.4814, 0.8254, 0.2480]])\n",
            " produto: tensor([[[[-1.2588e-03,  2.3262e-04, -6.5093e-04,  2.9445e-03, -6.5944e-03],\n",
            "          [ 1.5935e-03, -6.5055e-03, -3.3604e-03, -4.7992e-03,  4.1643e-03],\n",
            "          [-2.5016e-03,  2.3405e-03, -1.1957e-03, -4.5153e-04, -2.5003e-04],\n",
            "          [-1.9617e-03, -7.2953e-03,  4.3568e-03, -1.7557e-03,  2.5576e-03],\n",
            "          [ 6.5595e-03,  1.4772e-03,  1.3164e-03,  7.9674e-03, -1.1184e-03]],\n",
            "\n",
            "         [[ 9.7784e-04, -3.1244e-03,  9.3664e-04,  6.2359e-03, -7.1355e-03],\n",
            "          [ 1.8556e-03,  4.2739e-03,  1.8419e-03,  3.1267e-03,  7.6437e-03],\n",
            "          [-8.9394e-04, -5.2893e-03, -4.0425e-04, -5.2413e-04,  4.5015e-05],\n",
            "          [-1.8638e-03, -5.1294e-03, -6.0497e-04,  7.0530e-03, -6.2847e-04],\n",
            "          [ 2.9452e-04, -1.2366e-03,  7.5681e-04,  7.3545e-03,  1.5163e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0042]],\n",
            "\n",
            "         [[ 0.0171]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0042,  0.0171], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 4] = -0.004188653081655502\n",
            " somado na saída em [0, 1, 3, 4] = 0.017077535390853882\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 5\n",
            " alvo do kernel em x: x[0,0,3:8, 5:10]\n",
            " \n",
            " tensor([[7.0225e-01, 1.3106e-01, 7.8080e-01, 7.7394e-01, 5.6502e-01],\n",
            "        [8.9503e-01, 4.2267e-01, 7.5950e-01, 9.1949e-01, 9.9687e-01],\n",
            "        [6.2544e-01, 1.4088e-01, 7.4422e-02, 6.8094e-02, 4.5097e-04],\n",
            "        [9.5630e-01, 6.6538e-01, 7.4446e-01, 7.9679e-01, 9.2493e-01],\n",
            "        [7.9291e-01, 4.8141e-01, 8.2541e-01, 2.4797e-01, 9.6473e-01]])\n",
            " produto: tensor([[[[-2.8636e-03,  4.3414e-05, -3.8779e-03,  2.9186e-03, -4.8143e-03],\n",
            "          [ 6.5610e-03, -3.0722e-03, -6.0383e-03, -5.8102e-03,  4.5148e-03],\n",
            "          [-2.3109e-03,  5.2719e-04, -6.3164e-04, -4.1314e-04, -1.6558e-06],\n",
            "          [-1.8793e-03, -5.0759e-03,  4.8746e-03, -1.8791e-03,  2.9689e-03],\n",
            "          [ 5.6070e-03,  8.9689e-04,  2.2571e-03,  2.3935e-03, -4.3510e-03]],\n",
            "\n",
            "         [[ 2.2244e-03, -5.8312e-04,  5.5799e-03,  6.1811e-03, -5.2093e-03],\n",
            "          [ 7.6404e-03,  2.0183e-03,  3.3096e-03,  3.7853e-03,  8.2870e-03],\n",
            "          [-8.2583e-04, -1.1914e-03, -2.1355e-04, -4.7957e-04,  2.9812e-07],\n",
            "          [-1.7855e-03, -3.5690e-03, -6.7687e-04,  7.5488e-03, -7.2954e-04],\n",
            "          [ 2.5175e-04, -7.5081e-04,  1.2976e-03,  2.2094e-03,  5.8993e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0095]],\n",
            "\n",
            "         [[ 0.0402]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0095,  0.0402], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 5] = -0.009456047788262367\n",
            " somado na saída em [0, 1, 3, 5] = 0.04021880030632019\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 6\n",
            " alvo do kernel em x: x[0,0,3:8, 6:11]\n",
            " \n",
            " tensor([[1.3106e-01, 7.8080e-01, 7.7394e-01, 5.6502e-01, 5.0786e-01],\n",
            "        [4.2267e-01, 7.5950e-01, 9.1949e-01, 9.9687e-01, 5.0818e-02],\n",
            "        [1.4088e-01, 7.4422e-02, 6.8094e-02, 4.5097e-04, 2.7528e-01],\n",
            "        [6.6538e-01, 7.4446e-01, 7.9679e-01, 9.2493e-01, 3.7752e-01],\n",
            "        [4.8141e-01, 8.2541e-01, 2.4797e-01, 9.6473e-01, 2.5757e-01]])\n",
            " produto: tensor([[[[-5.3444e-04,  2.5863e-04, -3.8438e-03,  2.1308e-03, -4.3273e-03],\n",
            "          [ 3.0984e-03, -5.5203e-03, -7.3104e-03, -6.2991e-03,  2.3015e-04],\n",
            "          [-5.2054e-04,  2.7850e-04, -5.7794e-04, -2.7361e-06, -1.0108e-03],\n",
            "          [-1.3076e-03, -5.6792e-03,  5.2173e-03, -2.1813e-03,  1.2118e-03],\n",
            "          [ 3.4042e-03,  1.5378e-03,  6.7807e-04,  9.3122e-03, -1.1616e-03]],\n",
            "\n",
            "         [[ 4.1514e-04, -3.4739e-03,  5.5310e-03,  4.5125e-03, -4.6824e-03],\n",
            "          [ 3.6081e-03,  3.6267e-03,  4.0069e-03,  4.1039e-03,  4.2245e-04],\n",
            "          [-1.8602e-04, -6.2938e-04, -1.9540e-04, -3.1761e-06,  1.8198e-04],\n",
            "          [-1.2423e-03, -3.9932e-03, -7.2445e-04,  8.7629e-03, -2.9777e-04],\n",
            "          [ 1.5285e-04, -1.2873e-03,  3.8982e-04,  8.5959e-03,  1.5750e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0129]],\n",
            "\n",
            "         [[ 0.0292]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0129,  0.0292], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 6] = -0.012919282540678978\n",
            " somado na saída em [0, 1, 3, 6] = 0.029169831424951553\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 7\n",
            " alvo do kernel em x: x[0,0,3:8, 7:12]\n",
            " \n",
            " tensor([[7.8080e-01, 7.7394e-01, 5.6502e-01, 5.0786e-01, 1.4265e-01],\n",
            "        [7.5950e-01, 9.1949e-01, 9.9687e-01, 5.0818e-02, 8.1244e-01],\n",
            "        [7.4422e-02, 6.8094e-02, 4.5097e-04, 2.7528e-01, 1.6445e-01],\n",
            "        [7.4446e-01, 7.9679e-01, 9.2493e-01, 3.7752e-01, 5.8573e-01],\n",
            "        [8.2541e-01, 2.4797e-01, 9.6473e-01, 2.5757e-01, 8.0601e-01]])\n",
            " produto: tensor([[[[-3.1839e-03,  2.5636e-04, -2.8062e-03,  1.9152e-03, -1.2154e-03],\n",
            "          [ 5.5674e-03, -6.6833e-03, -7.9256e-03, -3.2111e-04,  3.6795e-03],\n",
            "          [-2.7498e-04,  2.5482e-04, -3.8275e-06, -1.6702e-03, -6.0382e-04],\n",
            "          [-1.4630e-03, -6.0784e-03,  6.0564e-03, -8.9032e-04,  1.8801e-03],\n",
            "          [ 5.8369e-03,  4.6198e-04,  2.6381e-03,  2.4862e-03, -3.6352e-03]],\n",
            "\n",
            "         [[ 2.4732e-03, -3.4434e-03,  4.0379e-03,  4.0561e-03, -1.3152e-03],\n",
            "          [ 6.4834e-03,  4.3907e-03,  4.3440e-03,  2.0921e-04,  6.7538e-03],\n",
            "          [-9.8266e-05, -5.7587e-04, -1.2940e-06, -1.9387e-03,  1.0871e-04],\n",
            "          [-1.3900e-03, -4.2738e-03, -8.4096e-04,  3.5767e-03, -4.6199e-04],\n",
            "          [ 2.6207e-04, -3.8673e-04,  1.5166e-03,  2.2949e-03,  4.9287e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0057]],\n",
            "\n",
            "         [[ 0.0307]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0057,  0.0307], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 7] = -0.005722254980355501\n",
            " somado na saída em [0, 1, 3, 7] = 0.030709821730852127\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 0\n",
            " alvo do kernel em x: x[0,0,4:9, 0:5]\n",
            " \n",
            " tensor([[0.4166, 0.5816, 0.0036, 0.6798, 0.2174],\n",
            "        [0.3212, 0.3049, 0.5938, 0.9811, 0.6770],\n",
            "        [0.8693, 0.5654, 0.1892, 0.7047, 0.9982],\n",
            "        [0.9398, 0.3753, 0.9446, 0.4064, 0.9276],\n",
            "        [0.9859, 0.9918, 0.3211, 0.3894, 0.4102]])\n",
            " produto: tensor([[[[-1.6989e-03,  1.9266e-04, -1.7887e-05,  2.5637e-03, -1.8522e-03],\n",
            "          [ 2.3549e-03, -2.2160e-03, -4.7206e-03, -6.1994e-03,  3.0662e-03],\n",
            "          [-3.2120e-03,  2.1156e-03, -1.6055e-03, -4.2753e-03, -3.6652e-03],\n",
            "          [-1.8470e-03, -2.8633e-03,  6.1854e-03, -9.5840e-04,  2.9775e-03],\n",
            "          [ 6.9721e-03,  1.8477e-03,  8.7801e-04,  3.7585e-03, -1.8502e-03]],\n",
            "\n",
            "         [[ 1.3197e-03, -2.5878e-03,  2.5737e-05,  5.4295e-03, -2.0042e-03],\n",
            "          [ 2.7423e-03,  1.4558e-03,  2.5874e-03,  4.0389e-03,  5.6281e-03],\n",
            "          [-1.1478e-03, -4.7812e-03, -5.4281e-04, -4.9627e-03,  6.5989e-04],\n",
            "          [-1.7548e-03, -2.0132e-03, -8.5888e-04,  3.8502e-03, -7.3166e-04],\n",
            "          [ 3.1304e-04, -1.5468e-03,  5.0477e-04,  3.4694e-03,  2.5085e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0041]],\n",
            "\n",
            "         [[ 0.0116]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0041,  0.0116], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 4, 0] = -0.004069487098604441\n",
            " somado na saída em [0, 1, 4, 0] = 0.01160156074911356\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 1\n",
            " alvo do kernel em x: x[0,0,4:9, 1:6]\n",
            " \n",
            " tensor([[0.5816, 0.0036, 0.6798, 0.2174, 0.8950],\n",
            "        [0.3049, 0.5938, 0.9811, 0.6770, 0.6254],\n",
            "        [0.5654, 0.1892, 0.7047, 0.9982, 0.9563],\n",
            "        [0.3753, 0.9446, 0.4064, 0.9276, 0.7929],\n",
            "        [0.9918, 0.3211, 0.3894, 0.4102, 0.8482]])\n",
            " produto: tensor([[[[-2.3718e-03,  1.1929e-06, -3.3764e-03,  8.1976e-04, -7.6262e-03],\n",
            "          [ 2.2349e-03, -4.3157e-03, -7.8001e-03, -4.2780e-03,  2.8326e-03],\n",
            "          [-2.0889e-03,  7.0788e-04, -5.9806e-03, -6.0564e-03, -3.5113e-03],\n",
            "          [-7.3761e-04, -7.2063e-03,  2.6610e-03, -2.1876e-03,  2.5451e-03],\n",
            "          [ 7.0132e-03,  5.9820e-04,  1.0648e-03,  3.9598e-03, -3.8253e-03]],\n",
            "\n",
            "         [[ 1.8423e-03, -1.6023e-05,  4.8584e-03,  1.7361e-03, -8.2520e-03],\n",
            "          [ 2.6026e-03,  2.8353e-03,  4.2753e-03,  2.7871e-03,  5.1993e-03],\n",
            "          [-7.4649e-04, -1.5998e-03, -2.0220e-03, -7.0302e-03,  6.3218e-04],\n",
            "          [-7.0078e-04, -5.0669e-03, -3.6950e-04,  8.7882e-03, -6.2541e-04],\n",
            "          [ 3.1489e-04, -5.0076e-04,  6.1213e-04,  3.6552e-03,  5.1864e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0369]],\n",
            "\n",
            "         [[ 0.0184]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0369,  0.0184], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 4, 1] = -0.03692392259836197\n",
            " somado na saída em [0, 1, 4, 1] = 0.01839558407664299\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 2\n",
            " alvo do kernel em x: x[0,0,4:9, 2:7]\n",
            " \n",
            " tensor([[0.0036, 0.6798, 0.2174, 0.8950, 0.4227],\n",
            "        [0.5938, 0.9811, 0.6770, 0.6254, 0.1409],\n",
            "        [0.1892, 0.7047, 0.9982, 0.9563, 0.6654],\n",
            "        [0.9446, 0.4064, 0.9276, 0.7929, 0.4814],\n",
            "        [0.3211, 0.3894, 0.4102, 0.8482, 0.3394]])\n",
            " produto: tensor([[[[-1.4686e-05,  2.2519e-04, -1.0796e-03,  3.3753e-03, -3.6014e-03],\n",
            "          [ 4.3525e-03, -7.1310e-03, -5.3826e-03, -3.9521e-03,  6.3803e-04],\n",
            "          [-6.9895e-04,  2.6369e-03, -8.4722e-03, -5.8021e-03, -2.4431e-03],\n",
            "          [-1.8564e-03, -3.1002e-03,  6.0739e-03, -1.8699e-03,  1.5453e-03],\n",
            "          [ 2.2705e-03,  7.2543e-04,  1.1218e-03,  8.1869e-03, -1.5307e-03]],\n",
            "\n",
            "         [[ 1.1407e-05, -3.0247e-03,  1.5535e-03,  7.1482e-03, -3.8969e-03],\n",
            "          [ 5.0686e-03,  4.6849e-03,  2.9503e-03,  2.5748e-03,  1.1711e-03],\n",
            "          [-2.4977e-04, -5.9593e-03, -2.8644e-03, -6.7350e-03,  4.3986e-04],\n",
            "          [-1.7637e-03, -2.1798e-03, -8.4340e-04,  7.5120e-03, -3.7971e-04],\n",
            "          [ 1.0194e-04, -6.0727e-04,  6.4491e-04,  7.5572e-03,  2.0754e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0158]],\n",
            "\n",
            "         [[ 0.0150]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0158,  0.0150], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 4, 2] = -0.01578327640891075\n",
            " somado na saída em [0, 1, 4, 2] = 0.01499008759856224\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 3\n",
            " alvo do kernel em x: x[0,0,4:9, 3:8]\n",
            " \n",
            " tensor([[0.6798, 0.2174, 0.8950, 0.4227, 0.7595],\n",
            "        [0.9811, 0.6770, 0.6254, 0.1409, 0.0744],\n",
            "        [0.7047, 0.9982, 0.9563, 0.6654, 0.7445],\n",
            "        [0.4064, 0.9276, 0.7929, 0.4814, 0.8254],\n",
            "        [0.3894, 0.4102, 0.8482, 0.3394, 0.1067]])\n",
            " produto: tensor([[[[-2.7722e-03,  7.2006e-05, -4.4453e-03,  1.5940e-03, -6.4713e-03],\n",
            "          [ 7.1918e-03, -4.9209e-03, -4.9725e-03, -8.9020e-04,  3.3705e-04],\n",
            "          [-2.6037e-03,  3.7355e-03, -8.1164e-03, -4.0370e-03, -2.7335e-03],\n",
            "          [-7.9864e-04, -7.0764e-03,  5.1919e-03, -1.1353e-03,  2.6495e-03],\n",
            "          [ 2.7535e-03,  7.6428e-04,  2.3193e-03,  3.2761e-03, -4.8121e-04]],\n",
            "\n",
            "         [[ 2.1534e-03, -9.6715e-04,  6.3964e-03,  3.3757e-03, -7.0024e-03],\n",
            "          [ 8.3750e-03,  3.2329e-03,  2.7255e-03,  5.7996e-04,  6.1867e-04],\n",
            "          [-9.3043e-04, -8.4419e-03, -2.7441e-03, -4.6861e-03,  4.9214e-04],\n",
            "          [-7.5877e-04, -4.9756e-03, -7.2092e-04,  4.5609e-03, -6.5105e-04],\n",
            "          [ 1.2363e-04, -6.3979e-04,  1.3334e-03,  3.0241e-03,  6.5244e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0216]],\n",
            "\n",
            "         [[ 0.0051]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0216,  0.0051], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 4, 3] = -0.02156973071396351\n",
            " somado na saída em [0, 1, 4, 3] = 0.005125861614942551\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 4\n",
            " alvo do kernel em x: x[0,0,4:9, 4:9]\n",
            " \n",
            " tensor([[0.2174, 0.8950, 0.4227, 0.7595, 0.9195],\n",
            "        [0.6770, 0.6254, 0.1409, 0.0744, 0.0681],\n",
            "        [0.9982, 0.9563, 0.6654, 0.7445, 0.7968],\n",
            "        [0.9276, 0.7929, 0.4814, 0.8254, 0.2480],\n",
            "        [0.4102, 0.8482, 0.3394, 0.1067, 0.9725]])\n",
            " produto: tensor([[[[-0.0009,  0.0003, -0.0021,  0.0029, -0.0078],\n",
            "          [ 0.0050, -0.0045, -0.0011, -0.0005,  0.0003],\n",
            "          [-0.0037,  0.0036, -0.0056, -0.0045, -0.0029],\n",
            "          [-0.0018, -0.0060,  0.0032, -0.0019,  0.0008],\n",
            "          [ 0.0029,  0.0016,  0.0009,  0.0010, -0.0044]],\n",
            "\n",
            "         [[ 0.0007, -0.0040,  0.0030,  0.0061, -0.0085],\n",
            "          [ 0.0058,  0.0030,  0.0006,  0.0003,  0.0006],\n",
            "          [-0.0013, -0.0081, -0.0019, -0.0052,  0.0005],\n",
            "          [-0.0017, -0.0043, -0.0004,  0.0078, -0.0002],\n",
            "          [ 0.0001, -0.0013,  0.0005,  0.0010,  0.0059]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0255]],\n",
            "\n",
            "         [[-0.0010]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0255, -0.0010], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 4, 4] = -0.02554125338792801\n",
            " somado na saída em [0, 1, 4, 4] = -0.0010230304906144738\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 5\n",
            " alvo do kernel em x: x[0,0,4:9, 5:10]\n",
            " \n",
            " tensor([[8.9503e-01, 4.2267e-01, 7.5950e-01, 9.1949e-01, 9.9687e-01],\n",
            "        [6.2544e-01, 1.4088e-01, 7.4422e-02, 6.8094e-02, 4.5097e-04],\n",
            "        [9.5630e-01, 6.6538e-01, 7.4446e-01, 7.9679e-01, 9.2493e-01],\n",
            "        [7.9291e-01, 4.8141e-01, 8.2541e-01, 2.4797e-01, 9.6473e-01],\n",
            "        [8.4816e-01, 3.3940e-01, 1.0670e-01, 9.7252e-01, 9.5843e-01]])\n",
            " produto: tensor([[[[-3.6497e-03,  1.4001e-04, -3.7721e-03,  3.4675e-03, -8.4939e-03],\n",
            "          [ 4.5847e-03, -1.0240e-03, -5.9168e-04, -4.3028e-04,  2.0424e-06],\n",
            "          [-3.5335e-03,  2.4899e-03, -6.3184e-03, -4.8343e-03, -3.3961e-03],\n",
            "          [-1.5582e-03, -3.6725e-03,  5.4047e-03, -5.8478e-04,  3.0967e-03],\n",
            "          [ 5.9977e-03,  6.3232e-04,  2.9176e-04,  9.3874e-03, -4.3226e-03]],\n",
            "\n",
            "         [[ 2.8350e-03, -1.8805e-03,  5.4277e-03,  7.3436e-03, -9.1909e-03],\n",
            "          [ 5.3390e-03,  6.7272e-04,  3.2431e-04,  2.8033e-04,  3.7489e-06],\n",
            "          [-1.2627e-03, -5.6271e-03, -2.1362e-03, -5.6116e-03,  6.1144e-04],\n",
            "          [-1.4804e-03, -2.5822e-03, -7.5048e-04,  2.3492e-03, -7.6094e-04],\n",
            "          [ 2.6929e-04, -5.2933e-04,  1.6773e-04,  8.6653e-03,  5.8607e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0107]],\n",
            "\n",
            "         [[ 0.0083]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0107,  0.0083], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 4, 5] = -0.010687274858355522\n",
            " somado na saída em [0, 1, 4, 5] = 0.008337898179888725\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 6\n",
            " alvo do kernel em x: x[0,0,4:9, 6:11]\n",
            " \n",
            " tensor([[4.2267e-01, 7.5950e-01, 9.1949e-01, 9.9687e-01, 5.0818e-02],\n",
            "        [1.4088e-01, 7.4422e-02, 6.8094e-02, 4.5097e-04, 2.7528e-01],\n",
            "        [6.6538e-01, 7.4446e-01, 7.9679e-01, 9.2493e-01, 3.7752e-01],\n",
            "        [4.8141e-01, 8.2541e-01, 2.4797e-01, 9.6473e-01, 2.5757e-01],\n",
            "        [3.3940e-01, 1.0670e-01, 9.7252e-01, 9.5843e-01, 9.2813e-01]])\n",
            " produto: tensor([[[[-1.7236e-03,  2.5158e-04, -4.5667e-03,  3.7593e-03, -4.3300e-04],\n",
            "          [ 1.0327e-03, -5.4093e-04, -5.4138e-04, -2.8496e-06,  1.2467e-03],\n",
            "          [-2.4585e-03,  2.7859e-03, -6.7626e-03, -5.6118e-03, -1.3862e-03],\n",
            "          [-9.4606e-04, -6.2968e-03,  1.6237e-03, -2.2751e-03,  8.2675e-04],\n",
            "          [ 2.4000e-03,  1.9878e-04,  2.6594e-03,  9.2513e-03, -4.1859e-03]],\n",
            "\n",
            "         [[ 1.3388e-03, -3.3791e-03,  6.5712e-03,  7.9616e-03, -4.6853e-04],\n",
            "          [ 1.2026e-03,  3.5537e-04,  2.9673e-04,  1.8565e-06,  2.2884e-03],\n",
            "          [-8.7856e-04, -6.2959e-03, -2.2864e-03, -6.5141e-03,  2.4957e-04],\n",
            "          [-8.9883e-04, -4.4274e-03, -2.2545e-04,  9.1399e-03, -2.0316e-04],\n",
            "          [ 1.0776e-04, -1.6640e-04,  1.5289e-03,  8.5397e-03,  5.6754e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0117]],\n",
            "\n",
            "         [[ 0.0195]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0117,  0.0195], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 4, 6] = -0.01169529464095831\n",
            " somado na saída em [0, 1, 4, 6] = 0.019514068961143494\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 7\n",
            " alvo do kernel em x: x[0,0,4:9, 7:12]\n",
            " \n",
            " tensor([[7.5950e-01, 9.1949e-01, 9.9687e-01, 5.0818e-02, 8.1244e-01],\n",
            "        [7.4422e-02, 6.8094e-02, 4.5097e-04, 2.7528e-01, 1.6445e-01],\n",
            "        [7.4446e-01, 7.9679e-01, 9.2493e-01, 3.7752e-01, 5.8573e-01],\n",
            "        [8.2541e-01, 2.4797e-01, 9.6473e-01, 2.5757e-01, 8.0601e-01],\n",
            "        [1.0670e-01, 9.7252e-01, 9.5843e-01, 9.2813e-01, 1.9656e-01]])\n",
            " produto: tensor([[[[-3.0970e-03,  3.0458e-04, -4.9511e-03,  1.9164e-04, -6.9224e-03],\n",
            "          [ 5.4554e-04, -4.9494e-04, -3.5854e-06, -1.7395e-03,  7.4479e-04],\n",
            "          [-2.7507e-03,  2.9817e-03, -7.8502e-03, -2.2905e-03, -2.1506e-03],\n",
            "          [-1.6221e-03, -1.8916e-03,  6.3170e-03, -6.0742e-04,  2.5872e-03],\n",
            "          [ 7.5450e-04,  1.8119e-03,  2.6208e-03,  8.9588e-03, -8.8649e-04]],\n",
            "\n",
            "         [[ 2.4057e-03, -4.0910e-03,  7.1241e-03,  4.0586e-04, -7.4905e-03],\n",
            "          [ 6.3530e-04,  3.2516e-04,  1.9652e-06,  1.1333e-03,  1.3671e-03],\n",
            "          [-9.8298e-04, -6.7384e-03, -2.6541e-03, -2.6588e-03,  3.8720e-04],\n",
            "          [-1.5411e-03, -1.3301e-03, -8.7715e-04,  2.4402e-03, -6.3574e-04],\n",
            "          [ 3.3876e-05, -1.5168e-03,  1.5067e-03,  8.2697e-03,  1.2019e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0094]],\n",
            "\n",
            "         [[-0.0033]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0094, -0.0033], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 4, 7] = -0.009439838118851185\n",
            " somado na saída em [0, 1, 4, 7] = -0.0032783900387585163\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 0\n",
            " alvo do kernel em x: x[0,0,5:10, 0:5]\n",
            " \n",
            " tensor([[0.3212, 0.3049, 0.5938, 0.9811, 0.6770],\n",
            "        [0.8693, 0.5654, 0.1892, 0.7047, 0.9982],\n",
            "        [0.9398, 0.3753, 0.9446, 0.4064, 0.9276],\n",
            "        [0.9859, 0.9918, 0.3211, 0.3894, 0.4102],\n",
            "        [0.0462, 0.9147, 0.2579, 0.9333, 0.4410]])\n",
            " produto: tensor([[[[-1.3100e-03,  1.0099e-04, -2.9489e-03,  3.6998e-03, -5.7686e-03],\n",
            "          [ 6.3723e-03, -4.1092e-03, -1.5039e-03, -4.4526e-03,  4.5209e-03],\n",
            "          [-3.4726e-03,  1.4046e-03, -8.0174e-03, -2.4657e-03, -3.4060e-03],\n",
            "          [-1.9376e-03, -7.5658e-03,  2.1024e-03, -9.1827e-04,  1.3168e-03],\n",
            "          [ 3.2682e-04,  1.7042e-03,  7.0530e-04,  9.0085e-03, -1.9891e-03]],\n",
            "\n",
            "         [[ 1.0176e-03, -1.3564e-03,  4.2433e-03,  7.8355e-03, -6.2420e-03],\n",
            "          [ 7.4207e-03,  2.6996e-03,  8.2432e-04,  2.9009e-03,  8.2982e-03],\n",
            "          [-1.2410e-03, -3.1742e-03, -2.7106e-03, -2.8621e-03,  6.1321e-04],\n",
            "          [-1.8408e-03, -5.3197e-03, -2.9193e-04,  3.6890e-03, -3.2357e-04],\n",
            "          [ 1.4674e-05, -1.4266e-03,  4.0548e-04,  8.3155e-03,  2.6968e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0186]],\n",
            "\n",
            "         [[ 0.0242]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0186,  0.0242], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 5, 0] = -0.018603218719363213\n",
            " somado na saída em [0, 1, 5, 0] = 0.024185825139284134\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 1\n",
            " alvo do kernel em x: x[0,0,5:10, 1:6]\n",
            " \n",
            " tensor([[0.3049, 0.5938, 0.9811, 0.6770, 0.6254],\n",
            "        [0.5654, 0.1892, 0.7047, 0.9982, 0.9563],\n",
            "        [0.3753, 0.9446, 0.4064, 0.9276, 0.7929],\n",
            "        [0.9918, 0.3211, 0.3894, 0.4102, 0.8482],\n",
            "        [0.9147, 0.2579, 0.9333, 0.4410, 0.8357]])\n",
            " produto: tensor([[[[-0.0012,  0.0002, -0.0049,  0.0026, -0.0053],\n",
            "          [ 0.0041, -0.0014, -0.0056, -0.0063,  0.0043],\n",
            "          [-0.0014,  0.0035, -0.0034, -0.0056, -0.0029],\n",
            "          [-0.0019, -0.0024,  0.0025, -0.0010,  0.0027],\n",
            "          [ 0.0065,  0.0005,  0.0026,  0.0043, -0.0038]],\n",
            "\n",
            "         [[ 0.0010, -0.0026,  0.0070,  0.0054, -0.0058],\n",
            "          [ 0.0048,  0.0009,  0.0031,  0.0041,  0.0079],\n",
            "          [-0.0005, -0.0080, -0.0012, -0.0065,  0.0005],\n",
            "          [-0.0019, -0.0017, -0.0004,  0.0039, -0.0007],\n",
            "          [ 0.0003, -0.0004,  0.0015,  0.0039,  0.0051]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0134]],\n",
            "\n",
            "         [[ 0.0199]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0134,  0.0199], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 5, 1] = -0.01344994641840458\n",
            " somado na saída em [0, 1, 5, 1] = 0.019860686734318733\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 2\n",
            " alvo do kernel em x: x[0,0,5:10, 2:7]\n",
            " \n",
            " tensor([[0.5938, 0.9811, 0.6770, 0.6254, 0.1409],\n",
            "        [0.1892, 0.7047, 0.9982, 0.9563, 0.6654],\n",
            "        [0.9446, 0.4064, 0.9276, 0.7929, 0.4814],\n",
            "        [0.3211, 0.3894, 0.4102, 0.8482, 0.3394],\n",
            "        [0.2579, 0.9333, 0.4410, 0.8357, 0.7493]])\n",
            " produto: tensor([[[[-2.4212e-03,  3.2498e-04, -3.3625e-03,  2.3586e-03, -1.2004e-03],\n",
            "          [ 1.3867e-03, -5.1217e-03, -7.9363e-03, -6.0427e-03,  3.0135e-03],\n",
            "          [-3.4904e-03,  1.5208e-03, -7.8729e-03, -4.8108e-03, -1.7676e-03],\n",
            "          [-6.3099e-04, -2.9704e-03,  2.6861e-03, -2.0002e-03,  1.0894e-03],\n",
            "          [ 1.8239e-03,  1.7387e-03,  1.2060e-03,  8.0667e-03, -3.3793e-03]],\n",
            "\n",
            "         [[ 1.8807e-03, -4.3650e-03,  4.8384e-03,  4.9951e-03, -1.2989e-03],\n",
            "          [ 1.6148e-03,  3.3648e-03,  4.3499e-03,  3.9368e-03,  5.5313e-03],\n",
            "          [-1.2473e-03, -3.4369e-03, -2.6618e-03, -5.5842e-03,  3.1824e-04],\n",
            "          [-5.9949e-04, -2.0886e-03, -3.7298e-04,  8.0355e-03, -2.6770e-04],\n",
            "          [ 8.1892e-05, -1.4555e-03,  6.9332e-04,  7.4462e-03,  4.5818e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0278]],\n",
            "\n",
            "         [[ 0.0283]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0278,  0.0283], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 5, 2] = -0.027792083099484444\n",
            " somado na saída em [0, 1, 5, 2] = 0.02829047292470932\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 3\n",
            " alvo do kernel em x: x[0,0,5:10, 3:8]\n",
            " \n",
            " tensor([[0.9811, 0.6770, 0.6254, 0.1409, 0.0744],\n",
            "        [0.7047, 0.9982, 0.9563, 0.6654, 0.7445],\n",
            "        [0.4064, 0.9276, 0.7929, 0.4814, 0.8254],\n",
            "        [0.3894, 0.4102, 0.8482, 0.3394, 0.1067],\n",
            "        [0.9333, 0.4410, 0.8357, 0.7493, 0.2781]])\n",
            " produto: tensor([[[[-4.0007e-03,  2.2426e-04, -3.1063e-03,  5.3127e-04, -6.3411e-04],\n",
            "          [ 5.1655e-03, -7.2555e-03, -7.6030e-03, -4.2044e-03,  3.3716e-03],\n",
            "          [-1.5016e-03,  3.4712e-03, -6.7296e-03, -2.9208e-03, -3.0307e-03],\n",
            "          [-7.6520e-04, -3.1295e-03,  5.5536e-03, -8.0041e-04,  3.4248e-04],\n",
            "          [ 6.5996e-03,  8.2166e-04,  2.2852e-03,  7.2325e-03, -1.2541e-03]],\n",
            "\n",
            "         [[ 3.1076e-03, -3.0122e-03,  4.4697e-03,  1.1251e-03, -6.8615e-04],\n",
            "          [ 6.0153e-03,  4.7666e-03,  4.1672e-03,  2.7392e-03,  6.1887e-03],\n",
            "          [-5.3660e-04, -7.8448e-03, -2.2752e-03, -3.3904e-03,  5.4565e-04],\n",
            "          [-7.2700e-04, -2.2004e-03, -7.7115e-04,  3.2155e-03, -8.4157e-05],\n",
            "          [ 2.9631e-04, -6.8783e-04,  1.3138e-03,  6.6762e-03,  1.7004e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0113]],\n",
            "\n",
            "         [[ 0.0241]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0113,  0.0241], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 5, 3] = -0.011336978524923325\n",
            " somado na saída em [0, 1, 5, 3] = 0.024111319333314896\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 4\n",
            " alvo do kernel em x: x[0,0,5:10, 4:9]\n",
            " \n",
            " tensor([[0.6770, 0.6254, 0.1409, 0.0744, 0.0681],\n",
            "        [0.9982, 0.9563, 0.6654, 0.7445, 0.7968],\n",
            "        [0.9276, 0.7929, 0.4814, 0.8254, 0.2480],\n",
            "        [0.4102, 0.8482, 0.3394, 0.1067, 0.9725],\n",
            "        [0.4410, 0.8357, 0.7493, 0.2781, 0.5913]])\n",
            " produto: tensor([[[[-0.0028,  0.0002, -0.0007,  0.0003, -0.0006],\n",
            "          [ 0.0073, -0.0070, -0.0053, -0.0047,  0.0036],\n",
            "          [-0.0034,  0.0030, -0.0041, -0.0050, -0.0009],\n",
            "          [-0.0008, -0.0065,  0.0022, -0.0003,  0.0031],\n",
            "          [ 0.0031,  0.0016,  0.0020,  0.0027, -0.0027]],\n",
            "\n",
            "         [[ 0.0021, -0.0028,  0.0010,  0.0006, -0.0006],\n",
            "          [ 0.0085,  0.0046,  0.0029,  0.0031,  0.0066],\n",
            "          [-0.0012, -0.0067, -0.0014, -0.0058,  0.0002],\n",
            "          [-0.0008, -0.0045, -0.0003,  0.0010, -0.0008],\n",
            "          [ 0.0001, -0.0013,  0.0012,  0.0025,  0.0036]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0155]],\n",
            "\n",
            "         [[ 0.0118]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0155,  0.0118], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 5, 4] = -0.015478533692657948\n",
            " somado na saída em [0, 1, 5, 4] = 0.011777503415942192\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 5\n",
            " alvo do kernel em x: x[0,0,5:10, 5:10]\n",
            " \n",
            " tensor([[6.2544e-01, 1.4088e-01, 7.4422e-02, 6.8094e-02, 4.5097e-04],\n",
            "        [9.5630e-01, 6.6538e-01, 7.4446e-01, 7.9679e-01, 9.2493e-01],\n",
            "        [7.9291e-01, 4.8141e-01, 8.2541e-01, 2.4797e-01, 9.6473e-01],\n",
            "        [8.4816e-01, 3.3940e-01, 1.0670e-01, 9.7252e-01, 9.5843e-01],\n",
            "        [8.3570e-01, 7.4928e-01, 2.7807e-01, 5.9129e-01, 9.5765e-01]])\n",
            " produto: tensor([[[[-2.5504e-03,  4.6666e-05, -3.6962e-04,  2.5679e-04, -3.8425e-06],\n",
            "          [ 7.0101e-03, -4.8362e-03, -5.9187e-03, -5.0348e-03,  4.1890e-03],\n",
            "          [-2.9297e-03,  1.8015e-03, -7.0055e-03, -1.5045e-03, -3.5423e-03],\n",
            "          [-1.6668e-03, -2.5891e-03,  6.9864e-04, -2.2935e-03,  3.0764e-03],\n",
            "          [ 5.9096e-03,  1.3960e-03,  7.6037e-04,  5.7075e-03, -4.3191e-03]],\n",
            "\n",
            "         [[ 1.9811e-03, -6.2679e-04,  5.3185e-04,  5.4384e-04, -4.1578e-06],\n",
            "          [ 8.1634e-03,  3.1773e-03,  3.2441e-03,  3.2802e-03,  7.6890e-03],\n",
            "          [-1.0470e-03, -4.0713e-03, -2.3685e-03, -1.7464e-03,  6.3775e-04],\n",
            "          [-1.5836e-03, -1.8205e-03, -9.7010e-05,  9.2137e-03, -7.5596e-04],\n",
            "          [ 2.6534e-04, -1.1686e-03,  4.3714e-04,  5.2685e-03,  5.8560e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0137]],\n",
            "\n",
            "         [[ 0.0350]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0137,  0.0350], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 5, 5] = -0.013711702078580856\n",
            " somado na saída em [0, 1, 5, 5] = 0.034999411553144455\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 6\n",
            " alvo do kernel em x: x[0,0,5:10, 6:11]\n",
            " \n",
            " tensor([[1.4088e-01, 7.4422e-02, 6.8094e-02, 4.5097e-04, 2.7528e-01],\n",
            "        [6.6538e-01, 7.4446e-01, 7.9679e-01, 9.2493e-01, 3.7752e-01],\n",
            "        [4.8141e-01, 8.2541e-01, 2.4797e-01, 9.6473e-01, 2.5757e-01],\n",
            "        [3.3940e-01, 1.0670e-01, 9.7252e-01, 9.5843e-01, 9.2813e-01],\n",
            "        [7.4928e-01, 2.7807e-01, 5.9129e-01, 9.5765e-01, 4.6077e-01]])\n",
            " produto: tensor([[[[-5.7447e-04,  2.4652e-05, -3.3820e-04,  1.7007e-06, -2.3456e-03],\n",
            "          [ 4.8775e-03, -5.4110e-03, -6.3348e-03, -5.8445e-03,  1.7098e-03],\n",
            "          [-1.7788e-03,  3.0888e-03, -2.1046e-03, -5.8533e-03, -9.4572e-04],\n",
            "          [-6.6699e-04, -8.1395e-04,  6.3680e-03, -2.2603e-03,  2.9792e-03],\n",
            "          [ 5.2985e-03,  5.1805e-04,  1.6169e-03,  9.2438e-03, -2.0781e-03]],\n",
            "\n",
            "         [[ 4.4624e-04, -3.3111e-04,  4.8664e-04,  3.6017e-06, -2.5380e-03],\n",
            "          [ 5.6800e-03,  3.5549e-03,  3.4721e-03,  3.8077e-03,  3.1384e-03],\n",
            "          [-6.3565e-04, -6.9805e-03, -7.1154e-04, -6.7944e-03,  1.7027e-04],\n",
            "          [-6.3368e-04, -5.7230e-04, -8.8423e-04,  9.0802e-03, -7.3207e-04],\n",
            "          [ 2.3790e-04, -4.3367e-04,  9.2955e-04,  8.5328e-03,  2.8176e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0016]],\n",
            "\n",
            "         [[ 0.0211]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0016,  0.0211], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 5, 6] = -0.001623270334675908\n",
            " somado na saída em [0, 1, 5, 6] = 0.021110650151968002\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 7\n",
            " alvo do kernel em x: x[0,0,5:10, 7:12]\n",
            " \n",
            " tensor([[7.4422e-02, 6.8094e-02, 4.5097e-04, 2.7528e-01, 1.6445e-01],\n",
            "        [7.4446e-01, 7.9679e-01, 9.2493e-01, 3.7752e-01, 5.8573e-01],\n",
            "        [8.2541e-01, 2.4797e-01, 9.6473e-01, 2.5757e-01, 8.0601e-01],\n",
            "        [1.0670e-01, 9.7252e-01, 9.5843e-01, 9.2813e-01, 1.9656e-01],\n",
            "        [2.7807e-01, 5.9129e-01, 9.5765e-01, 4.6077e-01, 8.2454e-01]])\n",
            " produto: tensor([[[[-3.0347e-04,  2.2556e-05, -2.2398e-06,  1.0381e-03, -1.4012e-03],\n",
            "          [ 5.4572e-03, -5.7914e-03, -7.3536e-03, -2.3855e-03,  2.6527e-03],\n",
            "          [-3.0498e-03,  9.2792e-04, -8.1880e-03, -1.5627e-03, -2.9595e-03],\n",
            "          [-2.0968e-04, -7.4190e-03,  6.2757e-03, -2.1888e-03,  6.3092e-04],\n",
            "          [ 1.9663e-03,  1.1016e-03,  2.6187e-03,  4.4476e-03, -3.7188e-03]],\n",
            "\n",
            "         [[ 2.3573e-04, -3.0296e-04,  3.2228e-06,  2.1986e-03, -1.5162e-03],\n",
            "          [ 6.3550e-03,  3.8048e-03,  4.0306e-03,  1.5542e-03,  4.8691e-03],\n",
            "          [-1.0899e-03, -2.0971e-03, -2.7683e-03, -1.8140e-03,  5.3282e-04],\n",
            "          [-1.9921e-04, -5.2165e-03, -8.7142e-04,  8.7931e-03, -1.5503e-04],\n",
            "          [ 8.8286e-05, -9.2218e-04,  1.5055e-03,  4.1055e-03,  5.0420e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0194]],\n",
            "\n",
            "         [[ 0.0262]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0194,  0.0262], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 5, 7] = -0.019394278526306152\n",
            " somado na saída em [0, 1, 5, 7] = 0.02616581693291664\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 0\n",
            " alvo do kernel em x: x[0,0,6:11, 0:5]\n",
            " \n",
            " tensor([[0.8693, 0.5654, 0.1892, 0.7047, 0.9982],\n",
            "        [0.9398, 0.3753, 0.9446, 0.4064, 0.9276],\n",
            "        [0.9859, 0.9918, 0.3211, 0.3894, 0.4102],\n",
            "        [0.0462, 0.9147, 0.2579, 0.9333, 0.4410],\n",
            "        [0.0877, 0.7694, 0.3068, 0.5401, 0.8144]])\n",
            " produto: tensor([[[[-3.5448e-03,  1.8727e-04, -9.3950e-04,  2.6574e-03, -8.5054e-03],\n",
            "          [ 6.8895e-03, -2.7281e-03, -7.5103e-03, -2.5679e-03,  4.2011e-03],\n",
            "          [-3.6430e-03,  3.7113e-03, -2.7251e-03, -2.3624e-03, -1.5063e-03],\n",
            "          [-9.0826e-05, -6.9782e-03,  1.6889e-03, -2.2009e-03,  1.4156e-03],\n",
            "          [ 6.2043e-04,  1.4335e-03,  8.3885e-04,  5.2138e-03, -3.6731e-03]],\n",
            "\n",
            "         [[ 2.7535e-03, -2.5153e-03,  1.3519e-03,  5.6278e-03, -9.2033e-03],\n",
            "          [ 8.0229e-03,  1.7923e-03,  4.1164e-03,  1.6730e-03,  7.7112e-03],\n",
            "          [-1.3018e-03, -8.3873e-03, -9.2135e-04, -2.7423e-03,  2.7119e-04],\n",
            "          [-8.6291e-05, -4.9065e-03, -2.3451e-04,  8.8418e-03, -3.4786e-04],\n",
            "          [ 2.7857e-05, -1.2000e-03,  4.8226e-04,  4.8128e-03,  4.9802e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0201]],\n",
            "\n",
            "         [[ 0.0206]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0201,  0.0206], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 6, 0] = -0.02011830545961857\n",
            " somado na saída em [0, 1, 6, 0] = 0.0206184983253479\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 1\n",
            " alvo do kernel em x: x[0,0,6:11, 1:6]\n",
            " \n",
            " tensor([[0.5654, 0.1892, 0.7047, 0.9982, 0.9563],\n",
            "        [0.3753, 0.9446, 0.4064, 0.9276, 0.7929],\n",
            "        [0.9918, 0.3211, 0.3894, 0.4102, 0.8482],\n",
            "        [0.9147, 0.2579, 0.9333, 0.4410, 0.8357],\n",
            "        [0.7694, 0.3068, 0.5401, 0.8144, 0.9217]])\n",
            " produto: tensor([[[[-2.3054e-03,  6.2660e-05, -3.4997e-03,  3.7644e-03, -8.1482e-03],\n",
            "          [ 2.7514e-03, -6.8660e-03, -3.2310e-03, -5.8615e-03,  3.5910e-03],\n",
            "          [-3.6645e-03,  1.2015e-03, -3.3048e-03, -2.4889e-03, -3.1142e-03],\n",
            "          [-1.7976e-03, -1.9676e-03,  6.1110e-03, -1.0401e-03,  2.6825e-03],\n",
            "          [ 5.4409e-03,  5.7152e-04,  1.4770e-03,  7.8613e-03, -4.1571e-03]],\n",
            "\n",
            "         [[ 1.7908e-03, -8.4162e-04,  5.0358e-03,  7.9724e-03, -8.8168e-03],\n",
            "          [ 3.2040e-03,  4.5108e-03,  1.7709e-03,  3.8187e-03,  6.5914e-03],\n",
            "          [-1.3095e-03, -2.7154e-03, -1.1173e-03, -2.8891e-03,  5.6069e-04],\n",
            "          [-1.7079e-03, -1.3835e-03, -8.4854e-04,  4.1783e-03, -6.5916e-04],\n",
            "          [ 2.4429e-04, -4.7843e-04,  8.4915e-04,  7.2566e-03,  5.6363e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0159]],\n",
            "\n",
            "         [[ 0.0307]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0159,  0.0307], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 6, 1] = -0.015931349247694016\n",
            " somado na saída em [0, 1, 6, 1] = 0.030652929097414017\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 2\n",
            " alvo do kernel em x: x[0,0,6:11, 2:7]\n",
            " \n",
            " tensor([[0.1892, 0.7047, 0.9982, 0.9563, 0.6654],\n",
            "        [0.9446, 0.4064, 0.9276, 0.7929, 0.4814],\n",
            "        [0.3211, 0.3894, 0.4102, 0.8482, 0.3394],\n",
            "        [0.2579, 0.9333, 0.4410, 0.8357, 0.7493],\n",
            "        [0.3068, 0.5401, 0.8144, 0.9217, 0.2125]])\n",
            " produto: tensor([[[[-7.7137e-04,  2.3341e-04, -4.9577e-03,  3.6063e-03, -5.6694e-03],\n",
            "          [ 6.9246e-03, -2.9538e-03, -7.3749e-03, -5.0103e-03,  2.1803e-03],\n",
            "          [-1.1864e-03,  1.4571e-03, -3.4817e-03, -5.1460e-03, -1.2462e-03],\n",
            "          [-5.0688e-04, -7.1196e-03,  2.8878e-03, -1.9708e-03,  2.4051e-03],\n",
            "          [ 2.1693e-03,  1.0063e-03,  2.2271e-03,  8.8971e-03, -9.5821e-04]],\n",
            "\n",
            "         [[ 5.9918e-04, -3.1351e-03,  7.1338e-03,  7.6375e-03, -6.1346e-03],\n",
            "          [ 8.0639e-03,  1.9406e-03,  4.0422e-03,  3.2642e-03,  4.0019e-03],\n",
            "          [-4.2396e-04, -3.2930e-03, -1.1771e-03, -5.9733e-03,  2.2437e-04],\n",
            "          [-4.8157e-04, -5.0059e-03, -4.0099e-04,  7.9175e-03, -5.9100e-04],\n",
            "          [ 9.7398e-05, -8.4242e-04,  1.2803e-03,  8.2127e-03,  1.2992e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0144]],\n",
            "\n",
            "         [[ 0.0283]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0144,  0.0283], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 6, 2] = -0.014358870685100555\n",
            " somado na saída em [0, 1, 6, 2] = 0.028255797922611237\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 3\n",
            " alvo do kernel em x: x[0,0,6:11, 3:8]\n",
            " \n",
            " tensor([[0.7047, 0.9982, 0.9563, 0.6654, 0.7445],\n",
            "        [0.4064, 0.9276, 0.7929, 0.4814, 0.8254],\n",
            "        [0.3894, 0.4102, 0.8482, 0.3394, 0.1067],\n",
            "        [0.9333, 0.4410, 0.8357, 0.7493, 0.2781],\n",
            "        [0.5401, 0.8144, 0.9217, 0.2125, 0.3115]])\n",
            " produto: tensor([[[[-2.8734e-03,  3.3066e-04, -4.7495e-03,  2.5092e-03, -6.3432e-03],\n",
            "          [ 2.9790e-03, -6.7423e-03, -6.3039e-03, -3.0420e-03,  3.7382e-03],\n",
            "          [-1.4387e-03,  1.5351e-03, -7.1985e-03, -2.0592e-03, -3.9176e-04],\n",
            "          [-1.8341e-03, -3.3644e-03,  5.4721e-03, -1.7670e-03,  8.9256e-04],\n",
            "          [ 3.8196e-03,  1.5173e-03,  2.5205e-03,  2.0508e-03, -1.4047e-03]],\n",
            "\n",
            "         [[ 2.2320e-03, -4.4412e-03,  6.8342e-03,  5.3141e-03, -6.8637e-03],\n",
            "          [ 3.4692e-03,  4.4295e-03,  3.4552e-03,  1.9818e-03,  6.8617e-03],\n",
            "          [-5.1413e-04, -3.4693e-03, -2.4338e-03, -2.3903e-03,  7.0533e-05],\n",
            "          [-1.7425e-03, -2.3656e-03, -7.5983e-04,  7.0987e-03, -2.1933e-04],\n",
            "          [ 1.7150e-04, -1.2702e-03,  1.4490e-03,  1.8930e-03,  1.9045e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0221]],\n",
            "\n",
            "         [[ 0.0207]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0221,  0.0207], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 6, 3] = -0.022147610783576965\n",
            " somado na saída em [0, 1, 6, 3] = 0.020695194602012634\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 4\n",
            " alvo do kernel em x: x[0,0,6:11, 4:9]\n",
            " \n",
            " tensor([[0.9982, 0.9563, 0.6654, 0.7445, 0.7968],\n",
            "        [0.9276, 0.7929, 0.4814, 0.8254, 0.2480],\n",
            "        [0.4102, 0.8482, 0.3394, 0.1067, 0.9725],\n",
            "        [0.4410, 0.8357, 0.7493, 0.2781, 0.5913],\n",
            "        [0.8144, 0.9217, 0.2125, 0.3115, 0.1429]])\n",
            " produto: tensor([[[[-0.0041,  0.0003, -0.0033,  0.0028, -0.0068],\n",
            "          [ 0.0068, -0.0058, -0.0038, -0.0052,  0.0011],\n",
            "          [-0.0015,  0.0032, -0.0029, -0.0006, -0.0036],\n",
            "          [-0.0009, -0.0064,  0.0049, -0.0007,  0.0019],\n",
            "          [ 0.0058,  0.0017,  0.0006,  0.0030, -0.0006]],\n",
            "\n",
            "         [[ 0.0032, -0.0043,  0.0048,  0.0059, -0.0073],\n",
            "          [ 0.0079,  0.0038,  0.0021,  0.0034,  0.0021],\n",
            "          [-0.0005, -0.0072, -0.0010, -0.0008,  0.0006],\n",
            "          [-0.0008, -0.0045, -0.0007,  0.0026, -0.0005],\n",
            "          [ 0.0003, -0.0014,  0.0003,  0.0028,  0.0009]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0140]],\n",
            "\n",
            "         [[ 0.0117]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0140,  0.0117], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 6, 4] = -0.01403842680156231\n",
            " somado na saída em [0, 1, 6, 4] = 0.011711683124303818\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 5\n",
            " alvo do kernel em x: x[0,0,6:11, 5:10]\n",
            " \n",
            " tensor([[0.9563, 0.6654, 0.7445, 0.7968, 0.9249],\n",
            "        [0.7929, 0.4814, 0.8254, 0.2480, 0.9647],\n",
            "        [0.8482, 0.3394, 0.1067, 0.9725, 0.9584],\n",
            "        [0.8357, 0.7493, 0.2781, 0.5913, 0.9577],\n",
            "        [0.9217, 0.2125, 0.3115, 0.1429, 0.3531]])\n",
            " produto: tensor([[[[-0.0039,  0.0002, -0.0037,  0.0030, -0.0079],\n",
            "          [ 0.0058, -0.0035, -0.0066, -0.0016,  0.0044],\n",
            "          [-0.0031,  0.0013, -0.0009, -0.0059, -0.0035],\n",
            "          [-0.0016, -0.0057,  0.0018, -0.0014,  0.0031],\n",
            "          [ 0.0065,  0.0004,  0.0009,  0.0014, -0.0016]],\n",
            "\n",
            "         [[ 0.0030, -0.0030,  0.0053,  0.0064, -0.0085],\n",
            "          [ 0.0068,  0.0023,  0.0036,  0.0010,  0.0080],\n",
            "          [-0.0011, -0.0029, -0.0003, -0.0068,  0.0006],\n",
            "          [-0.0016, -0.0040, -0.0003,  0.0056, -0.0008],\n",
            "          [ 0.0003, -0.0003,  0.0005,  0.0013,  0.0022]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0222]],\n",
            "\n",
            "         [[ 0.0173]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0222,  0.0173], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 6, 5] = -0.022194163873791695\n",
            " somado na saída em [0, 1, 6, 5] = 0.017315911129117012\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 6\n",
            " alvo do kernel em x: x[0,0,6:11, 6:11]\n",
            " \n",
            " tensor([[0.6654, 0.7445, 0.7968, 0.9249, 0.3775],\n",
            "        [0.4814, 0.8254, 0.2480, 0.9647, 0.2576],\n",
            "        [0.3394, 0.1067, 0.9725, 0.9584, 0.9281],\n",
            "        [0.7493, 0.2781, 0.5913, 0.9577, 0.4608],\n",
            "        [0.2125, 0.3115, 0.1429, 0.3531, 0.6216]])\n",
            " produto: tensor([[[[-2.7133e-03,  2.4660e-04, -3.9573e-03,  3.4880e-03, -3.2167e-03],\n",
            "          [ 3.5289e-03, -5.9994e-03, -1.9714e-03, -6.0960e-03,  1.1665e-03],\n",
            "          [-1.2541e-03,  3.9927e-04, -8.2541e-03, -5.8150e-03, -3.4079e-03],\n",
            "          [-1.4725e-03, -2.1213e-03,  3.8717e-03, -2.2584e-03,  1.4790e-03],\n",
            "          [ 1.5024e-03,  5.8027e-04,  3.9082e-04,  3.4086e-03, -2.8033e-03]],\n",
            "\n",
            "         [[ 2.1076e-03, -3.3122e-03,  5.6942e-03,  7.3870e-03, -3.4807e-03],\n",
            "          [ 4.1095e-03,  3.9415e-03,  1.0806e-03,  3.9716e-03,  2.1411e-03],\n",
            "          [-4.4814e-04, -9.0233e-04, -2.7906e-03, -6.7500e-03,  6.1356e-04],\n",
            "          [-1.3990e-03, -1.4915e-03, -5.3761e-04,  9.0729e-03, -3.6343e-04],\n",
            "          [ 6.7456e-05, -4.8575e-04,  2.2468e-04,  3.1464e-03,  3.8007e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0313]],\n",
            "\n",
            "         [[ 0.0254]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0313,  0.0254], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 6, 6] = -0.03127850592136383\n",
            " somado na saída em [0, 1, 6, 6] = 0.02539757452905178\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 7\n",
            " alvo do kernel em x: x[0,0,6:11, 7:12]\n",
            " \n",
            " tensor([[0.7445, 0.7968, 0.9249, 0.3775, 0.5857],\n",
            "        [0.8254, 0.2480, 0.9647, 0.2576, 0.8060],\n",
            "        [0.1067, 0.9725, 0.9584, 0.9281, 0.1966],\n",
            "        [0.2781, 0.5913, 0.9577, 0.4608, 0.8245],\n",
            "        [0.3115, 0.1429, 0.3531, 0.6216, 0.4888]])\n",
            " produto: tensor([[[[-3.0357e-03,  2.6393e-04, -4.5938e-03,  1.4237e-03, -4.9907e-03],\n",
            "          [ 6.0506e-03, -1.8023e-03, -7.6700e-03, -1.6275e-03,  3.6503e-03],\n",
            "          [-3.9423e-04,  3.6393e-03, -8.1345e-03, -5.6312e-03, -7.2171e-04],\n",
            "          [-5.4645e-04, -4.5107e-03,  6.2706e-03, -1.0866e-03,  2.6467e-03],\n",
            "          [ 2.2025e-03,  2.6627e-04,  9.6563e-04,  5.9996e-03, -2.2047e-03]],\n",
            "\n",
            "         [[ 2.3581e-03, -3.5450e-03,  6.6100e-03,  3.0151e-03, -5.4002e-03],\n",
            "          [ 7.0461e-03,  1.1841e-03,  4.2040e-03,  1.0603e-03,  6.7003e-03],\n",
            "          [-1.4088e-04, -8.2246e-03, -2.7502e-03, -6.5366e-03,  1.2994e-04],\n",
            "          [-5.1917e-04, -3.1716e-03, -8.7071e-04,  4.3653e-03, -6.5036e-04],\n",
            "          [ 9.8888e-05, -2.2290e-04,  5.5514e-04,  5.5381e-03,  2.9892e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0136]],\n",
            "\n",
            "         [[ 0.0138]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0136,  0.0138], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 6, 7] = -0.01357097178697586\n",
            " somado na saída em [0, 1, 6, 7] = 0.013822388835251331\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 0\n",
            " alvo do kernel em x: x[0,0,7:12, 0:5]\n",
            " \n",
            " tensor([[0.9398, 0.3753, 0.9446, 0.4064, 0.9276],\n",
            "        [0.9859, 0.9918, 0.3211, 0.3894, 0.4102],\n",
            "        [0.0462, 0.9147, 0.2579, 0.9333, 0.4410],\n",
            "        [0.0877, 0.7694, 0.3068, 0.5401, 0.8144],\n",
            "        [0.6716, 0.8080, 0.9115, 0.0670, 0.6109]])\n",
            " produto: tensor([[[[-3.8325e-03,  1.2433e-04, -4.6916e-03,  1.5326e-03, -7.9038e-03],\n",
            "          [ 7.2274e-03, -7.2085e-03, -2.5528e-03, -2.4604e-03,  1.8579e-03],\n",
            "          [-1.7077e-04,  3.4231e-03, -2.1891e-03, -5.6624e-03, -1.6193e-03],\n",
            "          [-1.7242e-04, -5.8697e-03,  2.0087e-03, -1.2738e-03,  2.6142e-03],\n",
            "          [ 4.7490e-03,  1.5054e-03,  2.4926e-03,  6.4648e-04, -2.7553e-03]],\n",
            "\n",
            "         [[ 2.9770e-03, -1.6699e-03,  6.7509e-03,  3.2457e-03, -8.5523e-03],\n",
            "          [ 8.4165e-03,  4.7358e-03,  1.3992e-03,  1.6030e-03,  3.4102e-03],\n",
            "          [-6.1025e-05, -7.7359e-03, -7.4012e-04, -6.5728e-03,  2.9155e-04],\n",
            "          [-1.6381e-04, -4.1271e-03, -2.7892e-04,  5.1174e-03, -6.4238e-04],\n",
            "          [ 2.1322e-04, -1.2602e-03,  1.4330e-03,  5.9675e-04,  3.7357e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0202]],\n",
            "\n",
            "         [[ 0.0121]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0202,  0.0121], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 7, 0] = -0.020180733874440193\n",
            " somado na saída em [0, 1, 7, 0] = 0.012121223844587803\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 1\n",
            " alvo do kernel em x: x[0,0,7:12, 1:6]\n",
            " \n",
            " tensor([[0.3753, 0.9446, 0.4064, 0.9276, 0.7929],\n",
            "        [0.9918, 0.3211, 0.3894, 0.4102, 0.8482],\n",
            "        [0.9147, 0.2579, 0.9333, 0.4410, 0.8357],\n",
            "        [0.7694, 0.3068, 0.5401, 0.8144, 0.9217],\n",
            "        [0.8080, 0.9115, 0.0670, 0.6109, 0.1301]])\n",
            " produto: tensor([[[[-0.0015,  0.0003, -0.0020,  0.0035, -0.0068],\n",
            "          [ 0.0073, -0.0023, -0.0031, -0.0026,  0.0038],\n",
            "          [-0.0034,  0.0010, -0.0079, -0.0027, -0.0031],\n",
            "          [-0.0015, -0.0023,  0.0035, -0.0019,  0.0030],\n",
            "          [ 0.0057,  0.0017,  0.0002,  0.0059, -0.0006]],\n",
            "\n",
            "         [[ 0.0012, -0.0042,  0.0029,  0.0074, -0.0073],\n",
            "          [ 0.0085,  0.0015,  0.0017,  0.0017,  0.0071],\n",
            "          [-0.0012, -0.0022, -0.0027, -0.0031,  0.0006],\n",
            "          [-0.0014, -0.0016, -0.0005,  0.0077, -0.0007],\n",
            "          [ 0.0003, -0.0014,  0.0001,  0.0054,  0.0008]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0059]],\n",
            "\n",
            "         [[ 0.0204]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0059,  0.0204], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 7, 1] = -0.005856288596987724\n",
            " somado na saída em [0, 1, 7, 1] = 0.02039818838238716\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 2\n",
            " alvo do kernel em x: x[0,0,7:12, 2:7]\n",
            " \n",
            " tensor([[0.9446, 0.4064, 0.9276, 0.7929, 0.4814],\n",
            "        [0.3211, 0.3894, 0.4102, 0.8482, 0.3394],\n",
            "        [0.2579, 0.9333, 0.4410, 0.8357, 0.7493],\n",
            "        [0.3068, 0.5401, 0.8144, 0.9217, 0.2125],\n",
            "        [0.9115, 0.0670, 0.6109, 0.1301, 0.8512]])\n",
            " produto: tensor([[[[-0.0039,  0.0001, -0.0046,  0.0030, -0.0041],\n",
            "          [ 0.0024, -0.0028, -0.0033, -0.0054,  0.0015],\n",
            "          [-0.0010,  0.0035, -0.0037, -0.0051, -0.0028],\n",
            "          [-0.0006, -0.0041,  0.0053, -0.0022,  0.0007],\n",
            "          [ 0.0064,  0.0001,  0.0017,  0.0013, -0.0038]],\n",
            "\n",
            "         [[ 0.0030, -0.0018,  0.0066,  0.0063, -0.0044],\n",
            "          [ 0.0027,  0.0019,  0.0018,  0.0035,  0.0028],\n",
            "          [-0.0003, -0.0079, -0.0013, -0.0059,  0.0005],\n",
            "          [-0.0006, -0.0029, -0.0007,  0.0087, -0.0002],\n",
            "          [ 0.0003, -0.0001,  0.0010,  0.0012,  0.0052]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0212]],\n",
            "\n",
            "         [[ 0.0194]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0212,  0.0194], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 7, 2] = -0.021246079355478287\n",
            " somado na saída em [0, 1, 7, 2] = 0.019383322447538376\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 3\n",
            " alvo do kernel em x: x[0,0,7:12, 3:8]\n",
            " \n",
            " tensor([[0.4064, 0.9276, 0.7929, 0.4814, 0.8254],\n",
            "        [0.3894, 0.4102, 0.8482, 0.3394, 0.1067],\n",
            "        [0.9333, 0.4410, 0.8357, 0.7493, 0.2781],\n",
            "        [0.5401, 0.8144, 0.9217, 0.2125, 0.3115],\n",
            "        [0.0670, 0.6109, 0.1301, 0.8512, 0.7878]])\n",
            " produto: tensor([[[[-1.6572e-03,  3.0727e-04, -3.9380e-03,  1.8155e-03, -7.0330e-03],\n",
            "          [ 2.8543e-03, -2.9817e-03, -6.7432e-03, -2.1446e-03,  4.8322e-04],\n",
            "          [-3.4484e-03,  1.6504e-03, -7.0928e-03, -4.5461e-03, -1.0210e-03],\n",
            "          [-1.0615e-03, -6.2129e-03,  6.0354e-03, -5.0105e-04,  9.9974e-04],\n",
            "          [ 4.7361e-04,  1.1382e-03,  3.5579e-04,  8.2162e-03, -3.5530e-03]],\n",
            "\n",
            "         [[ 1.2873e-03, -4.1271e-03,  5.6665e-03,  3.8448e-03, -7.6101e-03],\n",
            "          [ 3.3239e-03,  1.9589e-03,  3.6960e-03,  1.3972e-03,  8.8697e-04],\n",
            "          [-1.2323e-03, -3.7297e-03, -2.3980e-03, -5.2770e-03,  1.8382e-04],\n",
            "          [-1.0085e-03, -4.3685e-03, -8.3805e-04,  2.0128e-03, -2.4566e-04],\n",
            "          [ 2.1265e-05, -9.5278e-04,  2.0454e-04,  7.5842e-03,  4.8172e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0276]],\n",
            "\n",
            "         [[ 0.0051]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0276,  0.0051], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 7, 3] = -0.027604907751083374\n",
            " somado na saída em [0, 1, 7, 3] = 0.005097698420286179\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 4\n",
            " alvo do kernel em x: x[0,0,7:12, 4:9]\n",
            " \n",
            " tensor([[0.9276, 0.7929, 0.4814, 0.8254, 0.2480],\n",
            "        [0.4102, 0.8482, 0.3394, 0.1067, 0.9725],\n",
            "        [0.4410, 0.8357, 0.7493, 0.2781, 0.5913],\n",
            "        [0.8144, 0.9217, 0.2125, 0.3115, 0.1429],\n",
            "        [0.6109, 0.1301, 0.8512, 0.7878, 0.8646]])\n",
            " produto: tensor([[[[-0.0038,  0.0003, -0.0024,  0.0031, -0.0021],\n",
            "          [ 0.0030, -0.0062, -0.0027, -0.0007,  0.0044],\n",
            "          [-0.0016,  0.0031, -0.0064, -0.0017, -0.0022],\n",
            "          [-0.0016, -0.0070,  0.0014, -0.0007,  0.0005],\n",
            "          [ 0.0043,  0.0002,  0.0023,  0.0076, -0.0039]],\n",
            "\n",
            "         [[ 0.0029, -0.0035,  0.0034,  0.0066, -0.0023],\n",
            "          [ 0.0035,  0.0041,  0.0015,  0.0004,  0.0081],\n",
            "          [-0.0006, -0.0071, -0.0022, -0.0020,  0.0004],\n",
            "          [-0.0015, -0.0049, -0.0002,  0.0030, -0.0001],\n",
            "          [ 0.0002, -0.0002,  0.0013,  0.0070,  0.0053]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0127]],\n",
            "\n",
            "         [[ 0.0232]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0127,  0.0232], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 7, 4] = -0.01267842948436737\n",
            " somado na saída em [0, 1, 7, 4] = 0.02315988391637802\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 5\n",
            " alvo do kernel em x: x[0,0,7:12, 5:10]\n",
            " \n",
            " tensor([[0.7929, 0.4814, 0.8254, 0.2480, 0.9647],\n",
            "        [0.8482, 0.3394, 0.1067, 0.9725, 0.9584],\n",
            "        [0.8357, 0.7493, 0.2781, 0.5913, 0.9577],\n",
            "        [0.9217, 0.2125, 0.3115, 0.1429, 0.3531],\n",
            "        [0.1301, 0.8512, 0.7878, 0.8646, 0.2197]])\n",
            " produto: tensor([[[[-3.2333e-03,  1.5946e-04, -4.0995e-03,  9.3512e-04, -8.2200e-03],\n",
            "          [ 6.2173e-03, -2.4669e-03, -8.4828e-04, -6.1452e-03,  4.3407e-03],\n",
            "          [-3.0878e-03,  2.8039e-03, -2.3600e-03, -3.5875e-03, -3.5163e-03],\n",
            "          [-1.8114e-03, -1.6208e-03,  2.0394e-03, -3.3705e-04,  1.1335e-03],\n",
            "          [ 9.2007e-04,  1.5858e-03,  2.1542e-03,  8.3457e-03, -9.9075e-04]],\n",
            "\n",
            "         [[ 2.5115e-03, -2.1419e-03,  5.8988e-03,  1.9804e-03, -8.8946e-03],\n",
            "          [ 7.2402e-03,  1.6207e-03,  4.6495e-04,  4.0036e-03,  7.9674e-03],\n",
            "          [-1.1035e-03, -6.3367e-03, -7.9791e-04, -4.1643e-03,  6.3307e-04],\n",
            "          [-1.7209e-03, -1.1396e-03, -2.8318e-04,  1.3540e-03, -2.7853e-04],\n",
            "          [ 4.1310e-05, -1.3275e-03,  1.2384e-03,  7.7037e-03,  1.3433e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0117]],\n",
            "\n",
            "         [[ 0.0158]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0117,  0.0158], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 7, 5] = -0.011689680628478527\n",
            " somado na saída em [0, 1, 7, 5] = 0.015813009813427925\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 6\n",
            " alvo do kernel em x: x[0,0,7:12, 6:11]\n",
            " \n",
            " tensor([[0.4814, 0.8254, 0.2480, 0.9647, 0.2576],\n",
            "        [0.3394, 0.1067, 0.9725, 0.9584, 0.9281],\n",
            "        [0.7493, 0.2781, 0.5913, 0.9577, 0.4608],\n",
            "        [0.2125, 0.3115, 0.1429, 0.3531, 0.6216],\n",
            "        [0.8512, 0.7878, 0.8646, 0.2197, 0.5026]])\n",
            " produto: tensor([[[[-0.0020,  0.0003, -0.0012,  0.0036, -0.0022],\n",
            "          [ 0.0025, -0.0008, -0.0077, -0.0061,  0.0042],\n",
            "          [-0.0028,  0.0010, -0.0050, -0.0058, -0.0017],\n",
            "          [-0.0004, -0.0024,  0.0009, -0.0008,  0.0020],\n",
            "          [ 0.0060,  0.0015,  0.0024,  0.0021, -0.0023]],\n",
            "\n",
            "         [[ 0.0015, -0.0037,  0.0018,  0.0077, -0.0024],\n",
            "          [ 0.0029,  0.0005,  0.0042,  0.0039,  0.0077],\n",
            "          [-0.0010, -0.0024, -0.0017, -0.0067,  0.0003],\n",
            "          [-0.0004, -0.0017, -0.0001,  0.0033, -0.0005],\n",
            "          [ 0.0003, -0.0012,  0.0014,  0.0020,  0.0031]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0146]],\n",
            "\n",
            "         [[ 0.0189]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0146,  0.0189], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 7, 6] = -0.014589402824640274\n",
            " somado na saída em [0, 1, 7, 6] = 0.01887291669845581\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 7\n",
            " alvo do kernel em x: x[0,0,7:12, 7:12]\n",
            " \n",
            " tensor([[0.8254, 0.2480, 0.9647, 0.2576, 0.8060],\n",
            "        [0.1067, 0.9725, 0.9584, 0.9281, 0.1966],\n",
            "        [0.2781, 0.5913, 0.9577, 0.4608, 0.8245],\n",
            "        [0.3115, 0.1429, 0.3531, 0.6216, 0.4888],\n",
            "        [0.7878, 0.8646, 0.2197, 0.5026, 0.9169]])\n",
            " produto: tensor([[[[-3.3658e-03,  8.2138e-05, -4.7914e-03,  9.7131e-04, -6.8676e-03],\n",
            "          [ 7.8213e-04, -7.0687e-03, -7.6199e-03, -5.8647e-03,  8.9019e-04],\n",
            "          [-1.0274e-03,  2.2127e-03, -8.1279e-03, -2.7956e-03, -3.0275e-03],\n",
            "          [-6.1208e-04, -1.0903e-03,  2.3122e-03, -1.4658e-03,  1.5691e-03],\n",
            "          [ 5.5707e-03,  1.6108e-03,  6.0070e-04,  4.8519e-03, -4.1355e-03]],\n",
            "\n",
            "         [[ 2.6145e-03, -1.1032e-03,  6.8945e-03,  2.0571e-03, -7.4311e-03],\n",
            "          [ 9.1081e-04,  4.6439e-03,  4.1765e-03,  3.8209e-03,  1.6340e-03],\n",
            "          [-3.6716e-04, -5.0005e-03, -2.7480e-03, -3.2451e-03,  5.4508e-04],\n",
            "          [-5.8152e-04, -7.6660e-04, -3.2107e-04,  5.8886e-03, -3.8557e-04],\n",
            "          [ 2.5012e-04, -1.3484e-03,  3.4534e-04,  4.4787e-03,  5.6070e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0364]],\n",
            "\n",
            "         [[ 0.0206]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0364,  0.0206], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 7, 7] = -0.03640642389655113\n",
            " somado na saída em [0, 1, 7, 7] = 0.02056865766644478\n",
            "\n",
            "ndx_amostra: 1\n",
            "\n",
            "ndx_in_channels: 0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 0\n",
            " alvo do kernel em x: x[1,0,0:5, 0:5]\n",
            " \n",
            " tensor([[0.1217, 0.4824, 0.2845, 0.6832, 0.2663],\n",
            "        [0.9385, 0.3673, 0.1423, 0.6957, 0.8008],\n",
            "        [0.5097, 0.4730, 0.5628, 0.2998, 0.5782],\n",
            "        [0.6232, 0.8195, 0.5177, 0.0437, 0.7119],\n",
            "        [0.0968, 0.2017, 0.3258, 0.1467, 0.4204]])\n",
            " produto: tensor([[[[-4.9638e-04,  1.5978e-04, -1.4132e-03,  2.5763e-03, -2.2689e-03],\n",
            "          [ 6.8798e-03, -2.6698e-03, -1.1311e-03, -4.3961e-03,  3.6267e-03],\n",
            "          [-1.8834e-03,  1.7699e-03, -4.7768e-03, -1.8190e-03, -2.1232e-03],\n",
            "          [-1.2247e-03, -6.2520e-03,  3.3899e-03, -1.0294e-04,  2.2852e-03],\n",
            "          [ 6.8485e-04,  3.7574e-04,  8.9082e-04,  1.4163e-03, -1.8962e-03]],\n",
            "\n",
            "         [[ 3.8558e-04, -2.1461e-03,  2.0335e-03,  5.4560e-03, -2.4551e-03],\n",
            "          [ 8.0117e-03,  1.7540e-03,  6.1998e-04,  2.8640e-03,  6.6570e-03],\n",
            "          [-6.7304e-04, -3.9999e-03, -1.6150e-03, -2.1114e-03,  3.8226e-04],\n",
            "          [-1.1635e-03, -4.3959e-03, -4.7071e-04,  4.1355e-04, -5.6152e-04],\n",
            "          [ 3.0749e-05, -3.1454e-04,  5.1213e-04,  1.3073e-03,  2.5709e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0084]],\n",
            "\n",
            "         [[ 0.0131]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0084,  0.0131], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 0, 0] = -0.008398318663239479\n",
            " somado na saída em [1, 1, 0, 0] = 0.013091996312141418\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 1\n",
            " alvo do kernel em x: x[1,0,0:5, 1:6]\n",
            " \n",
            " tensor([[0.4824, 0.2845, 0.6832, 0.2663, 0.0925],\n",
            "        [0.3673, 0.1423, 0.6957, 0.8008, 0.7165],\n",
            "        [0.4730, 0.5628, 0.2998, 0.5782, 0.3526],\n",
            "        [0.8195, 0.5177, 0.0437, 0.7119, 0.4252],\n",
            "        [0.2017, 0.3258, 0.1467, 0.4204, 0.9732]])\n",
            " produto: tensor([[[[-1.9670e-03,  9.4253e-05, -3.3929e-03,  1.0042e-03, -7.8797e-04],\n",
            "          [ 2.6926e-03, -1.0341e-03, -5.5311e-03, -5.0601e-03,  3.2448e-03],\n",
            "          [-1.7476e-03,  2.1061e-03, -2.5445e-03, -3.5084e-03, -1.2946e-03],\n",
            "          [-1.6106e-03, -3.9494e-03,  2.8582e-04, -1.6789e-03,  1.3647e-03],\n",
            "          [ 1.4262e-03,  6.0693e-04,  4.0122e-04,  4.0582e-03, -4.3892e-03]],\n",
            "\n",
            "         [[ 1.5279e-03, -1.2660e-03,  4.8821e-03,  2.1267e-03, -8.5263e-04],\n",
            "          [ 3.1356e-03,  6.7938e-04,  3.0317e-03,  3.2967e-03,  5.9560e-03],\n",
            "          [-6.2450e-04, -4.7597e-03, -8.6027e-04, -4.0725e-03,  2.3309e-04],\n",
            "          [-1.5301e-03, -2.7769e-03, -3.9688e-05,  6.7447e-03, -3.3534e-04],\n",
            "          [ 6.4033e-05, -5.0807e-04,  2.3066e-04,  3.7461e-03,  5.9510e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0212]],\n",
            "\n",
            "         [[ 0.0240]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0212,  0.0240], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 0, 1] = -0.02121133729815483\n",
            " somado na saída em [1, 1, 0, 1] = 0.023979922756552696\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 2\n",
            " alvo do kernel em x: x[1,0,0:5, 2:7]\n",
            " \n",
            " tensor([[0.2845, 0.6832, 0.2663, 0.0925, 0.0368],\n",
            "        [0.1423, 0.6957, 0.8008, 0.7165, 0.5242],\n",
            "        [0.5628, 0.2998, 0.5782, 0.3526, 0.1289],\n",
            "        [0.5177, 0.0437, 0.7119, 0.4252, 0.2123],\n",
            "        [0.3258, 0.1467, 0.4204, 0.9732, 0.6671]])\n",
            " produto: tensor([[[[-1.1603e-03,  2.2629e-04, -1.3226e-03,  3.4875e-04, -3.1344e-04],\n",
            "          [ 1.0429e-03, -5.0567e-03, -6.3666e-03, -4.5273e-03,  2.3740e-03],\n",
            "          [-2.0795e-03,  1.1219e-03, -4.9078e-03, -2.1393e-03, -4.7331e-04],\n",
            "          [-1.0174e-03, -3.3300e-04,  4.6615e-03, -1.0026e-03,  6.8132e-04],\n",
            "          [ 2.3037e-03,  2.7336e-04,  1.1497e-03,  9.3938e-03, -3.0088e-03]],\n",
            "\n",
            "         [[ 9.0129e-04, -3.0395e-03,  1.9030e-03,  7.3859e-04, -3.3916e-04],\n",
            "          [ 1.2145e-03,  3.3221e-03,  3.4896e-03,  2.9495e-03,  4.3576e-03],\n",
            "          [-7.4314e-04, -2.5354e-03, -1.6593e-03, -2.4832e-03,  8.5215e-05],\n",
            "          [-9.6661e-04, -2.3414e-04, -6.4728e-04,  4.0279e-03, -1.6742e-04],\n",
            "          [ 1.0343e-04, -2.2883e-04,  6.6094e-04,  8.6713e-03,  4.0794e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0101]],\n",
            "\n",
            "         [[ 0.0235]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0101,  0.0235], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 0, 2] = -0.010131290182471275\n",
            " somado na saída em [1, 1, 0, 2] = 0.023460429161787033\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 3\n",
            " alvo do kernel em x: x[1,0,0:5, 3:8]\n",
            " \n",
            " tensor([[0.6832, 0.2663, 0.0925, 0.0368, 0.0938],\n",
            "        [0.6957, 0.8008, 0.7165, 0.5242, 0.3098],\n",
            "        [0.2998, 0.5782, 0.3526, 0.1289, 0.6350],\n",
            "        [0.0437, 0.7119, 0.4252, 0.2123, 0.9024],\n",
            "        [0.1467, 0.4204, 0.9732, 0.6671, 0.6361]])\n",
            " produto: tensor([[[[-2.7857e-03,  8.8208e-05, -4.5930e-04,  1.3873e-04, -7.9965e-04],\n",
            "          [ 5.0998e-03, -5.8205e-03, -5.6962e-03, -3.3123e-03,  1.4032e-03],\n",
            "          [-1.1077e-03,  2.1639e-03, -2.9926e-03, -7.8210e-04, -2.3315e-03],\n",
            "          [-8.5782e-05, -5.4309e-03,  2.7839e-03, -5.0057e-04,  2.8967e-03],\n",
            "          [ 1.0376e-03,  7.8328e-04,  2.6612e-03,  6.4394e-03, -2.8688e-03]],\n",
            "\n",
            "         [[ 2.1639e-03, -1.1848e-03,  6.6090e-04,  2.9380e-04, -8.6527e-04],\n",
            "          [ 5.9389e-03,  3.8239e-03,  3.1221e-03,  2.1580e-03,  2.5757e-03],\n",
            "          [-3.9585e-04, -4.8902e-03, -1.0118e-03, -9.0785e-04,  4.1976e-04],\n",
            "          [-8.1499e-05, -3.8186e-03, -3.8655e-04,  2.0109e-03, -7.1179e-04],\n",
            "          [ 4.6586e-05, -6.5570e-04,  1.5299e-03,  5.9441e-03,  3.8896e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0095]],\n",
            "\n",
            "         [[ 0.0197]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0095,  0.0197], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 0, 3] = -0.009477764368057251\n",
            " somado na saída em [1, 1, 0, 3] = 0.01966813951730728\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 4\n",
            " alvo do kernel em x: x[1,0,0:5, 4:9]\n",
            " \n",
            " tensor([[0.2663, 0.0925, 0.0368, 0.0938, 0.0085],\n",
            "        [0.8008, 0.7165, 0.5242, 0.3098, 0.6991],\n",
            "        [0.5782, 0.3526, 0.1289, 0.6350, 0.1601],\n",
            "        [0.7119, 0.4252, 0.2123, 0.9024, 0.3795],\n",
            "        [0.4204, 0.9732, 0.6671, 0.6361, 0.3680]])\n",
            " produto: tensor([[[[-1.0859e-03,  3.0633e-05, -1.8271e-04,  3.5392e-04, -7.2095e-05],\n",
            "          [ 5.8702e-03, -5.2076e-03, -4.1675e-03, -1.9578e-03,  3.1662e-03],\n",
            "          [-2.1366e-03,  1.3195e-03, -1.0941e-03, -3.8526e-03, -5.8784e-04],\n",
            "          [-1.3991e-03, -3.2433e-03,  1.3898e-03, -2.1282e-03,  1.2182e-03],\n",
            "          [ 2.9730e-03,  1.8131e-03,  1.8242e-03,  6.1398e-03, -1.6599e-03]],\n",
            "\n",
            "         [[ 8.4348e-04, -4.1145e-04,  2.6290e-04,  7.4954e-04, -7.8011e-05],\n",
            "          [ 6.8359e-03,  3.4212e-03,  2.2843e-03,  1.2755e-03,  5.8117e-03],\n",
            "          [-7.6352e-04, -2.9819e-03, -3.6989e-04, -4.4720e-03,  1.0583e-04],\n",
            "          [-1.3292e-03, -2.2805e-03, -1.9299e-04,  8.5496e-03, -2.9934e-04],\n",
            "          [ 1.3349e-04, -1.5178e-03,  1.0488e-03,  5.6676e-03,  2.2505e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0027]],\n",
            "\n",
            "         [[ 0.0245]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0027,  0.0245], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 0, 4] = -0.0026765030343085527\n",
            " somado na saída em [1, 1, 0, 4] = 0.024543844163417816\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 5\n",
            " alvo do kernel em x: x[1,0,0:5, 5:10]\n",
            " \n",
            " tensor([[0.0925, 0.0368, 0.0938, 0.0085, 0.3702],\n",
            "        [0.7165, 0.5242, 0.3098, 0.6991, 0.4595],\n",
            "        [0.3526, 0.1289, 0.6350, 0.1601, 0.4915],\n",
            "        [0.4252, 0.2123, 0.9024, 0.3795, 0.7841],\n",
            "        [0.9732, 0.6671, 0.6361, 0.3680, 0.1596]])\n",
            " produto: tensor([[[[-3.7711e-04,  1.2185e-05, -4.6611e-04,  3.1909e-05, -3.1540e-03],\n",
            "          [ 5.2520e-03, -3.8100e-03, -2.4634e-03, -4.4176e-03,  2.0812e-03],\n",
            "          [-1.3028e-03,  4.8238e-04, -5.3892e-03, -9.7134e-04, -1.8046e-03],\n",
            "          [-8.3551e-04, -1.6192e-03,  5.9090e-03, -8.9499e-04,  2.5167e-03],\n",
            "          [ 6.8819e-03,  1.2429e-03,  1.7394e-03,  3.5525e-03, -7.1984e-04]],\n",
            "\n",
            "         [[ 2.9293e-04, -1.6367e-04,  6.7070e-04,  6.7577e-05, -3.4128e-03],\n",
            "          [ 6.1161e-03,  2.5031e-03,  1.3502e-03,  2.8781e-03,  3.8202e-03],\n",
            "          [-4.6556e-04, -1.0902e-03, -1.8221e-03, -1.1275e-03,  3.2490e-04],\n",
            "          [-7.9379e-04, -1.1385e-03, -8.2050e-04,  3.5954e-03, -6.1843e-04],\n",
            "          [ 3.0899e-04, -1.0404e-03,  9.9997e-04,  3.2792e-03,  9.7599e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[0.0015]],\n",
            "\n",
            "         [[0.0147]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([0.0015, 0.0147], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 0, 5] = 0.0014763404615223408\n",
            " somado na saída em [1, 1, 0, 5] = 0.014689842239022255\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 6\n",
            " alvo do kernel em x: x[1,0,0:5, 6:11]\n",
            " \n",
            " tensor([[0.0368, 0.0938, 0.0085, 0.3702, 0.8290],\n",
            "        [0.5242, 0.3098, 0.6991, 0.4595, 0.3907],\n",
            "        [0.1289, 0.6350, 0.1601, 0.4915, 0.5033],\n",
            "        [0.2123, 0.9024, 0.3795, 0.7841, 0.2753],\n",
            "        [0.6671, 0.6361, 0.3680, 0.1596, 0.7024]])\n",
            " produto: tensor([[[[-1.5001e-04,  3.1087e-05, -4.2024e-05,  1.3960e-03, -7.0638e-03],\n",
            "          [ 3.8426e-03, -2.2520e-03, -5.5582e-03, -2.9038e-03,  1.7696e-03],\n",
            "          [-4.7630e-04,  2.3762e-03, -1.3588e-03, -2.9819e-03, -1.8481e-03],\n",
            "          [-4.1713e-04, -6.8843e-03,  2.4850e-03, -1.8491e-03,  8.8369e-04],\n",
            "          [ 4.7175e-03,  1.1851e-03,  1.0064e-03,  1.5406e-03, -3.1681e-03]],\n",
            "\n",
            "         [[ 1.1652e-04, -4.1755e-04,  6.0469e-05,  2.9564e-03, -7.6434e-03],\n",
            "          [ 4.4747e-03,  1.4795e-03,  3.0465e-03,  1.8918e-03,  3.2481e-03],\n",
            "          [-1.7021e-04, -5.3700e-03, -4.5939e-04, -3.4613e-03,  3.3274e-04],\n",
            "          [-3.9630e-04, -4.8405e-03, -3.4505e-04,  7.4282e-03, -2.1715e-04],\n",
            "          [ 2.1181e-04, -9.9204e-04,  5.7858e-04,  1.4221e-03,  4.2953e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0157]],\n",
            "\n",
            "         [[ 0.0072]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0157,  0.0072], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 0, 6] = -0.01571996882557869\n",
            " somado na saída em [1, 1, 0, 6] = 0.0072299460880458355\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 7\n",
            " alvo do kernel em x: x[1,0,0:5, 7:12]\n",
            " \n",
            " tensor([[0.0938, 0.0085, 0.3702, 0.8290, 0.4571],\n",
            "        [0.3098, 0.6991, 0.4595, 0.3907, 0.7779],\n",
            "        [0.6350, 0.1601, 0.4915, 0.5033, 0.0505],\n",
            "        [0.9024, 0.3795, 0.7841, 0.2753, 0.3868],\n",
            "        [0.6361, 0.3680, 0.1596, 0.7024, 0.4539]])\n",
            " produto: tensor([[[[-3.8270e-04,  2.8028e-06, -1.8385e-03,  3.1264e-03, -3.8951e-03],\n",
            "          [ 2.2713e-03, -5.0814e-03, -3.6536e-03, -2.4689e-03,  3.5229e-03],\n",
            "          [-2.3462e-03,  5.9910e-04, -4.1713e-03, -3.0539e-03, -1.8549e-04],\n",
            "          [-1.7734e-03, -2.8951e-03,  5.1339e-03, -6.4925e-04,  1.2417e-03],\n",
            "          [ 4.4980e-03,  6.8567e-04,  4.3645e-04,  6.7803e-03, -2.0473e-03]],\n",
            "\n",
            "         [[ 2.9727e-04, -3.7646e-05,  2.6454e-03,  6.6211e-03, -4.2148e-03],\n",
            "          [ 2.6449e-03,  3.3383e-03,  2.0025e-03,  1.6085e-03,  6.4663e-03],\n",
            "          [-8.3842e-04, -1.3539e-03, -1.4103e-03, -3.5449e-03,  3.3395e-05],\n",
            "          [-1.6849e-03, -2.0356e-03, -7.1288e-04,  2.6082e-03, -3.0513e-04],\n",
            "          [ 2.0196e-04, -5.7399e-04,  2.5091e-04,  6.2588e-03,  2.7758e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0061]],\n",
            "\n",
            "         [[ 0.0210]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0061,  0.0210], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 0, 7] = -0.006143610924482346\n",
            " somado na saída em [1, 1, 0, 7] = 0.021041110157966614\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 0\n",
            " alvo do kernel em x: x[1,0,1:6, 0:5]\n",
            " \n",
            " tensor([[0.9385, 0.3673, 0.1423, 0.6957, 0.8008],\n",
            "        [0.5097, 0.4730, 0.5628, 0.2998, 0.5782],\n",
            "        [0.6232, 0.8195, 0.5177, 0.0437, 0.7119],\n",
            "        [0.0968, 0.2017, 0.3258, 0.1467, 0.4204],\n",
            "        [0.8581, 0.0401, 0.5533, 0.1137, 0.3734]])\n",
            " produto: tensor([[[[-3.8271e-03,  1.2167e-04, -7.0661e-04,  2.6236e-03, -6.8232e-03],\n",
            "          [ 3.7365e-03, -3.4377e-03, -4.4746e-03, -1.8944e-03,  2.6189e-03],\n",
            "          [-2.3026e-03,  3.0668e-03, -4.3940e-03, -2.6484e-04, -2.6140e-03],\n",
            "          [-1.9033e-04, -1.5385e-03,  2.1331e-03, -3.4603e-04,  1.3495e-03],\n",
            "          [ 6.0677e-03,  7.4623e-05,  1.5130e-03,  1.0974e-03, -1.6840e-03]],\n",
            "\n",
            "         [[ 2.9728e-03, -1.6343e-03,  1.0168e-03,  5.5563e-03, -7.3831e-03],\n",
            "          [ 4.3513e-03,  2.2585e-03,  2.4526e-03,  1.2342e-03,  4.8070e-03],\n",
            "          [-8.2284e-04, -6.9308e-03, -1.4856e-03, -3.0742e-04,  4.7062e-04],\n",
            "          [-1.8082e-04, -1.0818e-03, -2.9619e-04,  1.3901e-03, -3.3161e-04],\n",
            "          [ 2.7244e-04, -6.2468e-05,  8.6984e-04,  1.0130e-03,  2.2833e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0101]],\n",
            "\n",
            "         [[ 0.0104]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0101,  0.0104], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 1, 0] = -0.010094990953803062\n",
            " somado na saída em [1, 1, 1, 0] = 0.010431692935526371\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 1\n",
            " alvo do kernel em x: x[1,0,1:6, 1:6]\n",
            " \n",
            " tensor([[0.3673, 0.1423, 0.6957, 0.8008, 0.7165],\n",
            "        [0.4730, 0.5628, 0.2998, 0.5782, 0.3526],\n",
            "        [0.8195, 0.5177, 0.0437, 0.7119, 0.4252],\n",
            "        [0.2017, 0.3258, 0.1467, 0.4204, 0.9732],\n",
            "        [0.0401, 0.5533, 0.1137, 0.3734, 0.4479]])\n",
            " produto: tensor([[[[-1.4978e-03,  4.7127e-05, -3.4553e-03,  3.0199e-03, -6.1047e-03],\n",
            "          [ 3.4670e-03, -4.0907e-03, -2.3835e-03, -3.6539e-03,  1.5969e-03],\n",
            "          [-3.0281e-03,  1.9373e-03, -3.7048e-04, -4.3193e-03, -1.5611e-03],\n",
            "          [-3.9634e-04, -2.4852e-03,  9.6075e-04, -9.9150e-04,  3.1238e-03],\n",
            "          [ 2.8324e-04,  1.0309e-03,  3.1089e-04,  3.6042e-03, -2.0201e-03]],\n",
            "\n",
            "         [[ 1.1635e-03, -6.3300e-04,  4.9719e-03,  6.3956e-03, -6.6056e-03],\n",
            "          [ 4.0374e-03,  2.6875e-03,  1.3064e-03,  2.3805e-03,  2.9311e-03],\n",
            "          [-1.0821e-03, -4.3783e-03, -1.2526e-04, -5.0138e-03,  2.8105e-04],\n",
            "          [-3.7655e-04, -1.7474e-03, -1.3341e-04,  3.9832e-03, -7.6761e-04],\n",
            "          [ 1.2717e-05, -8.6295e-04,  1.7873e-04,  3.3270e-03,  2.7389e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0170]],\n",
            "\n",
            "         [[ 0.0147]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0170,  0.0147], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 1, 1] = -0.016976019367575645\n",
            " somado na saída em [1, 1, 1, 1] = 0.014669477939605713\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 2\n",
            " alvo do kernel em x: x[1,0,1:6, 2:7]\n",
            " \n",
            " tensor([[0.1423, 0.6957, 0.8008, 0.7165, 0.5242],\n",
            "        [0.5628, 0.2998, 0.5782, 0.3526, 0.1289],\n",
            "        [0.5177, 0.0437, 0.7119, 0.4252, 0.2123],\n",
            "        [0.3258, 0.1467, 0.4204, 0.9732, 0.6671],\n",
            "        [0.5533, 0.1137, 0.3734, 0.4479, 0.4630]])\n",
            " produto: tensor([[[[-0.0006,  0.0002, -0.0040,  0.0027, -0.0045],\n",
            "          [ 0.0041, -0.0022, -0.0046, -0.0022,  0.0006],\n",
            "          [-0.0019,  0.0002, -0.0060, -0.0026, -0.0008],\n",
            "          [-0.0006, -0.0011,  0.0028, -0.0023,  0.0021],\n",
            "          [ 0.0039,  0.0002,  0.0010,  0.0043, -0.0021]],\n",
            "\n",
            "         [[ 0.0005, -0.0031,  0.0057,  0.0057, -0.0048],\n",
            "          [ 0.0048,  0.0014,  0.0025,  0.0015,  0.0011],\n",
            "          [-0.0007, -0.0004, -0.0020, -0.0030,  0.0001],\n",
            "          [-0.0006, -0.0008, -0.0004,  0.0092, -0.0005],\n",
            "          [ 0.0002, -0.0002,  0.0006,  0.0040,  0.0028]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0133]],\n",
            "\n",
            "         [[ 0.0236]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0133,  0.0236], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 1, 2] = -0.013316535390913486\n",
            " somado na saída em [1, 1, 1, 2] = 0.02362077683210373\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 3\n",
            " alvo do kernel em x: x[1,0,1:6, 3:8]\n",
            " \n",
            " tensor([[0.6957, 0.8008, 0.7165, 0.5242, 0.3098],\n",
            "        [0.2998, 0.5782, 0.3526, 0.1289, 0.6350],\n",
            "        [0.0437, 0.7119, 0.4252, 0.2123, 0.9024],\n",
            "        [0.1467, 0.4204, 0.9732, 0.6671, 0.6361],\n",
            "        [0.1137, 0.3734, 0.4479, 0.4630, 0.2687]])\n",
            " produto: tensor([[[[-2.8369e-03,  2.6526e-04, -3.5584e-03,  1.9768e-03, -2.6400e-03],\n",
            "          [ 2.1977e-03, -4.2029e-03, -2.8033e-03, -8.1454e-04,  2.8758e-03],\n",
            "          [-1.6129e-04,  2.6641e-03, -3.6084e-03, -1.2878e-03, -3.3135e-03],\n",
            "          [-2.8835e-04, -3.2073e-03,  6.3724e-03, -1.5733e-03,  2.0417e-03],\n",
            "          [ 8.0397e-04,  6.9565e-04,  1.2248e-03,  4.4692e-03, -1.2120e-03]],\n",
            "\n",
            "         [[ 2.2037e-03, -3.5629e-03,  5.1202e-03,  4.1865e-03, -2.8566e-03],\n",
            "          [ 2.5592e-03,  2.7612e-03,  1.5365e-03,  5.3067e-04,  5.2786e-03],\n",
            "          [-5.7636e-05, -6.0206e-03, -1.2200e-03, -1.4949e-03,  5.9657e-04],\n",
            "          [-2.7395e-04, -2.2551e-03, -8.8484e-04,  6.3203e-03, -5.0171e-04],\n",
            "          [ 3.6098e-05, -5.8235e-04,  7.0413e-04,  4.1255e-03,  1.6433e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0059]],\n",
            "\n",
            "         [[ 0.0179]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0059,  0.0179], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 1, 3] = -0.005920639261603355\n",
            " somado na saída em [1, 1, 1, 3] = 0.01789173297584057\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 4\n",
            " alvo do kernel em x: x[1,0,1:6, 4:9]\n",
            " \n",
            " tensor([[0.8008, 0.7165, 0.5242, 0.3098, 0.6991],\n",
            "        [0.5782, 0.3526, 0.1289, 0.6350, 0.1601],\n",
            "        [0.7119, 0.4252, 0.2123, 0.9024, 0.3795],\n",
            "        [0.4204, 0.9732, 0.6671, 0.6361, 0.3680],\n",
            "        [0.3734, 0.4479, 0.4630, 0.2687, 0.7386]])\n",
            " produto: tensor([[[[-0.0033,  0.0002, -0.0026,  0.0012, -0.0060],\n",
            "          [ 0.0042, -0.0026, -0.0010, -0.0040,  0.0007],\n",
            "          [-0.0026,  0.0016, -0.0018, -0.0055, -0.0014],\n",
            "          [-0.0008, -0.0074,  0.0044, -0.0015,  0.0012],\n",
            "          [ 0.0026,  0.0008,  0.0013,  0.0026, -0.0033]],\n",
            "\n",
            "         [[ 0.0025, -0.0032,  0.0037,  0.0025, -0.0064],\n",
            "          [ 0.0049,  0.0017,  0.0006,  0.0026,  0.0013],\n",
            "          [-0.0009, -0.0036, -0.0006, -0.0064,  0.0003],\n",
            "          [-0.0008, -0.0052, -0.0006,  0.0060, -0.0003],\n",
            "          [ 0.0001, -0.0007,  0.0007,  0.0024,  0.0045]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0230]],\n",
            "\n",
            "         [[ 0.0052]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0230,  0.0052], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 1, 4] = -0.022963009774684906\n",
            " somado na saída em [1, 1, 1, 4] = 0.005184636451303959\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 5\n",
            " alvo do kernel em x: x[1,0,1:6, 5:10]\n",
            " \n",
            " tensor([[0.7165, 0.5242, 0.3098, 0.6991, 0.4595],\n",
            "        [0.3526, 0.1289, 0.6350, 0.1601, 0.4915],\n",
            "        [0.4252, 0.2123, 0.9024, 0.3795, 0.7841],\n",
            "        [0.9732, 0.6671, 0.6361, 0.3680, 0.1596],\n",
            "        [0.4479, 0.4630, 0.2687, 0.7386, 0.1300]])\n",
            " produto: tensor([[[[-0.0029,  0.0002, -0.0015,  0.0026, -0.0039],\n",
            "          [ 0.0026, -0.0009, -0.0050, -0.0010,  0.0022],\n",
            "          [-0.0016,  0.0008, -0.0077, -0.0023, -0.0029],\n",
            "          [-0.0019, -0.0051,  0.0042, -0.0009,  0.0005],\n",
            "          [ 0.0032,  0.0009,  0.0007,  0.0071, -0.0006]],\n",
            "\n",
            "         [[ 0.0023, -0.0023,  0.0022,  0.0056, -0.0042],\n",
            "          [ 0.0030,  0.0006,  0.0028,  0.0007,  0.0041],\n",
            "          [-0.0006, -0.0018, -0.0026, -0.0027,  0.0005],\n",
            "          [-0.0018, -0.0036, -0.0006,  0.0035, -0.0001],\n",
            "          [ 0.0001, -0.0007,  0.0004,  0.0066,  0.0008]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0133]],\n",
            "\n",
            "         [[ 0.0121]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0133,  0.0121], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 1, 5] = -0.013253342360258102\n",
            " somado na saída em [1, 1, 1, 5] = 0.012140821665525436\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 6\n",
            " alvo do kernel em x: x[1,0,1:6, 6:11]\n",
            " \n",
            " tensor([[0.5242, 0.3098, 0.6991, 0.4595, 0.3907],\n",
            "        [0.1289, 0.6350, 0.1601, 0.4915, 0.5033],\n",
            "        [0.2123, 0.9024, 0.3795, 0.7841, 0.2753],\n",
            "        [0.6671, 0.6361, 0.3680, 0.1596, 0.7024],\n",
            "        [0.4630, 0.2687, 0.7386, 0.1300, 0.2547]])\n",
            " produto: tensor([[[[-0.0021,  0.0001, -0.0035,  0.0017, -0.0033],\n",
            "          [ 0.0009, -0.0046, -0.0013, -0.0031,  0.0023],\n",
            "          [-0.0008,  0.0034, -0.0032, -0.0048, -0.0010],\n",
            "          [-0.0013, -0.0049,  0.0024, -0.0004,  0.0023],\n",
            "          [ 0.0033,  0.0005,  0.0020,  0.0013, -0.0011]],\n",
            "\n",
            "         [[ 0.0017, -0.0014,  0.0050,  0.0037, -0.0036],\n",
            "          [ 0.0011,  0.0030,  0.0007,  0.0020,  0.0042],\n",
            "          [-0.0003, -0.0076, -0.0011, -0.0055,  0.0002],\n",
            "          [-0.0012, -0.0034, -0.0003,  0.0015, -0.0006],\n",
            "          [ 0.0001, -0.0004,  0.0012,  0.0012,  0.0016]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0152]],\n",
            "\n",
            "         [[ 0.0016]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0152,  0.0016], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 1, 6] = -0.015243392437696457\n",
            " somado na saída em [1, 1, 1, 6] = 0.0016129985451698303\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 7\n",
            " alvo do kernel em x: x[1,0,1:6, 7:12]\n",
            " \n",
            " tensor([[0.3098, 0.6991, 0.4595, 0.3907, 0.7779],\n",
            "        [0.6350, 0.1601, 0.4915, 0.5033, 0.0505],\n",
            "        [0.9024, 0.3795, 0.7841, 0.2753, 0.3868],\n",
            "        [0.6361, 0.3680, 0.1596, 0.7024, 0.4539],\n",
            "        [0.2687, 0.7386, 0.1300, 0.2547, 0.9303]])\n",
            " produto: tensor([[[[-1.2635e-03,  2.3158e-04, -2.2824e-03,  1.4735e-03, -6.6278e-03],\n",
            "          [ 4.6547e-03, -1.1636e-03, -3.9074e-03, -3.1805e-03,  2.2879e-04],\n",
            "          [-3.3344e-03,  1.4202e-03, -6.6545e-03, -1.6703e-03, -1.4204e-03],\n",
            "          [-1.2500e-03, -2.8076e-03,  1.0451e-03, -1.6566e-03,  1.4571e-03],\n",
            "          [ 1.9003e-03,  1.3761e-03,  3.5539e-04,  2.4584e-03, -4.1956e-03]],\n",
            "\n",
            "         [[ 9.8143e-04, -3.1104e-03,  3.2841e-03,  3.1206e-03, -7.1716e-03],\n",
            "          [ 5.4204e-03,  7.6448e-04,  2.1417e-03,  2.0721e-03,  4.1995e-04],\n",
            "          [-1.1916e-03, -3.2095e-03, -2.2498e-03, -1.9389e-03,  2.5573e-04],\n",
            "          [-1.1876e-03, -1.9741e-03, -1.4512e-04,  6.6549e-03, -3.5805e-04],\n",
            "          [ 8.5321e-05, -1.1520e-03,  2.0431e-04,  2.2693e-03,  5.6885e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0248]],\n",
            "\n",
            "         [[ 0.0097]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0248,  0.0097], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 1, 7] = -0.024813633412122726\n",
            " somado na saída em [1, 1, 1, 7] = 0.009674161672592163\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 0\n",
            " alvo do kernel em x: x[1,0,2:7, 0:5]\n",
            " \n",
            " tensor([[0.5097, 0.4730, 0.5628, 0.2998, 0.5782],\n",
            "        [0.6232, 0.8195, 0.5177, 0.0437, 0.7119],\n",
            "        [0.0968, 0.2017, 0.3258, 0.1467, 0.4204],\n",
            "        [0.8581, 0.0401, 0.5533, 0.1137, 0.3734],\n",
            "        [0.0880, 0.0660, 0.1810, 0.5789, 0.4243]])\n",
            " produto: tensor([[[[-2.0785e-03,  1.5667e-04, -2.7953e-03,  1.1306e-03, -4.9270e-03],\n",
            "          [ 4.5682e-03, -5.9567e-03, -4.1160e-03, -2.7582e-04,  3.2242e-03],\n",
            "          [-3.5785e-04,  7.5471e-04, -2.7649e-03, -8.9022e-04, -1.5437e-03],\n",
            "          [-1.6863e-03, -3.0556e-04,  3.6230e-03, -2.6812e-04,  1.1985e-03],\n",
            "          [ 6.2222e-04,  1.2304e-04,  4.9502e-04,  5.5875e-03, -1.9136e-03]],\n",
            "\n",
            "         [[ 1.6146e-03, -2.1043e-03,  4.0221e-03,  2.3944e-03, -5.3313e-03],\n",
            "          [ 5.3198e-03,  3.9134e-03,  2.2560e-03,  1.7970e-04,  5.9181e-03],\n",
            "          [-1.2788e-04, -1.7056e-03, -9.3479e-04, -1.0334e-03,  2.7793e-04],\n",
            "          [-1.6021e-03, -2.1484e-04, -5.0308e-04,  1.0771e-03, -2.9451e-04],\n",
            "          [ 2.7937e-05, -1.0300e-04,  2.8459e-04,  5.1577e-03,  2.5945e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0084]],\n",
            "\n",
            "         [[ 0.0211]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0084,  0.0211], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 2, 0] = -0.008395876735448837\n",
            " somado na saída em [1, 1, 2, 0] = 0.021083146333694458\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 1\n",
            " alvo do kernel em x: x[1,0,2:7, 1:6]\n",
            " \n",
            " tensor([[0.4730, 0.5628, 0.2998, 0.5782, 0.3526],\n",
            "        [0.8195, 0.5177, 0.0437, 0.7119, 0.4252],\n",
            "        [0.2017, 0.3258, 0.1467, 0.4204, 0.9732],\n",
            "        [0.0401, 0.5533, 0.1137, 0.3734, 0.4479],\n",
            "        [0.0660, 0.1810, 0.5789, 0.4243, 0.6723]])\n",
            " produto: tensor([[[[-1.9286e-03,  1.8643e-04, -1.4890e-03,  2.1807e-03, -3.0043e-03],\n",
            "          [ 6.0076e-03, -3.7629e-03, -3.4704e-04, -4.4985e-03,  1.9255e-03],\n",
            "          [-7.4519e-04,  1.2191e-03, -1.2453e-03, -2.5508e-03, -3.5733e-03],\n",
            "          [-7.8714e-05, -4.2210e-03,  7.4445e-04, -8.8058e-04,  1.4377e-03],\n",
            "          [ 4.6699e-04,  3.3727e-04,  1.5829e-03,  4.0954e-03, -3.0320e-03]],\n",
            "\n",
            "         [[ 1.4981e-03, -2.5040e-03,  2.1425e-03,  4.6182e-03, -3.2508e-03],\n",
            "          [ 6.9960e-03,  2.4721e-03,  1.9022e-04,  2.9308e-03,  3.5343e-03],\n",
            "          [-2.6630e-04, -2.7550e-03, -4.2103e-04, -2.9610e-03,  6.4335e-04],\n",
            "          [-7.4784e-05, -2.9679e-03, -1.0337e-04,  3.5375e-03, -3.5329e-04],\n",
            "          [ 2.0968e-05, -2.8233e-04,  9.1001e-04,  3.7804e-03,  4.1109e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0112]],\n",
            "\n",
            "         [[ 0.0214]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0112,  0.0214], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 2, 1] = -0.011173389852046967\n",
            " somado na saída em [1, 1, 2, 1] = 0.021445641294121742\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 2\n",
            " alvo do kernel em x: x[1,0,2:7, 2:7]\n",
            " \n",
            " tensor([[0.5628, 0.2998, 0.5782, 0.3526, 0.1289],\n",
            "        [0.5177, 0.0437, 0.7119, 0.4252, 0.2123],\n",
            "        [0.3258, 0.1467, 0.4204, 0.9732, 0.6671],\n",
            "        [0.5533, 0.1137, 0.3734, 0.4479, 0.4630],\n",
            "        [0.1810, 0.5789, 0.4243, 0.6723, 0.0261]])\n",
            " produto: tensor([[[[-2.2950e-03,  9.9307e-05, -2.8719e-03,  1.3297e-03, -1.0983e-03],\n",
            "          [ 3.7951e-03, -3.1727e-04, -5.6600e-03, -2.6865e-03,  9.6130e-04],\n",
            "          [-1.2037e-03,  5.4907e-04, -3.5683e-03, -5.9046e-03, -2.4495e-03],\n",
            "          [-1.0874e-03, -8.6732e-04,  2.4449e-03, -1.0563e-03,  1.4862e-03],\n",
            "          [ 1.2801e-03,  1.0784e-03,  1.1602e-03,  6.4892e-03, -1.1757e-04]],\n",
            "\n",
            "         [[ 1.7827e-03, -1.3339e-03,  4.1325e-03,  2.8160e-03, -1.1885e-03],\n",
            "          [ 4.4194e-03,  2.0844e-04,  3.1023e-03,  1.7502e-03,  1.7645e-03],\n",
            "          [-4.3014e-04, -1.2409e-03, -1.2064e-03, -6.8540e-03,  4.4101e-04],\n",
            "          [-1.0331e-03, -6.0983e-04, -3.3949e-04,  4.2435e-03, -3.6520e-04],\n",
            "          [ 5.7476e-05, -9.0279e-04,  6.6700e-04,  5.9901e-03,  1.5940e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0105]],\n",
            "\n",
            "         [[ 0.0160]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0105,  0.0160], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 2, 2] = -0.010510114952921867\n",
            " somado na saída em [1, 1, 2, 2] = 0.016030393540859222\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 3\n",
            " alvo do kernel em x: x[1,0,2:7, 3:8]\n",
            " \n",
            " tensor([[0.2998, 0.5782, 0.3526, 0.1289, 0.6350],\n",
            "        [0.0437, 0.7119, 0.4252, 0.2123, 0.9024],\n",
            "        [0.1467, 0.4204, 0.9732, 0.6671, 0.6361],\n",
            "        [0.1137, 0.3734, 0.4479, 0.4630, 0.2687],\n",
            "        [0.5789, 0.4243, 0.6723, 0.0261, 0.2146]])\n",
            " produto: tensor([[[[-0.0012,  0.0002, -0.0018,  0.0005, -0.0054],\n",
            "          [ 0.0003, -0.0052, -0.0034, -0.0013,  0.0041],\n",
            "          [-0.0005,  0.0016, -0.0083, -0.0040, -0.0023],\n",
            "          [-0.0002, -0.0028,  0.0029, -0.0011,  0.0009],\n",
            "          [ 0.0041,  0.0008,  0.0018,  0.0003, -0.0010]],\n",
            "\n",
            "         [[ 0.0009, -0.0026,  0.0025,  0.0010, -0.0059],\n",
            "          [ 0.0004,  0.0034,  0.0019,  0.0009,  0.0075],\n",
            "          [-0.0002, -0.0036, -0.0028, -0.0047,  0.0004],\n",
            "          [-0.0002, -0.0020, -0.0004,  0.0044, -0.0002],\n",
            "          [ 0.0002, -0.0007,  0.0011,  0.0002,  0.0013]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0212]],\n",
            "\n",
            "         [[ 0.0029]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0212,  0.0029], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 2, 3] = -0.02116929180920124\n",
            " somado na saída em [1, 1, 2, 3] = 0.002928281668573618\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 4\n",
            " alvo do kernel em x: x[1,0,2:7, 4:9]\n",
            " \n",
            " tensor([[0.5782, 0.3526, 0.1289, 0.6350, 0.1601],\n",
            "        [0.7119, 0.4252, 0.2123, 0.9024, 0.3795],\n",
            "        [0.4204, 0.9732, 0.6671, 0.6361, 0.3680],\n",
            "        [0.3734, 0.4479, 0.4630, 0.2687, 0.7386],\n",
            "        [0.4243, 0.6723, 0.0261, 0.2146, 0.0651]])\n",
            " produto: tensor([[[[-2.3580e-03,  1.1680e-04, -6.4022e-04,  2.3946e-03, -1.3641e-03],\n",
            "          [ 5.2186e-03, -3.0902e-03, -1.6875e-03, -5.7023e-03,  1.7188e-03],\n",
            "          [-1.5534e-03,  3.6418e-03, -5.6620e-03, -3.8593e-03, -1.3513e-03],\n",
            "          [-7.3379e-04, -3.4169e-03,  3.0317e-03, -6.3374e-04,  2.3710e-03],\n",
            "          [ 3.0003e-03,  1.2525e-03,  7.1282e-05,  2.0712e-03, -2.9345e-04]],\n",
            "\n",
            "         [[ 1.8316e-03, -1.5688e-03,  9.2122e-04,  5.0713e-03, -1.4760e-03],\n",
            "          [ 6.0772e-03,  2.0302e-03,  9.2495e-04,  3.7151e-03,  3.1548e-03],\n",
            "          [-5.5513e-04, -8.2303e-03, -1.9143e-03, -4.4798e-03,  2.4330e-04],\n",
            "          [-6.9715e-04, -2.4025e-03, -4.2097e-04,  2.5459e-03, -5.8261e-04],\n",
            "          [ 1.3471e-04, -1.0485e-03,  4.0980e-05,  1.9119e-03,  3.9787e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0075]],\n",
            "\n",
            "         [[ 0.0056]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0075,  0.0056], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 2, 4] = -0.007457686588168144\n",
            " somado na saída em [1, 1, 2, 4] = 0.00562505004927516\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 5\n",
            " alvo do kernel em x: x[1,0,2:7, 5:10]\n",
            " \n",
            " tensor([[0.3526, 0.1289, 0.6350, 0.1601, 0.4915],\n",
            "        [0.4252, 0.2123, 0.9024, 0.3795, 0.7841],\n",
            "        [0.9732, 0.6671, 0.6361, 0.3680, 0.1596],\n",
            "        [0.4479, 0.4630, 0.2687, 0.7386, 0.1300],\n",
            "        [0.6723, 0.0261, 0.2146, 0.0651, 0.2332]])\n",
            " produto: tensor([[[[-1.4378e-03,  4.2699e-05, -3.1537e-03,  6.0374e-04, -4.1876e-03],\n",
            "          [ 3.1166e-03, -1.5428e-03, -7.1747e-03, -2.3980e-03,  3.5510e-03],\n",
            "          [-3.5959e-03,  2.4964e-03, -5.3986e-03, -2.2330e-03, -5.8604e-04],\n",
            "          [-8.8022e-04, -3.5321e-03,  1.7596e-03, -1.7420e-03,  4.1717e-04],\n",
            "          [ 4.7540e-03,  4.8565e-05,  5.8676e-04,  6.2805e-04, -1.0517e-03]],\n",
            "\n",
            "         [[ 1.1168e-03, -5.7352e-04,  4.5379e-03,  1.2786e-03, -4.5313e-03],\n",
            "          [ 3.6293e-03,  1.0136e-03,  3.9325e-03,  1.5623e-03,  6.5179e-03],\n",
            "          [-1.2850e-03, -5.6418e-03, -1.8252e-03, -2.5920e-03,  1.0551e-04],\n",
            "          [-8.3627e-04, -2.4835e-03, -2.4433e-04,  6.9980e-03, -1.0251e-04],\n",
            "          [ 2.1345e-04, -4.0655e-05,  3.3733e-04,  5.7974e-04,  1.4259e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0209]],\n",
            "\n",
            "         [[ 0.0131]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0209,  0.0131], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 2, 5] = -0.020909525454044342\n",
            " somado na saída em [1, 1, 2, 5] = 0.013092655688524246\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 6\n",
            " alvo do kernel em x: x[1,0,2:7, 6:11]\n",
            " \n",
            " tensor([[0.1289, 0.6350, 0.1601, 0.4915, 0.5033],\n",
            "        [0.2123, 0.9024, 0.3795, 0.7841, 0.2753],\n",
            "        [0.6671, 0.6361, 0.3680, 0.1596, 0.7024],\n",
            "        [0.4630, 0.2687, 0.7386, 0.1300, 0.2547],\n",
            "        [0.0261, 0.2146, 0.0651, 0.2332, 0.0755]])\n",
            " produto: tensor([[[[-5.2565e-04,  2.1033e-04, -7.9513e-04,  1.8534e-03, -4.2887e-03],\n",
            "          [ 1.5559e-03, -6.5592e-03, -3.0172e-03, -4.9544e-03,  1.2468e-03],\n",
            "          [-2.4649e-03,  2.3803e-03, -3.1236e-03, -9.6837e-04, -2.5792e-03],\n",
            "          [-9.0990e-04, -2.0500e-03,  4.8366e-03, -3.0649e-04,  8.1751e-04],\n",
            "          [ 1.8433e-04,  3.9977e-04,  1.7792e-04,  2.2508e-03, -3.4030e-04]],\n",
            "\n",
            "         [[ 4.0831e-04, -2.8251e-03,  1.1441e-03,  3.9252e-03, -4.6406e-03],\n",
            "          [ 1.8119e-03,  4.3092e-03,  1.6538e-03,  3.2278e-03,  2.2886e-03],\n",
            "          [-8.8086e-04, -5.3793e-03, -1.0561e-03, -1.1241e-03,  4.6436e-04],\n",
            "          [-8.6447e-04, -1.4414e-03, -6.7159e-04,  1.2313e-03, -2.0088e-04],\n",
            "          [ 8.2764e-06, -3.3465e-04,  1.0229e-04,  2.0776e-03,  4.6140e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0170]],\n",
            "\n",
            "         [[ 0.0037]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0170,  0.0037], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 2, 6] = -0.01696941815316677\n",
            " somado na saída em [1, 1, 2, 6] = 0.0036950588691979647\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 7\n",
            " alvo do kernel em x: x[1,0,2:7, 7:12]\n",
            " \n",
            " tensor([[0.6350, 0.1601, 0.4915, 0.5033, 0.0505],\n",
            "        [0.9024, 0.3795, 0.7841, 0.2753, 0.3868],\n",
            "        [0.6361, 0.3680, 0.1596, 0.7024, 0.4539],\n",
            "        [0.2687, 0.7386, 0.1300, 0.2547, 0.9303],\n",
            "        [0.2146, 0.0651, 0.2332, 0.0755, 0.4111]])\n",
            " produto: tensor([[[[-2.5893e-03,  5.3031e-05, -2.4410e-03,  1.8981e-03, -4.3043e-04],\n",
            "          [ 6.6152e-03, -2.7584e-03, -6.2336e-03, -1.7396e-03,  1.7520e-03],\n",
            "          [-2.3503e-03,  1.3772e-03, -1.3546e-03, -4.2618e-03, -1.6668e-03],\n",
            "          [-5.2810e-04, -5.6349e-03,  8.5099e-04, -6.0063e-04,  2.9861e-03],\n",
            "          [ 1.5174e-03,  1.2122e-04,  6.3763e-04,  7.2833e-04, -1.8541e-03]],\n",
            "\n",
            "         [[ 2.0113e-03, -7.1229e-04,  3.5123e-03,  4.0199e-03, -4.6575e-04],\n",
            "          [ 7.7035e-03,  1.8122e-03,  3.4167e-03,  1.1334e-03,  3.2159e-03],\n",
            "          [-8.3988e-04, -3.1125e-03, -4.5799e-04, -4.9471e-03,  3.0009e-04],\n",
            "          [-5.0174e-04, -3.9620e-03, -1.1816e-04,  2.4129e-03, -7.3375e-04],\n",
            "          [ 6.8128e-05, -1.0148e-04,  3.6657e-04,  6.7230e-04,  2.5139e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0159]],\n",
            "\n",
            "         [[ 0.0172]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0159,  0.0172], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 2, 7] = -0.01590632274746895\n",
            " somado na saída em [1, 1, 2, 7] = 0.017206482589244843\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 0\n",
            " alvo do kernel em x: x[1,0,3:8, 0:5]\n",
            " \n",
            " tensor([[0.6232, 0.8195, 0.5177, 0.0437, 0.7119],\n",
            "        [0.0968, 0.2017, 0.3258, 0.1467, 0.4204],\n",
            "        [0.8581, 0.0401, 0.5533, 0.1137, 0.3734],\n",
            "        [0.0880, 0.0660, 0.1810, 0.5789, 0.4243],\n",
            "        [0.8865, 0.8172, 0.8094, 0.1320, 0.6076]])\n",
            " produto: tensor([[[[-0.0025,  0.0003, -0.0026,  0.0002, -0.0061],\n",
            "          [ 0.0007, -0.0015, -0.0026, -0.0009,  0.0019],\n",
            "          [-0.0032,  0.0001, -0.0047, -0.0007, -0.0014],\n",
            "          [-0.0002, -0.0005,  0.0012, -0.0014,  0.0014],\n",
            "          [ 0.0063,  0.0015,  0.0022,  0.0013, -0.0027]],\n",
            "\n",
            "         [[ 0.0020, -0.0036,  0.0037,  0.0003, -0.0066],\n",
            "          [ 0.0008,  0.0010,  0.0014,  0.0006,  0.0035],\n",
            "          [-0.0011, -0.0003, -0.0016, -0.0008,  0.0002],\n",
            "          [-0.0002, -0.0004, -0.0002,  0.0055, -0.0003],\n",
            "          [ 0.0003, -0.0013,  0.0013,  0.0012,  0.0037]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0138]],\n",
            "\n",
            "         [[ 0.0091]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0138,  0.0091], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 3, 0] = -0.013845452107489109\n",
            " somado na saída em [1, 1, 3, 0] = 0.009144430980086327\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 1\n",
            " alvo do kernel em x: x[1,0,3:8, 1:6]\n",
            " \n",
            " tensor([[0.8195, 0.5177, 0.0437, 0.7119, 0.4252],\n",
            "        [0.2017, 0.3258, 0.1467, 0.4204, 0.9732],\n",
            "        [0.0401, 0.5533, 0.1137, 0.3734, 0.4479],\n",
            "        [0.0660, 0.1810, 0.5789, 0.4243, 0.6723],\n",
            "        [0.8172, 0.8094, 0.1320, 0.6076, 0.0339]])\n",
            " produto: tensor([[[[-3.3419e-03,  1.7149e-04, -2.1679e-04,  2.6847e-03, -3.6225e-03],\n",
            "          [ 1.4784e-03, -2.3678e-03, -1.1665e-03, -2.6566e-03,  4.4075e-03],\n",
            "          [-1.4800e-04,  2.0706e-03, -9.6494e-04, -2.2655e-03, -1.6446e-03],\n",
            "          [-1.2978e-04, -1.3810e-03,  3.7903e-03, -1.0006e-03,  2.1579e-03],\n",
            "          [ 5.7784e-03,  1.5079e-03,  3.6087e-04,  5.8645e-03, -1.5278e-04]],\n",
            "\n",
            "         [[ 2.5959e-03, -2.3034e-03,  3.1195e-04,  5.6857e-03, -3.9198e-03],\n",
            "          [ 1.7216e-03,  1.5556e-03,  6.3938e-04,  1.7308e-03,  8.0902e-03],\n",
            "          [-5.2887e-05, -4.6793e-03, -3.2624e-04, -2.6297e-03,  2.9609e-04],\n",
            "          [-1.2330e-04, -9.7100e-04, -5.2631e-04,  4.0197e-03, -5.3026e-04],\n",
            "          [ 2.5945e-04, -1.2623e-03,  2.0747e-04,  5.4134e-03,  2.0715e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[0.0092]],\n",
            "\n",
            "         [[0.0154]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([0.0092, 0.0154], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 3, 1] = 0.009213386103510857\n",
            " somado na saída em [1, 1, 3, 1] = 0.015409884974360466\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 2\n",
            " alvo do kernel em x: x[1,0,3:8, 2:7]\n",
            " \n",
            " tensor([[0.5177, 0.0437, 0.7119, 0.4252, 0.2123],\n",
            "        [0.3258, 0.1467, 0.4204, 0.9732, 0.6671],\n",
            "        [0.5533, 0.1137, 0.3734, 0.4479, 0.4630],\n",
            "        [0.1810, 0.5789, 0.4243, 0.6723, 0.0261],\n",
            "        [0.8094, 0.1320, 0.6076, 0.0339, 0.5086]])\n",
            " produto: tensor([[[[-2.1111e-03,  1.4459e-05, -3.5358e-03,  1.6033e-03, -1.8085e-03],\n",
            "          [ 2.3880e-03, -1.0665e-03, -3.3426e-03, -6.1495e-03,  3.0213e-03],\n",
            "          [-2.0444e-03,  4.2545e-04, -3.1691e-03, -2.7175e-03, -1.7001e-03],\n",
            "          [-3.5575e-04, -4.4159e-03,  2.7782e-03, -1.5854e-03,  8.3673e-05],\n",
            "          [ 5.7235e-03,  2.4587e-04,  1.6614e-03,  3.2699e-04, -2.2938e-03]],\n",
            "\n",
            "         [[ 1.6399e-03, -1.9421e-04,  5.0877e-03,  3.3955e-03, -1.9570e-03],\n",
            "          [ 2.7809e-03,  7.0064e-04,  1.8321e-03,  4.0064e-03,  5.5457e-03],\n",
            "          [-7.3059e-04, -9.6150e-04, -1.0714e-03, -3.1545e-03,  3.0608e-04],\n",
            "          [-3.3799e-04, -3.1049e-03, -3.8577e-04,  6.3692e-03, -2.0561e-05],\n",
            "          [ 2.5698e-04, -2.0582e-04,  9.5513e-04,  3.0184e-04,  3.1100e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0180]],\n",
            "\n",
            "         [[ 0.0242]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0180,  0.0242], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 3, 2] = -0.018023783341050148\n",
            " somado na saída em [1, 1, 3, 2] = 0.02416379190981388\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 3\n",
            " alvo do kernel em x: x[1,0,3:8, 3:8]\n",
            " \n",
            " tensor([[0.0437, 0.7119, 0.4252, 0.2123, 0.9024],\n",
            "        [0.1467, 0.4204, 0.9732, 0.6671, 0.6361],\n",
            "        [0.1137, 0.3734, 0.4479, 0.4630, 0.2687],\n",
            "        [0.5789, 0.4243, 0.6723, 0.0261, 0.2146],\n",
            "        [0.1320, 0.6076, 0.0339, 0.5086, 0.5832]])\n",
            " produto: tensor([[[[-1.7800e-04,  2.3582e-04, -2.1116e-03,  8.0045e-04, -7.6892e-03],\n",
            "          [ 1.0756e-03, -3.0558e-03, -7.7373e-03, -4.2154e-03,  2.8808e-03],\n",
            "          [-4.2009e-04,  1.3973e-03, -3.8015e-03, -2.8092e-03, -9.8671e-04],\n",
            "          [-1.1376e-03, -3.2367e-03,  4.4020e-03, -6.1475e-05,  6.8876e-04],\n",
            "          [ 9.3321e-04,  1.1319e-03,  9.2634e-05,  4.9092e-03, -2.6303e-03]],\n",
            "\n",
            "         [[ 1.3826e-04, -3.1674e-03,  3.0384e-03,  1.6952e-03, -8.3201e-03],\n",
            "          [ 1.2525e-03,  2.0076e-03,  4.2409e-03,  2.7463e-03,  5.2877e-03],\n",
            "          [-1.5012e-04, -3.1578e-03, -1.2853e-03, -3.2608e-03,  1.7765e-04],\n",
            "          [-1.0808e-03, -2.2758e-03, -6.1124e-04,  2.4696e-04, -1.6925e-04],\n",
            "          [ 4.1900e-05, -9.4756e-04,  5.3255e-05,  4.5316e-03,  3.5662e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0215]],\n",
            "\n",
            "         [[ 0.0046]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0215,  0.0046], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 3, 3] = -0.021523121744394302\n",
            " somado na saída em [1, 1, 3, 3] = 0.00459827296435833\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 4\n",
            " alvo do kernel em x: x[1,0,3:8, 4:9]\n",
            " \n",
            " tensor([[0.7119, 0.4252, 0.2123, 0.9024, 0.3795],\n",
            "        [0.4204, 0.9732, 0.6671, 0.6361, 0.3680],\n",
            "        [0.3734, 0.4479, 0.4630, 0.2687, 0.7386],\n",
            "        [0.4243, 0.6723, 0.0261, 0.2146, 0.0651],\n",
            "        [0.6076, 0.0339, 0.5086, 0.5832, 0.3061]])\n",
            " produto: tensor([[[[-2.9030e-03,  1.4083e-04, -1.0542e-03,  3.4032e-03, -3.2336e-03],\n",
            "          [ 3.0819e-03, -7.0736e-03, -5.3038e-03, -4.0193e-03,  1.6668e-03],\n",
            "          [-1.3797e-03,  1.6761e-03, -3.9297e-03, -1.6304e-03, -2.7121e-03],\n",
            "          [-8.3380e-04, -5.1286e-03,  1.7069e-04, -5.0603e-04,  2.0885e-04],\n",
            "          [ 4.2963e-03,  6.3113e-05,  1.3907e-03,  5.6293e-03, -1.3807e-03]],\n",
            "\n",
            "         [[ 2.2550e-03, -1.8916e-03,  1.5169e-03,  7.2073e-03, -3.4989e-03],\n",
            "          [ 3.5890e-03,  4.6471e-03,  2.9071e-03,  2.6186e-03,  3.0595e-03],\n",
            "          [-4.9303e-04, -3.7879e-03, -1.3286e-03, -1.8926e-03,  4.8829e-04],\n",
            "          [-7.9217e-04, -3.6060e-03, -2.3701e-05,  2.0329e-03, -5.1320e-05],\n",
            "          [ 1.9290e-04, -5.2833e-05,  7.9954e-04,  5.1963e-03,  1.8721e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0194]],\n",
            "\n",
            "         [[ 0.0210]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0194,  0.0210], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 3, 4] = -0.019360696896910667\n",
            " somado na saída em [1, 1, 3, 4] = 0.02096380665898323\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 5\n",
            " alvo do kernel em x: x[1,0,3:8, 5:10]\n",
            " \n",
            " tensor([[0.4252, 0.2123, 0.9024, 0.3795, 0.7841],\n",
            "        [0.9732, 0.6671, 0.6361, 0.3680, 0.1596],\n",
            "        [0.4479, 0.4630, 0.2687, 0.7386, 0.1300],\n",
            "        [0.6723, 0.0261, 0.2146, 0.0651, 0.2332],\n",
            "        [0.0339, 0.5086, 0.5832, 0.3061, 0.9248]])\n",
            " produto: tensor([[[[-1.7337e-03,  7.0309e-05, -4.4820e-03,  1.4312e-03, -6.6806e-03],\n",
            "          [ 7.1339e-03, -4.8489e-03, -5.0571e-03, -2.3256e-03,  7.2285e-04],\n",
            "          [-1.6550e-03,  1.7326e-03, -2.2808e-03, -4.4815e-03, -4.7719e-04],\n",
            "          [-1.3212e-03, -1.9886e-04,  1.4050e-03, -1.5344e-04,  7.4847e-04],\n",
            "          [ 2.3955e-04,  9.4753e-04,  1.5947e-03,  2.9551e-03, -4.1709e-03]],\n",
            "\n",
            "         [[ 1.3467e-03, -9.4437e-04,  6.4492e-03,  3.0309e-03, -7.2288e-03],\n",
            "          [ 8.3076e-03,  3.1856e-03,  2.7718e-03,  1.5151e-03,  1.3268e-03],\n",
            "          [-5.9141e-04, -3.9157e-03, -7.7111e-04, -5.2021e-03,  8.5914e-05],\n",
            "          [-1.2552e-03, -1.3982e-04, -1.9509e-04,  6.1643e-04, -1.8392e-04],\n",
            "          [ 1.0756e-05, -7.9320e-04,  9.1682e-04,  2.7278e-03,  5.6551e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0209]],\n",
            "\n",
            "         [[ 0.0167]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0209,  0.0167], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 3, 5] = -0.020885374397039413\n",
            " somado na saída em [1, 1, 3, 5] = 0.016725929453969002\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 6\n",
            " alvo do kernel em x: x[1,0,3:8, 6:11]\n",
            " \n",
            " tensor([[0.2123, 0.9024, 0.3795, 0.7841, 0.2753],\n",
            "        [0.6671, 0.6361, 0.3680, 0.1596, 0.7024],\n",
            "        [0.4630, 0.2687, 0.7386, 0.1300, 0.2547],\n",
            "        [0.0261, 0.2146, 0.0651, 0.2332, 0.0755],\n",
            "        [0.5086, 0.5832, 0.3061, 0.9248, 0.3211]])\n",
            " produto: tensor([[[[-8.6553e-04,  2.9893e-04, -1.8848e-03,  2.9568e-03, -2.3457e-03],\n",
            "          [ 4.8902e-03, -4.6233e-03, -2.9260e-03, -1.0085e-03,  3.1813e-03],\n",
            "          [-1.7108e-03,  1.0056e-03, -6.2691e-03, -7.8852e-04, -9.3514e-04],\n",
            "          [-5.1228e-05, -1.6369e-03,  4.2604e-04, -5.4990e-04,  2.4220e-04],\n",
            "          [ 3.5965e-03,  1.0865e-03,  8.3716e-04,  8.9267e-03, -1.4481e-03]],\n",
            "\n",
            "         [[ 6.7233e-04, -4.0150e-03,  2.7121e-03,  6.2619e-03, -2.5382e-03],\n",
            "          [ 5.6948e-03,  3.0374e-03,  1.6038e-03,  6.5706e-04,  5.8393e-03],\n",
            "          [-6.1135e-04, -2.2726e-03, -2.1195e-03, -9.1530e-04,  1.6836e-04],\n",
            "          [-4.8670e-05, -1.1509e-03, -5.9158e-05,  2.2091e-03, -5.9515e-05],\n",
            "          [ 1.6148e-04, -9.0955e-04,  4.8128e-04,  8.2401e-03,  1.9634e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[0.0004]],\n",
            "\n",
            "         [[0.0250]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([0.0004, 0.0250], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 3, 6] = 0.0004042861983180046\n",
            " somado na saída em [1, 1, 3, 6] = 0.0250026173889637\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 7\n",
            " alvo do kernel em x: x[1,0,3:8, 7:12]\n",
            " \n",
            " tensor([[0.9024, 0.3795, 0.7841, 0.2753, 0.3868],\n",
            "        [0.6361, 0.3680, 0.1596, 0.7024, 0.4539],\n",
            "        [0.2687, 0.7386, 0.1300, 0.2547, 0.9303],\n",
            "        [0.2146, 0.0651, 0.2332, 0.0755, 0.4111],\n",
            "        [0.5832, 0.3061, 0.9248, 0.3211, 0.9655]])\n",
            " produto: tensor([[[[-0.0037,  0.0001, -0.0039,  0.0010, -0.0033],\n",
            "          [ 0.0047, -0.0027, -0.0013, -0.0044,  0.0021],\n",
            "          [-0.0010,  0.0028, -0.0011, -0.0015, -0.0034],\n",
            "          [-0.0004, -0.0005,  0.0015, -0.0002,  0.0013],\n",
            "          [ 0.0041,  0.0006,  0.0025,  0.0031, -0.0044]],\n",
            "\n",
            "         [[ 0.0029, -0.0017,  0.0056,  0.0022, -0.0036],\n",
            "          [ 0.0054,  0.0018,  0.0007,  0.0029,  0.0038],\n",
            "          [-0.0004, -0.0062, -0.0004, -0.0018,  0.0006],\n",
            "          [-0.0004, -0.0003, -0.0002,  0.0007, -0.0003],\n",
            "          [ 0.0002, -0.0005,  0.0015,  0.0029,  0.0059]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0079]],\n",
            "\n",
            "         [[ 0.0212]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0079,  0.0212], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 3, 7] = -0.007944566197693348\n",
            " somado na saída em [1, 1, 3, 7] = 0.021155843511223793\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 0\n",
            " alvo do kernel em x: x[1,0,4:9, 0:5]\n",
            " \n",
            " tensor([[0.0968, 0.2017, 0.3258, 0.1467, 0.4204],\n",
            "        [0.8581, 0.0401, 0.5533, 0.1137, 0.3734],\n",
            "        [0.0880, 0.0660, 0.1810, 0.5789, 0.4243],\n",
            "        [0.8865, 0.8172, 0.8094, 0.1320, 0.6076],\n",
            "        [0.5541, 0.5516, 0.1492, 0.1630, 0.3436]])\n",
            " produto: tensor([[[[-3.9492e-04,  6.6805e-05, -1.6180e-03,  5.5332e-04, -3.5823e-03],\n",
            "          [ 6.2900e-03, -2.9113e-04, -4.3990e-03, -7.1841e-04,  1.6911e-03],\n",
            "          [-3.2512e-04,  2.4713e-04, -1.5364e-03, -3.5121e-03, -1.5579e-03],\n",
            "          [-1.7421e-03, -6.2338e-03,  5.2998e-03, -3.1123e-04,  1.9502e-03],\n",
            "          [ 3.9180e-03,  1.0277e-03,  4.0786e-04,  1.5736e-03, -1.5499e-03]],\n",
            "\n",
            "         [[ 3.0677e-04, -8.9730e-04,  2.3281e-03,  1.1718e-03, -3.8762e-03],\n",
            "          [ 7.3248e-03,  1.9126e-04,  2.4111e-03,  4.6804e-04,  3.1040e-03],\n",
            "          [-1.1618e-04, -5.5850e-04, -5.1946e-04, -4.0768e-03,  2.8048e-04],\n",
            "          [-1.6551e-03, -4.3831e-03, -7.3591e-04,  1.2503e-03, -4.7922e-04],\n",
            "          [ 1.7591e-04, -8.6029e-04,  2.3448e-04,  1.4525e-03,  2.1014e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0047]],\n",
            "\n",
            "         [[ 0.0046]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0047,  0.0046], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 4, 0] = -0.00474680308252573\n",
            " somado na saída em [1, 1, 4, 0] = 0.004643041640520096\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 1\n",
            " alvo do kernel em x: x[1,0,4:9, 1:6]\n",
            " \n",
            " tensor([[0.2017, 0.3258, 0.1467, 0.4204, 0.9732],\n",
            "        [0.0401, 0.5533, 0.1137, 0.3734, 0.4479],\n",
            "        [0.0660, 0.1810, 0.5789, 0.4243, 0.6723],\n",
            "        [0.8172, 0.8094, 0.1320, 0.6076, 0.0339],\n",
            "        [0.5516, 0.1492, 0.1630, 0.3436, 0.1537]])\n",
            " produto: tensor([[[[-8.2240e-04,  1.0791e-04, -7.2873e-04,  1.5855e-03, -8.2922e-03],\n",
            "          [ 2.9361e-04, -4.0217e-03, -9.0391e-04, -2.3594e-03,  2.0285e-03],\n",
            "          [-2.4401e-04,  6.7743e-04, -4.9129e-03, -2.5742e-03, -2.4684e-03],\n",
            "          [-1.6059e-03, -6.1745e-03,  8.6412e-04, -1.4328e-03,  1.0874e-04],\n",
            "          [ 3.9006e-03,  2.7788e-04,  4.4578e-04,  3.3171e-03, -6.9324e-04]],\n",
            "\n",
            "         [[ 6.3882e-04, -1.4494e-03,  1.0486e-03,  3.3578e-03, -8.9726e-03],\n",
            "          [ 3.4192e-04,  2.6421e-03,  4.9544e-04,  1.5372e-03,  3.7234e-03],\n",
            "          [-8.7198e-05, -1.5309e-03, -1.6610e-03, -2.9881e-03,  4.4442e-04],\n",
            "          [-1.5257e-03, -4.3414e-03, -1.1999e-04,  5.7561e-03, -2.6720e-05],\n",
            "          [ 1.7514e-04, -2.3262e-04,  2.5628e-04,  3.0619e-03,  9.3992e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0236]],\n",
            "\n",
            "         [[ 0.0015]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0236,  0.0015], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 4, 1] = -0.023627176880836487\n",
            " somado na saída em [1, 1, 4, 1] = 0.001483225729316473\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 2\n",
            " alvo do kernel em x: x[1,0,4:9, 2:7]\n",
            " \n",
            " tensor([[0.3258, 0.1467, 0.4204, 0.9732, 0.6671],\n",
            "        [0.5533, 0.1137, 0.3734, 0.4479, 0.4630],\n",
            "        [0.1810, 0.5789, 0.4243, 0.6723, 0.0261],\n",
            "        [0.8094, 0.1320, 0.6076, 0.0339, 0.5086],\n",
            "        [0.1492, 0.1630, 0.3436, 0.1537, 0.5418]])\n",
            " produto: tensor([[[[-1.3284e-03,  4.8602e-05, -2.0881e-03,  3.6700e-03, -5.6842e-03],\n",
            "          [ 4.0560e-03, -8.2636e-04, -2.9686e-03, -2.8302e-03,  2.0969e-03],\n",
            "          [-6.6888e-04,  2.1662e-03, -3.6010e-03, -4.0789e-03, -9.5713e-05],\n",
            "          [-1.5906e-03, -1.0067e-03,  3.9783e-03, -7.9890e-05,  1.6325e-03],\n",
            "          [ 1.0547e-03,  3.0372e-04,  9.3970e-04,  1.4837e-03, -2.4434e-03]],\n",
            "\n",
            "         [[ 1.0319e-03, -6.5281e-04,  3.0046e-03,  7.7725e-03, -6.1506e-03],\n",
            "          [ 4.7233e-03,  5.4290e-04,  1.6271e-03,  1.8439e-03,  3.8490e-03],\n",
            "          [-2.3903e-04, -4.8954e-03, -1.2175e-03, -4.7347e-03,  1.7232e-05],\n",
            "          [-1.5112e-03, -7.0786e-04, -5.5240e-04,  3.2094e-04, -4.0115e-04],\n",
            "          [ 4.7357e-05, -2.5425e-04,  5.4023e-04,  1.3696e-03,  3.3129e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0079]],\n",
            "\n",
            "         [[ 0.0087]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0079,  0.0087], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 4, 2] = -0.007860735058784485\n",
            " somado na saída em [1, 1, 4, 2] = 0.008686494082212448\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 3\n",
            " alvo do kernel em x: x[1,0,4:9, 3:8]\n",
            " \n",
            " tensor([[0.1467, 0.4204, 0.9732, 0.6671, 0.6361],\n",
            "        [0.1137, 0.3734, 0.4479, 0.4630, 0.2687],\n",
            "        [0.5789, 0.4243, 0.6723, 0.0261, 0.2146],\n",
            "        [0.1320, 0.6076, 0.0339, 0.5086, 0.5832],\n",
            "        [0.1630, 0.3436, 0.1537, 0.5418, 0.4395]])\n",
            " produto: tensor([[[[-5.9831e-04,  1.3926e-04, -4.8335e-03,  2.5158e-03, -5.4198e-03],\n",
            "          [ 8.3342e-04, -2.7140e-03, -3.5610e-03, -2.9257e-03,  1.2171e-03],\n",
            "          [-2.1388e-03,  1.5877e-03, -5.7058e-03, -1.5816e-04, -7.8787e-04],\n",
            "          [-2.5935e-04, -4.6349e-03,  2.2182e-04, -1.1994e-03,  1.8720e-03],\n",
            "          [ 1.1528e-03,  6.4023e-04,  4.2032e-04,  5.2295e-03, -1.9824e-03]],\n",
            "\n",
            "         [[ 4.6476e-04, -1.8706e-03,  6.9549e-03,  5.3280e-03, -5.8645e-03],\n",
            "          [ 9.7053e-04,  1.7830e-03,  1.9518e-03,  1.9061e-03,  2.2339e-03],\n",
            "          [-7.6432e-04, -3.5882e-03, -1.9291e-03, -1.8359e-04,  1.4185e-04],\n",
            "          [-2.4640e-04, -3.2589e-03, -3.0801e-05,  4.8184e-03, -4.6000e-04],\n",
            "          [ 5.1759e-05, -5.3595e-04,  2.4164e-04,  4.8272e-03,  2.6877e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0211]],\n",
            "\n",
            "         [[ 0.0156]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0211,  0.0156], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 4, 3] = -0.021089015528559685\n",
            " somado na saída em [1, 1, 4, 3] = 0.015629392117261887\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 4\n",
            " alvo do kernel em x: x[1,0,4:9, 4:9]\n",
            " \n",
            " tensor([[0.4204, 0.9732, 0.6671, 0.6361, 0.3680],\n",
            "        [0.3734, 0.4479, 0.4630, 0.2687, 0.7386],\n",
            "        [0.4243, 0.6723, 0.0261, 0.2146, 0.0651],\n",
            "        [0.6076, 0.0339, 0.5086, 0.5832, 0.3061],\n",
            "        [0.3436, 0.1537, 0.5418, 0.4395, 0.7671]])\n",
            " produto: tensor([[[[-1.7144e-03,  3.2237e-04, -3.3133e-03,  2.3988e-03, -3.1359e-03],\n",
            "          [ 2.7371e-03, -3.2555e-03, -3.6811e-03, -1.6981e-03,  3.3453e-03],\n",
            "          [-1.5677e-03,  2.5158e-03, -2.2124e-04, -1.3019e-03, -2.3890e-04],\n",
            "          [-1.1940e-03, -2.5843e-04,  3.3302e-03, -1.3754e-03,  9.8269e-04],\n",
            "          [ 2.4301e-03,  2.8637e-04,  1.4815e-03,  4.2427e-03, -3.4595e-03]],\n",
            "\n",
            "         [[ 1.3317e-03, -4.3299e-03,  4.7675e-03,  5.0801e-03, -3.3932e-03],\n",
            "          [ 3.1875e-03,  2.1388e-03,  2.0176e-03,  1.1063e-03,  6.1403e-03],\n",
            "          [-5.6022e-04, -5.6854e-03, -7.4800e-05, -1.5112e-03,  4.3012e-05],\n",
            "          [-1.1344e-03, -1.8171e-04, -4.6242e-04,  5.5252e-03, -2.4147e-04],\n",
            "          [ 1.0911e-04, -2.3972e-04,  8.5170e-04,  3.9163e-03,  4.6905e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0023]],\n",
            "\n",
            "         [[ 0.0231]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0023,  0.0231], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 4, 4] = -0.0023425384424626827\n",
            " somado na saída em [1, 1, 4, 4] = 0.023091334849596024\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 5\n",
            " alvo do kernel em x: x[1,0,4:9, 5:10]\n",
            " \n",
            " tensor([[0.9732, 0.6671, 0.6361, 0.3680, 0.1596],\n",
            "        [0.4479, 0.4630, 0.2687, 0.7386, 0.1300],\n",
            "        [0.6723, 0.0261, 0.2146, 0.0651, 0.2332],\n",
            "        [0.0339, 0.5086, 0.5832, 0.3061, 0.9248],\n",
            "        [0.1537, 0.5418, 0.4395, 0.7671, 0.8655]])\n",
            " produto: tensor([[[[-3.9685e-03,  2.2098e-04, -3.1592e-03,  1.3879e-03, -1.3599e-03],\n",
            "          [ 3.2833e-03, -3.3653e-03, -2.1365e-03, -4.6674e-03,  5.8859e-04],\n",
            "          [-2.4840e-03,  9.7548e-05, -1.8212e-03, -3.9477e-04, -8.5617e-04],\n",
            "          [-6.6573e-05, -3.8798e-03,  3.8187e-03, -7.2199e-04,  2.9685e-03],\n",
            "          [ 1.0869e-03,  1.0093e-03,  1.2019e-03,  7.4042e-03, -3.9037e-03]],\n",
            "\n",
            "         [[ 3.0826e-03, -2.9681e-03,  4.5458e-03,  2.9393e-03, -1.4715e-03],\n",
            "          [ 3.8235e-03,  2.2109e-03,  1.1710e-03,  3.0408e-03,  1.0804e-03],\n",
            "          [-8.8767e-04, -2.2045e-04, -6.1572e-04, -4.5824e-04,  1.5415e-04],\n",
            "          [-6.3249e-05, -2.7280e-03, -5.3025e-04,  2.9004e-03, -7.2944e-04],\n",
            "          [ 4.8803e-05, -8.4495e-04,  6.9098e-04,  6.8346e-03,  5.2928e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0097]],\n",
            "\n",
            "         [[ 0.0263]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0097,  0.0263], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 4, 5] = -0.009717080742120743\n",
            " somado na saída em [1, 1, 4, 5] = 0.02629854530096054\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 6\n",
            " alvo do kernel em x: x[1,0,4:9, 6:11]\n",
            " \n",
            " tensor([[0.6671, 0.6361, 0.3680, 0.1596, 0.7024],\n",
            "        [0.4630, 0.2687, 0.7386, 0.1300, 0.2547],\n",
            "        [0.0261, 0.2146, 0.0651, 0.2332, 0.0755],\n",
            "        [0.5086, 0.5832, 0.3061, 0.9248, 0.3211],\n",
            "        [0.5418, 0.4395, 0.7671, 0.8655, 0.9959]])\n",
            " produto: tensor([[[[-2.7203e-03,  2.1070e-04, -1.8279e-03,  6.0190e-04, -5.9851e-03],\n",
            "          [ 3.3941e-03, -1.9532e-03, -5.8725e-03, -8.2122e-04,  1.1535e-03],\n",
            "          [-9.6317e-05,  8.0297e-04, -5.5223e-04, -1.4147e-03, -2.7705e-04],\n",
            "          [-9.9948e-04, -4.4490e-03,  2.0046e-03, -2.1810e-03,  1.0306e-03],\n",
            "          [ 3.8311e-03,  8.1888e-04,  2.0975e-03,  8.3548e-03, -4.4915e-03]],\n",
            "\n",
            "         [[ 2.1131e-03, -2.8300e-03,  2.6302e-03,  1.2747e-03, -6.4763e-03],\n",
            "          [ 3.9525e-03,  1.2832e-03,  3.2188e-03,  5.3503e-04,  2.1172e-03],\n",
            "          [-3.4419e-05, -1.8147e-03, -1.8670e-04, -1.6422e-03,  4.9880e-05],\n",
            "          [-9.4957e-04, -3.1282e-03, -2.7835e-04,  8.7616e-03, -2.5326e-04],\n",
            "          [ 1.7201e-04, -6.8550e-04,  1.2059e-03,  7.7121e-03,  6.0897e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0093]],\n",
            "\n",
            "         [[ 0.0228]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0093,  0.0228], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 4, 6] = -0.00934096984565258\n",
            " somado na saída em [1, 1, 4, 6] = 0.02283673733472824\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 7\n",
            " alvo do kernel em x: x[1,0,4:9, 7:12]\n",
            " \n",
            " tensor([[0.6361, 0.3680, 0.1596, 0.7024, 0.4539],\n",
            "        [0.2687, 0.7386, 0.1300, 0.2547, 0.9303],\n",
            "        [0.2146, 0.0651, 0.2332, 0.0755, 0.4111],\n",
            "        [0.5832, 0.3061, 0.9248, 0.3211, 0.9655],\n",
            "        [0.4395, 0.7671, 0.8655, 0.9959, 0.4935]])\n",
            " produto: tensor([[[[-0.0026,  0.0001, -0.0008,  0.0026, -0.0039],\n",
            "          [ 0.0020, -0.0054, -0.0010, -0.0016,  0.0042],\n",
            "          [-0.0008,  0.0002, -0.0020, -0.0005, -0.0015],\n",
            "          [-0.0011, -0.0023,  0.0061, -0.0008,  0.0031],\n",
            "          [ 0.0031,  0.0014,  0.0024,  0.0096, -0.0022]],\n",
            "\n",
            "         [[ 0.0020, -0.0016,  0.0011,  0.0056, -0.0042],\n",
            "          [ 0.0023,  0.0035,  0.0006,  0.0010,  0.0077],\n",
            "          [-0.0003, -0.0006, -0.0007, -0.0005,  0.0003],\n",
            "          [-0.0011, -0.0016, -0.0008,  0.0030, -0.0008],\n",
            "          [ 0.0001, -0.0012,  0.0014,  0.0089,  0.0030]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[0.0084]],\n",
            "\n",
            "         [[0.0273]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([0.0084, 0.0273], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 4, 7] = 0.008399605751037598\n",
            " somado na saída em [1, 1, 4, 7] = 0.027253421023488045\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 0\n",
            " alvo do kernel em x: x[1,0,5:10, 0:5]\n",
            " \n",
            " tensor([[0.8581, 0.0401, 0.5533, 0.1137, 0.3734],\n",
            "        [0.0880, 0.0660, 0.1810, 0.5789, 0.4243],\n",
            "        [0.8865, 0.8172, 0.8094, 0.1320, 0.6076],\n",
            "        [0.5541, 0.5516, 0.1492, 0.1630, 0.3436],\n",
            "        [0.8626, 0.4978, 0.5905, 0.5245, 0.7699]])\n",
            " produto: tensor([[[[-3.4990e-03,  1.3268e-05, -2.7481e-03,  4.2875e-04, -3.1815e-03],\n",
            "          [ 6.4501e-04, -4.8000e-04, -1.4392e-03, -3.6577e-03,  1.9216e-03],\n",
            "          [-3.2754e-03,  3.0579e-03, -6.8695e-03, -8.0069e-04, -2.2308e-03],\n",
            "          [-1.0888e-03, -4.2080e-03,  9.7665e-04, -3.8445e-04,  1.1031e-03],\n",
            "          [ 6.1001e-03,  9.2741e-04,  1.6148e-03,  5.0630e-03, -3.4723e-03]],\n",
            "\n",
            "         [[ 2.7179e-03, -1.7821e-04,  3.9542e-03,  9.0801e-04, -3.4426e-03],\n",
            "          [ 7.5112e-04,  3.1535e-04,  7.8886e-04,  2.3830e-03,  3.5271e-03],\n",
            "          [-1.1705e-03, -6.9107e-03, -2.3225e-03, -9.2943e-04,  4.0164e-04],\n",
            "          [-1.0345e-03, -2.9587e-03, -1.3561e-04,  1.5445e-03, -2.7105e-04],\n",
            "          [ 2.7389e-04, -7.7635e-04,  9.2834e-04,  4.6736e-03,  4.7078e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0155]],\n",
            "\n",
            "         [[ 0.0077]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0155,  0.0077], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 5, 0] = -0.015483930706977844\n",
            " somado na saída em [1, 1, 5, 0] = 0.0077452403493225574\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 1\n",
            " alvo do kernel em x: x[1,0,5:10, 1:6]\n",
            " \n",
            " tensor([[0.0401, 0.5533, 0.1137, 0.3734, 0.4479],\n",
            "        [0.0660, 0.1810, 0.5789, 0.4243, 0.6723],\n",
            "        [0.8172, 0.8094, 0.1320, 0.6076, 0.0339],\n",
            "        [0.5516, 0.1492, 0.1630, 0.3436, 0.1537],\n",
            "        [0.4978, 0.5905, 0.5245, 0.7699, 0.7739]])\n",
            " produto: tensor([[[[-1.6333e-04,  1.8328e-04, -5.6466e-04,  1.4081e-03, -3.8164e-03],\n",
            "          [ 4.8410e-04, -1.3158e-03, -4.6022e-03, -2.6810e-03,  3.0447e-03],\n",
            "          [-3.0193e-03,  3.0288e-03, -1.1201e-03, -3.6862e-03, -1.2438e-04],\n",
            "          [-1.0840e-03, -1.1378e-03,  1.0674e-03, -8.1042e-04,  4.9338e-04],\n",
            "          [ 3.5201e-03,  1.1002e-03,  1.4343e-03,  7.4314e-03, -3.4904e-03]],\n",
            "\n",
            "         [[ 1.2687e-04, -2.4618e-03,  8.1250e-04,  2.9821e-03, -4.1295e-03],\n",
            "          [ 5.6374e-04,  8.6443e-04,  2.5225e-03,  1.7467e-03,  5.5886e-03],\n",
            "          [-1.0790e-03, -6.8450e-03, -3.7869e-04, -4.2789e-03,  2.2394e-05],\n",
            "          [-1.0299e-03, -8.0004e-04, -1.4822e-04,  3.2557e-03, -1.2124e-04],\n",
            "          [ 1.5805e-04, -9.2098e-04,  8.2459e-04,  6.8598e-03,  4.7324e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0044]],\n",
            "\n",
            "         [[ 0.0089]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0044,  0.0089], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 5, 1] = -0.004420206882059574\n",
            " somado na saída em [1, 1, 5, 1] = 0.008867211639881134\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 2\n",
            " alvo do kernel em x: x[1,0,5:10, 2:7]\n",
            " \n",
            " tensor([[0.5533, 0.1137, 0.3734, 0.4479, 0.4630],\n",
            "        [0.1810, 0.5789, 0.4243, 0.6723, 0.0261],\n",
            "        [0.8094, 0.1320, 0.6076, 0.0339, 0.5086],\n",
            "        [0.1492, 0.1630, 0.3436, 0.1537, 0.5418],\n",
            "        [0.5905, 0.5245, 0.7699, 0.7739, 0.9466]])\n",
            " produto: tensor([[[[-2.2563e-03,  3.7660e-05, -1.8545e-03,  1.6891e-03, -3.9451e-03],\n",
            "          [ 1.3270e-03, -4.2074e-03, -3.3732e-03, -4.2480e-03,  1.1806e-04],\n",
            "          [-2.9906e-03,  4.9385e-04, -5.1565e-03, -2.0553e-04, -1.8674e-03],\n",
            "          [-2.9312e-04, -1.2436e-03,  2.2501e-03, -3.6249e-04,  1.7390e-03],\n",
            "          [ 4.1758e-03,  9.7722e-04,  2.1053e-03,  7.4703e-03, -4.2692e-03]],\n",
            "\n",
            "         [[ 1.7526e-03, -5.0584e-04,  2.6684e-03,  3.5772e-03, -4.2688e-03],\n",
            "          [ 1.5453e-03,  2.7641e-03,  1.8489e-03,  2.7676e-03,  2.1670e-04],\n",
            "          [-1.0687e-03, -1.1161e-03, -1.7434e-03, -2.3858e-04,  3.3621e-04],\n",
            "          [-2.7848e-04, -8.7442e-04, -3.1245e-04,  1.4562e-03, -4.2732e-04],\n",
            "          [ 1.8749e-04, -8.1805e-04,  1.2103e-03,  6.8957e-03,  5.7883e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0139]],\n",
            "\n",
            "         [[ 0.0214]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0139,  0.0214], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 5, 2] = -0.013889622874557972\n",
            " somado na saída em [1, 1, 5, 2] = 0.021363060921430588\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 3\n",
            " alvo do kernel em x: x[1,0,5:10, 3:8]\n",
            " \n",
            " tensor([[0.1137, 0.3734, 0.4479, 0.4630, 0.2687],\n",
            "        [0.5789, 0.4243, 0.6723, 0.0261, 0.2146],\n",
            "        [0.1320, 0.6076, 0.0339, 0.5086, 0.5832],\n",
            "        [0.1630, 0.3436, 0.1537, 0.5418, 0.4395],\n",
            "        [0.5245, 0.7699, 0.7739, 0.9466, 0.6837]])\n",
            " produto: tensor([[[[-4.6361e-04,  1.2368e-04, -2.2245e-03,  1.7461e-03, -2.2897e-03],\n",
            "          [ 4.2433e-03, -3.0839e-03, -5.3449e-03, -1.6472e-04,  9.7180e-04],\n",
            "          [-4.8762e-04,  2.2736e-03, -2.8752e-04, -3.0857e-03, -2.1413e-03],\n",
            "          [-3.2037e-04, -2.6215e-03,  1.0065e-03, -1.2777e-03,  1.4109e-03],\n",
            "          [ 3.7092e-03,  1.4343e-03,  2.1163e-03,  9.1370e-03, -3.0833e-03]],\n",
            "\n",
            "         [[ 3.6012e-04, -1.6613e-03,  3.2009e-03,  3.6978e-03, -2.4776e-03],\n",
            "          [ 4.9414e-03,  2.0260e-03,  2.9296e-03,  1.0731e-04,  1.7838e-03],\n",
            "          [-1.7425e-04, -5.1381e-03, -9.7207e-05, -3.5819e-03,  3.8553e-04],\n",
            "          [-3.0437e-04, -1.8433e-03, -1.3975e-04,  5.1327e-03, -3.4669e-04],\n",
            "          [ 1.6654e-04, -1.2007e-03,  1.2167e-03,  8.4342e-03,  4.1805e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[0.0013]],\n",
            "\n",
            "         [[0.0216]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([0.0013, 0.0216], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 5, 3] = 0.0012960704043507576\n",
            " somado na saída em [1, 1, 5, 3] = 0.021597985178232193\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 4\n",
            " alvo do kernel em x: x[1,0,5:10, 4:9]\n",
            " \n",
            " tensor([[0.3734, 0.4479, 0.4630, 0.2687, 0.7386],\n",
            "        [0.4243, 0.6723, 0.0261, 0.2146, 0.0651],\n",
            "        [0.6076, 0.0339, 0.5086, 0.5832, 0.3061],\n",
            "        [0.3436, 0.1537, 0.5418, 0.4395, 0.7671],\n",
            "        [0.7699, 0.7739, 0.9466, 0.6837, 0.3717]])\n",
            " produto: tensor([[[[-0.0015,  0.0001, -0.0023,  0.0010, -0.0063],\n",
            "          [ 0.0031, -0.0049, -0.0002, -0.0014,  0.0003],\n",
            "          [-0.0022,  0.0001, -0.0043, -0.0035, -0.0011],\n",
            "          [-0.0007, -0.0012,  0.0035, -0.0010,  0.0025],\n",
            "          [ 0.0054,  0.0014,  0.0026,  0.0066, -0.0017]],\n",
            "\n",
            "         [[ 0.0012, -0.0020,  0.0033,  0.0021, -0.0068],\n",
            "          [ 0.0036,  0.0032,  0.0001,  0.0009,  0.0005],\n",
            "          [-0.0008, -0.0003, -0.0015, -0.0041,  0.0002],\n",
            "          [-0.0006, -0.0008, -0.0005,  0.0042, -0.0006],\n",
            "          [ 0.0002, -0.0012,  0.0015,  0.0061,  0.0023]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0056]],\n",
            "\n",
            "         [[ 0.0102]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0056,  0.0102], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 5, 4] = -0.005573804024606943\n",
            " somado na saída em [1, 1, 5, 4] = 0.01024252362549305\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 5\n",
            " alvo do kernel em x: x[1,0,5:10, 5:10]\n",
            " \n",
            " tensor([[0.4479, 0.4630, 0.2687, 0.7386, 0.1300],\n",
            "        [0.6723, 0.0261, 0.2146, 0.0651, 0.2332],\n",
            "        [0.0339, 0.5086, 0.5832, 0.3061, 0.9248],\n",
            "        [0.1537, 0.5418, 0.4395, 0.7671, 0.8655],\n",
            "        [0.7739, 0.9466, 0.6837, 0.3717, 0.1778]])\n",
            " produto: tensor([[[[-1.8264e-03,  1.5337e-04, -1.3347e-03,  2.7855e-03, -1.1074e-03],\n",
            "          [ 4.9281e-03, -1.8947e-04, -1.7060e-03, -4.1114e-04,  1.0560e-03],\n",
            "          [-1.2517e-04,  1.9032e-03, -4.9497e-03, -1.8575e-03, -3.3957e-03],\n",
            "          [-3.0207e-04, -4.1330e-03,  2.8780e-03, -1.8090e-03,  2.7783e-03],\n",
            "          [ 5.4727e-03,  1.7635e-03,  1.8694e-03,  3.5883e-03, -8.0169e-04]],\n",
            "\n",
            "         [[ 1.4187e-03, -2.0600e-03,  1.9205e-03,  5.8992e-03, -1.1982e-03],\n",
            "          [ 5.7389e-03,  1.2448e-04,  9.3505e-04,  2.6786e-04,  1.9384e-03],\n",
            "          [-4.4730e-05, -4.3011e-03, -1.6735e-03, -2.1561e-03,  6.1136e-04],\n",
            "          [-2.8698e-04, -2.9060e-03, -3.9963e-04,  7.2672e-03, -6.8270e-04],\n",
            "          [ 2.4572e-04, -1.4763e-03,  1.0747e-03,  3.3123e-03,  1.0870e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[0.0052]],\n",
            "\n",
            "         [[0.0147]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([0.0052, 0.0147], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 5, 5] = 0.005227849818766117\n",
            " somado na saída em [1, 1, 5, 5] = 0.0146561274304986\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 6\n",
            " alvo do kernel em x: x[1,0,5:10, 6:11]\n",
            " \n",
            " tensor([[0.4630, 0.2687, 0.7386, 0.1300, 0.2547],\n",
            "        [0.0261, 0.2146, 0.0651, 0.2332, 0.0755],\n",
            "        [0.5086, 0.5832, 0.3061, 0.9248, 0.3211],\n",
            "        [0.5418, 0.4395, 0.7671, 0.8655, 0.9959],\n",
            "        [0.9466, 0.6837, 0.3717, 0.1778, 0.7179]])\n",
            " produto: tensor([[[[-1.8880e-03,  8.9015e-05, -3.6685e-03,  4.9011e-04, -2.1701e-03],\n",
            "          [ 1.9109e-04, -1.5596e-03, -5.1730e-04, -1.4734e-03,  3.4173e-04],\n",
            "          [-1.8792e-03,  2.1824e-03, -2.5984e-03, -5.6110e-03, -1.1789e-03],\n",
            "          [-1.0647e-03, -3.3531e-03,  5.0227e-03, -2.0412e-03,  3.1966e-03],\n",
            "          [ 6.6937e-03,  1.2737e-03,  1.0165e-03,  1.7158e-03, -3.2377e-03]],\n",
            "\n",
            "         [[ 1.4666e-03, -1.1956e-03,  5.2787e-03,  1.0380e-03, -2.3481e-03],\n",
            "          [ 2.2252e-04,  1.0246e-03,  2.8353e-04,  9.5993e-04,  6.2725e-04],\n",
            "          [-6.7154e-04, -4.9321e-03, -8.7848e-04, -6.5132e-03,  2.1226e-04],\n",
            "          [-1.0115e-03, -2.3576e-03, -6.9743e-04,  8.2002e-03, -7.8550e-04],\n",
            "          [ 3.0054e-04, -1.0662e-03,  5.8441e-04,  1.5838e-03,  4.3898e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0100]],\n",
            "\n",
            "         [[ 0.0037]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0100,  0.0037], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 5, 6] = -0.010027812793850899\n",
            " somado na saída em [1, 1, 5, 6] = 0.003714962163940072\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 7\n",
            " alvo do kernel em x: x[1,0,5:10, 7:12]\n",
            " \n",
            " tensor([[0.2687, 0.7386, 0.1300, 0.2547, 0.9303],\n",
            "        [0.2146, 0.0651, 0.2332, 0.0755, 0.4111],\n",
            "        [0.5832, 0.3061, 0.9248, 0.3211, 0.9655],\n",
            "        [0.4395, 0.7671, 0.8655, 0.9959, 0.4935],\n",
            "        [0.6837, 0.3717, 0.1778, 0.7179, 0.4353]])\n",
            " produto: tensor([[[[-0.0011,  0.0002, -0.0006,  0.0010, -0.0079],\n",
            "          [ 0.0016, -0.0005, -0.0019, -0.0005,  0.0019],\n",
            "          [-0.0022,  0.0011, -0.0078, -0.0019, -0.0035],\n",
            "          [-0.0009, -0.0059,  0.0057, -0.0023,  0.0016],\n",
            "          [ 0.0048,  0.0007,  0.0005,  0.0069, -0.0020]],\n",
            "\n",
            "         [[ 0.0009, -0.0033,  0.0009,  0.0020, -0.0086],\n",
            "          [ 0.0018,  0.0003,  0.0010,  0.0003,  0.0034],\n",
            "          [-0.0008, -0.0026, -0.0027, -0.0023,  0.0006],\n",
            "          [-0.0008, -0.0041, -0.0008,  0.0094, -0.0004],\n",
            "          [ 0.0002, -0.0006,  0.0003,  0.0064,  0.0027]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0130]],\n",
            "\n",
            "         [[ 0.0035]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0130,  0.0035], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 5, 7] = -0.01301596686244011\n",
            " somado na saída em [1, 1, 5, 7] = 0.0035003710072487593\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 0\n",
            " alvo do kernel em x: x[1,0,6:11, 0:5]\n",
            " \n",
            " tensor([[0.0880, 0.0660, 0.1810, 0.5789, 0.4243],\n",
            "        [0.8865, 0.8172, 0.8094, 0.1320, 0.6076],\n",
            "        [0.5541, 0.5516, 0.1492, 0.1630, 0.3436],\n",
            "        [0.8626, 0.4978, 0.5905, 0.5245, 0.7699],\n",
            "        [0.5779, 0.5465, 0.7795, 0.7811, 0.3611]])\n",
            " produto: tensor([[[[-3.5880e-04,  2.1875e-05, -8.9909e-04,  2.1830e-03, -3.6151e-03],\n",
            "          [ 6.4981e-03, -5.9394e-03, -6.4350e-03, -8.3390e-04,  2.7516e-03],\n",
            "          [-2.0472e-03,  2.0642e-03, -1.2659e-03, -9.8909e-04, -1.2618e-03],\n",
            "          [-1.6953e-03, -3.7974e-03,  3.8667e-03, -1.2370e-03,  2.4712e-03],\n",
            "          [ 4.0869e-03,  1.0182e-03,  2.1315e-03,  7.5398e-03, -1.6284e-03]],\n",
            "\n",
            "         [[ 2.7871e-04, -2.9382e-04,  1.2937e-03,  4.6231e-03, -3.9118e-03],\n",
            "          [ 7.5672e-03,  3.9020e-03,  3.5270e-03,  5.4329e-04,  5.0506e-03],\n",
            "          [-7.3157e-04, -4.6649e-03, -4.2800e-04, -1.1481e-03,  2.2717e-04],\n",
            "          [-1.6106e-03, -2.6701e-03, -5.3691e-04,  4.9694e-03, -6.0725e-04],\n",
            "          [ 1.8350e-04, -8.5233e-04,  1.2254e-03,  6.9599e-03,  2.2078e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[0.0026]],\n",
            "\n",
            "         [[0.0251]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([0.0026, 0.0251], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 6, 0] = 0.0026296302676200867\n",
            " somado na saída em [1, 1, 6, 0] = 0.025103474035859108\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 1\n",
            " alvo do kernel em x: x[1,0,6:11, 1:6]\n",
            " \n",
            " tensor([[0.0660, 0.1810, 0.5789, 0.4243, 0.6723],\n",
            "        [0.8172, 0.8094, 0.1320, 0.6076, 0.0339],\n",
            "        [0.5516, 0.1492, 0.1630, 0.3436, 0.1537],\n",
            "        [0.4978, 0.5905, 0.5245, 0.7699, 0.7739],\n",
            "        [0.5465, 0.7795, 0.7811, 0.3611, 0.2002]])\n",
            " produto: tensor([[[[-2.6929e-04,  5.9965e-05, -2.8750e-03,  1.6000e-03, -5.7282e-03],\n",
            "          [ 5.9901e-03, -5.8830e-03, -1.0492e-03, -3.8391e-03,  1.5342e-04],\n",
            "          [-2.0381e-03,  5.5815e-04, -1.3836e-03, -2.0850e-03, -5.6438e-04],\n",
            "          [-9.7825e-04, -4.5048e-03,  3.4345e-03, -1.8156e-03,  2.4842e-03],\n",
            "          [ 3.8646e-03,  1.4522e-03,  2.1360e-03,  3.4851e-03, -9.0272e-04]],\n",
            "\n",
            "         [[ 2.0918e-04, -8.0542e-04,  4.1368e-03,  3.3886e-03, -6.1982e-03],\n",
            "          [ 6.9756e-03,  3.8649e-03,  5.7508e-04,  2.5012e-03,  2.8161e-04],\n",
            "          [-7.2834e-04, -1.2614e-03, -4.6779e-04, -2.4202e-03,  1.0161e-04],\n",
            "          [-9.2941e-04, -3.1675e-03, -4.7691e-04,  7.2939e-03, -6.1043e-04],\n",
            "          [ 1.7352e-04, -1.2157e-03,  1.2280e-03,  3.2171e-03,  1.2239e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0087]],\n",
            "\n",
            "         [[ 0.0169]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0087,  0.0169], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 6, 1] = -0.008697976358234882\n",
            " somado na saída em [1, 1, 6, 1] = 0.0168897807598114\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 2\n",
            " alvo do kernel em x: x[1,0,6:11, 2:7]\n",
            " \n",
            " tensor([[0.1810, 0.5789, 0.4243, 0.6723, 0.0261],\n",
            "        [0.8094, 0.1320, 0.6076, 0.0339, 0.5086],\n",
            "        [0.1492, 0.1630, 0.3436, 0.1537, 0.5418],\n",
            "        [0.5905, 0.5245, 0.7699, 0.7739, 0.9466],\n",
            "        [0.7795, 0.7811, 0.3611, 0.2002, 0.0695]])\n",
            " produto: tensor([[[[-0.0007,  0.0002, -0.0021,  0.0025, -0.0002],\n",
            "          [ 0.0059, -0.0010, -0.0048, -0.0002,  0.0023],\n",
            "          [-0.0006,  0.0006, -0.0029, -0.0009, -0.0020],\n",
            "          [-0.0012, -0.0040,  0.0050, -0.0018,  0.0030],\n",
            "          [ 0.0055,  0.0015,  0.0010,  0.0019, -0.0003]],\n",
            "\n",
            "         [[ 0.0006, -0.0026,  0.0030,  0.0054, -0.0002],\n",
            "          [ 0.0069,  0.0006,  0.0026,  0.0001,  0.0042],\n",
            "          [-0.0002, -0.0014, -0.0010, -0.0011,  0.0004],\n",
            "          [-0.0011, -0.0028, -0.0007,  0.0073, -0.0007],\n",
            "          [ 0.0002, -0.0012,  0.0006,  0.0018,  0.0004]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[0.0068]],\n",
            "\n",
            "         [[0.0212]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([0.0068, 0.0212], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 6, 2] = 0.0067783622071146965\n",
            " somado na saída em [1, 1, 6, 2] = 0.02120211534202099\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 3\n",
            " alvo do kernel em x: x[1,0,6:11, 3:8]\n",
            " \n",
            " tensor([[0.5789, 0.4243, 0.6723, 0.0261, 0.2146],\n",
            "        [0.1320, 0.6076, 0.0339, 0.5086, 0.5832],\n",
            "        [0.1630, 0.3436, 0.1537, 0.5418, 0.4395],\n",
            "        [0.5245, 0.7699, 0.7739, 0.9466, 0.6837],\n",
            "        [0.7811, 0.3611, 0.2002, 0.0695, 0.9485]])\n",
            " produto: tensor([[[[-2.3604e-03,  1.4054e-04, -3.3389e-03,  9.8304e-05, -1.8283e-03],\n",
            "          [ 9.6739e-04, -4.4160e-03, -2.6933e-04, -3.2137e-03,  2.6412e-03],\n",
            "          [-6.0235e-04,  1.2860e-03, -1.3046e-03, -3.2870e-03, -1.6139e-03],\n",
            "          [-1.0308e-03, -5.8732e-03,  5.0675e-03, -2.2323e-03,  2.1944e-03],\n",
            "          [ 5.5236e-03,  6.7267e-04,  5.4733e-04,  6.7105e-04, -4.2777e-03]],\n",
            "\n",
            "         [[ 1.8335e-03, -1.8877e-03,  4.8044e-03,  2.0819e-04, -1.9783e-03],\n",
            "          [ 1.1266e-03,  2.9012e-03,  1.4762e-04,  2.0937e-03,  4.8481e-03],\n",
            "          [-2.1525e-04, -2.9062e-03, -4.4106e-04, -3.8155e-03,  2.9056e-04],\n",
            "          [-9.7933e-04, -4.1295e-03, -7.0366e-04,  8.9680e-03, -5.3923e-04],\n",
            "          [ 2.4801e-04, -5.6311e-04,  3.1466e-04,  6.1943e-04,  5.7998e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0158]],\n",
            "\n",
            "         [[ 0.0160]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0158,  0.0160], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 6, 3] = -0.015838416293263435\n",
            " somado na saída em [1, 1, 6, 3] = 0.01604483462870121\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 4\n",
            " alvo do kernel em x: x[1,0,6:11, 4:9]\n",
            " \n",
            " tensor([[0.4243, 0.6723, 0.0261, 0.2146, 0.0651],\n",
            "        [0.6076, 0.0339, 0.5086, 0.5832, 0.3061],\n",
            "        [0.3436, 0.1537, 0.5418, 0.4395, 0.7671],\n",
            "        [0.7699, 0.7739, 0.9466, 0.6837, 0.3717],\n",
            "        [0.3611, 0.2002, 0.0695, 0.9485, 0.4718]])\n",
            " produto: tensor([[[[-0.0017,  0.0002, -0.0001,  0.0008, -0.0006],\n",
            "          [ 0.0045, -0.0002, -0.0040, -0.0037,  0.0014],\n",
            "          [-0.0013,  0.0006, -0.0046, -0.0027, -0.0028],\n",
            "          [-0.0015, -0.0059,  0.0062, -0.0016,  0.0012],\n",
            "          [ 0.0026,  0.0004,  0.0002,  0.0092, -0.0021]],\n",
            "\n",
            "         [[ 0.0013, -0.0030,  0.0002,  0.0017, -0.0006],\n",
            "          [ 0.0052,  0.0002,  0.0022,  0.0024,  0.0025],\n",
            "          [-0.0005, -0.0013, -0.0016, -0.0031,  0.0005],\n",
            "          [-0.0014, -0.0042, -0.0009,  0.0065, -0.0003],\n",
            "          [ 0.0001, -0.0003,  0.0001,  0.0085,  0.0029]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0058]],\n",
            "\n",
            "         [[ 0.0172]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0058,  0.0172], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 6, 4] = -0.0057870554737746716\n",
            " somado na saída em [1, 1, 6, 4] = 0.017248865216970444\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 5\n",
            " alvo do kernel em x: x[1,0,6:11, 5:10]\n",
            " \n",
            " tensor([[0.6723, 0.0261, 0.2146, 0.0651, 0.2332],\n",
            "        [0.0339, 0.5086, 0.5832, 0.3061, 0.9248],\n",
            "        [0.1537, 0.5418, 0.4395, 0.7671, 0.8655],\n",
            "        [0.7739, 0.9466, 0.6837, 0.3717, 0.1778],\n",
            "        [0.2002, 0.0695, 0.9485, 0.4718, 0.3759]])\n",
            " produto: tensor([[[[-2.7414e-03,  8.6347e-06, -1.0657e-03,  2.4537e-04, -1.9868e-03],\n",
            "          [ 2.4833e-04, -3.6966e-03, -4.6366e-03, -1.9345e-03,  4.1884e-03],\n",
            "          [-5.6794e-04,  2.0274e-03, -3.7305e-03, -4.6540e-03, -3.1781e-03],\n",
            "          [-1.5209e-03, -7.2212e-03,  4.4765e-03, -8.7669e-04,  5.7057e-04],\n",
            "          [ 1.4154e-03,  1.2952e-04,  2.5936e-03,  4.5543e-03, -1.6952e-03]],\n",
            "\n",
            "         [[ 2.1294e-03, -1.1598e-04,  1.5335e-03,  5.1965e-04, -2.1498e-03],\n",
            "          [ 2.8918e-04,  2.4286e-03,  2.5414e-03,  1.2603e-03,  7.6879e-03],\n",
            "          [-2.0296e-04, -4.5817e-03, -1.2612e-03, -5.4022e-03,  5.7218e-04],\n",
            "          [-1.4450e-03, -5.0773e-03, -6.2158e-04,  3.5219e-03, -1.4021e-04],\n",
            "          [ 6.3549e-05, -1.0842e-04,  1.4911e-03,  4.2040e-03,  2.2984e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0190]],\n",
            "\n",
            "         [[ 0.0094]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0190,  0.0094], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 6, 5] = -0.019048113375902176\n",
            " somado na saída em [1, 1, 6, 5] = 0.009434444829821587\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 6\n",
            " alvo do kernel em x: x[1,0,6:11, 6:11]\n",
            " \n",
            " tensor([[0.0261, 0.2146, 0.0651, 0.2332, 0.0755],\n",
            "        [0.5086, 0.5832, 0.3061, 0.9248, 0.3211],\n",
            "        [0.5418, 0.4395, 0.7671, 0.8655, 0.9959],\n",
            "        [0.9466, 0.6837, 0.3717, 0.1778, 0.7179],\n",
            "        [0.0695, 0.9485, 0.4718, 0.3759, 0.0127]])\n",
            " produto: tensor([[[[-1.0630e-04,  7.1077e-05, -3.2315e-04,  8.7934e-04, -6.4291e-04],\n",
            "          [ 3.7282e-03, -4.2389e-03, -2.4340e-03, -5.8437e-03,  1.4542e-03],\n",
            "          [-2.0018e-03,  1.6448e-03, -6.5103e-03, -5.2515e-03, -3.6566e-03],\n",
            "          [-1.8602e-03, -5.2153e-03,  2.4342e-03, -4.1920e-04,  2.3043e-03],\n",
            "          [ 4.9161e-04,  1.7670e-03,  1.2902e-03,  3.6280e-03, -5.7111e-05]],\n",
            "\n",
            "         [[ 8.2569e-05, -9.5468e-04,  4.6499e-04,  1.8623e-03, -6.9566e-04],\n",
            "          [ 4.3415e-03,  2.7848e-03,  1.3341e-03,  3.8072e-03,  2.6692e-03],\n",
            "          [-7.1535e-04, -3.7172e-03, -2.2011e-03, -6.0958e-03,  6.5834e-04],\n",
            "          [-1.7673e-03, -3.6670e-03, -3.3800e-04,  1.6841e-03, -5.6624e-04],\n",
            "          [ 2.2073e-05, -1.4792e-03,  7.4174e-04,  3.3490e-03,  7.7433e-05]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0189]],\n",
            "\n",
            "         [[ 0.0017]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0189,  0.0017], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 6, 6] = -0.018868066370487213\n",
            " somado na saída em [1, 1, 6, 6] = 0.0016816819552332163\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 7\n",
            " alvo do kernel em x: x[1,0,6:11, 7:12]\n",
            " \n",
            " tensor([[0.2146, 0.0651, 0.2332, 0.0755, 0.4111],\n",
            "        [0.5832, 0.3061, 0.9248, 0.3211, 0.9655],\n",
            "        [0.4395, 0.7671, 0.8655, 0.9959, 0.4935],\n",
            "        [0.6837, 0.3717, 0.1778, 0.7179, 0.4353],\n",
            "        [0.9485, 0.4718, 0.3759, 0.0127, 0.0650]])\n",
            " produto: tensor([[[[-8.7499e-04,  2.1553e-05, -1.1581e-03,  2.8455e-04, -3.5029e-03],\n",
            "          [ 4.2751e-03, -2.2252e-03, -7.3526e-03, -2.0289e-03,  4.3728e-03],\n",
            "          [-1.6241e-03,  2.8705e-03, -7.3462e-03, -6.0422e-03, -1.8120e-03],\n",
            "          [-1.3435e-03, -2.8359e-03,  1.1639e-03, -1.6930e-03,  1.3972e-03],\n",
            "          [ 6.7070e-03,  8.7903e-04,  1.0278e-03,  1.2223e-04, -2.9331e-04]],\n",
            "\n",
            "         [[ 6.7967e-04, -2.8949e-04,  1.6664e-03,  6.0262e-04, -3.7903e-03],\n",
            "          [ 4.9784e-03,  1.4619e-03,  4.0300e-03,  1.3218e-03,  8.0264e-03],\n",
            "          [-5.8036e-04, -6.4871e-03, -2.4837e-03, -7.0137e-03,  3.2624e-04],\n",
            "          [-1.2764e-03, -1.9940e-03, -1.6162e-04,  6.8013e-03, -3.4334e-04],\n",
            "          [ 3.0114e-04, -7.3586e-04,  5.9088e-04,  1.1283e-04,  3.9768e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0170]],\n",
            "\n",
            "         [[ 0.0061]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0170,  0.0061], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 6, 7] = -0.017011184245347977\n",
            " somado na saída em [1, 1, 6, 7] = 0.006141358520835638\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 0\n",
            " alvo do kernel em x: x[1,0,7:12, 0:5]\n",
            " \n",
            " tensor([[0.8865, 0.8172, 0.8094, 0.1320, 0.6076],\n",
            "        [0.5541, 0.5516, 0.1492, 0.1630, 0.3436],\n",
            "        [0.8626, 0.4978, 0.5905, 0.5245, 0.7699],\n",
            "        [0.5779, 0.5465, 0.7795, 0.7811, 0.3611],\n",
            "        [0.3298, 0.7111, 0.4127, 0.5049, 0.9601]])\n",
            " produto: tensor([[[[-0.0036,  0.0003, -0.0040,  0.0005, -0.0052],\n",
            "          [ 0.0041, -0.0040, -0.0012, -0.0010,  0.0016],\n",
            "          [-0.0032,  0.0019, -0.0050, -0.0032, -0.0028],\n",
            "          [-0.0011, -0.0042,  0.0051, -0.0018,  0.0012],\n",
            "          [ 0.0023,  0.0013,  0.0011,  0.0049, -0.0043]],\n",
            "\n",
            "         [[ 0.0028, -0.0036,  0.0058,  0.0011, -0.0056],\n",
            "          [ 0.0047,  0.0026,  0.0006,  0.0007,  0.0029],\n",
            "          [-0.0011, -0.0042, -0.0017, -0.0037,  0.0005],\n",
            "          [-0.0011, -0.0029, -0.0007,  0.0074, -0.0003],\n",
            "          [ 0.0001, -0.0011,  0.0006,  0.0045,  0.0059]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0206]],\n",
            "\n",
            "         [[ 0.0141]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0206,  0.0141], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 7, 0] = -0.02055143564939499\n",
            " somado na saída em [1, 1, 7, 0] = 0.014132235199213028\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 1\n",
            " alvo do kernel em x: x[1,0,7:12, 1:6]\n",
            " \n",
            " tensor([[0.8172, 0.8094, 0.1320, 0.6076, 0.0339],\n",
            "        [0.5516, 0.1492, 0.1630, 0.3436, 0.1537],\n",
            "        [0.4978, 0.5905, 0.5245, 0.7699, 0.7739],\n",
            "        [0.5465, 0.7795, 0.7811, 0.3611, 0.2002],\n",
            "        [0.7111, 0.4127, 0.5049, 0.9601, 0.2528]])\n",
            " produto: tensor([[[[-0.0033,  0.0003, -0.0007,  0.0023, -0.0003],\n",
            "          [ 0.0040, -0.0011, -0.0013, -0.0022,  0.0007],\n",
            "          [-0.0018,  0.0022, -0.0045, -0.0047, -0.0028],\n",
            "          [-0.0011, -0.0059,  0.0051, -0.0009,  0.0006],\n",
            "          [ 0.0050,  0.0008,  0.0014,  0.0093, -0.0011]],\n",
            "\n",
            "         [[ 0.0026, -0.0036,  0.0009,  0.0049, -0.0003],\n",
            "          [ 0.0047,  0.0007,  0.0007,  0.0014,  0.0013],\n",
            "          [-0.0007, -0.0050, -0.0015, -0.0054,  0.0005],\n",
            "          [-0.0010, -0.0042, -0.0007,  0.0034, -0.0002],\n",
            "          [ 0.0002, -0.0006,  0.0008,  0.0086,  0.0015]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[6.6993e-05]],\n",
            "\n",
            "         [[9.0549e-03]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([6.6993e-05, 9.0549e-03], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 7, 1] = 6.699282675981522e-05\n",
            " somado na saída em [1, 1, 7, 1] = 0.00905485451221466\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 2\n",
            " alvo do kernel em x: x[1,0,7:12, 2:7]\n",
            " \n",
            " tensor([[0.8094, 0.1320, 0.6076, 0.0339, 0.5086],\n",
            "        [0.1492, 0.1630, 0.3436, 0.1537, 0.5418],\n",
            "        [0.5905, 0.5245, 0.7699, 0.7739, 0.9466],\n",
            "        [0.7795, 0.7811, 0.3611, 0.2002, 0.0695],\n",
            "        [0.4127, 0.5049, 0.9601, 0.2528, 0.6806]])\n",
            " produto: tensor([[[[-3.3005e-03,  4.3714e-05, -3.0175e-03,  1.2775e-04, -4.3335e-03],\n",
            "          [ 1.0934e-03, -1.1849e-03, -2.7321e-03, -9.7126e-04,  2.4536e-03],\n",
            "          [-2.1819e-03,  1.9628e-03, -6.5342e-03, -4.6955e-03, -3.4756e-03],\n",
            "          [-1.5318e-03, -5.9589e-03,  2.3642e-03, -4.7203e-04,  2.2315e-04],\n",
            "          [ 2.9183e-03,  9.4064e-04,  2.6253e-03,  2.4405e-03, -3.0694e-03]],\n",
            "\n",
            "         [[ 2.5637e-03, -5.8715e-04,  4.3419e-03,  2.7055e-04, -4.6890e-03],\n",
            "          [ 1.2732e-03,  7.7845e-04,  1.4975e-03,  6.3278e-04,  4.5037e-03],\n",
            "          [-7.7972e-04, -4.4359e-03, -2.2092e-03, -5.4505e-03,  6.2576e-04],\n",
            "          [-1.4553e-03, -4.1898e-03, -3.2828e-04,  1.8963e-03, -5.4834e-05],\n",
            "          [ 1.3103e-04, -7.8743e-04,  1.5093e-03,  2.2528e-03,  4.1616e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0263]],\n",
            "\n",
            "         [[ 0.0015]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0263,  0.0015], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 7, 2] = -0.026265759021043777\n",
            " somado na saída em [1, 1, 7, 2] = 0.0014714631251990795\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 3\n",
            " alvo do kernel em x: x[1,0,7:12, 3:8]\n",
            " \n",
            " tensor([[0.1320, 0.6076, 0.0339, 0.5086, 0.5832],\n",
            "        [0.1630, 0.3436, 0.1537, 0.5418, 0.4395],\n",
            "        [0.5245, 0.7699, 0.7739, 0.9466, 0.6837],\n",
            "        [0.7811, 0.3611, 0.2002, 0.0695, 0.9485],\n",
            "        [0.5049, 0.9601, 0.2528, 0.6806, 0.1828]])\n",
            " produto: tensor([[[[-0.0005,  0.0002, -0.0002,  0.0019, -0.0050],\n",
            "          [ 0.0012, -0.0025, -0.0012, -0.0034,  0.0020],\n",
            "          [-0.0019,  0.0029, -0.0066, -0.0057, -0.0025],\n",
            "          [-0.0015, -0.0028,  0.0013, -0.0002,  0.0030],\n",
            "          [ 0.0036,  0.0018,  0.0007,  0.0066, -0.0008]],\n",
            "\n",
            "         [[ 0.0004, -0.0027,  0.0002,  0.0041, -0.0054],\n",
            "          [ 0.0014,  0.0016,  0.0007,  0.0022,  0.0037],\n",
            "          [-0.0007, -0.0065, -0.0022, -0.0067,  0.0005],\n",
            "          [-0.0015, -0.0019, -0.0002,  0.0007, -0.0007],\n",
            "          [ 0.0002, -0.0015,  0.0004,  0.0061,  0.0011]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0097]],\n",
            "\n",
            "         [[-0.0068]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0097, -0.0068], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 7, 3] = -0.009695971384644508\n",
            " somado na saída em [1, 1, 7, 3] = -0.006834710948169231\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 4\n",
            " alvo do kernel em x: x[1,0,7:12, 4:9]\n",
            " \n",
            " tensor([[0.6076, 0.0339, 0.5086, 0.5832, 0.3061],\n",
            "        [0.3436, 0.1537, 0.5418, 0.4395, 0.7671],\n",
            "        [0.7699, 0.7739, 0.9466, 0.6837, 0.3717],\n",
            "        [0.3611, 0.2002, 0.0695, 0.9485, 0.4718],\n",
            "        [0.9601, 0.2528, 0.6806, 0.1828, 0.7716]])\n",
            " produto: tensor([[[[-2.4775e-03,  1.1221e-05, -2.5259e-03,  2.1993e-03, -2.6085e-03],\n",
            "          [ 2.5191e-03, -1.1172e-03, -4.3073e-03, -2.7774e-03,  3.4740e-03],\n",
            "          [-2.8447e-03,  2.8961e-03, -8.0340e-03, -4.1479e-03, -1.3650e-03],\n",
            "          [-7.0955e-04, -1.5269e-03,  4.5521e-04, -2.2368e-03,  1.5145e-03],\n",
            "          [ 6.7890e-03,  4.7105e-04,  1.8610e-03,  1.7645e-03, -3.4802e-03]],\n",
            "\n",
            "         [[ 1.9245e-03, -1.5072e-04,  3.6346e-03,  4.6577e-03, -2.8226e-03],\n",
            "          [ 2.9335e-03,  7.3398e-04,  2.3609e-03,  1.8095e-03,  6.3766e-03],\n",
            "          [-1.0166e-03, -6.5450e-03, -2.7162e-03, -4.8148e-03,  2.4575e-04],\n",
            "          [-6.7412e-04, -1.0736e-03, -6.3209e-05,  8.9858e-03, -3.7215e-04],\n",
            "          [ 3.0482e-04, -3.9433e-04,  1.0699e-03,  1.6288e-03,  4.7186e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0162]],\n",
            "\n",
            "         [[ 0.0207]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0162,  0.0207], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 7, 4] = -0.016203830018639565\n",
            " somado na saída em [1, 1, 7, 4] = 0.020741503685712814\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 5\n",
            " alvo do kernel em x: x[1,0,7:12, 5:10]\n",
            " \n",
            " tensor([[0.0339, 0.5086, 0.5832, 0.3061, 0.9248],\n",
            "        [0.1537, 0.5418, 0.4395, 0.7671, 0.8655],\n",
            "        [0.7739, 0.9466, 0.6837, 0.3717, 0.1778],\n",
            "        [0.2002, 0.0695, 0.9485, 0.4718, 0.3759],\n",
            "        [0.2528, 0.6806, 0.1828, 0.7716, 0.4357]])\n",
            " produto: tensor([[[[-1.3814e-04,  1.6847e-04, -2.8965e-03,  1.1545e-03, -7.8798e-03],\n",
            "          [ 1.1267e-03, -3.9378e-03, -3.4945e-03, -4.8470e-03,  3.9200e-03],\n",
            "          [-2.8596e-03,  3.5423e-03, -5.8023e-03, -2.2555e-03, -6.5268e-04],\n",
            "          [-3.9334e-04, -5.3034e-04,  6.2105e-03, -1.1127e-03,  1.2065e-03],\n",
            "          [ 1.7879e-03,  1.2679e-03,  4.9986e-04,  7.4484e-03, -1.9651e-03]],\n",
            "\n",
            "         [[ 1.0730e-04, -2.2628e-03,  4.1678e-03,  2.4451e-03, -8.5264e-03],\n",
            "          [ 1.3121e-03,  2.5870e-03,  1.9154e-03,  3.1578e-03,  7.1953e-03],\n",
            "          [-1.0219e-03, -8.0053e-03, -1.9617e-03, -2.6181e-03,  1.1751e-04],\n",
            "          [-3.7370e-04, -3.7290e-04, -8.6236e-04,  4.4701e-03, -2.9646e-04],\n",
            "          [ 8.0276e-05, -1.0614e-03,  2.8737e-04,  6.8755e-03,  2.6643e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0104]],\n",
            "\n",
            "         [[ 0.0100]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0104,  0.0100], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 7, 5] = -0.010432243347167969\n",
            " somado na saída em [1, 1, 7, 5] = 0.010019782930612564\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 6\n",
            " alvo do kernel em x: x[1,0,7:12, 6:11]\n",
            " \n",
            " tensor([[0.5086, 0.5832, 0.3061, 0.9248, 0.3211],\n",
            "        [0.5418, 0.4395, 0.7671, 0.8655, 0.9959],\n",
            "        [0.9466, 0.6837, 0.3717, 0.1778, 0.7179],\n",
            "        [0.0695, 0.9485, 0.4718, 0.3759, 0.0127],\n",
            "        [0.6806, 0.1828, 0.7716, 0.4357, 0.8552]])\n",
            " produto: tensor([[[[-2.0739e-03,  1.9318e-04, -1.5205e-03,  3.4876e-03, -2.7358e-03],\n",
            "          [ 3.9714e-03, -3.1947e-03, -6.0985e-03, -5.4693e-03,  4.5103e-03],\n",
            "          [-3.4976e-03,  2.5583e-03, -3.1551e-03, -1.0785e-03, -2.6359e-03],\n",
            "          [-1.3662e-04, -7.2355e-03,  3.0894e-03, -8.8639e-04,  4.0647e-05],\n",
            "          [ 4.8125e-03,  3.4056e-04,  2.1101e-03,  4.2058e-03, -3.8570e-03]],\n",
            "\n",
            "         [[ 1.6110e-03, -2.5947e-03,  2.1879e-03,  7.3860e-03, -2.9603e-03],\n",
            "          [ 4.6248e-03,  2.0989e-03,  3.3426e-03,  3.5632e-03,  8.2787e-03],\n",
            "          [-1.2499e-03, -5.7816e-03, -1.0667e-03, -1.2519e-03,  4.7457e-04],\n",
            "          [-1.2980e-04, -5.0874e-03, -4.2899e-04,  3.5609e-03, -9.9880e-06],\n",
            "          [ 2.1608e-04, -2.8509e-04,  1.2131e-03,  3.8823e-03,  5.2294e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0143]],\n",
            "\n",
            "         [[ 0.0268]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0143,  0.0268], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 7, 6] = -0.014255531132221222\n",
            " somado na saída em [1, 1, 7, 6] = 0.026822898536920547\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 7\n",
            " alvo do kernel em x: x[1,0,7:12, 7:12]\n",
            " \n",
            " tensor([[0.5832, 0.3061, 0.9248, 0.3211, 0.9655],\n",
            "        [0.4395, 0.7671, 0.8655, 0.9959, 0.4935],\n",
            "        [0.6837, 0.3717, 0.1778, 0.7179, 0.4353],\n",
            "        [0.9485, 0.4718, 0.3759, 0.0127, 0.0650],\n",
            "        [0.1828, 0.7716, 0.4357, 0.8552, 0.5799]])\n",
            " produto: tensor([[[[-2.3781e-03,  1.0141e-04, -4.5931e-03,  1.2109e-03, -8.2268e-03],\n",
            "          [ 3.2220e-03, -5.5753e-03, -6.8815e-03, -6.2928e-03,  2.2351e-03],\n",
            "          [-2.5260e-03,  1.3911e-03, -1.5087e-03, -4.3556e-03, -1.5983e-03],\n",
            "          [-1.8639e-03, -3.5994e-03,  2.4611e-03, -2.9863e-05,  2.0875e-04],\n",
            "          [ 1.2926e-03,  1.4376e-03,  1.1915e-03,  8.2547e-03, -2.6153e-03]],\n",
            "\n",
            "         [[ 1.8473e-03, -1.3621e-03,  6.6091e-03,  2.5644e-03, -8.9018e-03],\n",
            "          [ 3.7521e-03,  3.6628e-03,  3.7718e-03,  4.0998e-03,  4.1025e-03],\n",
            "          [-9.0269e-04, -3.1438e-03, -5.1007e-04, -5.0559e-03,  2.8776e-04],\n",
            "          [-1.7709e-03, -2.5308e-03, -3.4174e-04,  1.1997e-04, -5.1295e-05],\n",
            "          [ 5.8038e-05, -1.2035e-03,  6.8497e-04,  7.6198e-03,  3.5459e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0290]],\n",
            "\n",
            "         [[ 0.0170]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0290,  0.0170], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 7, 7] = -0.02903788536787033\n",
            " somado na saída em [1, 1, 7, 7] = 0.016951555386185646\n",
            " saida: tensor([[[[-1.9049e-02,  8.6621e-05, -2.6619e-02, -3.2468e-03, -2.5130e-02,\n",
            "            4.2080e-03, -5.7817e-03, -2.0972e-02],\n",
            "          [-1.0379e-02, -1.1470e-02, -5.9780e-03, -1.1358e-02, -1.5875e-02,\n",
            "           -1.7843e-02, -1.8476e-02, -2.1049e-02],\n",
            "          [-8.5054e-03, -5.3431e-03, -2.0411e-02, -7.4941e-03, -1.3942e-02,\n",
            "           -1.9693e-02, -1.5355e-02, -1.5620e-02],\n",
            "          [-1.6430e-02, -9.0748e-03, -4.0569e-03, -1.7141e-02, -4.1887e-03,\n",
            "           -9.4560e-03, -1.2919e-02, -5.7223e-03],\n",
            "          [-4.0695e-03, -3.6924e-02, -1.5783e-02, -2.1570e-02, -2.5541e-02,\n",
            "           -1.0687e-02, -1.1695e-02, -9.4398e-03],\n",
            "          [-1.8603e-02, -1.3450e-02, -2.7792e-02, -1.1337e-02, -1.5479e-02,\n",
            "           -1.3712e-02, -1.6233e-03, -1.9394e-02],\n",
            "          [-2.0118e-02, -1.5931e-02, -1.4359e-02, -2.2148e-02, -1.4038e-02,\n",
            "           -2.2194e-02, -3.1279e-02, -1.3571e-02],\n",
            "          [-2.0181e-02, -5.8563e-03, -2.1246e-02, -2.7605e-02, -1.2678e-02,\n",
            "           -1.1690e-02, -1.4589e-02, -3.6406e-02]],\n",
            "\n",
            "         [[ 2.2336e-02,  1.2157e-02,  1.9616e-02,  5.8870e-03,  1.5128e-02,\n",
            "            2.3489e-02,  1.6414e-02,  1.0260e-02],\n",
            "          [ 2.2252e-02,  2.1001e-02,  1.2372e-02,  1.8465e-02,  9.7045e-03,\n",
            "            6.5557e-03,  1.5748e-02, -1.5908e-03],\n",
            "          [ 2.3619e-02,  2.8980e-02,  1.5208e-02,  2.1300e-02,  1.5066e-02,\n",
            "            1.1979e-02,  1.3414e-02,  1.9581e-02],\n",
            "          [ 1.6673e-02,  2.3430e-02,  1.5282e-02,  1.6227e-02,  1.7078e-02,\n",
            "            4.0219e-02,  2.9170e-02,  3.0710e-02],\n",
            "          [ 1.1602e-02,  1.8396e-02,  1.4990e-02,  5.1259e-03, -1.0230e-03,\n",
            "            8.3379e-03,  1.9514e-02, -3.2784e-03],\n",
            "          [ 2.4186e-02,  1.9861e-02,  2.8290e-02,  2.4111e-02,  1.1778e-02,\n",
            "            3.4999e-02,  2.1111e-02,  2.6166e-02],\n",
            "          [ 2.0618e-02,  3.0653e-02,  2.8256e-02,  2.0695e-02,  1.1712e-02,\n",
            "            1.7316e-02,  2.5398e-02,  1.3822e-02],\n",
            "          [ 1.2121e-02,  2.0398e-02,  1.9383e-02,  5.0977e-03,  2.3160e-02,\n",
            "            1.5813e-02,  1.8873e-02,  2.0569e-02]]],\n",
            "\n",
            "\n",
            "        [[[-8.3983e-03, -2.1211e-02, -1.0131e-02, -9.4778e-03, -2.6765e-03,\n",
            "            1.4763e-03, -1.5720e-02, -6.1436e-03],\n",
            "          [-1.0095e-02, -1.6976e-02, -1.3317e-02, -5.9206e-03, -2.2963e-02,\n",
            "           -1.3253e-02, -1.5243e-02, -2.4814e-02],\n",
            "          [-8.3959e-03, -1.1173e-02, -1.0510e-02, -2.1169e-02, -7.4577e-03,\n",
            "           -2.0910e-02, -1.6969e-02, -1.5906e-02],\n",
            "          [-1.3845e-02,  9.2134e-03, -1.8024e-02, -2.1523e-02, -1.9361e-02,\n",
            "           -2.0885e-02,  4.0429e-04, -7.9446e-03],\n",
            "          [-4.7468e-03, -2.3627e-02, -7.8607e-03, -2.1089e-02, -2.3425e-03,\n",
            "           -9.7171e-03, -9.3410e-03,  8.3996e-03],\n",
            "          [-1.5484e-02, -4.4202e-03, -1.3890e-02,  1.2961e-03, -5.5738e-03,\n",
            "            5.2278e-03, -1.0028e-02, -1.3016e-02],\n",
            "          [ 2.6296e-03, -8.6980e-03,  6.7784e-03, -1.5838e-02, -5.7871e-03,\n",
            "           -1.9048e-02, -1.8868e-02, -1.7011e-02],\n",
            "          [-2.0551e-02,  6.6993e-05, -2.6266e-02, -9.6960e-03, -1.6204e-02,\n",
            "           -1.0432e-02, -1.4256e-02, -2.9038e-02]],\n",
            "\n",
            "         [[ 1.3092e-02,  2.3980e-02,  2.3460e-02,  1.9668e-02,  2.4544e-02,\n",
            "            1.4690e-02,  7.2299e-03,  2.1041e-02],\n",
            "          [ 1.0432e-02,  1.4669e-02,  2.3621e-02,  1.7892e-02,  5.1846e-03,\n",
            "            1.2141e-02,  1.6130e-03,  9.6742e-03],\n",
            "          [ 2.1083e-02,  2.1446e-02,  1.6030e-02,  2.9283e-03,  5.6251e-03,\n",
            "            1.3093e-02,  3.6951e-03,  1.7206e-02],\n",
            "          [ 9.1444e-03,  1.5410e-02,  2.4164e-02,  4.5983e-03,  2.0964e-02,\n",
            "            1.6726e-02,  2.5003e-02,  2.1156e-02],\n",
            "          [ 4.6430e-03,  1.4832e-03,  8.6865e-03,  1.5629e-02,  2.3091e-02,\n",
            "            2.6299e-02,  2.2837e-02,  2.7253e-02],\n",
            "          [ 7.7452e-03,  8.8672e-03,  2.1363e-02,  2.1598e-02,  1.0243e-02,\n",
            "            1.4656e-02,  3.7150e-03,  3.5004e-03],\n",
            "          [ 2.5103e-02,  1.6890e-02,  2.1202e-02,  1.6045e-02,  1.7249e-02,\n",
            "            9.4344e-03,  1.6817e-03,  6.1414e-03],\n",
            "          [ 1.4132e-02,  9.0549e-03,  1.4715e-03, -6.8347e-03,  2.0742e-02,\n",
            "            1.0020e-02,  2.6823e-02,  1.6952e-02]]]], grad_fn=<CopySlices>)\n",
            "\n",
            "ndx_amostra: 0\n",
            "\n",
            "ndx_amostra: 1\n",
            " saida apos somar bias: tensor([[[[-0.0155,  0.0036, -0.0231,  0.0003, -0.0216,  0.0078, -0.0022,\n",
            "           -0.0174],\n",
            "          [-0.0068, -0.0079, -0.0024, -0.0078, -0.0123, -0.0143, -0.0149,\n",
            "           -0.0175],\n",
            "          [-0.0050, -0.0018, -0.0169, -0.0039, -0.0104, -0.0161, -0.0118,\n",
            "           -0.0121],\n",
            "          [-0.0129, -0.0055, -0.0005, -0.0136, -0.0006, -0.0059, -0.0094,\n",
            "           -0.0022],\n",
            "          [-0.0005, -0.0334, -0.0122, -0.0180, -0.0220, -0.0071, -0.0081,\n",
            "           -0.0059],\n",
            "          [-0.0151, -0.0099, -0.0242, -0.0078, -0.0119, -0.0102,  0.0019,\n",
            "           -0.0158],\n",
            "          [-0.0166, -0.0124, -0.0108, -0.0186, -0.0105, -0.0186, -0.0277,\n",
            "           -0.0100],\n",
            "          [-0.0166, -0.0023, -0.0177, -0.0241, -0.0091, -0.0081, -0.0110,\n",
            "           -0.0329]],\n",
            "\n",
            "         [[ 0.0245,  0.0143,  0.0218,  0.0081,  0.0173,  0.0257,  0.0186,\n",
            "            0.0124],\n",
            "          [ 0.0244,  0.0232,  0.0145,  0.0206,  0.0119,  0.0087,  0.0179,\n",
            "            0.0006],\n",
            "          [ 0.0258,  0.0312,  0.0174,  0.0235,  0.0172,  0.0142,  0.0156,\n",
            "            0.0218],\n",
            "          [ 0.0188,  0.0256,  0.0175,  0.0184,  0.0193,  0.0424,  0.0313,\n",
            "            0.0329],\n",
            "          [ 0.0138,  0.0206,  0.0172,  0.0073,  0.0012,  0.0105,  0.0217,\n",
            "           -0.0011],\n",
            "          [ 0.0264,  0.0220,  0.0305,  0.0263,  0.0140,  0.0372,  0.0233,\n",
            "            0.0283],\n",
            "          [ 0.0228,  0.0328,  0.0304,  0.0229,  0.0139,  0.0195,  0.0276,\n",
            "            0.0160],\n",
            "          [ 0.0143,  0.0226,  0.0216,  0.0073,  0.0253,  0.0180,  0.0210,\n",
            "            0.0227]]],\n",
            "\n",
            "\n",
            "        [[[-0.0048, -0.0177, -0.0066, -0.0059,  0.0009,  0.0050, -0.0122,\n",
            "           -0.0026],\n",
            "          [-0.0065, -0.0134, -0.0098, -0.0024, -0.0194, -0.0097, -0.0117,\n",
            "           -0.0213],\n",
            "          [-0.0048, -0.0076, -0.0070, -0.0176, -0.0039, -0.0174, -0.0134,\n",
            "           -0.0124],\n",
            "          [-0.0103,  0.0128, -0.0145, -0.0180, -0.0158, -0.0173,  0.0040,\n",
            "           -0.0044],\n",
            "          [-0.0012, -0.0201, -0.0043, -0.0175,  0.0012, -0.0062, -0.0058,\n",
            "            0.0119],\n",
            "          [-0.0119, -0.0009, -0.0103,  0.0048, -0.0020,  0.0088, -0.0065,\n",
            "           -0.0095],\n",
            "          [ 0.0062, -0.0051,  0.0103, -0.0123, -0.0022, -0.0155, -0.0153,\n",
            "           -0.0135],\n",
            "          [-0.0170,  0.0036, -0.0227, -0.0061, -0.0127, -0.0069, -0.0107,\n",
            "           -0.0255]],\n",
            "\n",
            "         [[ 0.0153,  0.0262,  0.0256,  0.0218,  0.0267,  0.0169,  0.0094,\n",
            "            0.0232],\n",
            "          [ 0.0126,  0.0168,  0.0258,  0.0201,  0.0074,  0.0143,  0.0038,\n",
            "            0.0118],\n",
            "          [ 0.0233,  0.0236,  0.0182,  0.0051,  0.0078,  0.0153,  0.0059,\n",
            "            0.0194],\n",
            "          [ 0.0113,  0.0176,  0.0263,  0.0068,  0.0231,  0.0189,  0.0272,\n",
            "            0.0233],\n",
            "          [ 0.0068,  0.0037,  0.0109,  0.0178,  0.0253,  0.0285,  0.0250,\n",
            "            0.0294],\n",
            "          [ 0.0099,  0.0110,  0.0235,  0.0238,  0.0124,  0.0168,  0.0059,\n",
            "            0.0057],\n",
            "          [ 0.0273,  0.0191,  0.0234,  0.0182,  0.0194,  0.0116,  0.0039,\n",
            "            0.0083],\n",
            "          [ 0.0163,  0.0112,  0.0036, -0.0047,  0.0229,  0.0122,  0.0290,\n",
            "            0.0191]]]], grad_fn=<CopySlices>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSTrD1WRnGng",
        "outputId": "73d374e4-b855-45f3-a0d6-059a21ae2219"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weight=initial_conv_weight.reshape(out_channels, in_channels, kernel_size, kernel_size )\n",
        "weight.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbhX25ybm413",
        "outputId": "18b235da-7884-4e8b-fed1-ce15cf60d04b"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 5, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Usa os mesmos pesos para minha implementação e a do pytorch\n",
        "\n",
        "pytorch_conv_layer = torch.nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=0)\n",
        "pytorch_conv_layer.load_state_dict(dict(weight=initial_conv_weight.reshape(out_channels, in_channels, kernel_size, kernel_size ), bias=initial_conv_bias))\n",
        "\n",
        "target_out = pytorch_conv_layer(x)"
      ],
      "metadata": {
        "id": "HzIjuGpWlbIM"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2Sesz6onCEw",
        "outputId": "ab399827-9e13-4335-c88a-6a747e00551a"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert torch.allclose(out, target_out, atol=1e-6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "noWWzeCumRIY",
        "outputId": "4860cc8a-07cf-4235-bfac-621740212c5c"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-189-fc5fddf18f13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQA9Zg7GQT2G"
      },
      "source": [
        "## Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:10.802708Z",
          "start_time": "2018-08-20T21:03:10.793287Z"
        },
        "id": "_8Eg4h_kQT2H"
      },
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, height_in: int, width_in: int, in_channels: int, out_channels: int, kernel_size: int, stride: int):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv_layer = MyConv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride)\n",
        "   \n",
        "        height_out = (height_in - kernel_size - 1) // stride + 1\n",
        "        width_out = (width_in - kernel_size - 1) // stride + 1\n",
        "        self.classification_layer = torch.nn.Linear(out_channels * height_out * width_out, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        hidden = self.conv_layer(x)\n",
        "        hidden = torch.nn.functional.relu(hidden)\n",
        "        hidden = hidden.reshape(x.shape[0], -1)\n",
        "        logits = self.classification_layer(hidden)\n",
        "        return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NHQB4wGQT2K"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqs2JhJoQT2L"
      },
      "source": [
        "### Definição dos hiperparâmetros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:14.146259Z",
          "start_time": "2018-08-20T21:03:14.139515Z"
        },
        "id": "oZuYEkn_QT2M"
      },
      "source": [
        "n_epochs = 50\n",
        "lr = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmXarXeIQT2O"
      },
      "source": [
        "### Laço de treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:40.796410Z",
          "start_time": "2018-08-20T21:03:39.771981Z"
        },
        "id": "L5T_jZZPQT2P"
      },
      "source": [
        "model = Net(height_in=height_in, width_in=width_in, in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride)\n",
        "\n",
        "# Usa pesos iniciais pré-difinidos\n",
        "model.classification_layer.load_state_dict(dict(weight=initial_classification_weight, bias=initial_classification_bias))\n",
        "model.conv_layer.weight.data = initial_conv_weight\n",
        "model.conv_layer.bias.data = initial_conv_bias\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr)\n",
        "\n",
        "epochs = []\n",
        "loss_history = []\n",
        "loss_epoch_end = []\n",
        "total_trained_samples = 0\n",
        "for i in range(n_epochs):\n",
        "    for x_train, y_train in loader_train:\n",
        "        # predict da rede\n",
        "        outputs = model(x_train)\n",
        "\n",
        "        # calcula a perda\n",
        "        loss = criterion(outputs, y_train)\n",
        "\n",
        "        # zero, backpropagation, ajusta parâmetros pelo gradiente descendente\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_trained_samples += x_train.size(0)\n",
        "        epochs.append(total_trained_samples / len(dataset_train))\n",
        "        loss_history.append(loss.item())\n",
        "\n",
        "    loss_epoch_end.append(loss.item())\n",
        "    print(f'Epoch: {i:d}/{n_epochs - 1:d} Loss: {loss.item()}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLL-GQlKQT2Y"
      },
      "source": [
        "### Visualização usual da perda, somente no final de cada minibatch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:55.246851Z",
          "start_time": "2018-08-20T21:03:54.994428Z"
        },
        "id": "w38EtNxhQT2Z"
      },
      "source": [
        "n_batches_train = len(loader_train)\n",
        "plt.plot(epochs[::n_batches_train], loss_history[::n_batches_train])\n",
        "plt.xlabel('época')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_epoch_end"
      ],
      "metadata": {
        "id": "ToktJu4CK94z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:48.786969Z",
          "start_time": "2018-08-20T21:03:48.781787Z"
        },
        "id": "PiuMsjYtQT2R"
      },
      "source": [
        "# Assert do histórico de losses\n",
        "target_loss_epoch_end = np.array([\n",
        "    2.303267478942871,\n",
        "    2.227701187133789,\n",
        "    1.0923893451690674,\n",
        "    0.5867354869842529,\n",
        "    0.5144089460372925,\n",
        "    0.45026642084121704,\n",
        "    0.4075140357017517,\n",
        "    0.37713879346847534,\n",
        "    0.3534485101699829,\n",
        "    0.3341451585292816,\n",
        "    0.3181140422821045,\n",
        "    0.30457887053489685,\n",
        "    0.29283496737480164,\n",
        "    0.2827608287334442,\n",
        "    0.2738332152366638,\n",
        "    0.2657742500305176,\n",
        "    0.2583288848400116,\n",
        "    0.25117507576942444,\n",
        "    0.24439716339111328,\n",
        "    0.23789969086647034,\n",
        "    0.23167723417282104,\n",
        "    0.22562651336193085,\n",
        "    0.21984536945819855,\n",
        "    0.2142913043498993,\n",
        "    0.20894232392311096,\n",
        "    0.203872948884964,\n",
        "    0.19903430342674255,\n",
        "    0.19439971446990967,\n",
        "    0.18994088470935822,\n",
        "    0.18563991785049438,\n",
        "    0.18147490918636322,\n",
        "    0.17744913697242737,\n",
        "    0.17347246408462524,\n",
        "    0.16947467625141144,\n",
        "    0.16547319293022156,\n",
        "    0.16150487959384918,\n",
        "    0.1574639081954956,\n",
        "    0.1534043848514557,\n",
        "    0.14926929771900177,\n",
        "    0.1452063024044037,\n",
        "    0.1412365883588791,\n",
        "    0.13712672889232635,\n",
        "    0.1331038922071457,\n",
        "    0.1291467249393463,\n",
        "    0.1251506358385086,\n",
        "    0.12116757035255432,\n",
        "    0.11731722950935364,\n",
        "    0.11364627629518509,\n",
        "    0.11001908034086227,\n",
        "    0.10655981302261353])\n",
        "\n",
        "assert np.allclose(np.array(loss_epoch_end), target_loss_epoch_end, atol=1e-6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rascunho"
      ],
      "metadata": {
        "id": "yy2fvfxRnWDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wj1Ka9vdnXpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "St9ooPvvGnw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_channels_dummy = 1\n",
        "out_channels_dummy = 2\n",
        "kernel_size_dummy = 2\n",
        "stride_dummy = 1\n",
        "num_amostras_dummy = 1\n",
        "x = torch.arange(30).float().reshape(num_amostras_dummy, 1, 5, 6)"
      ],
      "metadata": {
        "id": "eHg1E0xkGn-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d04f3530-f4c2-4453-db59-7c2eff507c0c",
        "id": "GLcaZY0nGn-F"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
            "          [ 6.,  7.,  8.,  9., 10., 11.],\n",
            "          [12., 13., 14., 15., 16., 17.],\n",
            "          [18., 19., 20., 21., 22., 23.],\n",
            "          [24., 25., 26., 27., 28., 29.]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# falta stride e tratar out_channels > 1"
      ],
      "metadata": {
        "id": "G4-z1oWfI5j8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp = torch.tensor([[[[34.]]]])"
      ],
      "metadata": {
        "id": "JZUW6dbGeULx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp.squeeze()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8ATxh3DkQlS",
        "outputId": "6dea88af-1ef6-410b-d2e1-772f55b58de1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(34.)"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp.squeeze().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijHjn6Fwk_6S",
        "outputId": "fc8bbe28-ae31-472d-d2bd-50cfaa6eae0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([])"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp.squeeze().reshape(1,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrEMRgHxk7UK",
        "outputId": "d9d8d83d-cb40-4844-8e21-c1170d9417b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([34.])"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp.view(1,-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dx_BICd-kVsC",
        "outputId": "7242672c-05da-4aeb-b8bd-e72aadfa04c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[34.]])"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp = torch.tensor([[[[ 46.]], [[134.]]]])"
      ],
      "metadata": {
        "id": "xK5LO9EikKLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp.squeeze()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zgWxyfKeYhZ",
        "outputId": "758c69e0-7669-4021-b5b7-3f364d0222e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 46., 134.])"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp.squeeze().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74ouMw6ClWhp",
        "outputId": "f7e23e94-af1e-4251-b57a-ffc992ddede0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp.squeeze().reshape(2,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVj0YgbZknZE",
        "outputId": "634e9b79-0ca4-4b6c-cb05-903b27262855"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 46., 134.])"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp.squeeze().shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NKOwsD_eYsI",
        "outputId": "8bade88a-be35-4a88-ba2c-cb85f05613e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "conv_layer = MyConv2d(in_channels=in_channels_dummy, out_channels=out_channels_dummy, kernel_size=kernel_size_dummy, stride=stride_dummy)\n",
        "\n",
        "# Usa os mesmos pesos para minha implementação e a do pytorch\n",
        "initial_weights_dummy = torch.arange(in_channels_dummy * out_channels_dummy * kernel_size_dummy * kernel_size_dummy).float()\n",
        "initial_weights_dummy = initial_weights_dummy.reshape(in_channels_dummy, out_channels_dummy, kernel_size_dummy, kernel_size_dummy)\n",
        "initial_bias_dummy = torch.arange(out_channels_dummy,).float()\n",
        "\n",
        "print(f\"initial_weights_dummy.shape: {initial_weights_dummy.shape}\")\n",
        "conv_layer.weight.data = initial_weights_dummy\n",
        "conv_layer.bias.data = initial_bias_dummy\n",
        "print(f\"conv_layer.weight.data: {conv_layer.weight.data}\")\n",
        "print(f\"conv_layer.bias.data: {conv_layer.bias.data}\")\n",
        "\n",
        "out = conv_layer(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69f9ef84-1d90-4f4f-8231-007afc649806",
        "id": "m5oMLsHsGn-G"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inicializado MyConv2d\n",
            "in_channels: 1 \n",
            "out_channels: 2 \n",
            "kernel_size: 2 \n",
            "stride: 1 \n",
            "weight.shape: torch.Size([1, 2, 2, 2]) \n",
            "weight: Parameter containing:\n",
            "tensor([[[[ 1.2432e-03, -4.2557e-05],\n",
            "          [ 2.7263e-03,  6.7489e-03]],\n",
            "\n",
            "         [[-5.8188e-03,  8.4502e-03],\n",
            "          [-7.0384e-03,  8.2780e-03]]]], requires_grad=True) \n",
            "bias.shape: torch.Size([2]) \n",
            "bias: Parameter containing:\n",
            "tensor([-0.0028, -0.0097], requires_grad=True) \n",
            "initial_weights_dummy.shape: torch.Size([1, 2, 2, 2])\n",
            "conv_layer.weight.data: tensor([[[[0., 1.],\n",
            "          [2., 3.]],\n",
            "\n",
            "         [[4., 5.],\n",
            "          [6., 7.]]]])\n",
            "conv_layer.bias.data: tensor([0., 1.])\n",
            " num_amostras: 1, self.out_channels: 2, num_linhas_entrada: 5, num_colunas_entrada: 6, num_linhas_saida: 4, num_colunas_saida: 5\n",
            "saida.shape: torch.Size([1, 2, 4, 5])\n",
            "\n",
            "ndx_amostra: 0\n",
            "\n",
            "ndx_in_channels: 0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 0\n",
            " alvo do kernel em x: x[0,0,0:2, 0:2]\n",
            " \n",
            " tensor([[0., 1.],\n",
            "        [6., 7.]])\n",
            " produto: tensor([[[[ 0.,  1.],\n",
            "          [12., 21.]],\n",
            "\n",
            "         [[ 0.,  5.],\n",
            "          [36., 49.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[34.]],\n",
            "\n",
            "         [[90.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([34., 90.], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 0] = 34.0\n",
            " somado na saída em [0, 1, 0, 0] = 90.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 1\n",
            " alvo do kernel em x: x[0,0,0:2, 1:3]\n",
            " \n",
            " tensor([[1., 2.],\n",
            "        [7., 8.]])\n",
            " produto: tensor([[[[ 0.,  2.],\n",
            "          [14., 24.]],\n",
            "\n",
            "         [[ 4., 10.],\n",
            "          [42., 56.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[ 40.]],\n",
            "\n",
            "         [[112.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([ 40., 112.], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 1] = 40.0\n",
            " somado na saída em [0, 1, 0, 1] = 112.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 2\n",
            " alvo do kernel em x: x[0,0,0:2, 2:4]\n",
            " \n",
            " tensor([[2., 3.],\n",
            "        [8., 9.]])\n",
            " produto: tensor([[[[ 0.,  3.],\n",
            "          [16., 27.]],\n",
            "\n",
            "         [[ 8., 15.],\n",
            "          [48., 63.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[ 46.]],\n",
            "\n",
            "         [[134.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([ 46., 134.], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 2] = 46.0\n",
            " somado na saída em [0, 1, 0, 2] = 134.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 3\n",
            " alvo do kernel em x: x[0,0,0:2, 3:5]\n",
            " \n",
            " tensor([[ 3.,  4.],\n",
            "        [ 9., 10.]])\n",
            " produto: tensor([[[[ 0.,  4.],\n",
            "          [18., 30.]],\n",
            "\n",
            "         [[12., 20.],\n",
            "          [54., 70.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[ 52.]],\n",
            "\n",
            "         [[156.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([ 52., 156.], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 3] = 52.0\n",
            " somado na saída em [0, 1, 0, 3] = 156.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 4\n",
            " alvo do kernel em x: x[0,0,0:2, 4:6]\n",
            " \n",
            " tensor([[ 4.,  5.],\n",
            "        [10., 11.]])\n",
            " produto: tensor([[[[ 0.,  5.],\n",
            "          [20., 33.]],\n",
            "\n",
            "         [[16., 25.],\n",
            "          [60., 77.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[ 58.]],\n",
            "\n",
            "         [[178.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([ 58., 178.], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 4] = 58.0\n",
            " somado na saída em [0, 1, 0, 4] = 178.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 0\n",
            " alvo do kernel em x: x[0,0,1:3, 0:2]\n",
            " \n",
            " tensor([[ 6.,  7.],\n",
            "        [12., 13.]])\n",
            " produto: tensor([[[[ 0.,  7.],\n",
            "          [24., 39.]],\n",
            "\n",
            "         [[24., 35.],\n",
            "          [72., 91.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[ 70.]],\n",
            "\n",
            "         [[222.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([ 70., 222.], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 0] = 70.0\n",
            " somado na saída em [0, 1, 1, 0] = 222.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 1\n",
            " alvo do kernel em x: x[0,0,1:3, 1:3]\n",
            " \n",
            " tensor([[ 7.,  8.],\n",
            "        [13., 14.]])\n",
            " produto: tensor([[[[ 0.,  8.],\n",
            "          [26., 42.]],\n",
            "\n",
            "         [[28., 40.],\n",
            "          [78., 98.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[ 76.]],\n",
            "\n",
            "         [[244.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([ 76., 244.], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 1] = 76.0\n",
            " somado na saída em [0, 1, 1, 1] = 244.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 2\n",
            " alvo do kernel em x: x[0,0,1:3, 2:4]\n",
            " \n",
            " tensor([[ 8.,  9.],\n",
            "        [14., 15.]])\n",
            " produto: tensor([[[[  0.,   9.],\n",
            "          [ 28.,  45.]],\n",
            "\n",
            "         [[ 32.,  45.],\n",
            "          [ 84., 105.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[ 82.]],\n",
            "\n",
            "         [[266.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([ 82., 266.], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 2] = 82.0\n",
            " somado na saída em [0, 1, 1, 2] = 266.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 3\n",
            " alvo do kernel em x: x[0,0,1:3, 3:5]\n",
            " \n",
            " tensor([[ 9., 10.],\n",
            "        [15., 16.]])\n",
            " produto: tensor([[[[  0.,  10.],\n",
            "          [ 30.,  48.]],\n",
            "\n",
            "         [[ 36.,  50.],\n",
            "          [ 90., 112.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[ 88.]],\n",
            "\n",
            "         [[288.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([ 88., 288.], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 3] = 88.0\n",
            " somado na saída em [0, 1, 1, 3] = 288.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 4\n",
            " alvo do kernel em x: x[0,0,1:3, 4:6]\n",
            " \n",
            " tensor([[10., 11.],\n",
            "        [16., 17.]])\n",
            " produto: tensor([[[[  0.,  11.],\n",
            "          [ 32.,  51.]],\n",
            "\n",
            "         [[ 40.,  55.],\n",
            "          [ 96., 119.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[ 94.]],\n",
            "\n",
            "         [[310.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([ 94., 310.], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 4] = 94.0\n",
            " somado na saída em [0, 1, 1, 4] = 310.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 0\n",
            " alvo do kernel em x: x[0,0,2:4, 0:2]\n",
            " \n",
            " tensor([[12., 13.],\n",
            "        [18., 19.]])\n",
            " produto: tensor([[[[  0.,  13.],\n",
            "          [ 36.,  57.]],\n",
            "\n",
            "         [[ 48.,  65.],\n",
            "          [108., 133.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[106.]],\n",
            "\n",
            "         [[354.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([106., 354.], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 0] = 106.0\n",
            " somado na saída em [0, 1, 2, 0] = 354.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 1\n",
            " alvo do kernel em x: x[0,0,2:4, 1:3]\n",
            " \n",
            " tensor([[13., 14.],\n",
            "        [19., 20.]])\n",
            " produto: tensor([[[[  0.,  14.],\n",
            "          [ 38.,  60.]],\n",
            "\n",
            "         [[ 52.,  70.],\n",
            "          [114., 140.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[112.]],\n",
            "\n",
            "         [[376.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([112., 376.], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 1] = 112.0\n",
            " somado na saída em [0, 1, 2, 1] = 376.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 2\n",
            " alvo do kernel em x: x[0,0,2:4, 2:4]\n",
            " \n",
            " tensor([[14., 15.],\n",
            "        [20., 21.]])\n",
            " produto: tensor([[[[  0.,  15.],\n",
            "          [ 40.,  63.]],\n",
            "\n",
            "         [[ 56.,  75.],\n",
            "          [120., 147.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[118.]],\n",
            "\n",
            "         [[398.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([118., 398.], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 2] = 118.0\n",
            " somado na saída em [0, 1, 2, 2] = 398.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 3\n",
            " alvo do kernel em x: x[0,0,2:4, 3:5]\n",
            " \n",
            " tensor([[15., 16.],\n",
            "        [21., 22.]])\n",
            " produto: tensor([[[[  0.,  16.],\n",
            "          [ 42.,  66.]],\n",
            "\n",
            "         [[ 60.,  80.],\n",
            "          [126., 154.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[124.]],\n",
            "\n",
            "         [[420.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([124., 420.], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 3] = 124.0\n",
            " somado na saída em [0, 1, 2, 3] = 420.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 4\n",
            " alvo do kernel em x: x[0,0,2:4, 4:6]\n",
            " \n",
            " tensor([[16., 17.],\n",
            "        [22., 23.]])\n",
            " produto: tensor([[[[  0.,  17.],\n",
            "          [ 44.,  69.]],\n",
            "\n",
            "         [[ 64.,  85.],\n",
            "          [132., 161.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[130.]],\n",
            "\n",
            "         [[442.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([130., 442.], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 4] = 130.0\n",
            " somado na saída em [0, 1, 2, 4] = 442.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 0\n",
            " alvo do kernel em x: x[0,0,3:5, 0:2]\n",
            " \n",
            " tensor([[18., 19.],\n",
            "        [24., 25.]])\n",
            " produto: tensor([[[[  0.,  19.],\n",
            "          [ 48.,  75.]],\n",
            "\n",
            "         [[ 72.,  95.],\n",
            "          [144., 175.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[142.]],\n",
            "\n",
            "         [[486.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([142., 486.], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 0] = 142.0\n",
            " somado na saída em [0, 1, 3, 0] = 486.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 1\n",
            " alvo do kernel em x: x[0,0,3:5, 1:3]\n",
            " \n",
            " tensor([[19., 20.],\n",
            "        [25., 26.]])\n",
            " produto: tensor([[[[  0.,  20.],\n",
            "          [ 50.,  78.]],\n",
            "\n",
            "         [[ 76., 100.],\n",
            "          [150., 182.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[148.]],\n",
            "\n",
            "         [[508.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([148., 508.], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 1] = 148.0\n",
            " somado na saída em [0, 1, 3, 1] = 508.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 2\n",
            " alvo do kernel em x: x[0,0,3:5, 2:4]\n",
            " \n",
            " tensor([[20., 21.],\n",
            "        [26., 27.]])\n",
            " produto: tensor([[[[  0.,  21.],\n",
            "          [ 52.,  81.]],\n",
            "\n",
            "         [[ 80., 105.],\n",
            "          [156., 189.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[154.]],\n",
            "\n",
            "         [[530.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([154., 530.], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 2] = 154.0\n",
            " somado na saída em [0, 1, 3, 2] = 530.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 3\n",
            " alvo do kernel em x: x[0,0,3:5, 3:5]\n",
            " \n",
            " tensor([[21., 22.],\n",
            "        [27., 28.]])\n",
            " produto: tensor([[[[  0.,  22.],\n",
            "          [ 54.,  84.]],\n",
            "\n",
            "         [[ 84., 110.],\n",
            "          [162., 196.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[160.]],\n",
            "\n",
            "         [[552.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([160., 552.], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 3] = 160.0\n",
            " somado na saída em [0, 1, 3, 3] = 552.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 4\n",
            " alvo do kernel em x: x[0,0,3:5, 4:6]\n",
            " \n",
            " tensor([[22., 23.],\n",
            "        [28., 29.]])\n",
            " produto: tensor([[[[  0.,  23.],\n",
            "          [ 56.,  87.]],\n",
            "\n",
            "         [[ 88., 115.],\n",
            "          [168., 203.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[166.]],\n",
            "\n",
            "         [[574.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([166., 574.], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 4] = 166.0\n",
            " somado na saída em [0, 1, 3, 4] = 574.0\n",
            " saida: tensor([[[[ 34.,  40.,  46.,  52.,  58.],\n",
            "          [ 70.,  76.,  82.,  88.,  94.],\n",
            "          [106., 112., 118., 124., 130.],\n",
            "          [142., 148., 154., 160., 166.]],\n",
            "\n",
            "         [[ 90., 112., 134., 156., 178.],\n",
            "          [222., 244., 266., 288., 310.],\n",
            "          [354., 376., 398., 420., 442.],\n",
            "          [486., 508., 530., 552., 574.]]]], grad_fn=<CopySlices>)\n",
            "\n",
            "ndx_amostra: 0\n",
            " saida apos somar bias: tensor([[[[ 34.,  40.,  46.,  52.,  58.],\n",
            "          [ 70.,  76.,  82.,  88.,  94.],\n",
            "          [106., 112., 118., 124., 130.],\n",
            "          [142., 148., 154., 160., 166.]],\n",
            "\n",
            "         [[ 91., 113., 135., 157., 179.],\n",
            "          [223., 245., 267., 289., 311.],\n",
            "          [355., 377., 399., 421., 443.],\n",
            "          [487., 509., 531., 553., 575.]]]], grad_fn=<CopySlices>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ED6gJjl7GonF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2Vcc7RvMGo2s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}