{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "toc": {
      "nav_menu": {
        "height": "318px",
        "width": "252px"
      },
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "Aula 5 - Exercício - Marcus Borela",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unicamp-dl/IA025_2022S1/blob/main/ex05/Marcus_Vinicius_Borela_de_Castro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nome = 'Marcus Vinícius Borela de CAstro'\n",
        "\n",
        "print(f'Meu nome é {nome}')"
      ],
      "metadata": {
        "id": "CdORg7oe68oq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee5984eb-72b5-4141-efac-aa43d114163c"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meu nome é Marcus Vinícius Borela de CAstro\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkfGTqMVQT1u"
      },
      "source": [
        "Este exercicío consiste em treinar no MNIST um modelo de duas camadas, sendo a primeira uma camada convolucional e a segunda uma camada linear de classificação.\n",
        "\n",
        "Não podemos usar as funções torch.nn.Conv{1,2,3}d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFNf4RPxQT1w"
      },
      "source": [
        "## Importação das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-21T14:08:14.033692Z",
          "start_time": "2018-08-21T14:08:11.179981Z"
        },
        "id": "-fLUSHaCQT1x"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fixando as seeds"
      ],
      "metadata": {
        "id": "achvQ78sa3p3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkETIyWGkbOf"
      },
      "source": [
        "def inicializa_seed(num_semente:int=123):\n",
        "  \"\"\"\n",
        "  É recomendado reiniciar as seeds antes de inicializar o modelo, pois assim\n",
        "  garantimos que os pesos vao ser sempre os mesmos.\n",
        "  fontes de apoio: \n",
        "      http://nlp.seas.harvard.edu/2018/04/03/attention.html\n",
        "      https://github.com/CyberZHG/torch-multi-head-attention/blob/master/torch_multi_head_attention/multi_head_attention.py#L15\n",
        "  \"\"\"\n",
        "  random.seed(num_semente)\n",
        "  np.random.seed(num_semente)\n",
        "  torch.manual_seed(num_semente)\n",
        "  #torch.cuda.manual_seed(num_semente)\n",
        "  #Cuda algorithms\n",
        "  #torch.backends.cudnn.deterministic = True "
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViMcw_kVkbOf"
      },
      "source": [
        "inicializa_seed(123)"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define pesos iniciais"
      ],
      "metadata": {
        "id": "fzurMVpHxcNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_channels = 1\n",
        "out_channels = 2\n",
        "kernel_size = 5\n",
        "stride = 3\n",
        "\n",
        "# Input image size\n",
        "height_in = 28  \n",
        "width_in = 28\n",
        "\n",
        "# Image size after the first convolutional layer.\n",
        "height_out = (height_in - kernel_size - 1) // stride + 1\n",
        "width_out = (width_in - kernel_size - 1) // stride + 1\n",
        "\n",
        "\n",
        "initial_conv_weight = torch.FloatTensor(out_channels, in_channels, kernel_size, kernel_size).uniform_(-0.01, 0.01)\n",
        "initial_conv_bias = torch.FloatTensor(out_channels,).uniform_(-0.01, 0.01)\n",
        "\n",
        "initial_classification_weight = torch.FloatTensor(10, out_channels * height_out * width_out).uniform_(-0.01, 0.01)\n",
        "initial_classification_bias = torch.FloatTensor(10,).uniform_(-0.01, 0.01)"
      ],
      "metadata": {
        "id": "9a6jQJLLlfF3"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\" height_out {height_out}, width_out {width_out}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Y2-ILXqbE1d",
        "outputId": "ba0260dd-cdd4-4b9a-fae7-dee7af23f62b"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " height_out 8, width_out 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEMUsfJpQT11"
      },
      "source": [
        "## Dataset e dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHoQjDs_QT12"
      },
      "source": [
        "### Definição do tamanho do minibatch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-21T14:08:20.282474Z",
          "start_time": "2018-08-21T14:08:20.275450Z"
        },
        "id": "tEQYUr4TQT13"
      },
      "source": [
        "batch_size = 50"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc7Rv_2BQT16"
      },
      "source": [
        "### Carregamento, criação dataset e do dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-21T14:10:45.430605Z",
          "start_time": "2018-08-21T14:10:04.953051Z"
        },
        "id": "G0dEKCn-QT17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdf3167e-0dcd-4dc4-bf9e-7c9d295037e2"
      },
      "source": [
        "dataset_dir = '../data/'\n",
        "\n",
        "dataset_train_full = MNIST(dataset_dir, train=True, download=True,\n",
        "                           transform=torchvision.transforms.ToTensor())\n",
        "print(dataset_train_full.data.shape)\n",
        "print(dataset_train_full.targets.shape)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60000, 28, 28])\n",
            "torch.Size([60000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rOy9ntrQT2D"
      },
      "source": [
        "### Usando apenas 1000 amostras do MNIST\n",
        "\n",
        "Neste exercício utilizaremos 1000 amostras de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNF2XjLBWWe7"
      },
      "source": [
        "indices = torch.randperm(len(dataset_train_full))[:1000]\n",
        "dataset_train = torch.utils.data.Subset(dataset_train_full, indices)"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define os pesos iniciais"
      ],
      "metadata": {
        "id": "wYqj_oeSliYj"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSNLD2JyA2e-"
      },
      "source": [
        "loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-21T13:30:35.209157Z",
          "start_time": "2018-08-21T13:30:34.757103Z"
        },
        "id": "w52KGYlIQT2A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d52d6505-4cb1-4f49-cbc1-8621702e2f18"
      },
      "source": [
        "print('Número de minibatches de trenamento:', len(loader_train))\n"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de minibatches de trenamento: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = next(iter(loader_train))\n",
        "print(\"\\nDimensões dos dados de um minibatch:\", x_train.size())\n",
        "print(\"Valores mínimo e máximo dos pixels: \", torch.min(x_train), torch.max(x_train))\n",
        "print(\"Tipo dos dados das imagens:         \", type(x_train))\n",
        "print(\"Tipo das classes das imagens:       \", type(y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7vPdWoIbwht",
        "outputId": "09e90707-4a2d-4d45-8c12-0f89ddf7f3f9"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dimensões dos dados de um minibatch: torch.Size([50, 1, 28, 28])\n",
            "Valores mínimo e máximo dos pixels:  tensor(0.) tensor(1.)\n",
            "Tipo dos dados das imagens:          <class 'torch.Tensor'>\n",
            "Tipo das classes das imagens:        <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYw9dR89b3Is",
        "outputId": "c2f37e68-7a31-4669-dba6-736e148374c9"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([50, 1, 28, 28]), torch.Size([50]))"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0, 0, 0, ] # 1a linha da 1a amostra"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6g_7GhLcJak",
        "outputId": "d5982f9e-1385-4122-ec7c-ca28c08b3193"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0, 0,] # 28 linhas da 1a amostra"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7J64G0oDcYed",
        "outputId": "0ab55021-6a8a-482c-e082-b0460dc4e968"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2980, 0.9922, 0.9922, 0.6235,\n",
              "         0.3373, 0.0431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0667, 0.0196, 0.0353, 0.3608, 0.4824, 0.8745,\n",
              "         0.9882, 0.7569, 0.1490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.3255, 0.8196, 0.4196, 0.0000, 0.0000, 0.0000, 0.0980,\n",
              "         0.6784, 0.9922, 0.9412, 0.3216, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0667, 0.8196, 0.6902, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.4588, 0.9882, 0.9412, 0.1451, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.2902, 0.9176, 0.9882, 0.4235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0118, 0.4588, 0.9882, 0.7529, 0.0431, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4980,\n",
              "         1.0000, 0.9765, 0.4510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.1686, 0.9686, 0.9922, 0.3373, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9569,\n",
              "         0.9765, 0.4588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.4353, 0.9882, 0.5373, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3255, 0.9412, 0.9882,\n",
              "         0.4510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0745, 0.8588, 0.8667, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1490, 0.9412, 0.9882, 0.6157,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.8118, 0.9882, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5922, 0.9882, 0.9882, 0.1255,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.8118, 0.9882, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.3412, 0.9922, 0.9922, 0.1804, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.2745, 0.9922, 0.9529, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.5412, 0.9882, 0.8157, 0.0667, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.3569, 0.9882, 0.5373, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.5412, 0.9882, 0.5922, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.1333, 0.9176, 0.9882, 0.4157, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.5412, 0.9882, 0.2706, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0353, 0.4784, 0.9882, 0.8549, 0.0549, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.9529, 0.8235, 0.0235, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.5020, 0.9882, 0.9882, 0.2196, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.8275, 0.0275, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0353,\n",
              "         0.5020, 1.0000, 0.9765, 0.4510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.7059, 0.9882, 0.6039, 0.0353, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2588, 0.7608,\n",
              "         0.9882, 0.8941, 0.4588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.3961, 0.8902, 0.9882, 0.6039, 0.2745,\n",
              "         0.2510, 0.1255, 0.2000, 0.2745, 0.2745, 0.5176, 0.7216, 0.9176, 0.9882,\n",
              "         0.7412, 0.1255, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1961, 0.6275, 0.9255, 0.9882,\n",
              "         0.9765, 0.8941, 0.9412, 0.9882, 0.9882, 0.9922, 0.9216, 0.6275, 0.2588,\n",
              "         0.0157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0745, 0.0863,\n",
              "         0.5373, 0.5373, 0.6588, 0.8235, 0.5373, 0.2941, 0.0706, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape[1] # canais"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yo8ov5QdUNk",
        "outputId": "4a94e0c5-0a7e-460a-aa95-2846be97c621"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Camada Convolucional"
      ],
      "metadata": {
        "id": "dfU_v7aPfq40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.zeros((4,1,4,5),  dtype=torch.float, requires_grad=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWnT39vv2UFk",
        "outputId": "9226f373-f05d-4263-e8ff-a2631c6ae2cd"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "        [[[0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "        [[[0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "        [[[0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.]]]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saida = torch.empty((4,1,4,5),  dtype=torch.float, requires_grad=True)"
      ],
      "metadata": {
        "id": "uR3td8Fn7KZZ"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saida.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BwNMw6q7Q6I",
        "outputId": "ecebd162-4a16-4520-8f90-fe1205c85482"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 1, 4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saida[0,0,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8PB0cWe92X-",
        "outputId": "2688f919-cc58-48ef-9cb1-1791df6e8c9f"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0943e-35, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.cat((saida[0,0,0], torch.tensor([[12]])), dim=-1)"
      ],
      "metadata": {
        "id": "-FebDt7c__d1"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saida"
      ],
      "metadata": {
        "id": "1Qi-eoW97Sp_"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyConv2d(torch.nn.Module):\n",
        "  def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int, verbose:bool = False):\n",
        "    super(MyConv2d, self).__init__()\n",
        "\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.kernel_size = kernel_size  # The same for height and width.\n",
        "    self.stride = stride  # The same for height and width.\n",
        "    self.weight = torch.nn.Parameter(torch.FloatTensor(out_channels, in_channels, kernel_size, kernel_size).uniform_(-0.01, 0.01))\n",
        "    self.bias = torch.nn.Parameter(torch.FloatTensor(out_channels,).uniform_(-0.01, 0.01))\n",
        "    self.verbose = verbose\n",
        "    if self.verbose:\n",
        "      print(f\"Inicializado MyConv2d\")\n",
        "      print(f\"in_channels: {self.in_channels} \")\n",
        "      print(f\"out_channels: {self.out_channels} \")\n",
        "      print(f\"kernel_size: {self.kernel_size} \")\n",
        "      print(f\"stride: {self.stride} \")\n",
        "      print(f\"weight.shape: {self.weight.shape} \")\n",
        "      print(f\"weight: {self.weight} \")\n",
        "      print(f\"bias.shape: {self.bias.shape} \")\n",
        "      print(f\"bias: {self.bias} \")\n",
        "\n",
        "  def forward(self, x):\n",
        "    assert x.dim() == 4, f'x must have 4 dimensions, not {x.shape}'\n",
        "    assert x.shape[1] == 1, f'x must have only 1 channel, not {x.shape[1]}' # Num_canais sempre 1 (mnist, preto/branco)\n",
        "\n",
        "    # print(f\"kernel.shape: {self.weight.shape}, kernel: {self.weight}\")\n",
        "    # Escreva seu código aqui.\n",
        "    # versão com for nas dimensões de X\n",
        "    num_amostras = x.shape[0]\n",
        "    num_linhas_entrada = x.shape[2]\n",
        "    num_colunas_entrada = x.shape[3]\n",
        "    num_linhas_saida = (num_linhas_entrada - self.kernel_size) // self.stride + 1\n",
        "    num_colunas_saida = (num_colunas_entrada - self.kernel_size) // self.stride + 1\n",
        "    saida = torch.zeros((num_amostras,self.out_channels,num_linhas_saida,num_colunas_saida), dtype=torch.float, requires_grad=False)        \n",
        "    if self.verbose:\n",
        "      print(f\" num_amostras: {num_amostras}, self.out_channels: {self.out_channels}, num_linhas_entrada: {num_linhas_entrada}, num_colunas_entrada: {num_colunas_entrada}, num_linhas_saida: {num_linhas_saida}, num_colunas_saida: {num_colunas_saida}\")\n",
        "      print(f\"saida.shape: {saida.shape}\")\n",
        "    for ndx_amostra in range(num_amostras):\n",
        "      if self.verbose:\n",
        "        print(f\"\\nndx_amostra: {ndx_amostra}\")\n",
        "      # for ndx_out_channels in range(self.out_channels):\n",
        "      #   print(f\"\\nndx_out_channels: {ndx_out_channels}\")\n",
        "      for ndx_in_channels in range(self.in_channels):\n",
        "        if self.verbose:\n",
        "          print(f\"\\nndx_in_channels: {ndx_in_channels}\")\n",
        "        ndx_linhas_entrada = 0\n",
        "        for ndx_linhas_saida in range(num_linhas_saida):\n",
        "          ndx_colunas_entrada = 0\n",
        "          for ndx_colunas_saida in range(num_colunas_saida):\n",
        "            produto = torch.mul(x[ndx_amostra, ndx_in_channels, ndx_linhas_entrada:ndx_linhas_entrada+self.kernel_size, ndx_colunas_entrada:ndx_colunas_entrada+self.kernel_size], self.weight)\n",
        "            soma = torch.sum(produto, dim=(2,3), keepdim=True )\n",
        "            valor_soma = soma.squeeze()\n",
        "            if self.verbose:\n",
        "              print(f\"\\nndx_linhas_saida, ndx_colunas_saida: {ndx_linhas_saida}, {ndx_colunas_saida}\")\n",
        "              print(f\" alvo do kernel em x: x[{ndx_amostra},{ndx_in_channels},{ndx_linhas_entrada}:{ndx_linhas_entrada+self.kernel_size}, {ndx_colunas_entrada}:{ndx_colunas_entrada+self.kernel_size}]\")\n",
        "              print(f\" \\n {x[ndx_amostra, ndx_in_channels, ndx_linhas_entrada:ndx_linhas_entrada+self.kernel_size, ndx_colunas_entrada:ndx_colunas_entrada+self.kernel_size]}\")\n",
        "              print(f\" produto: {produto}\")\n",
        "              print(f\" soma: {soma}\")\n",
        "              print(f\" valor_soma: {valor_soma}\")\n",
        "            # saida = torch.cat((saida, soma))\n",
        "            if self.out_channels > 1:  # soma é um com dimensões, como em torch.tensor([[[[ 46.]], [[134.]]]])\n",
        "              for ndx_out_channels in range(self.out_channels):\n",
        "                saida[ndx_amostra, ndx_out_channels, ndx_linhas_saida, ndx_colunas_saida] += valor_soma[ndx_out_channels]\n",
        "                if self.verbose:\n",
        "                  print(f\" somado na saída em [{ndx_amostra}, {ndx_out_channels}, {ndx_linhas_saida}, {ndx_colunas_saida}] = {saida[ndx_amostra, ndx_out_channels, ndx_linhas_saida, ndx_colunas_saida]}\")\n",
        "            else: # soma é um tensor escalar, como em tensor(34.)\n",
        "                saida[ndx_amostra, 0, ndx_linhas_saida, ndx_colunas_saida] += valor_soma\n",
        "                if self.verbose:\n",
        "                  print(f\" somado na saída em [{ndx_amostra}, 0, {ndx_linhas_saida}, {ndx_colunas_saida}] = {saida[ndx_amostra, 0, ndx_linhas_saida, ndx_colunas_saida]}\")\n",
        "            ndx_colunas_entrada += self.stride\n",
        "          ndx_linhas_entrada += self.stride\n",
        "    if self.verbose:\n",
        "      print(f\" saida: {saida}\")\n",
        "    # somando bias\n",
        "    for ndx_amostra in range(num_amostras):\n",
        "      if self.verbose:\n",
        "        print(f\"\\nndx_amostra: {ndx_amostra}\")\n",
        "      for ndx_out_channels in range(self.out_channels):\n",
        "        saida[ndx_amostra, ndx_out_channels] += self.bias[ndx_out_channels]\n",
        "    if self.verbose:\n",
        "      print(f\" saida apos somar bias: {saida}\")\n",
        "    # versão com for no kernel\n",
        "\n",
        "    return saida"
      ],
      "metadata": {
        "id": "wRtpLJSFfsf8"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare se sua implementação está igual à do pytorch usando um exemplo simples"
      ],
      "metadata": {
        "id": "ROizI33sqE79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_channels_dummy = 1\n",
        "out_channels_dummy = 1\n",
        "kernel_size_dummy = 2\n",
        "stride_dummy = 1\n",
        "x = torch.arange(30).float().reshape(1, 1, 5, 6)"
      ],
      "metadata": {
        "id": "i1TuxWbkqMJc"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-FSsEC9icLX",
        "outputId": "0dcc8d1f-c715-4f1a-b720-7dbea44ae890"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
            "          [ 6.,  7.,  8.,  9., 10., 11.],\n",
            "          [12., 13., 14., 15., 16., 17.],\n",
            "          [18., 19., 20., 21., 22., 23.],\n",
            "          [24., 25., 26., 27., 28., 29.]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "conv_layer = MyConv2d( in_channels=in_channels_dummy,out_channels=out_channels_dummy, kernel_size=kernel_size_dummy, stride=stride_dummy, verbose=True)\n",
        "\n",
        "# Usa os mesmos pesos para minha implementação e a do pytorch\n",
        "initial_weights_dummy = torch.arange(in_channels_dummy * out_channels_dummy * kernel_size_dummy * kernel_size_dummy).float()\n",
        "initial_weights_dummy = initial_weights_dummy.reshape(in_channels_dummy, out_channels_dummy, kernel_size_dummy, kernel_size_dummy)\n",
        "initial_bias_dummy = torch.arange(out_channels_dummy,).float()\n",
        "\n",
        "conv_layer.weight.data = initial_weights_dummy\n",
        "conv_layer.bias.data = initial_bias_dummy\n",
        "\n",
        "out = conv_layer(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASbzrpDHiaxm",
        "outputId": "fadc573f-dbce-4528-a4e9-f6037d2b0130"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inicializado MyConv2d\n",
            "in_channels: 1 \n",
            "out_channels: 1 \n",
            "kernel_size: 2 \n",
            "stride: 1 \n",
            "weight.shape: torch.Size([1, 1, 2, 2]) \n",
            "weight: Parameter containing:\n",
            "tensor([[[[-0.0086, -0.0075],\n",
            "          [ 0.0077,  0.0033]]]], requires_grad=True) \n",
            "bias.shape: torch.Size([1]) \n",
            "bias: Parameter containing:\n",
            "tensor([0.0023], requires_grad=True) \n",
            " num_amostras: 1, self.out_channels: 1, num_linhas_entrada: 5, num_colunas_entrada: 6, num_linhas_saida: 4, num_colunas_saida: 5\n",
            "saida.shape: torch.Size([1, 1, 4, 5])\n",
            "\n",
            "ndx_amostra: 0\n",
            "\n",
            "ndx_in_channels: 0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 0\n",
            " alvo do kernel em x: x[0,0,0:2, 0:2]\n",
            " \n",
            " tensor([[0., 1.],\n",
            "        [6., 7.]])\n",
            " produto: tensor([[[[ 0.,  1.],\n",
            "          [12., 21.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[34.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 34.0\n",
            " somado na saída em [0, 0, 0, 0] = 34.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 1\n",
            " alvo do kernel em x: x[0,0,0:2, 1:3]\n",
            " \n",
            " tensor([[1., 2.],\n",
            "        [7., 8.]])\n",
            " produto: tensor([[[[ 0.,  2.],\n",
            "          [14., 24.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[40.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 40.0\n",
            " somado na saída em [0, 0, 0, 1] = 40.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 2\n",
            " alvo do kernel em x: x[0,0,0:2, 2:4]\n",
            " \n",
            " tensor([[2., 3.],\n",
            "        [8., 9.]])\n",
            " produto: tensor([[[[ 0.,  3.],\n",
            "          [16., 27.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[46.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 46.0\n",
            " somado na saída em [0, 0, 0, 2] = 46.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 3\n",
            " alvo do kernel em x: x[0,0,0:2, 3:5]\n",
            " \n",
            " tensor([[ 3.,  4.],\n",
            "        [ 9., 10.]])\n",
            " produto: tensor([[[[ 0.,  4.],\n",
            "          [18., 30.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[52.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 52.0\n",
            " somado na saída em [0, 0, 0, 3] = 52.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 4\n",
            " alvo do kernel em x: x[0,0,0:2, 4:6]\n",
            " \n",
            " tensor([[ 4.,  5.],\n",
            "        [10., 11.]])\n",
            " produto: tensor([[[[ 0.,  5.],\n",
            "          [20., 33.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[58.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 58.0\n",
            " somado na saída em [0, 0, 0, 4] = 58.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 0\n",
            " alvo do kernel em x: x[0,0,1:3, 0:2]\n",
            " \n",
            " tensor([[ 6.,  7.],\n",
            "        [12., 13.]])\n",
            " produto: tensor([[[[ 0.,  7.],\n",
            "          [24., 39.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[70.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 70.0\n",
            " somado na saída em [0, 0, 1, 0] = 70.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 1\n",
            " alvo do kernel em x: x[0,0,1:3, 1:3]\n",
            " \n",
            " tensor([[ 7.,  8.],\n",
            "        [13., 14.]])\n",
            " produto: tensor([[[[ 0.,  8.],\n",
            "          [26., 42.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[76.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 76.0\n",
            " somado na saída em [0, 0, 1, 1] = 76.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 2\n",
            " alvo do kernel em x: x[0,0,1:3, 2:4]\n",
            " \n",
            " tensor([[ 8.,  9.],\n",
            "        [14., 15.]])\n",
            " produto: tensor([[[[ 0.,  9.],\n",
            "          [28., 45.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[82.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 82.0\n",
            " somado na saída em [0, 0, 1, 2] = 82.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 3\n",
            " alvo do kernel em x: x[0,0,1:3, 3:5]\n",
            " \n",
            " tensor([[ 9., 10.],\n",
            "        [15., 16.]])\n",
            " produto: tensor([[[[ 0., 10.],\n",
            "          [30., 48.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[88.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 88.0\n",
            " somado na saída em [0, 0, 1, 3] = 88.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 4\n",
            " alvo do kernel em x: x[0,0,1:3, 4:6]\n",
            " \n",
            " tensor([[10., 11.],\n",
            "        [16., 17.]])\n",
            " produto: tensor([[[[ 0., 11.],\n",
            "          [32., 51.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[94.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 94.0\n",
            " somado na saída em [0, 0, 1, 4] = 94.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 0\n",
            " alvo do kernel em x: x[0,0,2:4, 0:2]\n",
            " \n",
            " tensor([[12., 13.],\n",
            "        [18., 19.]])\n",
            " produto: tensor([[[[ 0., 13.],\n",
            "          [36., 57.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[106.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 106.0\n",
            " somado na saída em [0, 0, 2, 0] = 106.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 1\n",
            " alvo do kernel em x: x[0,0,2:4, 1:3]\n",
            " \n",
            " tensor([[13., 14.],\n",
            "        [19., 20.]])\n",
            " produto: tensor([[[[ 0., 14.],\n",
            "          [38., 60.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[112.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 112.0\n",
            " somado na saída em [0, 0, 2, 1] = 112.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 2\n",
            " alvo do kernel em x: x[0,0,2:4, 2:4]\n",
            " \n",
            " tensor([[14., 15.],\n",
            "        [20., 21.]])\n",
            " produto: tensor([[[[ 0., 15.],\n",
            "          [40., 63.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[118.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 118.0\n",
            " somado na saída em [0, 0, 2, 2] = 118.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 3\n",
            " alvo do kernel em x: x[0,0,2:4, 3:5]\n",
            " \n",
            " tensor([[15., 16.],\n",
            "        [21., 22.]])\n",
            " produto: tensor([[[[ 0., 16.],\n",
            "          [42., 66.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[124.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 124.0\n",
            " somado na saída em [0, 0, 2, 3] = 124.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 4\n",
            " alvo do kernel em x: x[0,0,2:4, 4:6]\n",
            " \n",
            " tensor([[16., 17.],\n",
            "        [22., 23.]])\n",
            " produto: tensor([[[[ 0., 17.],\n",
            "          [44., 69.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[130.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 130.0\n",
            " somado na saída em [0, 0, 2, 4] = 130.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 0\n",
            " alvo do kernel em x: x[0,0,3:5, 0:2]\n",
            " \n",
            " tensor([[18., 19.],\n",
            "        [24., 25.]])\n",
            " produto: tensor([[[[ 0., 19.],\n",
            "          [48., 75.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[142.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 142.0\n",
            " somado na saída em [0, 0, 3, 0] = 142.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 1\n",
            " alvo do kernel em x: x[0,0,3:5, 1:3]\n",
            " \n",
            " tensor([[19., 20.],\n",
            "        [25., 26.]])\n",
            " produto: tensor([[[[ 0., 20.],\n",
            "          [50., 78.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[148.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 148.0\n",
            " somado na saída em [0, 0, 3, 1] = 148.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 2\n",
            " alvo do kernel em x: x[0,0,3:5, 2:4]\n",
            " \n",
            " tensor([[20., 21.],\n",
            "        [26., 27.]])\n",
            " produto: tensor([[[[ 0., 21.],\n",
            "          [52., 81.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[154.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 154.0\n",
            " somado na saída em [0, 0, 3, 2] = 154.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 3\n",
            " alvo do kernel em x: x[0,0,3:5, 3:5]\n",
            " \n",
            " tensor([[21., 22.],\n",
            "        [27., 28.]])\n",
            " produto: tensor([[[[ 0., 22.],\n",
            "          [54., 84.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[160.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 160.0\n",
            " somado na saída em [0, 0, 3, 3] = 160.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 4\n",
            " alvo do kernel em x: x[0,0,3:5, 4:6]\n",
            " \n",
            " tensor([[22., 23.],\n",
            "        [28., 29.]])\n",
            " produto: tensor([[[[ 0., 23.],\n",
            "          [56., 87.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[166.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 166.0\n",
            " somado na saída em [0, 0, 3, 4] = 166.0\n",
            " saida: tensor([[[[ 34.,  40.,  46.,  52.,  58.],\n",
            "          [ 70.,  76.,  82.,  88.,  94.],\n",
            "          [106., 112., 118., 124., 130.],\n",
            "          [142., 148., 154., 160., 166.]]]], grad_fn=<CopySlices>)\n",
            "\n",
            "ndx_amostra: 0\n",
            " saida apos somar bias: tensor([[[[ 34.,  40.,  46.,  52.,  58.],\n",
            "          [ 70.,  76.,  82.,  88.,  94.],\n",
            "          [106., 112., 118., 124., 130.],\n",
            "          [142., 148., 154., 160., 166.]]]], grad_fn=<CopySlices>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pytorch_conv_layer = torch.nn.Conv2d(out_channels=out_channels_dummy, in_channels=in_channels_dummy, kernel_size=kernel_size_dummy, stride=stride_dummy, padding=0)\n",
        "pytorch_conv_layer.load_state_dict(dict(weight=initial_weights_dummy, bias=initial_bias_dummy))\n",
        "target_out = pytorch_conv_layer(x)"
      ],
      "metadata": {
        "id": "xN--jid1fn-p"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blRMn_9hgIGZ",
        "outputId": "36bdb69d-5f57-4c5a-d4ee-a6545d8a8158"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert torch.allclose(out, target_out, atol=1e-6)"
      ],
      "metadata": {
        "id": "FUgUwtXPgGaD"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare se sua implementação está igual à do pytorch usando um exemplo aleatório"
      ],
      "metadata": {
        "id": "_75UnRhdd_MW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2, in_channels, height_in, width_in)\n",
        "print(f\"x.shape: {x.shape}, x:{x}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7X_A2jeDs4f",
        "outputId": "d3c82578-41cf-406b-9bbe-44cb01ea5738"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.shape: torch.Size([2, 1, 28, 28]), x:tensor([[[[0.5455, 0.3101, 0.0920,  ..., 0.9578, 0.6826, 0.8853],\n",
            "          [0.5961, 0.6101, 0.5993,  ..., 0.4560, 0.5637, 0.3034],\n",
            "          [0.4390, 0.1588, 0.3511,  ..., 0.1117, 0.4930, 0.1629],\n",
            "          ...,\n",
            "          [0.6152, 0.2852, 0.8054,  ..., 0.3297, 0.2332, 0.6874],\n",
            "          [0.5257, 0.5642, 0.3265,  ..., 0.8634, 0.6886, 0.6107],\n",
            "          [0.4996, 0.8803, 0.2029,  ..., 0.8815, 0.3183, 0.3953]]],\n",
            "\n",
            "\n",
            "        [[[0.6082, 0.3287, 0.8834,  ..., 0.1798, 0.4401, 0.8556],\n",
            "          [0.8919, 0.6539, 0.3631,  ..., 0.9050, 0.6740, 0.4383],\n",
            "          [0.4295, 0.3832, 0.0433,  ..., 0.3678, 0.3228, 0.4308],\n",
            "          ...,\n",
            "          [0.9189, 0.8832, 0.5742,  ..., 0.8215, 0.8630, 0.0347],\n",
            "          [0.5718, 0.9940, 0.8956,  ..., 0.3014, 0.6284, 0.8481],\n",
            "          [0.1658, 0.4905, 0.1542,  ..., 0.2615, 0.4488, 0.7076]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_layer = MyConv2d(out_channels=out_channels, in_channels=in_channels, kernel_size=kernel_size, stride=stride, verbose=True)\n",
        "conv_layer.weight.data = initial_conv_weight\n",
        "conv_layer.bias.data = initial_conv_bias\n",
        "print(f\"conv_layer.weight.data.shape: {conv_layer.weight.data.shape}, conv_layer.bias.data.shape: {conv_layer.bias.data.shape}\")\n",
        "print(f\"conv_layer.weight.data: {conv_layer.weight.data}, conv_layer.bias.data: {conv_layer.bias.data}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPL18MC-Ed9x",
        "outputId": "03c76ed9-2fe5-4a14-ae21-93bd0ad3dc89"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inicializado MyConv2d\n",
            "in_channels: 1 \n",
            "out_channels: 2 \n",
            "kernel_size: 5 \n",
            "stride: 3 \n",
            "weight.shape: torch.Size([2, 1, 5, 5]) \n",
            "weight: Parameter containing:\n",
            "tensor([[[[ 0.0008,  0.0056, -0.0072, -0.0082,  0.0032],\n",
            "          [ 0.0022,  0.0017, -0.0063,  0.0087, -0.0062],\n",
            "          [ 0.0099,  0.0029, -0.0072,  0.0052,  0.0080],\n",
            "          [-0.0063,  0.0090,  0.0075,  0.0028, -0.0072],\n",
            "          [-0.0068, -0.0099, -0.0066,  0.0015,  0.0053]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0058, -0.0063, -0.0015,  0.0055,  0.0050],\n",
            "          [ 0.0091,  0.0066,  0.0017,  0.0025, -0.0018],\n",
            "          [-0.0048, -0.0093, -0.0090, -0.0052, -0.0045],\n",
            "          [-0.0096, -0.0060,  0.0076,  0.0046, -0.0072],\n",
            "          [ 0.0017,  0.0064, -0.0099, -0.0048,  0.0045]]]], requires_grad=True) \n",
            "bias.shape: torch.Size([2]) \n",
            "bias: Parameter containing:\n",
            "tensor([-0.0091, -0.0073], requires_grad=True) \n",
            "conv_layer.weight.data.shape: torch.Size([2, 1, 5, 5]), conv_layer.bias.data.shape: torch.Size([2])\n",
            "conv_layer.weight.data: tensor([[[[-0.0041,  0.0003, -0.0050,  0.0038, -0.0085],\n",
            "          [ 0.0073, -0.0073, -0.0080, -0.0063,  0.0045],\n",
            "          [-0.0037,  0.0037, -0.0085, -0.0061, -0.0037],\n",
            "          [-0.0020, -0.0076,  0.0065, -0.0024,  0.0032],\n",
            "          [ 0.0071,  0.0019,  0.0027,  0.0097, -0.0045]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0032, -0.0044,  0.0071,  0.0080, -0.0092],\n",
            "          [ 0.0085,  0.0048,  0.0044,  0.0041,  0.0083],\n",
            "          [-0.0013, -0.0085, -0.0029, -0.0070,  0.0007],\n",
            "          [-0.0019, -0.0054, -0.0009,  0.0095, -0.0008],\n",
            "          [ 0.0003, -0.0016,  0.0016,  0.0089,  0.0061]]]]), conv_layer.bias.data: tensor([0.0035, 0.0022])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = conv_layer(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fs0iR9kb0Vy",
        "outputId": "38803e56-9a60-44d6-95b0-f8a736be386e"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " num_amostras: 2, self.out_channels: 2, num_linhas_entrada: 28, num_colunas_entrada: 28, num_linhas_saida: 8, num_colunas_saida: 8\n",
            "saida.shape: torch.Size([2, 2, 8, 8])\n",
            "\n",
            "ndx_amostra: 0\n",
            "\n",
            "ndx_in_channels: 0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 0\n",
            " alvo do kernel em x: x[0,0,0:5, 0:5]\n",
            " \n",
            " tensor([[0.5455, 0.3101, 0.0920, 0.7078, 0.7724],\n",
            "        [0.5961, 0.6101, 0.5993, 0.1743, 0.6640],\n",
            "        [0.4390, 0.1588, 0.3511, 0.6755, 0.4505],\n",
            "        [0.9398, 0.6030, 0.0968, 0.8615, 0.7700],\n",
            "        [0.6040, 0.6931, 0.0116, 0.7928, 0.1653]])\n",
            " produto: tensor([[[[-2.2242e-03,  1.0272e-04, -4.5687e-04,  2.6693e-03, -6.5817e-03],\n",
            "          [ 4.3699e-03, -4.4341e-03, -4.7650e-03, -1.1013e-03,  3.0073e-03],\n",
            "          [-1.6220e-03,  5.9416e-04, -2.9797e-03, -4.0984e-03, -1.6540e-03],\n",
            "          [-1.8468e-03, -4.6004e-03,  6.3367e-04, -2.0317e-03,  2.4717e-03],\n",
            "          [ 4.2710e-03,  1.2913e-03,  3.1844e-05,  7.6530e-03, -7.4545e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7277e-03, -1.3796e-03,  6.5740e-04,  5.6531e-03, -7.1218e-03],\n",
            "          [ 5.0888e-03,  2.9131e-03,  2.6117e-03,  7.1747e-04,  5.5200e-03],\n",
            "          [-5.7964e-04, -1.3428e-03, -1.0074e-03, -4.7574e-03,  2.9779e-04],\n",
            "          [-1.7546e-03, -3.2346e-03, -8.7989e-05,  8.1620e-03, -6.0738e-04],\n",
            "          [ 1.9176e-04, -1.0810e-03,  1.8307e-05,  7.0644e-03,  1.0107e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0120]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0187]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0120,  0.0187], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 0] = -0.012045865878462791\n",
            " somado na saída em [0, 1, 0, 0] = 0.018680047243833542\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 1\n",
            " alvo do kernel em x: x[0,0,0:5, 3:8]\n",
            " \n",
            " tensor([[0.7078, 0.7724, 0.6800, 0.2293, 0.1038],\n",
            "        [0.1743, 0.6640, 0.3247, 0.4648, 0.5734],\n",
            "        [0.6755, 0.4505, 0.9113, 0.4179, 0.5228],\n",
            "        [0.8615, 0.7700, 0.7859, 0.9540, 0.6195],\n",
            "        [0.7928, 0.1653, 0.0580, 0.2209, 0.2548]])\n",
            " produto: tensor([[[[-2.8863e-03,  2.5587e-04, -3.3773e-03,  8.6463e-04, -8.8440e-04],\n",
            "          [ 1.2776e-03, -4.8264e-03, -2.5817e-03, -2.9368e-03,  2.5970e-03],\n",
            "          [-2.4959e-03,  1.6857e-03, -7.7344e-03, -2.5353e-03, -1.9194e-03],\n",
            "          [-1.6930e-03, -5.8744e-03,  5.1458e-03, -2.2499e-03,  1.9886e-03],\n",
            "          [ 5.6066e-03,  3.0794e-04,  1.5854e-04,  2.1321e-03, -1.1491e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.2420e-03, -3.4367e-03,  4.8596e-03,  1.8311e-03, -9.5697e-04],\n",
            "          [ 1.4877e-03,  3.1708e-03,  1.4151e-03,  1.9133e-03,  4.7668e-03],\n",
            "          [-8.9193e-04, -3.8096e-03, -2.6149e-03, -2.9429e-03,  3.4558e-04],\n",
            "          [-1.6085e-03, -4.1304e-03, -7.1452e-04,  9.0386e-03, -4.8865e-04],\n",
            "          [ 2.5173e-04, -2.5778e-04,  9.1143e-05,  1.9681e-03,  1.5580e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0211]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0131]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0211,  0.0131], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 1] = -0.021124225109815598\n",
            " somado na saída em [0, 1, 0, 1] = 0.013086742721498013\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 2\n",
            " alvo do kernel em x: x[0,0,0:5, 6:11]\n",
            " \n",
            " tensor([[0.2293, 0.1038, 0.5722, 0.9984, 0.0346],\n",
            "        [0.4648, 0.5734, 0.8699, 0.6128, 0.2485],\n",
            "        [0.4179, 0.5228, 0.4451, 0.3358, 0.9162],\n",
            "        [0.9540, 0.6195, 0.7813, 0.4424, 0.9186],\n",
            "        [0.2209, 0.2548, 0.0019, 0.0367, 0.7613]])\n",
            " produto: tensor([[[[-9.3493e-04,  3.4382e-05, -2.8417e-03,  3.7651e-03, -2.9474e-04],\n",
            "          [ 3.4069e-03, -4.1678e-03, -6.9164e-03, -3.8720e-03,  1.1255e-03],\n",
            "          [-1.5440e-03,  1.9562e-03, -3.7778e-03, -2.0376e-03, -3.3640e-03],\n",
            "          [-1.8749e-03, -4.7261e-03,  5.1159e-03, -1.0432e-03,  2.9486e-03],\n",
            "          [ 1.5619e-03,  4.7469e-04,  5.3092e-06,  3.5403e-04, -3.4334e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 7.2623e-04, -4.6181e-04,  4.0890e-03,  7.9739e-03, -3.1893e-04],\n",
            "          [ 3.9674e-03,  2.7382e-03,  3.7909e-03,  2.5226e-03,  2.0659e-03],\n",
            "          [-5.5175e-04, -4.4210e-03, -1.2773e-03, -2.3652e-03,  6.0565e-04],\n",
            "          [-1.7813e-03, -3.3230e-03, -7.1037e-04,  4.1910e-03, -7.2454e-04],\n",
            "          [ 7.0130e-05, -3.9737e-04,  3.0523e-06,  3.2680e-04,  4.6551e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0201]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0214]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0201,  0.0214], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 2] = -0.02008002996444702\n",
            " somado na saída em [0, 1, 0, 2] = 0.021393485367298126\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 3\n",
            " alvo do kernel em x: x[0,0,0:5, 9:14]\n",
            " \n",
            " tensor([[0.9984, 0.0346, 0.0323, 0.3022, 0.6538],\n",
            "        [0.6128, 0.2485, 0.8844, 0.0092, 0.5815],\n",
            "        [0.3358, 0.9162, 0.3278, 0.3903, 0.5634],\n",
            "        [0.4424, 0.9186, 0.5622, 0.4979, 0.6363],\n",
            "        [0.0367, 0.7613, 0.1013, 0.6424, 0.2690]])\n",
            " produto: tensor([[[[-4.0713e-03,  1.1458e-05, -1.6049e-04,  1.1397e-03, -5.5706e-03],\n",
            "          [ 4.4919e-03, -1.8063e-03, -7.0311e-03, -5.8186e-05,  2.6335e-03],\n",
            "          [-1.2409e-03,  3.4285e-03, -2.7823e-03, -2.3683e-03, -2.0688e-03],\n",
            "          [-8.6933e-04, -7.0076e-03,  3.6810e-03, -1.1741e-03,  2.0425e-03],\n",
            "          [ 2.5936e-04,  1.4183e-03,  2.7699e-04,  6.2009e-03, -1.2133e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 3.1625e-03, -1.5390e-04,  2.3094e-04,  2.4136e-03, -6.0277e-03],\n",
            "          [ 5.2309e-03,  1.1867e-03,  3.8538e-03,  3.7908e-05,  4.8338e-03],\n",
            "          [-4.4343e-04, -7.7481e-03, -9.4068e-04, -2.7491e-03,  3.7247e-04],\n",
            "          [-8.2593e-04, -4.9272e-03, -5.1112e-04,  4.7169e-03, -5.0190e-04],\n",
            "          [ 1.1645e-05, -1.1873e-03,  1.5924e-04,  5.7239e-03,  1.6450e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0118]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0076]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0118,  0.0076], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 3] = -0.0118386996909976\n",
            " somado na saída em [0, 1, 0, 3] = 0.007563034538179636\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 4\n",
            " alvo do kernel em x: x[0,0,0:5, 12:17]\n",
            " \n",
            " tensor([[0.3022, 0.6538, 0.5510, 0.3370, 0.8271],\n",
            "        [0.0092, 0.5815, 0.8102, 0.1896, 0.8256],\n",
            "        [0.3903, 0.5634, 0.6967, 0.1121, 0.3111],\n",
            "        [0.4979, 0.6363, 0.8374, 0.2091, 0.9225],\n",
            "        [0.6424, 0.2690, 0.7972, 0.4132, 0.6962]])\n",
            " produto: tensor([[[[-1.2323e-03,  2.1656e-04, -2.7368e-03,  1.2708e-03, -7.0474e-03],\n",
            "          [ 6.7501e-05, -4.2264e-03, -6.4416e-03, -1.1984e-03,  3.7389e-03],\n",
            "          [-1.4423e-03,  2.1085e-03, -5.9134e-03, -6.8012e-04, -1.1422e-03],\n",
            "          [-9.7842e-04, -4.8542e-03,  5.4835e-03, -4.9302e-04,  2.9612e-03],\n",
            "          [ 4.5428e-03,  5.0118e-04,  2.1800e-03,  3.9882e-03, -3.1399e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 9.5725e-04, -2.9088e-03,  3.9380e-03,  2.6914e-03, -7.6257e-03],\n",
            "          [ 7.8606e-05,  2.7766e-03,  3.5307e-03,  7.8073e-04,  6.8629e-03],\n",
            "          [-5.1540e-04, -4.7650e-03, -1.9993e-03, -7.8948e-04,  2.0564e-04],\n",
            "          [-9.2956e-04, -3.4131e-03, -7.6142e-04,  1.9806e-03, -7.2764e-04],\n",
            "          [ 2.0397e-04, -4.1955e-04,  1.2533e-03,  3.6814e-03,  4.2572e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0145]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0083]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0145,  0.0083], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 4] = -0.014467312954366207\n",
            " somado na saída em [0, 1, 0, 4] = 0.00834331102669239\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 5\n",
            " alvo do kernel em x: x[0,0,0:5, 15:20]\n",
            " \n",
            " tensor([[0.3370, 0.8271, 0.1451, 0.1687, 0.4031],\n",
            "        [0.1896, 0.8256, 0.4694, 0.7276, 0.6241],\n",
            "        [0.1121, 0.3111, 0.4573, 0.1769, 0.7831],\n",
            "        [0.2091, 0.9225, 0.1481, 0.9139, 0.3589],\n",
            "        [0.4132, 0.6962, 0.4461, 0.6978, 0.4535]])\n",
            " produto: tensor([[[[-0.0014,  0.0003, -0.0007,  0.0006, -0.0034],\n",
            "          [ 0.0014, -0.0060, -0.0037, -0.0046,  0.0028],\n",
            "          [-0.0004,  0.0012, -0.0039, -0.0011, -0.0029],\n",
            "          [-0.0004, -0.0070,  0.0010, -0.0022,  0.0012],\n",
            "          [ 0.0029,  0.0013,  0.0012,  0.0067, -0.0020]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0011, -0.0037,  0.0010,  0.0013, -0.0037],\n",
            "          [ 0.0016,  0.0039,  0.0020,  0.0030,  0.0052],\n",
            "          [-0.0001, -0.0026, -0.0013, -0.0012,  0.0005],\n",
            "          [-0.0004, -0.0049, -0.0001,  0.0087, -0.0003],\n",
            "          [ 0.0001, -0.0011,  0.0007,  0.0062,  0.0028]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0192]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0187]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0192,  0.0187], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 5] = -0.019165657460689545\n",
            " somado na saída em [0, 1, 0, 5] = 0.0186670683324337\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 6\n",
            " alvo do kernel em x: x[0,0,0:5, 18:23]\n",
            " \n",
            " tensor([[0.1687, 0.4031, 0.5845, 0.3002, 0.6779],\n",
            "        [0.7276, 0.6241, 0.0124, 0.7092, 0.5333],\n",
            "        [0.1769, 0.7831, 0.6486, 0.8572, 0.9553],\n",
            "        [0.9139, 0.3589, 0.0167, 0.9989, 0.9601],\n",
            "        [0.6978, 0.4535, 0.9315, 0.0675, 0.9634]])\n",
            " produto: tensor([[[[-6.8803e-04,  1.3352e-04, -2.9030e-03,  1.1320e-03, -5.7764e-03],\n",
            "          [ 5.3339e-03, -4.5365e-03, -9.8427e-05, -4.4816e-03,  2.4154e-03],\n",
            "          [-6.5357e-04,  2.9303e-03, -5.5049e-03, -5.2005e-03, -3.5075e-03],\n",
            "          [-1.7960e-03, -2.7382e-03,  1.0946e-04, -2.3557e-03,  3.0818e-03],\n",
            "          [ 4.9346e-03,  8.4490e-04,  2.5471e-03,  6.5188e-04, -4.3448e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 5.3445e-04, -1.7934e-03,  4.1772e-03,  2.3974e-03, -6.2504e-03],\n",
            "          [ 6.2114e-03,  2.9804e-03,  5.3948e-05,  2.9198e-03,  4.4335e-03],\n",
            "          [-2.3356e-04, -6.6224e-03, -1.8612e-03, -6.0367e-03,  6.3150e-04],\n",
            "          [-1.7063e-03, -1.9253e-03, -1.5200e-05,  9.4637e-03, -7.5729e-04],\n",
            "          [ 2.2156e-04, -7.0728e-04,  1.4644e-03,  6.0173e-04,  5.8909e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0205]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0141]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0205,  0.0141], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 6] = -0.020470375195145607\n",
            " somado na saída em [0, 1, 0, 6] = 0.014072632417082787\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 7\n",
            " alvo do kernel em x: x[0,0,0:5, 21:26]\n",
            " \n",
            " tensor([[0.3002, 0.6779, 0.3812, 0.4087, 0.9578],\n",
            "        [0.7092, 0.5333, 0.2807, 0.7335, 0.4560],\n",
            "        [0.8572, 0.9553, 0.5666, 0.6065, 0.1117],\n",
            "        [0.9989, 0.9601, 0.0829, 0.9035, 0.7787],\n",
            "        [0.0675, 0.9634, 0.2142, 0.2889, 0.2413]])\n",
            " produto: tensor([[[[-1.2240e-03,  2.2456e-04, -1.8934e-03,  1.5413e-03, -8.1612e-03],\n",
            "          [ 5.1991e-03, -3.8764e-03, -2.2320e-03, -4.6348e-03,  2.0653e-03],\n",
            "          [-3.1671e-03,  3.5748e-03, -4.8090e-03, -3.6799e-03, -4.1010e-04],\n",
            "          [-1.9630e-03, -7.3243e-03,  5.4300e-04, -2.1307e-03,  2.4997e-03],\n",
            "          [ 4.7756e-04,  1.7948e-03,  5.8576e-04,  2.7887e-03, -1.0884e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 9.5081e-04, -3.0163e-03,  2.7244e-03,  3.2643e-03, -8.8308e-03],\n",
            "          [ 6.0544e-03,  2.5467e-03,  1.2234e-03,  3.0196e-03,  3.7908e-03],\n",
            "          [-1.1318e-03, -8.0787e-03, -1.6259e-03, -4.2716e-03,  7.3834e-05],\n",
            "          [-1.8650e-03, -5.1499e-03, -7.5398e-05,  8.5596e-03, -6.1424e-04],\n",
            "          [ 2.1442e-05, -1.5025e-03,  3.3676e-04,  2.5742e-03,  1.4757e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0253]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0005]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0253,  0.0005], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 7] = -0.02529982477426529\n",
            " somado na saída em [0, 1, 0, 7] = 0.00045382697135210037\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 0\n",
            " alvo do kernel em x: x[0,0,3:8, 0:5]\n",
            " \n",
            " tensor([[0.9398, 0.6030, 0.0968, 0.8615, 0.7700],\n",
            "        [0.6040, 0.6931, 0.0116, 0.7928, 0.1653],\n",
            "        [0.2163, 0.9158, 0.6072, 0.0173, 0.1760],\n",
            "        [0.9546, 0.3150, 0.8017, 0.1512, 0.6010],\n",
            "        [0.3693, 0.8652, 0.0853, 0.2019, 0.3025]])\n",
            " produto: tensor([[[[-3.8321e-03,  1.9976e-04, -4.8064e-04,  3.2489e-03, -6.5612e-03],\n",
            "          [ 4.4274e-03, -5.0377e-03, -9.2584e-05, -5.0099e-03,  7.4856e-04],\n",
            "          [-7.9939e-04,  3.4272e-03, -5.1531e-03, -1.0502e-04, -6.4634e-04],\n",
            "          [-1.8760e-03, -2.4027e-03,  5.2494e-03, -3.5650e-04,  1.9291e-03],\n",
            "          [ 2.6118e-03,  1.6118e-03,  2.3336e-04,  1.9492e-03, -1.3641e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.9767e-03, -2.6831e-03,  6.9160e-04,  6.8805e-03, -7.0996e-03],\n",
            "          [ 5.1558e-03,  3.3096e-03,  5.0746e-05,  3.2639e-03,  1.3740e-03],\n",
            "          [-2.8567e-04, -7.7451e-03, -1.7422e-03, -1.2191e-04,  1.1637e-04],\n",
            "          [-1.7824e-03, -1.6894e-03, -7.2891e-04,  1.4322e-03, -4.7404e-04],\n",
            "          [ 1.1727e-04, -1.3493e-03,  1.3416e-04,  1.7992e-03,  1.8495e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0081]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0034]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0081,  0.0034], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 0] = -0.008080895058810711\n",
            " somado na saída em [0, 1, 1, 0] = 0.0034499955363571644\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 1\n",
            " alvo do kernel em x: x[0,0,3:8, 3:8]\n",
            " \n",
            " tensor([[0.8615, 0.7700, 0.7859, 0.9540, 0.6195],\n",
            "        [0.7928, 0.1653, 0.0580, 0.2209, 0.2548],\n",
            "        [0.0173, 0.1760, 0.2969, 0.0473, 0.2650],\n",
            "        [0.1512, 0.6010, 0.9224, 0.9866, 0.6201],\n",
            "        [0.2019, 0.3025, 0.2486, 0.9031, 0.8282]])\n",
            " produto: tensor([[[[-3.5130e-03,  2.5507e-04, -3.9031e-03,  3.5978e-03, -5.2786e-03],\n",
            "          [ 5.8119e-03, -1.2014e-03, -4.6094e-04, -1.3957e-03,  1.1539e-03],\n",
            "          [-6.3958e-05,  6.5873e-04, -2.5196e-03, -2.8714e-04, -9.7319e-04],\n",
            "          [-2.9707e-04, -4.5848e-03,  6.0397e-03, -2.3268e-03,  1.9904e-03],\n",
            "          [ 1.4280e-03,  5.6348e-04,  6.7984e-04,  8.7170e-03, -3.7355e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.7288e-03, -3.4261e-03,  5.6162e-03,  7.6195e-03, -5.7118e-03],\n",
            "          [ 6.7681e-03,  7.8926e-04,  2.5264e-04,  9.0931e-04,  2.1181e-03],\n",
            "          [-2.2856e-05, -1.4887e-03, -8.5184e-04, -3.3331e-04,  1.7521e-04],\n",
            "          [-2.8224e-04, -3.2236e-03, -8.3864e-04,  9.3475e-03, -4.8909e-04],\n",
            "          [ 6.4114e-05, -4.7170e-04,  3.9084e-04,  8.0465e-03,  5.0647e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[0.0004]]],\n",
            "\n",
            "\n",
            "        [[[0.0328]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([0.0004, 0.0328], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 1] = 0.00035509467124938965\n",
            " somado na saída em [0, 1, 1, 1] = 0.03275085240602493\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 2\n",
            " alvo do kernel em x: x[0,0,3:8, 6:11]\n",
            " \n",
            " tensor([[0.9540, 0.6195, 0.7813, 0.4424, 0.9186],\n",
            "        [0.2209, 0.2548, 0.0019, 0.0367, 0.7613],\n",
            "        [0.0473, 0.2650, 0.9732, 0.9548, 0.3147],\n",
            "        [0.9866, 0.6201, 0.3382, 0.2053, 0.6846],\n",
            "        [0.9031, 0.8282, 0.8094, 0.5871, 0.3559]])\n",
            " produto: tensor([[[[-3.8904e-03,  2.0521e-04, -3.8804e-03,  1.6682e-03, -7.8269e-03],\n",
            "          [ 1.6192e-03, -1.8519e-03, -1.5436e-05, -2.3176e-04,  3.4477e-03],\n",
            "          [-1.7487e-04,  9.9184e-04, -8.2595e-03, -5.7928e-03, -1.1555e-03],\n",
            "          [-1.9389e-03, -4.7304e-03,  2.2143e-03, -4.8427e-04,  2.1974e-03],\n",
            "          [ 6.3860e-03,  1.5431e-03,  2.2133e-03,  5.6668e-03, -1.6052e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 3.0219e-03, -2.7563e-03,  5.5835e-03,  3.5330e-03, -8.4692e-03],\n",
            "          [ 1.8855e-03,  1.2167e-03,  8.4607e-06,  1.5099e-04,  6.3284e-03],\n",
            "          [-6.2489e-05, -2.2415e-03, -2.7925e-03, -6.7242e-03,  2.0803e-04],\n",
            "          [-1.8421e-03, -3.3260e-03, -3.0747e-04,  1.9454e-03, -5.3997e-04],\n",
            "          [ 2.8673e-04, -1.2917e-03,  1.2725e-03,  5.2309e-03,  2.1764e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0137]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0025]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0137,  0.0025], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 2] = -0.01368502527475357\n",
            " somado na saída em [0, 1, 1, 2] = 0.002495052758604288\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 3\n",
            " alvo do kernel em x: x[0,0,3:8, 9:14]\n",
            " \n",
            " tensor([[0.4424, 0.9186, 0.5622, 0.4979, 0.6363],\n",
            "        [0.0367, 0.7613, 0.1013, 0.6424, 0.2690],\n",
            "        [0.9548, 0.3147, 0.6628, 0.1707, 0.3211],\n",
            "        [0.2053, 0.6846, 0.0996, 0.7510, 0.6047],\n",
            "        [0.5871, 0.3559, 0.7117, 0.3087, 0.7022]])\n",
            " produto: tensor([[[[-1.8039e-03,  3.0428e-04, -2.7920e-03,  1.8775e-03, -5.4217e-03],\n",
            "          [ 2.6886e-04, -5.5332e-03, -8.0532e-04, -4.0593e-03,  1.2183e-03],\n",
            "          [-3.5278e-03,  1.1776e-03, -5.6250e-03, -1.0359e-03, -1.1788e-03],\n",
            "          [-4.0354e-04, -5.2224e-03,  6.5213e-04, -1.7710e-03,  1.9411e-03],\n",
            "          [ 4.1514e-03,  6.6310e-04,  1.9463e-03,  2.9799e-03, -3.1672e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4012e-03, -4.0870e-03,  4.0175e-03,  3.9763e-03, -5.8666e-03],\n",
            "          [ 3.1309e-04,  3.6352e-03,  4.4140e-04,  2.6446e-03,  2.2363e-03],\n",
            "          [-1.2607e-03, -2.6613e-03, -1.9018e-03, -1.2025e-03,  2.1224e-04],\n",
            "          [-3.8339e-04, -3.6720e-03, -9.0552e-05,  7.1145e-03, -4.7698e-04],\n",
            "          [ 1.8640e-04, -5.5510e-04,  1.1189e-03,  2.7506e-03,  4.2942e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0252]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0122]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0252,  0.0122], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 3] = -0.02516663260757923\n",
            " somado na saída em [0, 1, 1, 3] = 0.012184630148112774\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 4\n",
            " alvo do kernel em x: x[0,0,3:8, 12:17]\n",
            " \n",
            " tensor([[0.4979, 0.6363, 0.8374, 0.2091, 0.9225],\n",
            "        [0.6424, 0.2690, 0.7972, 0.4132, 0.6962],\n",
            "        [0.1707, 0.3211, 0.7584, 0.0487, 0.1954],\n",
            "        [0.7510, 0.6047, 0.8701, 0.2930, 0.3102],\n",
            "        [0.3087, 0.7022, 0.1311, 0.7808, 0.7739]])\n",
            " produto: tensor([[[[-2.0302e-03,  2.1078e-04, -4.1592e-03,  7.8839e-04, -7.8603e-03],\n",
            "          [ 4.7091e-03, -1.9553e-03, -6.3383e-03, -2.6108e-03,  3.1530e-03],\n",
            "          [-6.3086e-04,  1.2014e-03, -6.4372e-03, -2.9531e-04, -7.1739e-04],\n",
            "          [-1.4758e-03, -4.6132e-03,  5.6972e-03, -6.9106e-04,  9.9570e-04],\n",
            "          [ 2.1830e-03,  1.3083e-03,  3.5839e-04,  7.5367e-03, -3.4905e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5770e-03, -2.8311e-03,  5.9848e-03,  1.6697e-03, -8.5053e-03],\n",
            "          [ 5.4839e-03,  1.2846e-03,  3.4740e-03,  1.7009e-03,  5.7874e-03],\n",
            "          [-2.2544e-04, -2.7151e-03, -2.1764e-03, -3.4279e-04,  1.2916e-04],\n",
            "          [-1.4021e-03, -3.2436e-03, -7.9109e-04,  2.7762e-03, -2.4467e-04],\n",
            "          [ 9.8016e-05, -1.0952e-03,  2.0604e-04,  6.9570e-03,  4.7326e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0152]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0183]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0152,  0.0183], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 4] = -0.015163278207182884\n",
            " somado na saída em [0, 1, 1, 4] = 0.01828852668404579\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 5\n",
            " alvo do kernel em x: x[0,0,3:8, 15:20]\n",
            " \n",
            " tensor([[0.2091, 0.9225, 0.1481, 0.9139, 0.3589],\n",
            "        [0.4132, 0.6962, 0.4461, 0.6978, 0.4535],\n",
            "        [0.0487, 0.1954, 0.6941, 0.4569, 0.6867],\n",
            "        [0.2930, 0.3102, 0.8282, 0.5365, 0.4530],\n",
            "        [0.7808, 0.7739, 0.5650, 0.5079, 0.1426]])\n",
            " produto: tensor([[[[-8.5249e-04,  3.0558e-04, -7.3546e-04,  3.4464e-03, -3.0584e-03],\n",
            "          [ 3.0287e-03, -5.0602e-03, -3.5464e-03, -4.4094e-03,  2.0539e-03],\n",
            "          [-1.7984e-04,  7.3113e-04, -5.8906e-03, -2.7723e-03, -2.5215e-03],\n",
            "          [-5.7587e-04, -2.3664e-03,  5.4229e-03, -1.2651e-03,  1.4539e-03],\n",
            "          [ 5.5213e-03,  1.4419e-03,  1.5450e-03,  4.9022e-03, -6.4335e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 6.6219e-04, -4.1044e-03,  1.0583e-03,  7.2989e-03, -3.3093e-03],\n",
            "          [ 3.5270e-03,  3.3244e-03,  1.9438e-03,  2.8728e-03,  3.7699e-03],\n",
            "          [-6.4267e-05, -1.6523e-03, -1.9916e-03, -3.2180e-03,  4.5397e-04],\n",
            "          [-5.4711e-04, -1.6639e-03, -7.5300e-04,  5.0824e-03, -3.5727e-04],\n",
            "          [ 2.4790e-04, -1.2070e-03,  8.8825e-04,  4.5251e-03,  8.7228e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0040]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0177]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0040,  0.0177], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 5] = -0.004024266730993986\n",
            " somado na saída em [0, 1, 1, 5] = 0.017659012228250504\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 6\n",
            " alvo do kernel em x: x[0,0,3:8, 18:23]\n",
            " \n",
            " tensor([[0.9139, 0.3589, 0.0167, 0.9989, 0.9601],\n",
            "        [0.6978, 0.4535, 0.9315, 0.0675, 0.9634],\n",
            "        [0.4569, 0.6867, 0.4274, 0.3525, 0.2159],\n",
            "        [0.5365, 0.4530, 0.0758, 0.0471, 0.9457],\n",
            "        [0.5079, 0.1426, 0.3156, 0.1637, 0.2939]])\n",
            " produto: tensor([[[[-3.7267e-03,  1.1890e-04, -8.3028e-05,  3.7670e-03, -8.1806e-03],\n",
            "          [ 5.1153e-03, -3.2962e-03, -7.4057e-03, -4.2674e-04,  4.3630e-03],\n",
            "          [-1.6883e-03,  2.5698e-03, -3.6275e-03, -2.1386e-03, -7.9267e-04],\n",
            "          [-1.0542e-03, -3.4555e-03,  4.9663e-04, -1.1096e-04,  3.0357e-03],\n",
            "          [ 3.5913e-03,  2.6576e-04,  8.6291e-04,  1.5805e-03, -1.3254e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.8948e-03, -1.5970e-03,  1.1947e-04,  7.9778e-03, -8.8519e-03],\n",
            "          [ 5.9569e-03,  2.1655e-03,  4.0591e-03,  2.7802e-04,  8.0084e-03],\n",
            "          [-6.0333e-04, -5.8076e-03, -1.2264e-03, -2.4824e-03,  1.4271e-04],\n",
            "          [-1.0016e-03, -2.4296e-03, -6.8960e-05,  4.4576e-04, -7.4595e-04],\n",
            "          [ 1.6125e-04, -2.2247e-04,  4.9609e-04,  1.4589e-03,  1.7970e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0115]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0109]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0115,  0.0109], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 6] = -0.011545230634510517\n",
            " somado na saída em [0, 1, 1, 6] = 0.010924465954303741\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 7\n",
            " alvo do kernel em x: x[0,0,3:8, 21:26]\n",
            " \n",
            " tensor([[0.9989, 0.9601, 0.0829, 0.9035, 0.7787],\n",
            "        [0.0675, 0.9634, 0.2142, 0.2889, 0.2413],\n",
            "        [0.3525, 0.2159, 0.0086, 0.9784, 0.4424],\n",
            "        [0.0471, 0.9457, 0.0358, 0.1100, 0.1932],\n",
            "        [0.1637, 0.2939, 0.0296, 0.2192, 0.5753]])\n",
            " produto: tensor([[[[-4.0733e-03,  3.1803e-04, -4.1186e-04,  3.4071e-03, -6.6354e-03],\n",
            "          [ 4.9505e-04, -7.0021e-03, -1.7031e-03, -1.8256e-03,  1.0929e-03],\n",
            "          [-1.3024e-03,  8.0786e-04, -7.2642e-05, -5.9362e-03, -1.6245e-03],\n",
            "          [-9.2464e-05, -7.2147e-03,  2.3418e-04, -2.5951e-04,  6.2006e-04],\n",
            "          [ 1.1578e-03,  5.4751e-04,  8.1021e-05,  2.1158e-03, -2.5947e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 3.1640e-03, -4.2717e-03,  5.9264e-04,  7.2157e-03, -7.1798e-03],\n",
            "          [ 5.7650e-04,  4.6002e-03,  9.3346e-04,  1.1894e-03,  2.0061e-03],\n",
            "          [-4.6541e-04, -1.8257e-03, -2.4560e-05, -6.8906e-03,  2.9248e-04],\n",
            "          [-8.7847e-05, -5.0728e-03, -3.2517e-05,  1.0425e-03, -1.5237e-04],\n",
            "          [ 5.1986e-05, -4.5833e-04,  4.6579e-05,  1.9531e-03,  3.5179e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0299]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0007]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0299,  0.0007], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 7] = -0.029870852828025818\n",
            " somado na saída em [0, 1, 1, 7] = 0.0007208858150988817\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 0\n",
            " alvo do kernel em x: x[0,0,6:11, 0:5]\n",
            " \n",
            " tensor([[0.9546, 0.3150, 0.8017, 0.1512, 0.6010],\n",
            "        [0.3693, 0.8652, 0.0853, 0.2019, 0.3025],\n",
            "        [0.5282, 0.8158, 0.0770, 0.6413, 0.8167],\n",
            "        [0.1564, 0.2400, 0.5526, 0.4235, 0.6437],\n",
            "        [0.9772, 0.6404, 0.9218, 0.4470, 0.8405]])\n",
            " produto: tensor([[[[-0.0039,  0.0001, -0.0040,  0.0006, -0.0051],\n",
            "          [ 0.0027, -0.0063, -0.0007, -0.0013,  0.0014],\n",
            "          [-0.0020,  0.0031, -0.0007, -0.0039, -0.0030],\n",
            "          [-0.0003, -0.0018,  0.0036, -0.0010,  0.0021],\n",
            "          [ 0.0069,  0.0012,  0.0025,  0.0043, -0.0038]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0030, -0.0014,  0.0057,  0.0012, -0.0055],\n",
            "          [ 0.0032,  0.0041,  0.0004,  0.0008,  0.0025],\n",
            "          [-0.0007, -0.0069, -0.0002, -0.0045,  0.0005],\n",
            "          [-0.0003, -0.0013, -0.0005,  0.0040, -0.0005],\n",
            "          [ 0.0003, -0.0010,  0.0014,  0.0040,  0.0051]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0092]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0135]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0092,  0.0135], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 0] = -0.009232847020030022\n",
            " somado na saída em [0, 1, 2, 0] = 0.013531133532524109\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 1\n",
            " alvo do kernel em x: x[0,0,6:11, 3:8]\n",
            " \n",
            " tensor([[0.1512, 0.6010, 0.9224, 0.9866, 0.6201],\n",
            "        [0.2019, 0.3025, 0.2486, 0.9031, 0.8282],\n",
            "        [0.6413, 0.8167, 0.0586, 0.9914, 0.3989],\n",
            "        [0.4235, 0.6437, 0.8225, 0.3820, 0.0744],\n",
            "        [0.4470, 0.8405, 0.4695, 0.2194, 0.6571]])\n",
            " produto: tensor([[[[-6.1643e-04,  1.9908e-04, -4.5811e-03,  3.7208e-03, -5.2834e-03],\n",
            "          [ 1.4803e-03, -2.1983e-03, -1.9766e-03, -5.7064e-03,  3.7511e-03],\n",
            "          [-2.3696e-03,  3.0564e-03, -4.9772e-04, -6.0153e-03, -1.4645e-03],\n",
            "          [-8.3220e-04, -4.9107e-03,  5.3855e-03, -9.0085e-04,  2.3882e-04],\n",
            "          [ 3.1609e-03,  1.5659e-03,  1.2838e-03,  2.1180e-03, -2.9635e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 4.7883e-04, -2.6739e-03,  6.5918e-03,  7.8799e-03, -5.7170e-03],\n",
            "          [ 1.7238e-03,  1.4442e-03,  1.0834e-03,  3.7177e-03,  6.8852e-03],\n",
            "          [-8.4680e-04, -6.9072e-03, -1.6828e-04, -6.9824e-03,  2.6367e-04],\n",
            "          [-7.9065e-04, -3.4528e-03, -7.4781e-04,  3.6190e-03, -5.8684e-05],\n",
            "          [ 1.4192e-04, -1.3109e-03,  7.3803e-04,  1.9551e-03,  4.0180e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0144]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0109]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0144,  0.0109], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 1] = -0.014356261119246483\n",
            " somado na saída em [0, 1, 2, 1] = 0.010884040035307407\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 2\n",
            " alvo do kernel em x: x[0,0,6:11, 6:11]\n",
            " \n",
            " tensor([[0.9866, 0.6201, 0.3382, 0.2053, 0.6846],\n",
            "        [0.9031, 0.8282, 0.8094, 0.5871, 0.3559],\n",
            "        [0.9914, 0.3989, 0.4166, 0.5816, 0.0036],\n",
            "        [0.3820, 0.0744, 0.3212, 0.3049, 0.5938],\n",
            "        [0.2194, 0.6571, 0.8693, 0.5654, 0.1892]])\n",
            " produto: tensor([[[[-4.0233e-03,  2.0540e-04, -1.6796e-03,  7.7438e-04, -5.8330e-03],\n",
            "          [ 6.6199e-03, -6.0200e-03, -6.4352e-03, -3.7096e-03,  1.6119e-03],\n",
            "          [-3.6633e-03,  1.4926e-03, -3.5360e-03, -3.5289e-03, -1.3223e-05],\n",
            "          [-7.5069e-04, -5.6757e-04,  2.1035e-03, -7.1900e-04,  1.9059e-03],\n",
            "          [ 1.5516e-03,  1.2242e-03,  2.3771e-03,  5.4571e-03, -8.5315e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 3.1252e-03, -2.7588e-03,  2.4168e-03,  1.6400e-03, -6.3116e-03],\n",
            "          [ 7.7091e-03,  3.9550e-03,  3.5271e-03,  2.4168e-03,  2.9588e-03],\n",
            "          [-1.3091e-03, -3.3732e-03, -1.1955e-03, -4.0963e-03,  2.3807e-06],\n",
            "          [-7.1320e-04, -3.9907e-04, -2.9208e-04,  2.8884e-03, -4.6833e-04],\n",
            "          [ 6.9666e-05, -1.0248e-03,  1.3666e-03,  5.0373e-03,  1.1567e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0160]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0163]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0160,  0.0163], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 2] = -0.016008887439966202\n",
            " somado na saída em [0, 1, 2, 2] = 0.01632791943848133\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 3\n",
            " alvo do kernel em x: x[0,0,6:11, 9:14]\n",
            " \n",
            " tensor([[0.2053, 0.6846, 0.0996, 0.7510, 0.6047],\n",
            "        [0.5871, 0.3559, 0.7117, 0.3087, 0.7022],\n",
            "        [0.5816, 0.0036, 0.6798, 0.2174, 0.8950],\n",
            "        [0.3049, 0.5938, 0.9811, 0.6770, 0.6254],\n",
            "        [0.5654, 0.1892, 0.7047, 0.9982, 0.9563]])\n",
            " produto: tensor([[[[-8.3735e-04,  2.2676e-04, -4.9464e-04,  2.8319e-03, -5.1526e-03],\n",
            "          [ 4.3035e-03, -2.5870e-03, -5.6586e-03, -1.9507e-03,  3.1804e-03],\n",
            "          [-2.1491e-03,  1.3477e-05, -5.7699e-03, -1.3189e-03, -3.2864e-03],\n",
            "          [-5.9914e-04, -4.5296e-03,  6.4241e-03, -1.5966e-03,  2.0076e-03],\n",
            "          [ 3.9978e-03,  3.5243e-04,  1.9269e-03,  9.6354e-03, -4.3130e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 6.5043e-04, -3.0458e-03,  7.1174e-04,  5.9975e-03, -5.5754e-03],\n",
            "          [ 5.0115e-03,  1.6996e-03,  3.1015e-03,  1.2709e-03,  5.8378e-03],\n",
            "          [-7.6799e-04, -3.0457e-05, -1.9508e-03, -1.5309e-03,  5.9168e-04],\n",
            "          [-5.6923e-04, -3.1848e-03, -8.9202e-04,  6.4142e-03, -4.9332e-04],\n",
            "          [ 1.7950e-04, -2.9502e-04,  1.1078e-03,  8.8943e-03,  5.8477e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0053]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0290]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0053,  0.0290], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 3] = -0.005343128927052021\n",
            " somado na saída em [0, 1, 2, 3] = 0.028980351984500885\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 4\n",
            " alvo do kernel em x: x[0,0,6:11, 12:17]\n",
            " \n",
            " tensor([[0.7510, 0.6047, 0.8701, 0.2930, 0.3102],\n",
            "        [0.3087, 0.7022, 0.1311, 0.7808, 0.7739],\n",
            "        [0.2174, 0.8950, 0.4227, 0.7595, 0.9195],\n",
            "        [0.6770, 0.6254, 0.1409, 0.0744, 0.0681],\n",
            "        [0.9982, 0.9563, 0.6654, 0.7445, 0.7968]])\n",
            " produto: tensor([[[[-3.0622e-03,  2.0031e-04, -4.3214e-03,  1.1051e-03, -2.6431e-03],\n",
            "          [ 2.2630e-03, -5.1042e-03, -1.0420e-03, -4.9337e-03,  3.5051e-03],\n",
            "          [-8.0320e-04,  3.3493e-03, -3.5874e-03, -4.6080e-03, -3.3762e-03],\n",
            "          [-1.3305e-03, -4.7712e-03,  9.2246e-04, -1.7551e-04,  2.1857e-04],\n",
            "          [ 7.0589e-03,  1.7816e-03,  1.8195e-03,  7.1859e-03, -3.5936e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3786e-03, -2.6905e-03,  6.2181e-03,  2.3403e-03, -2.8600e-03],\n",
            "          [ 2.6353e-03,  3.3533e-03,  5.7113e-04,  3.2143e-03,  6.4338e-03],\n",
            "          [-2.8703e-04, -7.5693e-03, -1.2129e-03, -5.3489e-03,  6.0785e-04],\n",
            "          [-1.2641e-03, -3.3548e-03, -1.2809e-04,  7.0507e-04, -5.3710e-05],\n",
            "          [ 3.1694e-04, -1.4915e-03,  1.0460e-03,  6.6332e-03,  4.8723e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0139]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0151]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0139,  0.0151], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 4] = -0.013942391611635685\n",
            " somado na saída em [0, 1, 2, 4] = 0.015065622515976429\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 5\n",
            " alvo do kernel em x: x[0,0,6:11, 15:20]\n",
            " \n",
            " tensor([[2.9303e-01, 3.1020e-01, 8.2819e-01, 5.3646e-01, 4.5296e-01],\n",
            "        [7.8080e-01, 7.7394e-01, 5.6502e-01, 5.0786e-01, 1.4265e-01],\n",
            "        [7.5950e-01, 9.1949e-01, 9.9687e-01, 5.0818e-02, 8.1244e-01],\n",
            "        [7.4422e-02, 6.8094e-02, 4.5097e-04, 2.7528e-01, 1.6445e-01],\n",
            "        [7.4446e-01, 7.9679e-01, 9.2493e-01, 3.7752e-01, 5.8573e-01]])\n",
            " produto: tensor([[[[-1.1949e-03,  1.0275e-04, -4.1133e-03,  2.0231e-03, -3.8595e-03],\n",
            "          [ 5.7236e-03, -5.6253e-03, -4.4921e-03, -3.2091e-03,  6.4604e-04],\n",
            "          [-2.8063e-03,  3.4409e-03, -8.4607e-03, -3.0833e-04, -2.9831e-03],\n",
            "          [-1.4625e-04, -5.1947e-04,  2.9529e-06, -6.4920e-04,  5.2787e-04],\n",
            "          [ 5.2644e-03,  1.4845e-03,  2.5292e-03,  3.6441e-03, -2.6417e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 9.2818e-04, -1.3801e-03,  5.9186e-03,  4.2845e-03, -4.1762e-03],\n",
            "          [ 6.6652e-03,  3.6957e-03,  2.4622e-03,  2.0907e-03,  1.1858e-03],\n",
            "          [-1.0028e-03, -7.7761e-03, -2.8605e-03, -3.5790e-04,  5.3708e-04],\n",
            "          [-1.3895e-04, -3.6525e-04, -4.1003e-07,  2.6080e-03, -1.2971e-04],\n",
            "          [ 2.3637e-04, -1.2427e-03,  1.4541e-03,  3.3638e-03,  3.5817e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0156]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0196]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0156,  0.0196], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 5] = -0.015619980171322823\n",
            " somado na saída em [0, 1, 2, 5] = 0.019581248983740807\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 6\n",
            " alvo do kernel em x: x[0,0,6:11, 18:23]\n",
            " \n",
            " tensor([[0.5365, 0.4530, 0.0758, 0.0471, 0.9457],\n",
            "        [0.5079, 0.1426, 0.3156, 0.1637, 0.2939],\n",
            "        [0.0508, 0.8124, 0.8328, 0.1836, 0.1876],\n",
            "        [0.2753, 0.1645, 0.1084, 0.9889, 0.7995],\n",
            "        [0.3775, 0.5857, 0.2115, 0.9219, 0.6013]])\n",
            " produto: tensor([[[[-2.1876e-03,  1.5004e-04, -3.7670e-04,  1.7743e-04, -8.0582e-03],\n",
            "          [ 3.7229e-03, -1.0368e-03, -2.5089e-03, -1.0346e-03,  1.3310e-03],\n",
            "          [-1.8777e-04,  3.0403e-03, -7.0684e-03, -1.1139e-03, -6.8884e-04],\n",
            "          [-5.4099e-04, -1.2545e-03,  7.1000e-04, -2.3320e-03,  2.5663e-03],\n",
            "          [ 2.6696e-03,  1.0912e-03,  5.7833e-04,  8.8988e-03, -2.7118e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6992e-03, -2.0153e-03,  5.4203e-04,  3.7577e-04, -8.7194e-03],\n",
            "          [ 4.3354e-03,  6.8116e-04,  1.3751e-03,  6.7405e-04,  2.4430e-03],\n",
            "          [-6.7100e-05, -6.8708e-03, -2.3898e-03, -1.2929e-03,  1.2402e-04],\n",
            "          [-5.1397e-04, -8.8209e-04, -9.8588e-05,  9.3684e-03, -6.3060e-04],\n",
            "          [ 1.1986e-04, -9.1350e-04,  3.3248e-04,  8.2143e-03,  3.6768e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0062]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0096]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0062,  0.0096], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 6] = -0.0061651370488107204\n",
            " somado na saída em [0, 1, 2, 6] = 0.00956752710044384\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 7\n",
            " alvo do kernel em x: x[0,0,6:11, 21:26]\n",
            " \n",
            " tensor([[0.0471, 0.9457, 0.0358, 0.1100, 0.1932],\n",
            "        [0.1637, 0.2939, 0.0296, 0.2192, 0.5753],\n",
            "        [0.1836, 0.1876, 0.7302, 0.1538, 0.5159],\n",
            "        [0.9889, 0.7995, 0.4866, 0.6398, 0.6164],\n",
            "        [0.9219, 0.6013, 0.6750, 0.9234, 0.5146]])\n",
            " produto: tensor([[[[-0.0002,  0.0003, -0.0002,  0.0004, -0.0016],\n",
            "          [ 0.0012, -0.0021, -0.0002, -0.0014,  0.0026],\n",
            "          [-0.0007,  0.0007, -0.0062, -0.0009, -0.0019],\n",
            "          [-0.0019, -0.0061,  0.0032, -0.0015,  0.0020],\n",
            "          [ 0.0065,  0.0011,  0.0018,  0.0089, -0.0023]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0001, -0.0042,  0.0003,  0.0009, -0.0018],\n",
            "          [ 0.0014,  0.0014,  0.0001,  0.0009,  0.0048],\n",
            "          [-0.0002, -0.0016, -0.0021, -0.0011,  0.0003],\n",
            "          [-0.0018, -0.0043, -0.0004,  0.0061, -0.0005],\n",
            "          [ 0.0003, -0.0009,  0.0011,  0.0082,  0.0031]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[0.0015]]],\n",
            "\n",
            "\n",
            "        [[[0.0100]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([0.0015, 0.0100], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 7] = 0.0014517633244395256\n",
            " somado na saída em [0, 1, 2, 7] = 0.01003233902156353\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 0\n",
            " alvo do kernel em x: x[0,0,9:14, 0:5]\n",
            " \n",
            " tensor([[0.1564, 0.2400, 0.5526, 0.4235, 0.6437],\n",
            "        [0.9772, 0.6404, 0.9218, 0.4470, 0.8405],\n",
            "        [0.0555, 0.6745, 0.8302, 0.5713, 0.2732],\n",
            "        [0.5642, 0.7089, 0.8265, 0.8762, 0.1509],\n",
            "        [0.4859, 0.8830, 0.2448, 0.2268, 0.9077]])\n",
            " produto: tensor([[[[-6.3770e-04,  7.9496e-05, -2.7447e-03,  1.5970e-03, -5.4849e-03],\n",
            "          [ 7.1632e-03, -4.6550e-03, -7.3283e-03, -2.8245e-03,  3.8067e-03],\n",
            "          [-2.0508e-04,  2.5240e-03, -7.0461e-03, -3.4661e-03, -1.0032e-03],\n",
            "          [-1.1087e-03, -5.4079e-03,  5.4121e-03, -2.0663e-03,  4.8448e-04],\n",
            "          [ 3.4359e-03,  1.6451e-03,  6.6936e-04,  2.1889e-03, -4.0937e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 4.9535e-04, -1.0678e-03,  3.9494e-03,  3.3821e-03, -5.9350e-03],\n",
            "          [ 8.3417e-03,  3.0582e-03,  4.0167e-03,  1.8402e-03,  6.9873e-03],\n",
            "          [-7.3285e-05, -5.7042e-03, -2.3822e-03, -4.0234e-03,  1.8062e-04],\n",
            "          [-1.0533e-03, -3.8024e-03, -7.5150e-04,  8.3009e-03, -1.1905e-04],\n",
            "          [ 1.5427e-04, -1.3771e-03,  3.8482e-04,  2.0206e-03,  5.5504e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0191]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0224]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0191,  0.0224], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 0] = -0.01906590536236763\n",
            " somado na saída em [0, 1, 3, 0] = 0.022373134270310402\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 1\n",
            " alvo do kernel em x: x[0,0,9:14, 3:8]\n",
            " \n",
            " tensor([[0.4235, 0.6437, 0.8225, 0.3820, 0.0744],\n",
            "        [0.4470, 0.8405, 0.4695, 0.2194, 0.6571],\n",
            "        [0.5713, 0.2732, 0.6607, 0.1731, 0.8929],\n",
            "        [0.8762, 0.1509, 0.3543, 0.0436, 0.3680],\n",
            "        [0.2268, 0.9077, 0.9922, 0.9266, 0.6386]])\n",
            " produto: tensor([[[[-1.7268e-03,  2.1323e-04, -4.0849e-03,  1.4405e-03, -6.3393e-04],\n",
            "          [ 3.2767e-03, -6.1093e-03, -3.7325e-03, -1.3865e-03,  2.9758e-03],\n",
            "          [-2.1108e-03,  1.0225e-03, -5.6075e-03, -1.0505e-03, -3.2787e-03],\n",
            "          [-1.7219e-03, -1.1514e-03,  2.3198e-03, -1.0291e-04,  1.1813e-03],\n",
            "          [ 1.6036e-03,  1.6911e-03,  2.7132e-03,  8.9438e-03, -2.8802e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.3413e-03, -2.8640e-03,  5.8778e-03,  3.0508e-03, -6.8595e-04],\n",
            "          [ 3.8158e-03,  4.0136e-03,  2.0458e-03,  9.0329e-04,  5.4622e-03],\n",
            "          [-7.5432e-04, -2.3107e-03, -1.8959e-03, -1.2194e-03,  5.9030e-04],\n",
            "          [-1.6359e-03, -8.0959e-04, -3.2212e-04,  4.1343e-04, -2.9027e-04],\n",
            "          [ 7.2000e-05, -1.4156e-03,  1.5598e-03,  8.2558e-03,  3.9050e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0082]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0271]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0082,  0.0271], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 1] = -0.008196310140192509\n",
            " somado na saída em [0, 1, 3, 1] = 0.02710333839058876\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 2\n",
            " alvo do kernel em x: x[0,0,9:14, 6:11]\n",
            " \n",
            " tensor([[0.3820, 0.0744, 0.3212, 0.3049, 0.5938],\n",
            "        [0.2194, 0.6571, 0.8693, 0.5654, 0.1892],\n",
            "        [0.1731, 0.8929, 0.9398, 0.3753, 0.9446],\n",
            "        [0.0436, 0.3680, 0.9859, 0.9918, 0.3211],\n",
            "        [0.9266, 0.6386, 0.0462, 0.9147, 0.2579]])\n",
            " produto: tensor([[[[-1.5577e-03,  2.4645e-05, -1.5955e-03,  1.1497e-03, -5.0591e-03],\n",
            "          [ 1.6084e-03, -4.7759e-03, -6.9112e-03, -3.5724e-03,  8.5671e-04],\n",
            "          [-6.3972e-04,  3.3415e-03, -7.9767e-03, -2.2772e-03, -3.4685e-03],\n",
            "          [-8.5758e-05, -2.8074e-03,  6.4559e-03, -2.3389e-03,  1.0306e-03],\n",
            "          [ 6.5522e-03,  1.1898e-03,  1.2638e-04,  8.8296e-03, -1.1633e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2100e-03, -3.3102e-04,  2.2958e-03,  2.4349e-03, -5.4743e-03],\n",
            "          [ 1.8731e-03,  3.1376e-03,  3.7881e-03,  2.3274e-03,  1.5725e-03],\n",
            "          [-2.2861e-04, -7.5516e-03, -2.6969e-03, -2.6434e-03,  6.2447e-04],\n",
            "          [-8.1477e-05, -1.9740e-03, -8.9644e-04,  9.3960e-03, -2.5326e-04],\n",
            "          [ 2.9419e-04, -9.9597e-04,  7.2657e-05,  8.1505e-03,  1.5772e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0131]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0156]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0131,  0.0156], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 2] = -0.013063861057162285\n",
            " somado na saída em [0, 1, 3, 2] = 0.015627458691596985\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 3\n",
            " alvo do kernel em x: x[0,0,9:14, 9:14]\n",
            " \n",
            " tensor([[0.3049, 0.5938, 0.9811, 0.6770, 0.6254],\n",
            "        [0.5654, 0.1892, 0.7047, 0.9982, 0.9563],\n",
            "        [0.3753, 0.9446, 0.4064, 0.9276, 0.7929],\n",
            "        [0.9918, 0.3211, 0.3894, 0.4102, 0.8482],\n",
            "        [0.9147, 0.2579, 0.9333, 0.4410, 0.8357]])\n",
            " produto: tensor([[[[-0.0012,  0.0002, -0.0049,  0.0026, -0.0053],\n",
            "          [ 0.0041, -0.0014, -0.0056, -0.0063,  0.0043],\n",
            "          [-0.0014,  0.0035, -0.0034, -0.0056, -0.0029],\n",
            "          [-0.0019, -0.0024,  0.0025, -0.0010,  0.0027],\n",
            "          [ 0.0065,  0.0005,  0.0026,  0.0043, -0.0038]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0010, -0.0026,  0.0070,  0.0054, -0.0058],\n",
            "          [ 0.0048,  0.0009,  0.0031,  0.0041,  0.0079],\n",
            "          [-0.0005, -0.0080, -0.0012, -0.0065,  0.0005],\n",
            "          [-0.0019, -0.0017, -0.0004,  0.0039, -0.0007],\n",
            "          [ 0.0003, -0.0004,  0.0015,  0.0039,  0.0051]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0134]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0199]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0134,  0.0199], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 3] = -0.01344994641840458\n",
            " somado na saída em [0, 1, 3, 3] = 0.019860686734318733\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 4\n",
            " alvo do kernel em x: x[0,0,9:14, 12:17]\n",
            " \n",
            " tensor([[0.6770, 0.6254, 0.1409, 0.0744, 0.0681],\n",
            "        [0.9982, 0.9563, 0.6654, 0.7445, 0.7968],\n",
            "        [0.9276, 0.7929, 0.4814, 0.8254, 0.2480],\n",
            "        [0.4102, 0.8482, 0.3394, 0.1067, 0.9725],\n",
            "        [0.4410, 0.8357, 0.7493, 0.2781, 0.5913]])\n",
            " produto: tensor([[[[-0.0028,  0.0002, -0.0007,  0.0003, -0.0006],\n",
            "          [ 0.0073, -0.0070, -0.0053, -0.0047,  0.0036],\n",
            "          [-0.0034,  0.0030, -0.0041, -0.0050, -0.0009],\n",
            "          [-0.0008, -0.0065,  0.0022, -0.0003,  0.0031],\n",
            "          [ 0.0031,  0.0016,  0.0020,  0.0027, -0.0027]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0021, -0.0028,  0.0010,  0.0006, -0.0006],\n",
            "          [ 0.0085,  0.0046,  0.0029,  0.0031,  0.0066],\n",
            "          [-0.0012, -0.0067, -0.0014, -0.0058,  0.0002],\n",
            "          [-0.0008, -0.0045, -0.0003,  0.0010, -0.0008],\n",
            "          [ 0.0001, -0.0013,  0.0012,  0.0025,  0.0036]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0155]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0118]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0155,  0.0118], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 4] = -0.015478533692657948\n",
            " somado na saída em [0, 1, 3, 4] = 0.011777503415942192\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 5\n",
            " alvo do kernel em x: x[0,0,9:14, 15:20]\n",
            " \n",
            " tensor([[7.4422e-02, 6.8094e-02, 4.5097e-04, 2.7528e-01, 1.6445e-01],\n",
            "        [7.4446e-01, 7.9679e-01, 9.2493e-01, 3.7752e-01, 5.8573e-01],\n",
            "        [8.2541e-01, 2.4797e-01, 9.6473e-01, 2.5757e-01, 8.0601e-01],\n",
            "        [1.0670e-01, 9.7252e-01, 9.5843e-01, 9.2813e-01, 1.9656e-01],\n",
            "        [2.7807e-01, 5.9129e-01, 9.5765e-01, 4.6077e-01, 8.2454e-01]])\n",
            " produto: tensor([[[[-3.0347e-04,  2.2556e-05, -2.2398e-06,  1.0381e-03, -1.4012e-03],\n",
            "          [ 5.4572e-03, -5.7914e-03, -7.3536e-03, -2.3855e-03,  2.6527e-03],\n",
            "          [-3.0498e-03,  9.2792e-04, -8.1880e-03, -1.5627e-03, -2.9595e-03],\n",
            "          [-2.0968e-04, -7.4190e-03,  6.2757e-03, -2.1888e-03,  6.3092e-04],\n",
            "          [ 1.9663e-03,  1.1016e-03,  2.6187e-03,  4.4476e-03, -3.7188e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3573e-04, -3.0296e-04,  3.2228e-06,  2.1986e-03, -1.5162e-03],\n",
            "          [ 6.3550e-03,  3.8048e-03,  4.0306e-03,  1.5542e-03,  4.8691e-03],\n",
            "          [-1.0899e-03, -2.0971e-03, -2.7683e-03, -1.8140e-03,  5.3282e-04],\n",
            "          [-1.9921e-04, -5.2165e-03, -8.7142e-04,  8.7931e-03, -1.5503e-04],\n",
            "          [ 8.8286e-05, -9.2218e-04,  1.5055e-03,  4.1055e-03,  5.0420e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0194]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0262]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0194,  0.0262], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 5] = -0.019394278526306152\n",
            " somado na saída em [0, 1, 3, 5] = 0.02616581693291664\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 6\n",
            " alvo do kernel em x: x[0,0,9:14, 18:23]\n",
            " \n",
            " tensor([[0.2753, 0.1645, 0.1084, 0.9889, 0.7995],\n",
            "        [0.3775, 0.5857, 0.2115, 0.9219, 0.6013],\n",
            "        [0.2576, 0.8060, 0.6008, 0.4565, 0.9170],\n",
            "        [0.9281, 0.1966, 0.5652, 0.5444, 0.2343],\n",
            "        [0.4608, 0.8245, 0.5821, 0.6924, 0.2506]])\n",
            " produto: tensor([[[[-1.1225e-03,  5.4474e-05, -5.3854e-04,  3.7291e-03, -6.8121e-03],\n",
            "          [ 2.7674e-03, -4.2573e-03, -1.6814e-03, -5.8254e-03,  2.7231e-03],\n",
            "          [-9.5168e-04,  3.0162e-03, -5.0994e-03, -2.7696e-03, -3.3671e-03],\n",
            "          [-1.8240e-03, -1.4995e-03,  3.7009e-03, -1.2839e-03,  7.5205e-04],\n",
            "          [ 3.2583e-03,  1.5362e-03,  1.5918e-03,  6.6830e-03, -1.1301e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 8.7196e-04, -7.3167e-04,  7.7491e-04,  7.8975e-03, -7.3711e-03],\n",
            "          [ 3.2227e-03,  2.7969e-03,  9.2161e-04,  3.7953e-03,  4.9984e-03],\n",
            "          [-3.4009e-04, -6.8164e-03, -1.7241e-03, -3.2149e-03,  6.0622e-04],\n",
            "          [-1.7329e-03, -1.0543e-03, -5.1389e-04,  5.1577e-03, -1.8480e-04],\n",
            "          [ 1.4629e-04, -1.2860e-03,  9.1513e-04,  6.1690e-03,  1.5322e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0083]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0148]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0083,  0.0148], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 6] = -0.00834997184574604\n",
            " somado na saída em [0, 1, 3, 6] = 0.014835711568593979\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 7\n",
            " alvo do kernel em x: x[0,0,9:14, 21:26]\n",
            " \n",
            " tensor([[0.9889, 0.7995, 0.4866, 0.6398, 0.6164],\n",
            "        [0.9219, 0.6013, 0.6750, 0.9234, 0.5146],\n",
            "        [0.4565, 0.9170, 0.5604, 0.7637, 0.1787],\n",
            "        [0.5444, 0.2343, 0.5176, 0.7543, 0.6101],\n",
            "        [0.6924, 0.2506, 0.4776, 0.8068, 0.6635]])\n",
            " produto: tensor([[[[-0.0040,  0.0003, -0.0024,  0.0024, -0.0053],\n",
            "          [ 0.0068, -0.0044, -0.0054, -0.0058,  0.0023],\n",
            "          [-0.0017,  0.0034, -0.0048, -0.0046, -0.0007],\n",
            "          [-0.0011, -0.0018,  0.0034, -0.0018,  0.0020],\n",
            "          [ 0.0049,  0.0005,  0.0013,  0.0078, -0.0030]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0031, -0.0036,  0.0035,  0.0051, -0.0057],\n",
            "          [ 0.0079,  0.0029,  0.0029,  0.0038,  0.0043],\n",
            "          [-0.0006, -0.0078, -0.0016, -0.0054,  0.0001],\n",
            "          [-0.0010, -0.0013, -0.0005,  0.0071, -0.0005],\n",
            "          [ 0.0002, -0.0004,  0.0008,  0.0072,  0.0041]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0116]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0248]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0116,  0.0248], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 7] = -0.011632559821009636\n",
            " somado na saída em [0, 1, 3, 7] = 0.024760961532592773\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 0\n",
            " alvo do kernel em x: x[0,0,12:17, 0:5]\n",
            " \n",
            " tensor([[0.5642, 0.7089, 0.8265, 0.8762, 0.1509],\n",
            "        [0.4859, 0.8830, 0.2448, 0.2268, 0.9077],\n",
            "        [0.3423, 0.4430, 0.2205, 0.9662, 0.5369],\n",
            "        [0.5870, 0.8055, 0.7216, 0.9226, 0.1469],\n",
            "        [0.2687, 0.0378, 0.6399, 0.5489, 0.3048]])\n",
            " produto: tensor([[[[-2.3005e-03,  2.3482e-04, -4.1051e-03,  3.3042e-03, -1.2861e-03],\n",
            "          [ 3.5618e-03, -6.4180e-03, -1.9461e-03, -1.4329e-03,  4.1108e-03],\n",
            "          [-1.2648e-03,  1.6579e-03, -1.8718e-03, -5.8621e-03, -1.9712e-03],\n",
            "          [-1.1536e-03, -6.1449e-03,  4.7247e-03, -2.1757e-03,  4.7152e-04],\n",
            "          [ 1.9003e-03,  7.0514e-05,  1.7499e-03,  5.2979e-03, -1.3748e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7870e-03, -3.1540e-03,  5.9069e-03,  6.9976e-03, -1.3916e-03],\n",
            "          [ 4.1478e-03,  4.2165e-03,  1.0667e-03,  9.3356e-04,  7.5455e-03],\n",
            "          [-4.5198e-04, -3.7468e-03, -6.3285e-04, -6.8047e-03,  3.5490e-04],\n",
            "          [-1.0960e-03, -4.3206e-03, -6.5605e-04,  8.7404e-03, -1.1586e-04],\n",
            "          [ 8.5320e-05, -5.9029e-05,  1.0060e-03,  4.8904e-03,  1.8639e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0122]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0271]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0122,  0.0271], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 4, 0] = -0.012223310768604279\n",
            " somado na saída em [0, 1, 4, 0] = 0.027113039046525955\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 1\n",
            " alvo do kernel em x: x[0,0,12:17, 3:8]\n",
            " \n",
            " tensor([[0.8762, 0.1509, 0.3543, 0.0436, 0.3680],\n",
            "        [0.2268, 0.9077, 0.9922, 0.9266, 0.6386],\n",
            "        [0.9662, 0.5369, 0.8008, 0.7525, 0.1026],\n",
            "        [0.9226, 0.1469, 0.2380, 0.8381, 0.8017],\n",
            "        [0.5489, 0.3048, 0.9602, 0.7244, 0.4482]])\n",
            " produto: tensor([[[[-3.5728e-03,  4.9997e-05, -1.7596e-03,  1.6457e-04, -3.1357e-03],\n",
            "          [ 1.6623e-03, -6.5973e-03, -7.8883e-03, -5.8549e-03,  2.8922e-03],\n",
            "          [-3.5700e-03,  2.0090e-03, -6.7968e-03, -4.5654e-03, -3.7666e-04],\n",
            "          [-1.8130e-03, -1.1206e-03,  1.5587e-03, -1.9766e-03,  2.5734e-03],\n",
            "          [ 3.8812e-03,  5.6789e-04,  2.6258e-03,  6.9925e-03, -2.0214e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.7753e-03, -6.7154e-04,  2.5319e-03,  3.4852e-04, -3.3930e-03],\n",
            "          [ 1.9358e-03,  4.3343e-03,  4.3236e-03,  3.8144e-03,  5.3087e-03],\n",
            "          [-1.2758e-03, -4.5402e-03, -2.2980e-03, -5.2994e-03,  6.7815e-05],\n",
            "          [-1.7225e-03, -7.8793e-04, -2.1643e-04,  7.9405e-03, -6.3236e-04],\n",
            "          [ 1.7426e-04, -4.7539e-04,  1.5096e-03,  6.4546e-03,  2.7406e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0261]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0229]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0261,  0.0229], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 4, 1] = -0.026071548461914062\n",
            " somado na saída em [0, 1, 4, 1] = 0.022947540506720543\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 2\n",
            " alvo do kernel em x: x[0,0,12:17, 6:11]\n",
            " \n",
            " tensor([[0.0436, 0.3680, 0.9859, 0.9918, 0.3211],\n",
            "        [0.9266, 0.6386, 0.0462, 0.9147, 0.2579],\n",
            "        [0.7525, 0.1026, 0.0877, 0.7694, 0.3068],\n",
            "        [0.8381, 0.8017, 0.6716, 0.8080, 0.9115],\n",
            "        [0.7244, 0.4482, 0.1285, 0.4957, 0.2653]])\n",
            " produto: tensor([[[[-0.0002,  0.0001, -0.0049,  0.0037, -0.0027],\n",
            "          [ 0.0068, -0.0046, -0.0004, -0.0058,  0.0012],\n",
            "          [-0.0028,  0.0004, -0.0007, -0.0047, -0.0011],\n",
            "          [-0.0016, -0.0061,  0.0044, -0.0019,  0.0029],\n",
            "          [ 0.0051,  0.0008,  0.0004,  0.0048, -0.0012]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0001, -0.0016,  0.0070,  0.0079, -0.0030],\n",
            "          [ 0.0079,  0.0030,  0.0002,  0.0038,  0.0021],\n",
            "          [-0.0010, -0.0009, -0.0003, -0.0054,  0.0002],\n",
            "          [-0.0016, -0.0043, -0.0006,  0.0077, -0.0007],\n",
            "          [ 0.0002, -0.0007,  0.0002,  0.0044,  0.0016]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0082]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0265]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0082,  0.0265], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 4, 2] = -0.008161686360836029\n",
            " somado na saída em [0, 1, 4, 2] = 0.026481565088033676\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 3\n",
            " alvo do kernel em x: x[0,0,12:17, 9:14]\n",
            " \n",
            " tensor([[0.9918, 0.3211, 0.3894, 0.4102, 0.8482],\n",
            "        [0.9147, 0.2579, 0.9333, 0.4410, 0.8357],\n",
            "        [0.7694, 0.3068, 0.5401, 0.8144, 0.9217],\n",
            "        [0.8080, 0.9115, 0.0670, 0.6109, 0.1301],\n",
            "        [0.4957, 0.2653, 0.8149, 0.3625, 0.9895]])\n",
            " produto: tensor([[[[-4.0442e-03,  1.0636e-04, -1.9339e-03,  1.5470e-03, -7.2267e-03],\n",
            "          [ 6.7054e-03, -1.8747e-03, -7.4199e-03, -2.7868e-03,  3.7848e-03],\n",
            "          [-2.8430e-03,  1.1480e-03, -4.5844e-03, -4.9413e-03, -3.3844e-03],\n",
            "          [-1.5879e-03, -6.9536e-03,  4.3854e-04, -1.4407e-03,  4.1764e-04],\n",
            "          [ 3.5052e-03,  4.9435e-04,  2.2282e-03,  3.4995e-03, -4.4626e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 3.1414e-03, -1.4286e-03,  2.7827e-03,  3.2763e-03, -7.8198e-03],\n",
            "          [ 7.8086e-03,  1.2316e-03,  4.0669e-03,  1.8156e-03,  6.9472e-03],\n",
            "          [-1.0159e-03, -2.5943e-03, -1.5500e-03, -5.7358e-03,  6.0933e-04],\n",
            "          [-1.5086e-03, -4.8893e-03, -6.0894e-05,  5.7878e-03, -1.0263e-04],\n",
            "          [ 1.5738e-04, -4.1383e-04,  1.2810e-03,  3.2303e-03,  6.0505e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0316]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0211]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0316,  0.0211], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 4, 3] = -0.03160897269845009\n",
            " somado na saída em [0, 1, 4, 3] = 0.021067112684249878\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 4\n",
            " alvo do kernel em x: x[0,0,12:17, 12:17]\n",
            " \n",
            " tensor([[0.4102, 0.8482, 0.3394, 0.1067, 0.9725],\n",
            "        [0.4410, 0.8357, 0.7493, 0.2781, 0.5913],\n",
            "        [0.8144, 0.9217, 0.2125, 0.3115, 0.1429],\n",
            "        [0.6109, 0.1301, 0.8512, 0.7878, 0.8646],\n",
            "        [0.3625, 0.9895, 0.9265, 0.5831, 0.5604]])\n",
            " produto: tensor([[[[-1.6728e-03,  2.8095e-04, -1.6857e-03,  4.0237e-04, -8.2864e-03],\n",
            "          [ 3.2329e-03, -6.0742e-03, -5.9571e-03, -1.7571e-03,  2.6779e-03],\n",
            "          [-3.0092e-03,  3.4492e-03, -1.8032e-03, -1.8897e-03, -5.2477e-04],\n",
            "          [-1.2006e-03, -9.9257e-04,  5.5735e-03, -1.8578e-03,  2.7753e-03],\n",
            "          [ 2.5637e-03,  1.8434e-03,  2.5334e-03,  5.6281e-03, -2.5274e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2994e-03, -3.7736e-03,  2.4255e-03,  8.5214e-04, -8.9664e-03],\n",
            "          [ 3.7648e-03,  3.9906e-03,  3.2651e-03,  1.1447e-03,  4.9154e-03],\n",
            "          [-1.0754e-03, -7.7951e-03, -6.0965e-04, -2.1935e-03,  9.4480e-05],\n",
            "          [-1.1406e-03, -6.9790e-04, -7.7391e-04,  7.4634e-03, -6.8196e-04],\n",
            "          [ 1.1511e-04, -1.5432e-03,  1.4565e-03,  5.1952e-03,  3.4267e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0083]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0102]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0083,  0.0102], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 4, 4] = -0.008277708664536476\n",
            " somado na saída em [0, 1, 4, 4] = 0.010157883167266846\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 5\n",
            " alvo do kernel em x: x[0,0,12:17, 15:20]\n",
            " \n",
            " tensor([[0.1067, 0.9725, 0.9584, 0.9281, 0.1966],\n",
            "        [0.2781, 0.5913, 0.9577, 0.4608, 0.8245],\n",
            "        [0.3115, 0.1429, 0.3531, 0.6216, 0.4888],\n",
            "        [0.7878, 0.8646, 0.2197, 0.5026, 0.9169],\n",
            "        [0.5831, 0.5604, 0.0012, 0.8917, 0.9111]])\n",
            " produto: tensor([[[[-4.3508e-04,  3.2214e-04, -4.7601e-03,  3.5001e-03, -1.6748e-03],\n",
            "          [ 2.0383e-03, -4.2977e-03, -7.6138e-03, -2.9115e-03,  3.7343e-03],\n",
            "          [-1.1508e-03,  5.3483e-04, -2.9971e-03, -3.7711e-03, -1.7949e-03],\n",
            "          [-1.5481e-03, -6.5958e-03,  1.4384e-03, -1.1854e-03,  2.9433e-03],\n",
            "          [ 4.1231e-03,  1.0440e-03,  3.2901e-06,  8.6075e-03, -4.1092e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 3.3796e-04, -4.3269e-03,  6.8494e-03,  7.4126e-03, -1.8122e-03],\n",
            "          [ 2.3737e-03,  2.8235e-03,  4.1731e-03,  1.8969e-03,  6.8544e-03],\n",
            "          [-4.1125e-04, -1.2087e-03, -1.0133e-03, -4.3774e-03,  3.2315e-04],\n",
            "          [-1.4708e-03, -4.6376e-03, -1.9973e-04,  4.7621e-03, -7.2324e-04],\n",
            "          [ 1.8512e-04, -8.7397e-04,  1.8915e-06,  7.9455e-03,  5.5713e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0166]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0305]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0166,  0.0305], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 4, 5] = -0.016555994749069214\n",
            " somado na saída em [0, 1, 4, 5] = 0.030455490574240685\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 6\n",
            " alvo do kernel em x: x[0,0,12:17, 18:23]\n",
            " \n",
            " tensor([[0.9281, 0.1966, 0.5652, 0.5444, 0.2343],\n",
            "        [0.4608, 0.8245, 0.5821, 0.6924, 0.2506],\n",
            "        [0.6216, 0.4888, 0.0768, 0.4525, 0.9766],\n",
            "        [0.5026, 0.9169, 0.2716, 0.7833, 0.4165],\n",
            "        [0.8917, 0.9111, 0.2340, 0.3731, 0.9424]])\n",
            " produto: tensor([[[[-3.7847e-03,  6.5109e-05, -2.8071e-03,  2.0530e-03, -1.9963e-03],\n",
            "          [ 3.3776e-03, -5.9931e-03, -4.6281e-03, -4.3749e-03,  1.1348e-03],\n",
            "          [-2.2966e-03,  1.8293e-03, -6.5168e-04, -2.7452e-03, -3.5857e-03],\n",
            "          [-9.8781e-04, -6.9950e-03,  1.7784e-03, -1.8473e-03,  1.3368e-03],\n",
            "          [ 6.3058e-03,  1.6974e-03,  6.3979e-04,  3.6017e-03, -4.2502e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.9399e-03, -8.7451e-04,  4.0392e-03,  4.3479e-03, -2.1601e-03],\n",
            "          [ 3.9333e-03,  3.9373e-03,  2.5367e-03,  2.8502e-03,  2.0829e-03],\n",
            "          [-8.2069e-04, -4.1341e-03, -2.2033e-04, -3.1866e-03,  6.4558e-04],\n",
            "          [-9.3848e-04, -4.9183e-03, -2.4694e-04,  7.4210e-03, -3.2850e-04],\n",
            "          [ 2.8313e-04, -1.4210e-03,  3.6782e-04,  3.3247e-03,  5.7626e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0231]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0252]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0231,  0.0252], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 4, 6] = -0.023123854771256447\n",
            " somado na saída em [0, 1, 4, 6] = 0.02522270567715168\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 7\n",
            " alvo do kernel em x: x[0,0,12:17, 21:26]\n",
            " \n",
            " tensor([[0.5444, 0.2343, 0.5176, 0.7543, 0.6101],\n",
            "        [0.6924, 0.2506, 0.4776, 0.8068, 0.6635],\n",
            "        [0.4525, 0.9766, 0.1950, 0.3617, 0.5377],\n",
            "        [0.7833, 0.4165, 0.3604, 0.9559, 0.9772],\n",
            "        [0.3731, 0.9424, 0.9493, 0.7271, 0.0850]])\n",
            " produto: tensor([[[[-2.2199e-03,  7.7609e-05, -2.5709e-03,  2.8444e-03, -5.1983e-03],\n",
            "          [ 5.0753e-03, -1.8212e-03, -3.7970e-03, -5.0979e-03,  3.0050e-03],\n",
            "          [-1.6718e-03,  3.6545e-03, -1.6548e-03, -2.1947e-03, -1.9745e-03],\n",
            "          [-1.5393e-03, -3.1771e-03,  2.3601e-03, -2.2544e-03,  3.1365e-03],\n",
            "          [ 2.6386e-03,  1.7557e-03,  2.5959e-03,  7.0182e-03, -3.8354e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7244e-03, -1.0424e-03,  3.6992e-03,  6.0240e-03, -5.6248e-03],\n",
            "          [ 5.9102e-03,  1.1965e-03,  2.0812e-03,  3.3213e-03,  5.5158e-03],\n",
            "          [-5.9743e-04, -8.2589e-03, -5.5947e-04, -2.5476e-03,  3.5549e-04],\n",
            "          [-1.4625e-03, -2.2339e-03, -3.2771e-04,  9.0566e-03, -7.7073e-04],\n",
            "          [ 1.1847e-04, -1.4697e-03,  1.4924e-03,  6.4783e-03,  5.2001e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0014]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0226]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0014,  0.0226], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 4, 7] = -0.0013936746399849653\n",
            " somado na saída em [0, 1, 4, 7] = 0.022598762065172195\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 0\n",
            " alvo do kernel em x: x[0,0,15:20, 0:5]\n",
            " \n",
            " tensor([[0.5870, 0.8055, 0.7216, 0.9226, 0.1469],\n",
            "        [0.2687, 0.0378, 0.6399, 0.5489, 0.3048],\n",
            "        [0.5529, 0.6092, 0.0663, 0.3459, 0.0606],\n",
            "        [0.3012, 0.2169, 0.6647, 0.2981, 0.8370],\n",
            "        [0.5232, 0.3474, 0.7484, 0.4056, 0.3803]])\n",
            " produto: tensor([[[[-2.3936e-03,  2.6682e-04, -3.5836e-03,  3.4791e-03, -1.2516e-03],\n",
            "          [ 1.9699e-03, -2.7510e-04, -5.0878e-03, -3.4681e-03,  1.3805e-03],\n",
            "          [-2.0431e-03,  2.2798e-03, -5.6233e-04, -2.0985e-03, -2.2256e-04],\n",
            "          [-5.9197e-04, -1.6545e-03,  4.3524e-03, -7.0309e-04,  2.6867e-03],\n",
            "          [ 3.6997e-03,  6.4727e-04,  2.0464e-03,  3.9152e-03, -1.7153e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8593e-03, -3.5838e-03,  5.1566e-03,  7.3681e-03, -1.3543e-03],\n",
            "          [ 2.2939e-03,  1.8073e-04,  2.7886e-03,  2.2595e-03,  2.5339e-03],\n",
            "          [-7.3009e-04, -5.1522e-03, -1.9012e-04, -2.4359e-03,  4.0071e-05],\n",
            "          [-5.6241e-04, -1.1633e-03, -6.0435e-04,  2.8245e-03, -6.6020e-04],\n",
            "          [ 1.6611e-04, -5.4185e-04,  1.1765e-03,  3.6140e-03,  2.3257e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[0.0011]]],\n",
            "\n",
            "\n",
            "        [[[0.0176]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([0.0011, 0.0176], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 5, 0] = 0.0010725699830800295\n",
            " somado na saída em [0, 1, 5, 0] = 0.01760919764637947\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 1\n",
            " alvo do kernel em x: x[0,0,15:20, 3:8]\n",
            " \n",
            " tensor([[0.9226, 0.1469, 0.2380, 0.8381, 0.8017],\n",
            "        [0.5489, 0.3048, 0.9602, 0.7244, 0.4482],\n",
            "        [0.3459, 0.0606, 0.9691, 0.4308, 0.6637],\n",
            "        [0.2981, 0.8370, 0.5451, 0.5073, 0.7731],\n",
            "        [0.4056, 0.3803, 0.4641, 0.6467, 0.8383]])\n",
            " produto: tensor([[[[-3.7620e-03,  4.8659e-05, -1.1823e-03,  3.1607e-03, -6.8311e-03],\n",
            "          [ 4.0233e-03, -2.2155e-03, -7.6343e-03, -4.5775e-03,  2.0298e-03],\n",
            "          [-1.2780e-03,  2.2683e-04, -8.2248e-03, -2.6139e-03, -2.4369e-03],\n",
            "          [-5.8589e-04, -6.3853e-03,  3.5691e-03, -1.1964e-03,  2.4815e-03],\n",
            "          [ 2.8683e-03,  7.0858e-04,  1.2691e-03,  6.2423e-03, -3.7807e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.9222e-03, -6.5356e-04,  1.7012e-03,  6.6938e-03, -7.3916e-03],\n",
            "          [ 4.6853e-03,  1.4555e-03,  4.1844e-03,  2.9822e-03,  3.7258e-03],\n",
            "          [-4.5668e-04, -5.1262e-04, -2.7807e-03, -3.0341e-03,  4.3874e-04],\n",
            "          [-5.5664e-04, -4.4896e-03, -4.9559e-04,  4.8063e-03, -6.0978e-04],\n",
            "          [ 1.2878e-04, -5.9317e-04,  7.2958e-04,  5.7622e-03,  5.1259e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0261]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0238]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0261,  0.0238], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 5, 1] = -0.0260761845856905\n",
            " somado na saída em [0, 1, 5, 1] = 0.023767827078700066\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 2\n",
            " alvo do kernel em x: x[0,0,15:20, 6:11]\n",
            " \n",
            " tensor([[0.8381, 0.8017, 0.6716, 0.8080, 0.9115],\n",
            "        [0.7244, 0.4482, 0.1285, 0.4957, 0.2653],\n",
            "        [0.4308, 0.6637, 0.1643, 0.3637, 0.8209],\n",
            "        [0.5073, 0.7731, 0.3584, 0.0426, 0.8456],\n",
            "        [0.6467, 0.8383, 0.7701, 0.7831, 0.5132]])\n",
            " produto: tensor([[[[-0.0034,  0.0003, -0.0033,  0.0030, -0.0078],\n",
            "          [ 0.0053, -0.0033, -0.0010, -0.0031,  0.0012],\n",
            "          [-0.0016,  0.0025, -0.0014, -0.0022, -0.0030],\n",
            "          [-0.0010, -0.0059,  0.0023, -0.0001,  0.0027],\n",
            "          [ 0.0046,  0.0016,  0.0021,  0.0076, -0.0023]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0027, -0.0036,  0.0048,  0.0065, -0.0084],\n",
            "          [ 0.0062,  0.0021,  0.0006,  0.0020,  0.0022],\n",
            "          [-0.0006, -0.0056, -0.0005, -0.0026,  0.0005],\n",
            "          [-0.0009, -0.0041, -0.0003,  0.0004, -0.0007],\n",
            "          [ 0.0002, -0.0013,  0.0012,  0.0070,  0.0031]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0063]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0109]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0063,  0.0109], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 5, 2] = -0.006278761196881533\n",
            " somado na saída em [0, 1, 5, 2] = 0.010935643687844276\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 3\n",
            " alvo do kernel em x: x[0,0,15:20, 9:14]\n",
            " \n",
            " tensor([[0.8080, 0.9115, 0.0670, 0.6109, 0.1301],\n",
            "        [0.4957, 0.2653, 0.8149, 0.3625, 0.9895],\n",
            "        [0.3637, 0.8209, 0.3298, 0.3835, 0.1113],\n",
            "        [0.0426, 0.8456, 0.8448, 0.2694, 0.8500],\n",
            "        [0.7831, 0.5132, 0.8742, 0.5699, 0.5484]])\n",
            " produto: tensor([[[[-3.2949e-03,  3.0194e-04, -3.3264e-04,  2.3038e-03, -1.1086e-03],\n",
            "          [ 3.6336e-03, -1.9286e-03, -6.4784e-03, -2.2909e-03,  4.4812e-03],\n",
            "          [-1.3440e-03,  3.0719e-03, -2.7992e-03, -2.3268e-03, -4.0865e-04],\n",
            "          [-8.3640e-05, -6.4509e-03,  5.5317e-03, -6.3542e-04,  2.7283e-03],\n",
            "          [ 5.5376e-03,  9.5612e-04,  2.3906e-03,  5.5008e-03, -2.4732e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.5594e-03, -4.0555e-03,  4.7863e-04,  4.8791e-03, -1.1996e-03],\n",
            "          [ 4.2314e-03,  1.2671e-03,  3.5509e-03,  1.4925e-03,  8.2254e-03],\n",
            "          [-4.8027e-04, -6.9423e-03, -9.4637e-04, -2.7009e-03,  7.3573e-05],\n",
            "          [-7.9464e-05, -4.5358e-03, -7.6810e-04,  2.5527e-03, -6.7041e-04],\n",
            "          [ 2.4863e-04, -8.0039e-04,  1.3744e-03,  5.0777e-03,  3.3533e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[0.0045]]],\n",
            "\n",
            "\n",
            "        [[[0.0162]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([0.0045, 0.0162], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 5, 3] = 0.004481729585677385\n",
            " somado na saída em [0, 1, 5, 3] = 0.0161856971681118\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 4\n",
            " alvo do kernel em x: x[0,0,15:20, 12:17]\n",
            " \n",
            " tensor([[0.6109, 0.1301, 0.8512, 0.7878, 0.8646],\n",
            "        [0.3625, 0.9895, 0.9265, 0.5831, 0.5604],\n",
            "        [0.3835, 0.1113, 0.1272, 0.5285, 0.6189],\n",
            "        [0.2694, 0.8500, 0.4433, 0.1235, 0.9369],\n",
            "        [0.5699, 0.5484, 0.9828, 0.0514, 0.0972]])\n",
            " produto: tensor([[[[-2.4911e-03,  4.3099e-05, -4.2275e-03,  2.9708e-03, -7.3669e-03],\n",
            "          [ 2.6576e-03, -7.1919e-03, -7.3658e-03, -3.6843e-03,  2.5379e-03],\n",
            "          [-1.4170e-03,  4.1648e-04, -1.0797e-03, -3.2062e-03, -2.2726e-03],\n",
            "          [-5.2950e-04, -6.4840e-03,  2.9025e-03, -2.9118e-04,  3.0073e-03],\n",
            "          [ 4.0299e-03,  1.0217e-03,  2.6875e-03,  4.9628e-04, -4.3848e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9351e-03, -5.7889e-04,  6.0830e-03,  6.2916e-03, -7.9714e-03],\n",
            "          [ 3.0949e-03,  4.7249e-03,  4.0372e-03,  2.4003e-03,  4.6584e-03],\n",
            "          [-5.0636e-04, -9.4121e-04, -3.6505e-04, -3.7218e-03,  4.0916e-04],\n",
            "          [-5.0306e-04, -4.5591e-03, -4.0302e-04,  1.1698e-03, -7.3898e-04],\n",
            "          [ 1.8094e-04, -8.5525e-04,  1.5450e-03,  4.5811e-04,  5.9451e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0253]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0164]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0253,  0.0164], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 5, 4] = -0.02527528628706932\n",
            " somado na saída em [0, 1, 5, 4] = 0.016438882797956467\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 5\n",
            " alvo do kernel em x: x[0,0,15:20, 15:20]\n",
            " \n",
            " tensor([[0.7878, 0.8646, 0.2197, 0.5026, 0.9169],\n",
            "        [0.5831, 0.5604, 0.0012, 0.8917, 0.9111],\n",
            "        [0.5285, 0.6189, 0.6242, 0.3184, 0.6388],\n",
            "        [0.1235, 0.9369, 0.0123, 0.0822, 0.5987],\n",
            "        [0.0514, 0.0972, 0.8222, 0.3523, 0.2428]])\n",
            " produto: tensor([[[[-3.2124e-03,  2.8640e-04, -1.0910e-03,  1.8956e-03, -7.8129e-03],\n",
            "          [ 4.2741e-03, -4.0731e-03, -9.5658e-06, -5.6348e-03,  4.1263e-03],\n",
            "          [-1.9526e-03,  2.3162e-03, -5.2974e-03, -1.9316e-03, -2.3455e-03],\n",
            "          [-2.4265e-04, -7.1473e-03,  8.0742e-05, -1.9374e-04,  1.9217e-03],\n",
            "          [ 3.6357e-04,  1.8113e-04,  2.2483e-03,  3.4010e-03, -1.0952e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.4953e-03, -3.8468e-03,  1.5699e-03,  4.0144e-03, -8.4540e-03],\n",
            "          [ 4.9773e-03,  2.6759e-03,  5.2431e-06,  3.6710e-03,  7.5740e-03],\n",
            "          [-6.9777e-04, -5.2344e-03, -1.7910e-03, -2.2421e-03,  4.2228e-04],\n",
            "          [-2.3053e-04, -5.0254e-03, -1.1212e-05,  7.7829e-04, -4.7222e-04],\n",
            "          [ 1.6324e-05, -1.5163e-04,  1.2925e-03,  3.1394e-03,  1.4849e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0209]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0060]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0209,  0.0060], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 5, 5] = -0.020944537594914436\n",
            " somado na saída em [0, 1, 5, 5] = 0.005959858186542988\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 6\n",
            " alvo do kernel em x: x[0,0,15:20, 18:23]\n",
            " \n",
            " tensor([[0.5026, 0.9169, 0.2716, 0.7833, 0.4165],\n",
            "        [0.8917, 0.9111, 0.2340, 0.3731, 0.9424],\n",
            "        [0.3184, 0.6388, 0.1866, 0.8223, 0.0226],\n",
            "        [0.0822, 0.5987, 0.8644, 0.3956, 0.1831],\n",
            "        [0.3523, 0.2428, 0.1038, 0.4002, 0.7338]])\n",
            " produto: tensor([[[[-2.0497e-03,  3.0373e-04, -1.3489e-03,  2.9539e-03, -3.5486e-03],\n",
            "          [ 6.5368e-03, -6.6223e-03, -1.8602e-03, -2.3578e-03,  4.2680e-03],\n",
            "          [-1.1763e-03,  2.3904e-03, -1.5836e-03, -4.9890e-03, -8.2893e-05],\n",
            "          [-1.6144e-04, -4.5672e-03,  5.6598e-03, -9.3302e-04,  5.8781e-04],\n",
            "          [ 2.4916e-03,  4.5241e-04,  2.8381e-04,  3.8631e-03, -3.3097e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5921e-03, -4.0796e-03,  1.9410e-03,  6.2559e-03, -3.8398e-03],\n",
            "          [ 7.6122e-03,  4.3507e-03,  1.0196e-03,  1.5361e-03,  7.8339e-03],\n",
            "          [-4.2036e-04, -5.4022e-03, -5.3541e-04, -5.7911e-03,  1.4924e-05],\n",
            "          [-1.5338e-04, -3.2113e-03, -7.8589e-04,  3.7482e-03, -1.4444e-04],\n",
            "          [ 1.1187e-04, -3.7872e-04,  1.6316e-04,  3.5659e-03,  4.4874e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0048]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0195]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0048,  0.0195], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 5, 6] = -0.004799330607056618\n",
            " somado na saída em [0, 1, 5, 6] = 0.019490733742713928\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 7\n",
            " alvo do kernel em x: x[0,0,15:20, 21:26]\n",
            " \n",
            " tensor([[0.7833, 0.4165, 0.3604, 0.9559, 0.9772],\n",
            "        [0.3731, 0.9424, 0.9493, 0.7271, 0.0850],\n",
            "        [0.8223, 0.0226, 0.4928, 0.9972, 0.5046],\n",
            "        [0.3956, 0.1831, 0.6617, 0.1646, 0.2844],\n",
            "        [0.4002, 0.7338, 0.8931, 0.3488, 0.3107]])\n",
            " produto: tensor([[[[-3.1941e-03,  1.3796e-04, -1.7901e-03,  3.6050e-03, -8.3259e-03],\n",
            "          [ 2.7352e-03, -6.8496e-03, -7.5474e-03, -4.5943e-03,  3.8514e-04],\n",
            "          [-3.0383e-03,  8.4482e-05, -4.1826e-03, -6.0504e-03, -1.8529e-03],\n",
            "          [-7.7749e-04, -1.3970e-03,  4.3329e-03, -3.8822e-04,  9.1273e-04],\n",
            "          [ 2.8301e-03,  1.3672e-03,  2.4421e-03,  3.3670e-03, -1.4011e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.4811e-03, -1.8530e-03,  2.5758e-03,  7.6347e-03, -9.0091e-03],\n",
            "          [ 3.1852e-03,  4.5000e-03,  4.1368e-03,  2.9932e-03,  7.0694e-04],\n",
            "          [-1.0857e-03, -1.9092e-04, -1.4141e-03, -7.0232e-03,  3.3361e-04],\n",
            "          [-7.3867e-04, -9.8226e-04, -6.0164e-04,  1.5596e-03, -2.2428e-04],\n",
            "          [ 1.2707e-04, -1.1445e-03,  1.4040e-03,  3.1080e-03,  1.8997e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0292]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0124]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0292,  0.0124], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 5, 7] = -0.029189713299274445\n",
            " somado na saída em [0, 1, 5, 7] = 0.012378383427858353\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 0\n",
            " alvo do kernel em x: x[0,0,18:23, 0:5]\n",
            " \n",
            " tensor([[0.3012, 0.2169, 0.6647, 0.2981, 0.8370],\n",
            "        [0.5232, 0.3474, 0.7484, 0.4056, 0.3803],\n",
            "        [0.0743, 0.3453, 0.1975, 0.8564, 0.2783],\n",
            "        [0.6839, 0.4146, 0.0805, 0.0929, 0.6828],\n",
            "        [0.6645, 0.4220, 0.7127, 0.3802, 0.1408]])\n",
            " produto: tensor([[[[-1.2283e-03,  7.1839e-05, -3.3013e-03,  1.1243e-03, -7.1318e-03],\n",
            "          [ 3.8352e-03, -2.5252e-03, -5.9499e-03, -2.5630e-03,  1.7225e-03],\n",
            "          [-2.7439e-04,  1.2921e-03, -1.6761e-03, -5.1957e-03, -1.0217e-03],\n",
            "          [-1.3440e-03, -3.1629e-03,  5.2722e-04, -2.1916e-04,  2.1918e-03],\n",
            "          [ 4.6988e-03,  7.8618e-04,  1.9489e-03,  3.6701e-03, -6.3502e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 9.5413e-04, -9.6491e-04,  4.7503e-03,  2.3811e-03, -7.7170e-03],\n",
            "          [ 4.4661e-03,  1.6590e-03,  3.2612e-03,  1.6698e-03,  3.1617e-03],\n",
            "          [-9.8053e-05, -2.9200e-03, -5.6667e-04, -6.0311e-03,  1.8395e-04],\n",
            "          [-1.2769e-03, -2.2239e-03, -7.3208e-05,  8.8042e-04, -5.3859e-04],\n",
            "          [ 2.1097e-04, -6.5813e-04,  1.1205e-03,  3.3878e-03,  8.6098e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0144]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0059]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0144,  0.0059], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 6, 0] = -0.014359601773321629\n",
            " somado na saída em [0, 1, 6, 0] = 0.005879310891032219\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 1\n",
            " alvo do kernel em x: x[0,0,18:23, 3:8]\n",
            " \n",
            " tensor([[0.2981, 0.8370, 0.5451, 0.5073, 0.7731],\n",
            "        [0.4056, 0.3803, 0.4641, 0.6467, 0.8383],\n",
            "        [0.8564, 0.2783, 0.0369, 0.8507, 0.8377],\n",
            "        [0.0929, 0.6828, 0.5908, 0.8428, 0.3168],\n",
            "        [0.3802, 0.1408, 0.0066, 0.4132, 0.5380]])\n",
            " produto: tensor([[[[-1.2157e-03,  2.7726e-04, -2.7072e-03,  1.9132e-03, -6.5872e-03],\n",
            "          [ 2.9733e-03, -2.7644e-03, -3.6897e-03, -4.0864e-03,  3.7965e-03],\n",
            "          [-3.1642e-03,  1.0413e-03, -3.1286e-04, -5.1617e-03, -3.0758e-03],\n",
            "          [-1.8263e-04, -5.2091e-03,  3.8684e-03, -1.9876e-03,  1.0168e-03],\n",
            "          [ 2.6887e-03,  2.6232e-04,  1.8062e-05,  3.9880e-03, -2.4267e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 9.4434e-04, -3.7240e-03,  3.8954e-03,  4.0517e-03, -7.1277e-03],\n",
            "          [ 3.4625e-03,  1.8161e-03,  2.0223e-03,  2.6623e-03,  6.9685e-03],\n",
            "          [-1.1307e-03, -2.3532e-03, -1.0578e-04, -5.9916e-03,  5.5377e-04],\n",
            "          [-1.7351e-04, -3.6626e-03, -5.3715e-04,  7.9848e-03, -2.4985e-04],\n",
            "          [ 1.2072e-04, -2.1959e-04,  1.0384e-05,  3.6813e-03,  3.2901e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0207]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0162]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0207,  0.0162], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 6, 1] = -0.02072737365961075\n",
            " somado na saída em [0, 1, 6, 1] = 0.016188591718673706\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 2\n",
            " alvo do kernel em x: x[0,0,18:23, 6:11]\n",
            " \n",
            " tensor([[0.5073, 0.7731, 0.3584, 0.0426, 0.8456],\n",
            "        [0.6467, 0.8383, 0.7701, 0.7831, 0.5132],\n",
            "        [0.8507, 0.8377, 0.0824, 0.0919, 0.4202],\n",
            "        [0.8428, 0.3168, 0.1020, 0.9861, 0.9259],\n",
            "        [0.4132, 0.5380, 0.2704, 0.2187, 0.6690]])\n",
            " produto: tensor([[[[-2.0687e-03,  2.5609e-04, -1.7800e-03,  1.6050e-04, -7.2051e-03],\n",
            "          [ 4.7406e-03, -6.0929e-03, -6.1227e-03, -4.9483e-03,  2.3242e-03],\n",
            "          [-3.1434e-03,  3.1347e-03, -6.9970e-04, -5.5760e-04, -1.5427e-03],\n",
            "          [-1.6563e-03, -2.4165e-03,  6.6785e-04, -2.3255e-03,  2.9720e-03],\n",
            "          [ 2.9216e-03,  1.0024e-03,  7.3930e-04,  2.1111e-03, -3.0171e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6069e-03, -3.4396e-03,  2.5613e-03,  3.3991e-04, -7.7964e-03],\n",
            "          [ 5.5205e-03,  4.0028e-03,  3.3559e-03,  3.2238e-03,  4.2662e-03],\n",
            "          [-1.1233e-03, -7.0843e-03, -2.3656e-04, -6.4725e-04,  2.7775e-04],\n",
            "          [-1.5736e-03, -1.6991e-03, -9.2734e-05,  9.3422e-03, -7.3031e-04],\n",
            "          [ 1.3118e-04, -8.3914e-04,  4.2502e-04,  1.9487e-03,  4.0907e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0225]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0158]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0225,  0.0158], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 6, 2] = -0.022546064108610153\n",
            " somado na saída em [0, 1, 6, 2] = 0.015830688178539276\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 3\n",
            " alvo do kernel em x: x[0,0,18:23, 9:14]\n",
            " \n",
            " tensor([[0.0426, 0.8456, 0.8448, 0.2694, 0.8500],\n",
            "        [0.7831, 0.5132, 0.8742, 0.5699, 0.5484],\n",
            "        [0.0919, 0.4202, 0.8796, 0.7062, 0.1314],\n",
            "        [0.9861, 0.9259, 0.9400, 0.1858, 0.9539],\n",
            "        [0.2187, 0.6690, 0.1794, 0.5934, 0.5022]])\n",
            " produto: tensor([[[[-1.7355e-04,  2.8011e-04, -4.1958e-03,  1.0161e-03, -7.2421e-03],\n",
            "          [ 5.7405e-03, -3.7301e-03, -6.9506e-03, -3.6010e-03,  2.4836e-03],\n",
            "          [-3.3958e-04,  1.5723e-03, -7.4652e-03, -4.2846e-03, -4.8242e-04],\n",
            "          [-1.9379e-03, -7.0633e-03,  6.1550e-03, -4.3823e-04,  3.0620e-03],\n",
            "          [ 1.5466e-03,  1.2463e-03,  4.9052e-04,  5.7276e-03, -2.2649e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.3481e-04, -3.7623e-03,  6.0374e-03,  2.1519e-03, -7.8364e-03],\n",
            "          [ 6.6849e-03,  2.4506e-03,  3.8097e-03,  2.3460e-03,  4.5587e-03],\n",
            "          [-1.2135e-04, -3.5533e-03, -2.5239e-03, -4.9735e-03,  8.6854e-05],\n",
            "          [-1.8411e-03, -4.9664e-03, -8.5465e-04,  1.7605e-03, -7.5242e-04],\n",
            "          [ 6.9441e-05, -1.0433e-03,  2.8200e-04,  5.2870e-03,  3.0709e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0208]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0065]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0208,  0.0065], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 6, 3] = -0.02084878832101822\n",
            " somado na saída em [0, 1, 6, 3] = 0.006501953117549419\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 4\n",
            " alvo do kernel em x: x[0,0,18:23, 12:17]\n",
            " \n",
            " tensor([[0.2694, 0.8500, 0.4433, 0.1235, 0.9369],\n",
            "        [0.5699, 0.5484, 0.9828, 0.0514, 0.0972],\n",
            "        [0.7062, 0.1314, 0.8484, 0.5622, 0.7000],\n",
            "        [0.1858, 0.9539, 0.7355, 0.6471, 0.9995],\n",
            "        [0.5934, 0.5022, 0.9133, 0.8751, 0.1770]])\n",
            " produto: tensor([[[[-0.0011,  0.0003, -0.0022,  0.0005, -0.0080],\n",
            "          [ 0.0042, -0.0040, -0.0078, -0.0003,  0.0004],\n",
            "          [-0.0026,  0.0005, -0.0072, -0.0034, -0.0026],\n",
            "          [-0.0004, -0.0073,  0.0048, -0.0015,  0.0032],\n",
            "          [ 0.0042,  0.0009,  0.0025,  0.0084, -0.0008]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0009, -0.0038,  0.0032,  0.0010, -0.0086],\n",
            "          [ 0.0049,  0.0026,  0.0043,  0.0002,  0.0008],\n",
            "          [-0.0009, -0.0011, -0.0024, -0.0040,  0.0005],\n",
            "          [-0.0003, -0.0051, -0.0007,  0.0061, -0.0008],\n",
            "          [ 0.0002, -0.0008,  0.0014,  0.0078,  0.0011]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0192]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0063]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0192,  0.0063], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 6, 4] = -0.019207864999771118\n",
            " somado na saída em [0, 1, 6, 4] = 0.006330736912786961\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 5\n",
            " alvo do kernel em x: x[0,0,18:23, 15:20]\n",
            " \n",
            " tensor([[0.1235, 0.9369, 0.0123, 0.0822, 0.5987],\n",
            "        [0.0514, 0.0972, 0.8222, 0.3523, 0.2428],\n",
            "        [0.5622, 0.7000, 0.4247, 0.0742, 0.0962],\n",
            "        [0.6471, 0.9995, 0.4413, 0.3024, 0.3745],\n",
            "        [0.8751, 0.1770, 0.5928, 0.5778, 0.4477]])\n",
            " produto: tensor([[[[-5.0349e-04,  3.1034e-04, -6.1243e-05,  3.0980e-04, -5.1012e-03],\n",
            "          [ 3.7689e-04, -7.0665e-04, -6.5368e-03, -2.2264e-03,  1.0998e-03],\n",
            "          [-2.0771e-03,  2.6195e-03, -3.6045e-03, -4.5044e-04, -3.5334e-04],\n",
            "          [-1.2717e-03, -7.6246e-03,  2.8897e-03, -7.1320e-04,  1.2022e-03],\n",
            "          [ 6.1885e-03,  3.2985e-04,  1.6211e-03,  5.5768e-03, -2.0190e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 3.9110e-04, -4.1684e-03,  8.8124e-05,  6.5610e-04, -5.5198e-03],\n",
            "          [ 4.3889e-04,  4.6425e-04,  3.5828e-03,  1.4505e-03,  2.0187e-03],\n",
            "          [-7.4227e-04, -5.9199e-03, -1.2187e-03, -5.2286e-04,  6.3615e-05],\n",
            "          [-1.2082e-03, -5.3610e-03, -4.0125e-04,  2.8651e-03, -2.9542e-04],\n",
            "          [ 2.7786e-04, -2.7613e-04,  9.3197e-04,  5.1478e-03,  2.7374e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0107]]],\n",
            "\n",
            "\n",
            "        [[[-0.0045]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0107, -0.0045], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 6, 5] = -0.010725138708949089\n",
            " somado na saída em [0, 1, 6, 5] = -0.004519573878496885\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 6\n",
            " alvo do kernel em x: x[0,0,18:23, 18:23]\n",
            " \n",
            " tensor([[0.0822, 0.5987, 0.8644, 0.3956, 0.1831],\n",
            "        [0.3523, 0.2428, 0.1038, 0.4002, 0.7338],\n",
            "        [0.0742, 0.0962, 0.8626, 0.3439, 0.3000],\n",
            "        [0.3024, 0.3745, 0.3595, 0.0029, 0.1949],\n",
            "        [0.5778, 0.4477, 0.4334, 0.5618, 0.9661]])\n",
            " produto: tensor([[[[-3.3499e-04,  1.9831e-04, -4.2929e-03,  1.4920e-03, -1.5603e-03],\n",
            "          [ 2.5828e-03, -1.7650e-03, -8.2515e-04, -2.5289e-03,  3.3235e-03],\n",
            "          [-2.7432e-04,  3.6011e-04, -7.3214e-03, -2.0864e-03, -1.1016e-03],\n",
            "          [-5.9431e-04, -2.8572e-03,  2.3541e-03, -6.9457e-06,  6.2571e-04],\n",
            "          [ 4.0855e-03,  8.3402e-04,  1.1852e-03,  5.4229e-03, -4.3571e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.6021e-04, -2.6637e-03,  6.1772e-03,  3.1597e-03, -1.6884e-03],\n",
            "          [ 3.0078e-03,  1.1596e-03,  4.5227e-04,  1.6476e-03,  6.1004e-03],\n",
            "          [-9.8028e-05, -8.1383e-04, -2.4753e-03, -2.4219e-03,  1.9832e-04],\n",
            "          [-5.6464e-04, -2.0089e-03, -3.2688e-04,  2.7903e-05, -1.5375e-04],\n",
            "          [ 1.8344e-04, -6.9817e-04,  6.8138e-04,  5.0058e-03,  5.9075e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0074]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0201]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0074,  0.0201], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 6, 6] = -0.007442262955009937\n",
            " somado na saída em [0, 1, 6, 6] = 0.02005554735660553\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 7\n",
            " alvo do kernel em x: x[0,0,18:23, 21:26]\n",
            " \n",
            " tensor([[0.3956, 0.1831, 0.6617, 0.1646, 0.2844],\n",
            "        [0.4002, 0.7338, 0.8931, 0.3488, 0.3107],\n",
            "        [0.3439, 0.3000, 0.2462, 0.6714, 0.8969],\n",
            "        [0.0029, 0.1949, 0.3130, 0.8480, 0.0654],\n",
            "        [0.5618, 0.9661, 0.3418, 0.1073, 0.9870]])\n",
            " produto: tensor([[[[-1.6133e-03,  6.0660e-05, -3.2865e-03,  6.2080e-04, -2.4228e-03],\n",
            "          [ 2.9337e-03, -5.3338e-03, -7.1002e-03, -2.2041e-03,  1.4070e-03],\n",
            "          [-1.2706e-03,  1.1227e-03, -2.0894e-03, -4.0736e-03, -3.2930e-03],\n",
            "          [-5.7879e-06, -1.4871e-03,  2.0497e-03, -1.9998e-03,  2.0993e-04],\n",
            "          [ 3.9728e-03,  1.7999e-03,  9.3467e-04,  1.0355e-03, -4.4513e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2532e-03, -8.1476e-04,  4.7289e-03,  1.3147e-03, -2.6216e-03],\n",
            "          [ 3.4164e-03,  3.5042e-03,  3.8917e-03,  1.4360e-03,  2.5826e-03],\n",
            "          [-4.5406e-04, -2.5372e-03, -7.0640e-04, -4.7286e-03,  5.9288e-04],\n",
            "          [-5.4989e-06, -1.0456e-03, -2.8461e-04,  8.0338e-03, -5.1585e-05],\n",
            "          [ 1.7838e-04, -1.5067e-03,  5.3734e-04,  9.5586e-04,  6.0353e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0245]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0237]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0245,  0.0237], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 6, 7] = -0.024484099820256233\n",
            " somado na saída em [0, 1, 6, 7] = 0.02370462194085121\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 0\n",
            " alvo do kernel em x: x[0,0,21:26, 0:5]\n",
            " \n",
            " tensor([[0.6839, 0.4146, 0.0805, 0.0929, 0.6828],\n",
            "        [0.6645, 0.4220, 0.7127, 0.3802, 0.1408],\n",
            "        [0.5803, 0.7835, 0.0115, 0.8155, 0.8321],\n",
            "        [0.4647, 0.9978, 0.6899, 0.4651, 0.5745],\n",
            "        [0.6152, 0.2852, 0.8054, 0.7534, 0.8653]])\n",
            " produto: tensor([[[[-2.7888e-03,  1.3734e-04, -3.9990e-04,  3.5045e-04, -5.8181e-03],\n",
            "          [ 4.8709e-03, -3.0671e-03, -5.6665e-03, -2.4026e-03,  6.3768e-04],\n",
            "          [-2.1442e-03,  2.9319e-03, -9.8025e-05, -4.9478e-03, -3.0552e-03],\n",
            "          [-9.1326e-04, -7.6117e-03,  4.5173e-03, -1.0969e-03,  1.8442e-03],\n",
            "          [ 4.3501e-03,  5.3128e-04,  2.2023e-03,  7.2719e-03, -3.9024e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.1663e-03, -1.8447e-03,  5.7542e-04,  7.4219e-04, -6.2956e-03],\n",
            "          [ 5.6723e-03,  2.0150e-03,  3.1058e-03,  1.5653e-03,  1.1705e-03],\n",
            "          [-7.6625e-04, -6.6259e-03, -3.3141e-05, -5.7434e-03,  5.5006e-04],\n",
            "          [-8.6766e-04, -5.3520e-03, -6.2726e-04,  4.4064e-03, -4.5317e-04],\n",
            "          [ 1.9531e-04, -4.4474e-04,  1.2661e-03,  6.7125e-03,  5.2910e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0143]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0064]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0143,  0.0064], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 7, 0] = -0.014267239719629288\n",
            " somado na saída em [0, 1, 7, 0] = 0.00638057803735137\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 1\n",
            " alvo do kernel em x: x[0,0,21:26, 3:8]\n",
            " \n",
            " tensor([[0.0929, 0.6828, 0.5908, 0.8428, 0.3168],\n",
            "        [0.3802, 0.1408, 0.0066, 0.4132, 0.5380],\n",
            "        [0.8155, 0.8321, 0.4425, 0.9023, 0.3301],\n",
            "        [0.4651, 0.5745, 0.0738, 0.4326, 0.4611],\n",
            "        [0.7534, 0.8653, 0.4681, 0.8351, 0.6574]])\n",
            " produto: tensor([[[[-3.7895e-04,  2.2619e-04, -2.9342e-03,  3.1784e-03, -2.6990e-03],\n",
            "          [ 2.7872e-03, -1.0234e-03, -5.2513e-05, -2.6107e-03,  2.4368e-03],\n",
            "          [-3.0132e-03,  3.1137e-03, -3.7555e-03, -5.4745e-03, -1.2119e-03],\n",
            "          [-9.1403e-04, -4.3829e-03,  4.8332e-04, -1.0201e-03,  1.4801e-03],\n",
            "          [ 5.3273e-03,  1.6120e-03,  1.2801e-03,  8.0612e-03, -2.9650e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.9436e-04, -3.0380e-03,  4.2220e-03,  6.7312e-03, -2.9204e-03],\n",
            "          [ 3.2457e-03,  6.7234e-04,  2.8783e-05,  1.7009e-03,  4.4728e-03],\n",
            "          [-1.0768e-03, -7.0369e-03, -1.2697e-03, -6.3547e-03,  2.1819e-04],\n",
            "          [-8.6839e-04, -3.0817e-03, -6.7112e-05,  4.0982e-03, -3.6370e-04],\n",
            "          [ 2.3919e-04, -1.3495e-03,  7.3591e-04,  7.4411e-03,  4.0201e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0024]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0107]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0024,  0.0107], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 7, 1] = -0.002449585124850273\n",
            " somado na saída em [0, 1, 7, 1] = 0.01069384254515171\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 2\n",
            " alvo do kernel em x: x[0,0,21:26, 6:11]\n",
            " \n",
            " tensor([[0.8428, 0.3168, 0.1020, 0.9861, 0.9259],\n",
            "        [0.4132, 0.5380, 0.2704, 0.2187, 0.6690],\n",
            "        [0.9023, 0.3301, 0.1271, 0.4354, 0.4818],\n",
            "        [0.4326, 0.4611, 0.0410, 0.2284, 0.5011],\n",
            "        [0.8351, 0.6574, 0.2007, 0.1722, 0.2350]])\n",
            " produto: tensor([[[[-3.4368e-03,  1.0493e-04, -5.0656e-04,  3.7187e-03, -7.8892e-03],\n",
            "          [ 3.0286e-03, -3.9108e-03, -2.1495e-03, -1.3820e-03,  3.0297e-03],\n",
            "          [-3.3339e-03,  1.2351e-03, -1.0784e-03, -2.6414e-03, -1.7691e-03],\n",
            "          [-8.5009e-04, -3.5176e-03,  2.6826e-04, -5.3866e-04,  1.6084e-03],\n",
            "          [ 5.9056e-03,  1.2248e-03,  5.4868e-04,  1.6623e-03, -1.0599e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.6696e-03, -1.4093e-03,  7.2890e-04,  7.8755e-03, -8.5365e-03],\n",
            "          [ 3.5269e-03,  2.5693e-03,  1.1781e-03,  9.0037e-04,  5.5611e-03],\n",
            "          [-1.1914e-03, -2.7912e-03, -3.6461e-04, -3.0661e-03,  3.1852e-04],\n",
            "          [-8.0765e-04, -2.4733e-03, -3.7250e-05,  2.1639e-03, -3.9523e-04],\n",
            "          [ 2.6515e-04, -1.0253e-03,  3.1544e-04,  1.5345e-03,  1.4371e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0117]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0089]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0117,  0.0089], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 7, 2] = -0.01172877848148346\n",
            " somado na saída em [0, 1, 7, 2] = 0.008946401067078114\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 3\n",
            " alvo do kernel em x: x[0,0,21:26, 9:14]\n",
            " \n",
            " tensor([[0.9861, 0.9259, 0.9400, 0.1858, 0.9539],\n",
            "        [0.2187, 0.6690, 0.1794, 0.5934, 0.5022],\n",
            "        [0.4354, 0.4818, 0.9740, 0.3254, 0.4332],\n",
            "        [0.2284, 0.5011, 0.4256, 0.2185, 0.2625],\n",
            "        [0.1722, 0.2350, 0.9318, 0.3697, 0.5222]])\n",
            " produto: tensor([[[[-4.0210e-03,  3.0670e-04, -4.6685e-03,  7.0077e-04, -8.1280e-03],\n",
            "          [ 1.6032e-03, -4.8623e-03, -1.4262e-03, -3.7494e-03,  2.2744e-03],\n",
            "          [-1.6086e-03,  1.8030e-03, -8.2664e-03, -1.9742e-03, -1.5906e-03],\n",
            "          [-4.4887e-04, -3.8226e-03,  2.7866e-03, -5.1524e-04,  8.4248e-04],\n",
            "          [ 1.2178e-03,  4.3783e-04,  2.5479e-03,  3.5688e-03, -2.3553e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 3.1234e-03, -4.1195e-03,  6.7176e-03,  1.4841e-03, -8.7950e-03],\n",
            "          [ 1.8670e-03,  3.1944e-03,  7.8168e-04,  2.4428e-03,  4.1747e-03],\n",
            "          [-5.7484e-04, -4.0747e-03, -2.7948e-03, -2.2917e-03,  2.8637e-04],\n",
            "          [-4.2646e-04, -2.6877e-03, -3.8693e-04,  2.0699e-03, -2.0702e-04],\n",
            "          [ 5.4679e-05, -3.6652e-04,  1.4648e-03,  3.2943e-03,  3.1934e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0293]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0074]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0293,  0.0074], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 7, 3] = -0.029347747564315796\n",
            " somado na saída em [0, 1, 7, 3] = 0.007423884235322475\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 4\n",
            " alvo do kernel em x: x[0,0,21:26, 12:17]\n",
            " \n",
            " tensor([[0.1858, 0.9539, 0.7355, 0.6471, 0.9995],\n",
            "        [0.5934, 0.5022, 0.9133, 0.8751, 0.1770],\n",
            "        [0.3254, 0.4332, 0.8014, 0.1815, 0.1458],\n",
            "        [0.2185, 0.2625, 0.9541, 0.1997, 0.6482],\n",
            "        [0.3697, 0.5222, 0.4207, 0.2654, 0.3505]])\n",
            " produto: tensor([[[[-7.5775e-04,  3.1599e-04, -3.6528e-03,  2.4404e-03, -8.5160e-03],\n",
            "          [ 4.3497e-03, -3.6501e-03, -7.2612e-03, -5.5299e-03,  8.0185e-04],\n",
            "          [-1.2023e-03,  1.6211e-03, -6.8016e-03, -1.1014e-03, -5.3521e-04],\n",
            "          [-4.2935e-04, -2.0022e-03,  6.2475e-03, -4.7088e-04,  2.0807e-03],\n",
            "          [ 2.6145e-03,  9.7293e-04,  1.1505e-03,  2.5620e-03, -1.5810e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 5.8860e-04, -4.2442e-03,  5.2561e-03,  5.1682e-03, -9.2148e-03],\n",
            "          [ 5.0653e-03,  2.3980e-03,  3.9799e-03,  3.6028e-03,  1.4718e-03],\n",
            "          [-4.2965e-04, -3.6635e-03, -2.2996e-03, -1.2785e-03,  9.6360e-05],\n",
            "          [-4.0791e-04, -1.4078e-03, -8.6751e-04,  1.8917e-03, -5.1128e-04],\n",
            "          [ 1.1739e-04, -8.1446e-04,  6.6144e-04,  2.3649e-03,  2.1435e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0183]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0097]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0183,  0.0097], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 7, 4] = -0.018334869295358658\n",
            " somado na saída em [0, 1, 7, 4] = 0.009666807949543\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 5\n",
            " alvo do kernel em x: x[0,0,21:26, 15:20]\n",
            " \n",
            " tensor([[0.6471, 0.9995, 0.4413, 0.3024, 0.3745],\n",
            "        [0.8751, 0.1770, 0.5928, 0.5778, 0.4477],\n",
            "        [0.1815, 0.1458, 0.4893, 0.6895, 0.8526],\n",
            "        [0.1997, 0.6482, 0.6065, 0.4444, 0.3332],\n",
            "        [0.2654, 0.3505, 0.8529, 0.0761, 0.8144]])\n",
            " produto: tensor([[[[-2.6388e-03,  3.3107e-04, -2.1918e-03,  1.1405e-03, -3.1912e-03],\n",
            "          [ 6.4152e-03, -1.2869e-03, -4.7132e-03, -3.6507e-03,  2.0274e-03],\n",
            "          [-6.7076e-04,  5.4547e-04, -4.1525e-03, -4.1832e-03, -3.1304e-03],\n",
            "          [-3.9239e-04, -4.9449e-03,  3.9710e-03, -1.0480e-03,  1.0695e-03],\n",
            "          [ 1.8769e-03,  6.5307e-04,  2.3322e-03,  7.3429e-04, -3.6730e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.0497e-03, -4.4468e-03,  3.1538e-03,  2.4153e-03, -3.4531e-03],\n",
            "          [ 7.4707e-03,  8.4544e-04,  2.5834e-03,  2.3785e-03,  3.7214e-03],\n",
            "          [-2.3970e-04, -1.2327e-03, -1.4039e-03, -4.8558e-03,  5.6360e-04],\n",
            "          [-3.7280e-04, -3.4769e-03, -5.5139e-04,  4.2103e-03, -2.6281e-04],\n",
            "          [ 8.4270e-05, -5.4670e-04,  1.3408e-03,  6.7781e-04,  4.9799e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0188]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0156]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0188,  0.0156], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 7, 5] = -0.018771285191178322\n",
            " somado na saída em [0, 1, 7, 5] = 0.01563221774995327\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 6\n",
            " alvo do kernel em x: x[0,0,21:26, 18:23]\n",
            " \n",
            " tensor([[0.3024, 0.3745, 0.3595, 0.0029, 0.1949],\n",
            "        [0.5778, 0.4477, 0.4334, 0.5618, 0.9661],\n",
            "        [0.6895, 0.8526, 0.2484, 0.0402, 0.1985],\n",
            "        [0.4444, 0.3332, 0.1454, 0.2162, 0.9142],\n",
            "        [0.0761, 0.8144, 0.8095, 0.8956, 0.3598]])\n",
            " produto: tensor([[[[-1.2332e-03,  1.2406e-04, -1.7856e-03,  1.1107e-05, -1.6609e-03],\n",
            "          [ 4.2352e-03, -3.2538e-03, -3.4459e-03, -3.5500e-03,  4.3753e-03],\n",
            "          [-2.5475e-03,  3.1904e-03, -2.1084e-03, -2.4401e-04, -7.2872e-04],\n",
            "          [-8.7334e-04, -2.5418e-03,  9.5217e-04, -5.0995e-04,  2.9344e-03],\n",
            "          [ 5.3794e-04,  1.5172e-03,  2.2136e-03,  8.6452e-03, -1.6227e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 9.5792e-04, -1.6664e-03,  2.5693e-03,  2.3522e-05, -1.7972e-03],\n",
            "          [ 4.9320e-03,  2.1376e-03,  1.8887e-03,  2.3128e-03,  8.0310e-03],\n",
            "          [-9.1037e-04, -7.2101e-03, -7.1284e-04, -2.8324e-04,  1.3120e-04],\n",
            "          [-8.2974e-04, -1.7872e-03, -1.3221e-04,  2.0486e-03, -7.2106e-04],\n",
            "          [ 2.4153e-05, -1.2701e-03,  1.2726e-03,  7.9802e-03,  2.2001e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[0.0026]]],\n",
            "\n",
            "\n",
            "        [[[0.0192]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([0.0026, 0.0192], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 7, 6] = 0.0026306596118956804\n",
            " somado na saída em [0, 1, 7, 6] = 0.01918940618634224\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 7\n",
            " alvo do kernel em x: x[0,0,21:26, 21:26]\n",
            " \n",
            " tensor([[0.0029, 0.1949, 0.3130, 0.8480, 0.0654],\n",
            "        [0.5618, 0.9661, 0.3418, 0.1073, 0.9870],\n",
            "        [0.0402, 0.1985, 0.5810, 0.9573, 0.1618],\n",
            "        [0.2162, 0.9142, 0.3084, 0.0333, 0.7355],\n",
            "        [0.8956, 0.3598, 0.6429, 0.7729, 0.3297]])\n",
            " produto: tensor([[[[-1.2010e-05,  6.4571e-05, -1.5547e-03,  3.1979e-03, -5.5725e-04],\n",
            "          [ 4.1183e-03, -7.0219e-03, -2.7175e-03, -6.7787e-04,  4.4699e-03],\n",
            "          [-1.4860e-04,  7.4268e-04, -4.9309e-03, -5.8083e-03, -5.9407e-04],\n",
            "          [-4.2494e-04, -6.9739e-03,  2.0191e-03, -7.8539e-05,  2.3608e-03],\n",
            "          [ 6.3334e-03,  6.7032e-04,  1.7581e-03,  7.4607e-03, -1.4871e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 9.3289e-06, -8.6729e-04,  2.2371e-03,  6.7725e-03, -6.0298e-04],\n",
            "          [ 4.7959e-03,  4.6132e-03,  1.4895e-03,  4.4164e-04,  8.2047e-03],\n",
            "          [-5.3104e-05, -1.6784e-03, -1.6671e-03, -6.7421e-03,  1.0696e-04],\n",
            "          [-4.0373e-04, -4.9035e-03, -2.8037e-04,  3.1551e-04, -5.8011e-04],\n",
            "          [ 2.8436e-04, -5.6114e-04,  1.0107e-03,  6.8869e-03,  2.0162e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[0.0002]]],\n",
            "\n",
            "\n",
            "        [[[0.0208]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([0.0002, 0.0208], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 7, 7] = 0.000208310317248106\n",
            " somado na saída em [0, 1, 7, 7] = 0.020844556391239166\n",
            "\n",
            "ndx_amostra: 1\n",
            "\n",
            "ndx_in_channels: 0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 0\n",
            " alvo do kernel em x: x[1,0,0:5, 0:5]\n",
            " \n",
            " tensor([[0.6082, 0.3287, 0.8834, 0.4786, 0.5778],\n",
            "        [0.8919, 0.6539, 0.3631, 0.4467, 0.2111],\n",
            "        [0.4295, 0.3832, 0.0433, 0.4916, 0.9973],\n",
            "        [0.6656, 0.3397, 0.2799, 0.9612, 0.2968],\n",
            "        [0.9441, 0.6069, 0.7274, 0.9057, 0.9247]])\n",
            " produto: tensor([[[[-0.0025,  0.0001, -0.0044,  0.0018, -0.0049],\n",
            "          [ 0.0065, -0.0048, -0.0029, -0.0028,  0.0010],\n",
            "          [-0.0016,  0.0014, -0.0004, -0.0030, -0.0037],\n",
            "          [-0.0013, -0.0026,  0.0018, -0.0023,  0.0010],\n",
            "          [ 0.0067,  0.0011,  0.0020,  0.0087, -0.0042]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0019, -0.0015,  0.0063,  0.0038, -0.0053],\n",
            "          [ 0.0076,  0.0031,  0.0016,  0.0018,  0.0018],\n",
            "          [-0.0006, -0.0032, -0.0001, -0.0035,  0.0007],\n",
            "          [-0.0012, -0.0018, -0.0003,  0.0091, -0.0002],\n",
            "          [ 0.0003, -0.0009,  0.0011,  0.0081,  0.0057]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0090]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0342]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0090,  0.0342], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 0, 0] = -0.009022579528391361\n",
            " somado na saída em [1, 1, 0, 0] = 0.03422427177429199\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 1\n",
            " alvo do kernel em x: x[1,0,0:5, 3:8]\n",
            " \n",
            " tensor([[0.4786, 0.5778, 0.3406, 0.1141, 0.5673],\n",
            "        [0.4467, 0.2111, 0.2074, 0.3106, 0.8681],\n",
            "        [0.4916, 0.9973, 0.3895, 0.1751, 0.4259],\n",
            "        [0.9612, 0.2968, 0.1176, 0.0715, 0.4455],\n",
            "        [0.9057, 0.9247, 0.7503, 0.4703, 0.4557]])\n",
            " produto: tensor([[[[-0.0020,  0.0002, -0.0017,  0.0004, -0.0048],\n",
            "          [ 0.0033, -0.0015, -0.0016, -0.0020,  0.0039],\n",
            "          [-0.0018,  0.0037, -0.0033, -0.0011, -0.0016],\n",
            "          [-0.0019, -0.0023,  0.0008, -0.0002,  0.0014],\n",
            "          [ 0.0064,  0.0017,  0.0021,  0.0045, -0.0021]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0015, -0.0026,  0.0024,  0.0009, -0.0052],\n",
            "          [ 0.0038,  0.0010,  0.0009,  0.0013,  0.0072],\n",
            "          [-0.0006, -0.0084, -0.0011, -0.0012,  0.0003],\n",
            "          [-0.0018, -0.0016, -0.0001,  0.0007, -0.0004],\n",
            "          [ 0.0003, -0.0014,  0.0012,  0.0042,  0.0028]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[0.0007]]],\n",
            "\n",
            "\n",
            "        [[[0.0040]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([0.0007, 0.0040], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 0, 1] = 0.000729849562048912\n",
            " somado na saída em [1, 1, 0, 1] = 0.003962785471230745\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 2\n",
            " alvo do kernel em x: x[1,0,0:5, 6:11]\n",
            " \n",
            " tensor([[0.1141, 0.5673, 0.0831, 0.9683, 0.7009],\n",
            "        [0.3106, 0.8681, 0.7676, 0.2166, 0.2992],\n",
            "        [0.1751, 0.4259, 0.2837, 0.1579, 0.7146],\n",
            "        [0.0715, 0.4455, 0.9980, 0.9825, 0.5886],\n",
            "        [0.4703, 0.4557, 0.1217, 0.4824, 0.2845]])\n",
            " produto: tensor([[[[-0.0005,  0.0002, -0.0004,  0.0037, -0.0060],\n",
            "          [ 0.0023, -0.0063, -0.0061, -0.0014,  0.0014],\n",
            "          [-0.0006,  0.0016, -0.0024, -0.0010, -0.0026],\n",
            "          [-0.0001, -0.0034,  0.0065, -0.0023,  0.0019],\n",
            "          [ 0.0033,  0.0008,  0.0003,  0.0047, -0.0013]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0004, -0.0025,  0.0006,  0.0077, -0.0065],\n",
            "          [ 0.0027,  0.0041,  0.0033,  0.0009,  0.0025],\n",
            "          [-0.0002, -0.0036, -0.0008, -0.0011,  0.0005],\n",
            "          [-0.0001, -0.0024, -0.0009,  0.0093, -0.0005],\n",
            "          [ 0.0001, -0.0007,  0.0002,  0.0043,  0.0017]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0078]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0190]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0078,  0.0190], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 0, 2] = -0.007754089310765266\n",
            " somado na saída em [1, 1, 0, 2] = 0.019016478210687637\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 3\n",
            " alvo do kernel em x: x[1,0,0:5, 9:14]\n",
            " \n",
            " tensor([[0.9683, 0.7009, 0.5671, 0.4605, 0.0238],\n",
            "        [0.2166, 0.2992, 0.3729, 0.8711, 0.0155],\n",
            "        [0.1579, 0.7146, 0.6355, 0.2590, 0.7544],\n",
            "        [0.9825, 0.5886, 0.6393, 0.1672, 0.3405],\n",
            "        [0.4824, 0.2845, 0.6832, 0.2663, 0.0925]])\n",
            " produto: tensor([[[[-3.9483e-03,  2.3217e-04, -2.8164e-03,  1.7367e-03, -2.0286e-04],\n",
            "          [ 1.5878e-03, -2.1746e-03, -2.9651e-03, -5.5046e-03,  7.0313e-05],\n",
            "          [-5.8339e-04,  2.6742e-03, -5.3936e-03, -1.5712e-03, -2.7701e-03],\n",
            "          [-1.9307e-03, -4.4902e-03,  4.1863e-03, -3.9420e-04,  1.0929e-03],\n",
            "          [ 3.4110e-03,  5.3012e-04,  1.8681e-03,  2.5704e-03, -4.1709e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 3.0670e-03, -3.1185e-03,  4.0525e-03,  3.6780e-03, -2.1951e-04],\n",
            "          [ 1.8490e-03,  1.4287e-03,  1.6252e-03,  3.5862e-03,  1.2906e-04],\n",
            "          [-2.0848e-04, -6.0435e-03, -1.8235e-03, -1.8238e-03,  4.9873e-04],\n",
            "          [-1.8343e-03, -3.1571e-03, -5.8129e-04,  1.5836e-03, -2.6856e-04],\n",
            "          [ 1.5315e-04, -4.4377e-04,  1.0740e-03,  2.3727e-03,  5.6550e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0152]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0061]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0152,  0.0061], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 0, 3] = -0.015202385373413563\n",
            " somado na saída em [1, 1, 0, 3] = 0.0061409915797412395\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 4\n",
            " alvo do kernel em x: x[1,0,0:5, 12:17]\n",
            " \n",
            " tensor([[0.4605, 0.0238, 0.8237, 0.4264, 0.8838],\n",
            "        [0.8711, 0.0155, 0.3257, 0.7299, 0.2339],\n",
            "        [0.2590, 0.7544, 0.8678, 0.2583, 0.8059],\n",
            "        [0.1672, 0.3405, 0.5958, 0.7037, 0.5971],\n",
            "        [0.2663, 0.0925, 0.0368, 0.0938, 0.0085]])\n",
            " produto: tensor([[[[-1.8779e-03,  7.8866e-06, -4.0910e-03,  1.6082e-03, -7.5307e-03],\n",
            "          [ 6.3858e-03, -1.1284e-04, -2.5898e-03, -4.6123e-03,  1.0592e-03],\n",
            "          [-9.5684e-04,  2.8232e-03, -7.3650e-03, -1.5674e-03, -2.9589e-03],\n",
            "          [-3.2849e-04, -2.5974e-03,  3.9011e-03, -1.6596e-03,  1.9167e-03],\n",
            "          [ 1.8831e-03,  1.7229e-04,  1.0059e-04,  9.0589e-04, -3.8161e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4587e-03, -1.0593e-04,  5.8866e-03,  3.4058e-03, -8.1486e-03],\n",
            "          [ 7.4364e-03,  7.4135e-05,  1.4195e-03,  3.0049e-03,  1.9441e-03],\n",
            "          [-3.4193e-04, -6.3802e-03, -2.4901e-03, -1.8194e-03,  5.3273e-04],\n",
            "          [-3.1209e-04, -1.8263e-03, -5.4168e-04,  6.6672e-03, -4.7099e-04],\n",
            "          [ 8.4547e-05, -1.4423e-04,  5.7832e-05,  8.3621e-04,  5.1740e-05]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0175]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0103]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0175,  0.0103], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 0, 4] = -0.017522618174552917\n",
            " somado na saída em [1, 1, 0, 4] = 0.010279066860675812\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 5\n",
            " alvo do kernel em x: x[1,0,0:5, 15:20]\n",
            " \n",
            " tensor([[0.4264, 0.8838, 0.2565, 0.2929, 0.6653],\n",
            "        [0.7299, 0.2339, 0.7944, 0.6853, 0.4756],\n",
            "        [0.2583, 0.8059, 0.4724, 0.9721, 0.8547],\n",
            "        [0.7037, 0.5971, 0.7122, 0.6298, 0.3675],\n",
            "        [0.0938, 0.0085, 0.3702, 0.8290, 0.4571]])\n",
            " produto: tensor([[[[-1.7389e-03,  2.9276e-04, -1.2737e-03,  1.1047e-03, -5.6685e-03],\n",
            "          [ 5.3507e-03, -1.6998e-03, -6.3158e-03, -4.3302e-03,  2.1540e-03],\n",
            "          [-9.5452e-04,  3.0157e-03, -4.0098e-03, -5.8980e-03, -3.1382e-03],\n",
            "          [-1.3830e-03, -4.5553e-03,  4.6631e-03, -1.4853e-03,  1.1795e-03],\n",
            "          [ 6.6365e-04,  1.5764e-05,  1.0122e-03,  8.0023e-03, -2.0618e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.3507e-03, -3.9323e-03,  1.8328e-03,  2.3395e-03, -6.1337e-03],\n",
            "          [ 6.2310e-03,  1.1167e-03,  3.4617e-03,  2.8211e-03,  3.9538e-03],\n",
            "          [-3.4110e-04, -6.8152e-03, -1.3557e-03, -6.8463e-03,  5.6501e-04],\n",
            "          [-1.3139e-03, -3.2029e-03, -6.4750e-04,  5.9669e-03, -2.8984e-04],\n",
            "          [ 2.9797e-05, -1.3196e-05,  5.8193e-04,  7.3867e-03,  2.7954e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0171]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0095]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0171,  0.0095], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 0, 5] = -0.017058562487363815\n",
            " somado na saída em [1, 1, 0, 5] = 0.009541497565805912\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 6\n",
            " alvo do kernel em x: x[1,0,0:5, 18:23]\n",
            " \n",
            " tensor([[0.2929, 0.6653, 0.0685, 0.7829, 0.9162],\n",
            "        [0.6853, 0.4756, 0.5738, 0.1762, 0.3697],\n",
            "        [0.9721, 0.8547, 0.6103, 0.7801, 0.8129],\n",
            "        [0.6298, 0.3675, 0.5462, 0.0430, 0.7887],\n",
            "        [0.8290, 0.4571, 0.7265, 0.0622, 0.0128]])\n",
            " produto: tensor([[[[-1.1945e-03,  2.2037e-04, -3.4042e-04,  2.9525e-03, -7.8068e-03],\n",
            "          [ 5.0234e-03, -3.4570e-03, -4.5617e-03, -1.1132e-03,  1.6743e-03],\n",
            "          [-3.5919e-03,  3.1984e-03, -5.1795e-03, -4.7333e-03, -2.9847e-03],\n",
            "          [-1.2377e-03, -2.8033e-03,  3.5763e-03, -1.0133e-04,  2.5315e-03],\n",
            "          [ 5.8624e-03,  8.5169e-04,  1.9865e-03,  6.0056e-04, -5.7523e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 9.2785e-04, -2.9599e-03,  4.8983e-04,  6.2529e-03, -8.4474e-03],\n",
            "          [ 5.8499e-03,  2.2711e-03,  2.5003e-03,  7.2522e-04,  3.0733e-03],\n",
            "          [-1.2836e-03, -7.2282e-03, -1.7511e-03, -5.4944e-03,  5.3737e-04],\n",
            "          [-1.1759e-03, -1.9711e-03, -4.9658e-04,  4.0708e-04, -6.2207e-04],\n",
            "          [ 2.6322e-04, -7.1297e-04,  1.1420e-03,  5.5437e-04,  7.7991e-05]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0107]]],\n",
            "\n",
            "\n",
            "        [[[-0.0071]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0107, -0.0071], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 0, 6] = -0.010684750974178314\n",
            " somado na saída em [1, 1, 0, 6] = -0.007070690393447876\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 7\n",
            " alvo do kernel em x: x[1,0,0:5, 21:26]\n",
            " \n",
            " tensor([[0.7829, 0.9162, 0.3521, 0.9796, 0.1798],\n",
            "        [0.1762, 0.3697, 0.8489, 0.1646, 0.9050],\n",
            "        [0.7801, 0.8129, 0.7068, 0.2713, 0.3678],\n",
            "        [0.0430, 0.7887, 0.1111, 0.2627, 0.4115],\n",
            "        [0.0622, 0.0128, 0.5409, 0.7713, 0.3055]])\n",
            " produto: tensor([[[[-3.1926e-03,  3.0350e-04, -1.7489e-03,  3.6944e-03, -1.5324e-03],\n",
            "          [ 1.2914e-03, -2.6871e-03, -6.7489e-03, -1.0402e-03,  4.0988e-03],\n",
            "          [-2.8826e-03,  3.0419e-03, -5.9987e-03, -1.6461e-03, -1.3503e-03],\n",
            "          [-8.4441e-05, -6.0165e-03,  7.2722e-04, -6.1943e-04,  1.3210e-03],\n",
            "          [ 4.3997e-04,  2.3762e-05,  1.4791e-03,  7.4452e-03, -1.3777e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.4799e-03, -4.0765e-03,  2.5165e-03,  7.8240e-03, -1.6581e-03],\n",
            "          [ 1.5038e-03,  1.7653e-03,  3.6991e-03,  6.7767e-04,  7.5235e-03],\n",
            "          [-1.0301e-03, -6.8745e-03, -2.0281e-03, -1.9108e-03,  2.4311e-04],\n",
            "          [-8.0225e-05, -4.2303e-03, -1.0098e-04,  2.4884e-03, -3.2461e-04],\n",
            "          [ 1.9754e-05, -1.9892e-05,  8.5032e-04,  6.8725e-03,  1.8679e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0131]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0180]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0131,  0.0180], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 0, 7] = -0.01305957417935133\n",
            " somado na saída em [1, 1, 0, 7] = 0.017997853457927704\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 0\n",
            " alvo do kernel em x: x[1,0,3:8, 0:5]\n",
            " \n",
            " tensor([[0.6656, 0.3397, 0.2799, 0.9612, 0.2968],\n",
            "        [0.9441, 0.6069, 0.7274, 0.9057, 0.9247],\n",
            "        [0.3633, 0.4497, 0.6926, 0.2235, 0.7523],\n",
            "        [0.2143, 0.4318, 0.2741, 0.8009, 0.9363],\n",
            "        [0.2204, 0.0314, 0.7915, 0.5241, 0.1633]])\n",
            " produto: tensor([[[[-2.7144e-03,  1.1252e-04, -1.3903e-03,  3.6250e-03, -2.5291e-03],\n",
            "          [ 6.9204e-03, -4.4112e-03, -5.7829e-03, -5.7232e-03,  4.1878e-03],\n",
            "          [-1.3422e-03,  1.6829e-03, -5.8783e-03, -1.3563e-03, -2.7624e-03],\n",
            "          [-4.2116e-04, -3.2939e-03,  1.7945e-03, -1.8887e-03,  3.0055e-03],\n",
            "          [ 1.5587e-03,  5.8540e-05,  2.1644e-03,  5.0587e-03, -7.3639e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 2.1085e-03, -1.5113e-03,  2.0006e-03,  7.6771e-03, -2.7366e-03],\n",
            "          [ 8.0590e-03,  2.8981e-03,  3.1696e-03,  3.7287e-03,  7.6868e-03],\n",
            "          [-4.7964e-04, -3.8033e-03, -1.9874e-03, -1.5744e-03,  4.9734e-04],\n",
            "          [-4.0014e-04, -2.3160e-03, -2.4918e-04,  7.5875e-03, -7.3853e-04],\n",
            "          [ 6.9982e-05, -4.9005e-05,  1.2443e-03,  4.6695e-03,  9.9843e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0101]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0365]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0101,  0.0365], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 1, 0] = -0.01006152480840683\n",
            " somado na saída em [1, 1, 1, 0] = 0.0365498811006546\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 1\n",
            " alvo do kernel em x: x[1,0,3:8, 3:8]\n",
            " \n",
            " tensor([[0.9612, 0.2968, 0.1176, 0.0715, 0.4455],\n",
            "        [0.9057, 0.9247, 0.7503, 0.4703, 0.4557],\n",
            "        [0.2235, 0.7523, 0.3949, 0.0027, 0.6096],\n",
            "        [0.8009, 0.9363, 0.9886, 0.8045, 0.1761],\n",
            "        [0.5241, 0.1633, 0.1195, 0.2930, 0.6708]])\n",
            " produto: tensor([[[[-3.9197e-03,  9.8321e-05, -5.8391e-04,  2.6980e-04, -3.7958e-03],\n",
            "          [ 6.6394e-03, -6.7209e-03, -5.9656e-03, -2.9719e-03,  2.0639e-03],\n",
            "          [-8.2599e-04,  2.8153e-03, -3.3520e-03, -1.6102e-05, -2.2384e-03],\n",
            "          [-1.5739e-03, -7.1429e-03,  6.4731e-03, -1.8971e-03,  5.6530e-04],\n",
            "          [ 3.7059e-03,  3.0419e-04,  3.2667e-04,  2.8285e-03, -3.0252e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 3.0448e-03, -1.3206e-03,  8.4019e-04,  5.7139e-04, -4.1073e-03],\n",
            "          [ 7.7317e-03,  4.4155e-03,  3.2698e-03,  1.9362e-03,  3.7883e-03],\n",
            "          [-2.9517e-04, -6.3624e-03, -1.1333e-03, -1.8691e-05,  4.0300e-04],\n",
            "          [-1.4953e-03, -5.0223e-03, -8.9882e-04,  7.6214e-03, -1.3891e-04],\n",
            "          [ 1.6639e-04, -2.5465e-04,  1.8780e-04,  2.6110e-03,  4.1017e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0179]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0196]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0179,  0.0196], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 1, 1] = -0.017939001321792603\n",
            " somado na saída em [1, 1, 1, 1] = 0.01964167132973671\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 2\n",
            " alvo do kernel em x: x[1,0,3:8, 6:11]\n",
            " \n",
            " tensor([[0.0715, 0.4455, 0.9980, 0.9825, 0.5886],\n",
            "        [0.4703, 0.4557, 0.1217, 0.4824, 0.2845],\n",
            "        [0.0027, 0.6096, 0.9385, 0.3673, 0.1423],\n",
            "        [0.8045, 0.1761, 0.5097, 0.4730, 0.5628],\n",
            "        [0.2930, 0.6708, 0.6232, 0.8195, 0.5177]])\n",
            " produto: tensor([[[[-2.9174e-04,  1.4757e-04, -4.9569e-03,  3.7050e-03, -5.0152e-03],\n",
            "          [ 3.4477e-03, -3.3123e-03, -9.6780e-04, -3.0480e-03,  1.2887e-03],\n",
            "          [-9.8062e-06,  2.2813e-03, -7.9656e-03, -2.2286e-03, -5.2239e-04],\n",
            "          [-1.5809e-03, -1.3435e-03,  3.3376e-03, -1.1154e-03,  1.8066e-03],\n",
            "          [ 2.0722e-03,  1.2497e-03,  1.7041e-03,  7.9107e-03, -2.3349e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.2662e-04, -1.9820e-03,  7.1326e-03,  7.8465e-03, -5.4267e-03],\n",
            "          [ 4.0149e-03,  2.1761e-03,  5.3046e-04,  1.9858e-03,  2.3654e-03],\n",
            "          [-3.5043e-06, -5.1556e-03, -2.6931e-03, -2.5869e-03,  9.4052e-05],\n",
            "          [-1.5020e-03, -9.4465e-04, -4.6345e-04,  4.4809e-03, -4.4392e-04],\n",
            "          [ 9.3039e-05, -1.0461e-03,  9.7968e-04,  7.3022e-03,  3.1658e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0057]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0201]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0057,  0.0201], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 1, 2] = -0.005741964094340801\n",
            " somado na saída em [1, 1, 1, 2] = 0.020145926624536514\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 3\n",
            " alvo do kernel em x: x[1,0,3:8, 9:14]\n",
            " \n",
            " tensor([[0.9825, 0.5886, 0.6393, 0.1672, 0.3405],\n",
            "        [0.4824, 0.2845, 0.6832, 0.2663, 0.0925],\n",
            "        [0.3673, 0.1423, 0.6957, 0.8008, 0.7165],\n",
            "        [0.4730, 0.5628, 0.2998, 0.5782, 0.3526],\n",
            "        [0.8195, 0.5177, 0.0437, 0.7119, 0.4252]])\n",
            " produto: tensor([[[[-4.0063e-03,  1.9497e-04, -3.1753e-03,  6.3036e-04, -2.9011e-03],\n",
            "          [ 3.5359e-03, -2.0682e-03, -5.4313e-03, -1.6827e-03,  4.1883e-04],\n",
            "          [-1.3572e-03,  5.3241e-04, -5.9047e-03, -4.8586e-03, -2.6307e-03],\n",
            "          [-9.2947e-04, -4.2935e-03,  1.9631e-03, -1.3637e-03,  1.1318e-03],\n",
            "          [ 5.7953e-03,  9.6453e-04,  1.1936e-04,  6.8718e-03, -1.9175e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 3.1120e-03, -2.6188e-03,  4.5690e-03,  1.3350e-03, -3.1391e-03],\n",
            "          [ 4.1177e-03,  1.3587e-03,  2.9769e-03,  1.0963e-03,  7.6877e-04],\n",
            "          [-4.8500e-04, -1.2032e-03, -1.9963e-03, -5.6398e-03,  4.7363e-04],\n",
            "          [-8.8306e-04, -3.0188e-03, -2.7258e-04,  5.4784e-03, -2.7811e-04],\n",
            "          [ 2.6020e-04, -8.0743e-04,  6.8622e-05,  6.3432e-03,  2.5998e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0204]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0142]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0204,  0.0142], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 1, 3] = -0.02036168798804283\n",
            " somado na saída em [1, 1, 1, 3] = 0.014215882867574692\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 4\n",
            " alvo do kernel em x: x[1,0,3:8, 12:17]\n",
            " \n",
            " tensor([[0.1672, 0.3405, 0.5958, 0.7037, 0.5971],\n",
            "        [0.2663, 0.0925, 0.0368, 0.0938, 0.0085],\n",
            "        [0.8008, 0.7165, 0.5242, 0.3098, 0.6991],\n",
            "        [0.5782, 0.3526, 0.1289, 0.6350, 0.1601],\n",
            "        [0.7119, 0.4252, 0.2123, 0.9024, 0.3795]])\n",
            " produto: tensor([[[[-6.8161e-04,  1.1278e-04, -2.9590e-03,  2.6539e-03, -5.0879e-03],\n",
            "          [ 1.9520e-03, -6.7217e-04, -2.9247e-04, -5.9302e-04,  3.8321e-05],\n",
            "          [-2.9589e-03,  2.6811e-03, -4.4490e-03, -1.8799e-03, -2.5670e-03],\n",
            "          [-1.1364e-03, -2.6898e-03,  8.4406e-04, -1.4975e-03,  5.1389e-04],\n",
            "          [ 5.0343e-03,  7.9208e-04,  5.8042e-04,  8.7108e-03, -1.7116e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 5.2946e-04, -1.5149e-03,  4.2577e-03,  5.6204e-03, -5.5054e-03],\n",
            "          [ 2.2732e-03,  4.4160e-04,  1.6030e-04,  3.8636e-04,  7.0339e-05],\n",
            "          [-1.0574e-03, -6.0592e-03, -1.5042e-03, -2.1821e-03,  4.6216e-04],\n",
            "          [-1.0796e-03, -1.8913e-03, -1.1720e-04,  6.0158e-03, -1.2628e-04],\n",
            "          [ 2.2603e-04, -6.6307e-04,  3.3368e-04,  8.0407e-03,  2.3206e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0053]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0094]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0053,  0.0094], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 1, 4] = -0.005262437276542187\n",
            " somado na saída em [1, 1, 1, 4] = 0.00943792425096035\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 5\n",
            " alvo do kernel em x: x[1,0,3:8, 15:20]\n",
            " \n",
            " tensor([[0.7037, 0.5971, 0.7122, 0.6298, 0.3675],\n",
            "        [0.0938, 0.0085, 0.3702, 0.8290, 0.4571],\n",
            "        [0.3098, 0.6991, 0.4595, 0.3907, 0.7779],\n",
            "        [0.6350, 0.1601, 0.4915, 0.5033, 0.0505],\n",
            "        [0.9024, 0.3795, 0.7841, 0.2753, 0.3868]])\n",
            " produto: tensor([[[[-2.8697e-03,  1.9780e-04, -3.5370e-03,  2.3751e-03, -3.1310e-03],\n",
            "          [ 6.8796e-04, -6.1500e-05, -2.9430e-03, -5.2385e-03,  2.0704e-03],\n",
            "          [-1.1448e-03,  2.6162e-03, -3.9003e-03, -2.3706e-03, -2.8561e-03],\n",
            "          [-1.2479e-03, -1.2213e-03,  3.2181e-03, -1.1870e-03,  1.6215e-04],\n",
            "          [ 6.3815e-03,  7.0704e-04,  2.1440e-03,  2.6574e-03, -1.7447e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.2291e-03, -2.6567e-03,  5.0894e-03,  5.0300e-03, -3.3880e-03],\n",
            "          [ 8.0114e-04,  4.0404e-05,  1.6131e-03,  3.4129e-03,  3.8003e-03],\n",
            "          [-4.0911e-04, -5.9124e-03, -1.3187e-03, -2.7518e-03,  5.1422e-04],\n",
            "          [-1.1855e-03, -8.5873e-04, -4.4686e-04,  4.7686e-03, -3.9846e-05],\n",
            "          [ 2.8652e-04, -5.9188e-04,  1.2326e-03,  2.4530e-03,  2.3655e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0102]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0141]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0102,  0.0141], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 1, 5] = -0.010235849767923355\n",
            " somado na saída em [1, 1, 1, 5] = 0.014077320694923401\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 6\n",
            " alvo do kernel em x: x[1,0,3:8, 18:23]\n",
            " \n",
            " tensor([[0.6298, 0.3675, 0.5462, 0.0430, 0.7887],\n",
            "        [0.8290, 0.4571, 0.7265, 0.0622, 0.0128],\n",
            "        [0.3907, 0.7779, 0.2413, 0.7230, 0.6215],\n",
            "        [0.5033, 0.0505, 0.6921, 0.0685, 0.6277],\n",
            "        [0.2753, 0.3868, 0.3853, 0.3197, 0.5380]])\n",
            " produto: tensor([[[[-2.5682e-03,  1.2172e-04, -2.7126e-03,  1.6204e-04, -6.7199e-03],\n",
            "          [ 6.0771e-03, -3.3227e-03, -5.7756e-03, -3.9315e-04,  5.7763e-05],\n",
            "          [-1.4437e-03,  2.9108e-03, -2.0477e-03, -4.3868e-03, -2.2819e-03],\n",
            "          [-9.8915e-04, -3.8538e-04,  4.5316e-03, -1.6156e-04,  2.0148e-03],\n",
            "          [ 1.9468e-03,  7.2072e-04,  1.0537e-03,  3.0863e-03, -2.4263e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9949e-03, -1.6349e-03,  3.9032e-03,  3.4317e-04, -7.2713e-03],\n",
            "          [ 7.0770e-03,  2.1829e-03,  3.1657e-03,  2.5613e-04,  1.0603e-04],\n",
            "          [-5.1591e-04, -6.5783e-03, -6.9230e-04, -5.0921e-03,  4.1083e-04],\n",
            "          [-9.3977e-04, -2.7097e-04, -6.2924e-04,  6.4902e-04, -4.9509e-04],\n",
            "          [ 8.7409e-05, -6.0333e-04,  6.0575e-04,  2.8489e-03,  3.2896e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0129]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0022]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0129,  0.0022], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 1, 6] = -0.012931282632052898\n",
            " somado na saída em [1, 1, 1, 6] = 0.0021971617825329304\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 7\n",
            " alvo do kernel em x: x[1,0,3:8, 21:26]\n",
            " \n",
            " tensor([[0.0430, 0.7887, 0.1111, 0.2627, 0.4115],\n",
            "        [0.0622, 0.0128, 0.5409, 0.7713, 0.3055],\n",
            "        [0.7230, 0.6215, 0.6312, 0.2104, 0.7871],\n",
            "        [0.0685, 0.6277, 0.7880, 0.7282, 0.0600],\n",
            "        [0.3197, 0.5380, 0.5455, 0.6596, 0.8646]])\n",
            " produto: tensor([[[[-1.7521e-04,  2.6124e-04, -5.5160e-04,  9.9053e-04, -3.5066e-03],\n",
            "          [ 4.5608e-04, -9.2703e-05, -4.3003e-03, -4.8738e-03,  1.3834e-03],\n",
            "          [-2.6716e-03,  2.3256e-03, -5.3568e-03, -1.2763e-03, -2.8901e-03],\n",
            "          [-1.3463e-04, -4.7884e-03,  5.1600e-03, -1.7174e-03,  1.9271e-04],\n",
            "          [ 2.2610e-03,  1.0023e-03,  1.4918e-03,  6.3672e-03, -3.8992e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.3610e-04, -3.5089e-03,  7.9370e-04,  2.0977e-03, -3.7944e-03],\n",
            "          [ 5.3112e-04,  6.0903e-05,  2.3570e-03,  3.1753e-03,  2.5394e-03],\n",
            "          [-9.5469e-04, -5.2558e-03, -1.8111e-03, -1.4815e-03,  5.2033e-04],\n",
            "          [-1.2790e-04, -3.3668e-03, -7.1650e-04,  6.8994e-03, -4.7354e-05],\n",
            "          [ 1.0152e-04, -8.3901e-04,  8.5762e-04,  5.8774e-03,  5.2867e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0143]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0093]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0143,  0.0093], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 1, 7] = -0.014342792332172394\n",
            " somado na saída em [1, 1, 1, 7] = 0.009330281056463718\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 0\n",
            " alvo do kernel em x: x[1,0,6:11, 0:5]\n",
            " \n",
            " tensor([[0.2143, 0.4318, 0.2741, 0.8009, 0.9363],\n",
            "        [0.2204, 0.0314, 0.7915, 0.5241, 0.1633],\n",
            "        [0.3233, 0.9048, 0.5090, 0.5502, 0.1184],\n",
            "        [0.7873, 0.7164, 0.5037, 0.6412, 0.8473],\n",
            "        [0.8492, 0.1621, 0.6183, 0.5362, 0.7752]])\n",
            " produto: tensor([[[[-8.7391e-04,  1.4303e-04, -1.3612e-03,  3.0202e-03, -7.9780e-03],\n",
            "          [ 1.6157e-03, -2.2838e-04, -6.2929e-03, -3.3115e-03,  7.3947e-04],\n",
            "          [-1.1946e-03,  3.3860e-03, -4.3203e-03, -3.3382e-03, -4.3462e-04],\n",
            "          [-1.5471e-03, -5.4653e-03,  3.2983e-03, -1.5122e-03,  2.7198e-03],\n",
            "          [ 6.0052e-03,  3.0203e-04,  1.6906e-03,  5.1757e-03, -3.4964e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 6.7883e-04, -1.9211e-03,  1.9586e-03,  6.3963e-03, -8.6327e-03],\n",
            "          [ 1.8816e-03,  1.5004e-04,  3.4492e-03,  2.1575e-03,  1.3573e-03],\n",
            "          [-4.2690e-04, -7.6521e-03, -1.4607e-03, -3.8749e-03,  7.8249e-05],\n",
            "          [-1.4699e-03, -3.8428e-03, -4.5798e-04,  6.0751e-03, -6.6832e-04],\n",
            "          [ 2.6963e-04, -2.5283e-04,  9.7194e-04,  4.7776e-03,  4.7406e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0133]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0043]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0133,  0.0043], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 2, 0] = -0.013258698396384716\n",
            " somado na saída em [1, 1, 2, 0] = 0.004282189533114433\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 1\n",
            " alvo do kernel em x: x[1,0,6:11, 3:8]\n",
            " \n",
            " tensor([[0.8009, 0.9363, 0.9886, 0.8045, 0.1761],\n",
            "        [0.5241, 0.1633, 0.1195, 0.2930, 0.6708],\n",
            "        [0.5502, 0.1184, 0.5710, 0.9733, 0.7984],\n",
            "        [0.6412, 0.8473, 0.5324, 0.4217, 0.4210],\n",
            "        [0.5362, 0.7752, 0.1222, 0.4006, 0.6248]])\n",
            " produto: tensor([[[[-0.0033,  0.0003, -0.0049,  0.0030, -0.0015],\n",
            "          [ 0.0038, -0.0012, -0.0009, -0.0019,  0.0030],\n",
            "          [-0.0020,  0.0004, -0.0048, -0.0059, -0.0029],\n",
            "          [-0.0013, -0.0065,  0.0035, -0.0010,  0.0014],\n",
            "          [ 0.0038,  0.0014,  0.0003,  0.0039, -0.0028]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0025, -0.0042,  0.0071,  0.0064, -0.0016],\n",
            "          [ 0.0045,  0.0008,  0.0005,  0.0012,  0.0056],\n",
            "          [-0.0007, -0.0010, -0.0016, -0.0069,  0.0005],\n",
            "          [-0.0012, -0.0045, -0.0005,  0.0040, -0.0003],\n",
            "          [ 0.0002, -0.0012,  0.0002,  0.0036,  0.0038]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0160]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0171]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0160,  0.0171], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 2, 1] = -0.01597638800740242\n",
            " somado na saída em [1, 1, 2, 1] = 0.017081061378121376\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 2\n",
            " alvo do kernel em x: x[1,0,6:11, 6:11]\n",
            " \n",
            " tensor([[0.8045, 0.1761, 0.5097, 0.4730, 0.5628],\n",
            "        [0.2930, 0.6708, 0.6232, 0.8195, 0.5177],\n",
            "        [0.9733, 0.7984, 0.0968, 0.2017, 0.3258],\n",
            "        [0.4217, 0.4210, 0.8581, 0.0401, 0.5533],\n",
            "        [0.4006, 0.6248, 0.0880, 0.0660, 0.1810]])\n",
            " produto: tensor([[[[-3.2804e-03,  5.8337e-05, -2.5316e-03,  1.7836e-03, -4.7955e-03],\n",
            "          [ 2.1481e-03, -4.8754e-03, -4.9545e-03, -5.1786e-03,  2.3447e-03],\n",
            "          [-3.5961e-03,  2.9876e-03, -8.2198e-04, -1.2236e-03, -1.1961e-03],\n",
            "          [-8.2878e-04, -3.2116e-03,  5.6185e-03, -9.4460e-05,  1.7761e-03],\n",
            "          [ 2.8329e-03,  1.1641e-03,  2.4061e-04,  6.3745e-04, -8.1645e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 2.5481e-03, -7.8356e-04,  3.6428e-03,  3.7774e-03, -5.1890e-03],\n",
            "          [ 2.5015e-03,  3.2030e-03,  2.7156e-03,  3.3738e-03,  4.3037e-03],\n",
            "          [-1.2851e-03, -6.7517e-03, -2.7790e-04, -1.4204e-03,  2.1535e-04],\n",
            "          [-7.8740e-04, -2.2581e-03, -7.8016e-04,  3.7947e-04, -4.3643e-04],\n",
            "          [ 1.2719e-04, -9.7446e-04,  1.3833e-04,  5.8842e-04,  1.1070e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0158]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0077]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0158,  0.0077], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 2, 2] = -0.01581326499581337\n",
            " somado na saída em [1, 1, 2, 2] = 0.0076774246990680695\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 3\n",
            " alvo do kernel em x: x[1,0,6:11, 9:14]\n",
            " \n",
            " tensor([[0.4730, 0.5628, 0.2998, 0.5782, 0.3526],\n",
            "        [0.8195, 0.5177, 0.0437, 0.7119, 0.4252],\n",
            "        [0.2017, 0.3258, 0.1467, 0.4204, 0.9732],\n",
            "        [0.0401, 0.5533, 0.1137, 0.3734, 0.4479],\n",
            "        [0.0660, 0.1810, 0.5789, 0.4243, 0.6723]])\n",
            " produto: tensor([[[[-1.9286e-03,  1.8643e-04, -1.4890e-03,  2.1807e-03, -3.0043e-03],\n",
            "          [ 6.0076e-03, -3.7629e-03, -3.4704e-04, -4.4985e-03,  1.9255e-03],\n",
            "          [-7.4519e-04,  1.2191e-03, -1.2453e-03, -2.5508e-03, -3.5733e-03],\n",
            "          [-7.8714e-05, -4.2210e-03,  7.4445e-04, -8.8058e-04,  1.4377e-03],\n",
            "          [ 4.6699e-04,  3.3727e-04,  1.5829e-03,  4.0954e-03, -3.0320e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4981e-03, -2.5040e-03,  2.1425e-03,  4.6182e-03, -3.2508e-03],\n",
            "          [ 6.9960e-03,  2.4721e-03,  1.9022e-04,  2.9308e-03,  3.5343e-03],\n",
            "          [-2.6630e-04, -2.7550e-03, -4.2103e-04, -2.9610e-03,  6.4335e-04],\n",
            "          [-7.4784e-05, -2.9679e-03, -1.0337e-04,  3.5375e-03, -3.5329e-04],\n",
            "          [ 2.0968e-05, -2.8233e-04,  9.1001e-04,  3.7804e-03,  4.1109e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0112]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0214]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0112,  0.0214], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 2, 3] = -0.011173389852046967\n",
            " somado na saída em [1, 1, 2, 3] = 0.021445641294121742\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 4\n",
            " alvo do kernel em x: x[1,0,6:11, 12:17]\n",
            " \n",
            " tensor([[0.5782, 0.3526, 0.1289, 0.6350, 0.1601],\n",
            "        [0.7119, 0.4252, 0.2123, 0.9024, 0.3795],\n",
            "        [0.4204, 0.9732, 0.6671, 0.6361, 0.3680],\n",
            "        [0.3734, 0.4479, 0.4630, 0.2687, 0.7386],\n",
            "        [0.4243, 0.6723, 0.0261, 0.2146, 0.0651]])\n",
            " produto: tensor([[[[-2.3580e-03,  1.1680e-04, -6.4022e-04,  2.3946e-03, -1.3641e-03],\n",
            "          [ 5.2186e-03, -3.0902e-03, -1.6875e-03, -5.7023e-03,  1.7188e-03],\n",
            "          [-1.5534e-03,  3.6418e-03, -5.6620e-03, -3.8593e-03, -1.3513e-03],\n",
            "          [-7.3379e-04, -3.4169e-03,  3.0317e-03, -6.3374e-04,  2.3710e-03],\n",
            "          [ 3.0003e-03,  1.2525e-03,  7.1282e-05,  2.0712e-03, -2.9345e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8316e-03, -1.5688e-03,  9.2122e-04,  5.0713e-03, -1.4760e-03],\n",
            "          [ 6.0772e-03,  2.0302e-03,  9.2495e-04,  3.7151e-03,  3.1548e-03],\n",
            "          [-5.5513e-04, -8.2303e-03, -1.9143e-03, -4.4798e-03,  2.4330e-04],\n",
            "          [-6.9715e-04, -2.4025e-03, -4.2097e-04,  2.5459e-03, -5.8261e-04],\n",
            "          [ 1.3471e-04, -1.0485e-03,  4.0980e-05,  1.9119e-03,  3.9787e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0075]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0056]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0075,  0.0056], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 2, 4] = -0.007457686588168144\n",
            " somado na saída em [1, 1, 2, 4] = 0.00562505004927516\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 5\n",
            " alvo do kernel em x: x[1,0,6:11, 15:20]\n",
            " \n",
            " tensor([[0.6350, 0.1601, 0.4915, 0.5033, 0.0505],\n",
            "        [0.9024, 0.3795, 0.7841, 0.2753, 0.3868],\n",
            "        [0.6361, 0.3680, 0.1596, 0.7024, 0.4539],\n",
            "        [0.2687, 0.7386, 0.1300, 0.2547, 0.9303],\n",
            "        [0.2146, 0.0651, 0.2332, 0.0755, 0.4111]])\n",
            " produto: tensor([[[[-2.5893e-03,  5.3031e-05, -2.4410e-03,  1.8981e-03, -4.3043e-04],\n",
            "          [ 6.6152e-03, -2.7584e-03, -6.2336e-03, -1.7396e-03,  1.7520e-03],\n",
            "          [-2.3503e-03,  1.3772e-03, -1.3546e-03, -4.2618e-03, -1.6668e-03],\n",
            "          [-5.2810e-04, -5.6349e-03,  8.5099e-04, -6.0063e-04,  2.9861e-03],\n",
            "          [ 1.5174e-03,  1.2122e-04,  6.3763e-04,  7.2833e-04, -1.8541e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.0113e-03, -7.1229e-04,  3.5123e-03,  4.0199e-03, -4.6575e-04],\n",
            "          [ 7.7035e-03,  1.8122e-03,  3.4167e-03,  1.1334e-03,  3.2159e-03],\n",
            "          [-8.3988e-04, -3.1125e-03, -4.5799e-04, -4.9471e-03,  3.0009e-04],\n",
            "          [-5.0174e-04, -3.9620e-03, -1.1816e-04,  2.4129e-03, -7.3375e-04],\n",
            "          [ 6.8128e-05, -1.0148e-04,  3.6657e-04,  6.7230e-04,  2.5139e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0159]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0172]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0159,  0.0172], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 2, 5] = -0.01590632274746895\n",
            " somado na saída em [1, 1, 2, 5] = 0.017206482589244843\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 6\n",
            " alvo do kernel em x: x[1,0,6:11, 18:23]\n",
            " \n",
            " tensor([[0.5033, 0.0505, 0.6921, 0.0685, 0.6277],\n",
            "        [0.2753, 0.3868, 0.3853, 0.3197, 0.5380],\n",
            "        [0.7024, 0.4539, 0.2483, 0.5217, 0.7501],\n",
            "        [0.2547, 0.9303, 0.9065, 0.6617, 0.8802],\n",
            "        [0.0755, 0.4111, 0.2329, 0.5863, 0.2917]])\n",
            " produto: tensor([[[[-2.0525e-03,  1.6734e-05, -3.4372e-03,  2.5834e-04, -5.3482e-03],\n",
            "          [ 2.0181e-03, -2.8118e-03, -3.0634e-03, -2.0204e-03,  2.4364e-03],\n",
            "          [-2.5954e-03,  1.6987e-03, -2.1071e-03, -3.1653e-03, -2.7543e-03],\n",
            "          [-5.0051e-04, -7.0967e-03,  5.9355e-03, -1.5606e-03,  2.8255e-03],\n",
            "          [ 5.3357e-04,  7.6592e-04,  6.3700e-04,  5.6591e-03, -1.3158e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5943e-03, -2.2476e-04,  4.9459e-03,  5.4712e-04, -5.7871e-03],\n",
            "          [ 2.3501e-03,  1.8473e-03,  1.6791e-03,  1.3163e-03,  4.4721e-03],\n",
            "          [-9.2749e-04, -3.8390e-03, -7.1240e-04, -3.6742e-03,  4.9588e-04],\n",
            "          [-4.7552e-04, -4.9898e-03, -8.2418e-04,  6.2694e-03, -6.9429e-04],\n",
            "          [ 2.3957e-05, -6.4117e-04,  3.6621e-04,  5.2238e-03,  1.7840e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0170]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0101]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0170,  0.0101], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 2, 6] = -0.017044417560100555\n",
            " somado na saída em [1, 1, 2, 6] = 0.01012543123215437\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 7\n",
            " alvo do kernel em x: x[1,0,6:11, 21:26]\n",
            " \n",
            " tensor([[0.0685, 0.6277, 0.7880, 0.7282, 0.0600],\n",
            "        [0.3197, 0.5380, 0.5455, 0.6596, 0.8646],\n",
            "        [0.5217, 0.7501, 0.0301, 0.8318, 0.6212],\n",
            "        [0.6617, 0.8802, 0.7936, 0.1525, 0.7205],\n",
            "        [0.5863, 0.2917, 0.6405, 0.6309, 0.8607]])\n",
            " produto: tensor([[[[-2.7935e-04,  2.0792e-04, -3.9139e-03,  2.7463e-03, -5.1154e-04],\n",
            "          [ 2.3438e-03, -3.9101e-03, -4.3372e-03, -4.1681e-03,  3.9155e-03],\n",
            "          [-1.9277e-03,  2.8071e-03, -2.5526e-04, -5.0466e-03, -2.2809e-03],\n",
            "          [-1.3005e-03, -6.7150e-03,  5.1963e-03, -3.5957e-04,  2.3127e-03],\n",
            "          [ 4.1458e-03,  5.4353e-04,  1.7515e-03,  6.0903e-03, -3.8818e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.1699e-04, -2.7927e-03,  5.6317e-03,  5.8161e-03, -5.5352e-04],\n",
            "          [ 2.7294e-03,  2.5688e-03,  2.3773e-03,  2.7155e-03,  7.1870e-03],\n",
            "          [-6.8886e-04, -6.3438e-03, -8.6303e-05, -5.8581e-03,  4.1065e-04],\n",
            "          [-1.2355e-03, -4.7215e-03, -7.2154e-04,  1.4445e-03, -5.6829e-04],\n",
            "          [ 1.8614e-04, -4.5500e-04,  1.0069e-03,  5.6218e-03,  5.2630e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0068]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0192]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0068,  0.0192], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 2, 7] = -0.006826831493526697\n",
            " somado na saída em [1, 1, 2, 7] = 0.01915096864104271\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 0\n",
            " alvo do kernel em x: x[1,0,9:14, 0:5]\n",
            " \n",
            " tensor([[0.7873, 0.7164, 0.5037, 0.6412, 0.8473],\n",
            "        [0.8492, 0.1621, 0.6183, 0.5362, 0.7752],\n",
            "        [0.0987, 0.9108, 0.2868, 0.9781, 0.9937],\n",
            "        [0.2726, 0.2797, 0.9908, 0.3172, 0.8545],\n",
            "        [0.8399, 0.3802, 0.4918, 0.8820, 0.5710]])\n",
            " produto: tensor([[[[-0.0032,  0.0002, -0.0025,  0.0024, -0.0072],\n",
            "          [ 0.0062, -0.0012, -0.0049, -0.0034,  0.0035],\n",
            "          [-0.0004,  0.0034, -0.0024, -0.0059, -0.0036],\n",
            "          [-0.0005, -0.0021,  0.0065, -0.0007,  0.0027],\n",
            "          [ 0.0059,  0.0007,  0.0013,  0.0085, -0.0026]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0025, -0.0032,  0.0036,  0.0051, -0.0078],\n",
            "          [ 0.0072,  0.0008,  0.0027,  0.0022,  0.0064],\n",
            "          [-0.0001, -0.0077, -0.0008, -0.0069,  0.0007],\n",
            "          [-0.0005, -0.0015, -0.0009,  0.0030, -0.0007],\n",
            "          [ 0.0003, -0.0006,  0.0008,  0.0079,  0.0035]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[0.0007]]],\n",
            "\n",
            "\n",
            "        [[[0.0159]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([0.0007, 0.0159], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 3, 0] = 0.0007486008107662201\n",
            " somado na saída em [1, 1, 3, 0] = 0.015916207805275917\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 1\n",
            " alvo do kernel em x: x[1,0,9:14, 3:8]\n",
            " \n",
            " tensor([[0.6412, 0.8473, 0.5324, 0.4217, 0.4210],\n",
            "        [0.5362, 0.7752, 0.1222, 0.4006, 0.6248],\n",
            "        [0.9781, 0.9937, 0.9264, 0.1717, 0.4932],\n",
            "        [0.3172, 0.8545, 0.3639, 0.6014, 0.1025],\n",
            "        [0.8820, 0.5710, 0.9608, 0.2574, 0.3218]])\n",
            " produto: tensor([[[[-2.6148e-03,  2.8067e-04, -2.6440e-03,  1.5904e-03, -3.5871e-03],\n",
            "          [ 3.9306e-03, -5.6348e-03, -9.7129e-04, -2.5314e-03,  2.8297e-03],\n",
            "          [-3.6140e-03,  3.7186e-03, -7.8630e-03, -1.0419e-03, -1.8110e-03],\n",
            "          [-6.2339e-04, -6.5185e-03,  2.3825e-03, -1.4182e-03,  3.2911e-04],\n",
            "          [ 6.2370e-03,  1.0638e-03,  2.6274e-03,  2.4842e-03, -1.4512e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.0311e-03, -3.7698e-03,  3.8045e-03,  3.3682e-03, -3.8814e-03],\n",
            "          [ 4.5772e-03,  3.7019e-03,  5.3237e-04,  1.6492e-03,  5.1941e-03],\n",
            "          [-1.2915e-03, -8.4037e-03, -2.6584e-03, -1.2095e-03,  3.2605e-04],\n",
            "          [-5.9227e-04, -4.5833e-03, -3.3082e-04,  5.6975e-03, -8.0870e-05],\n",
            "          [ 2.8003e-04, -8.9052e-04,  1.5105e-03,  2.2931e-03,  1.9676e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0149]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0092]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0149,  0.0092], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 3, 1] = -0.014850851148366928\n",
            " somado na saída em [1, 1, 3, 1] = 0.009241189807653427\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 2\n",
            " alvo do kernel em x: x[1,0,9:14, 6:11]\n",
            " \n",
            " tensor([[0.4217, 0.4210, 0.8581, 0.0401, 0.5533],\n",
            "        [0.4006, 0.6248, 0.0880, 0.0660, 0.1810],\n",
            "        [0.1717, 0.4932, 0.8865, 0.8172, 0.8094],\n",
            "        [0.6014, 0.1025, 0.5541, 0.5516, 0.1492],\n",
            "        [0.2574, 0.3218, 0.8626, 0.4978, 0.5905]])\n",
            " produto: tensor([[[[-1.7197e-03,  1.3945e-04, -4.2616e-03,  1.5105e-04, -4.7145e-03],\n",
            "          [ 2.9367e-03, -4.5414e-03, -6.9956e-04, -4.1730e-04,  8.1986e-04],\n",
            "          [-6.3454e-04,  1.8457e-03, -7.5236e-03, -4.9579e-03, -2.9719e-03],\n",
            "          [-1.1818e-03, -7.8216e-04,  3.6279e-03, -1.3009e-03,  4.7877e-04],\n",
            "          [ 1.8199e-03,  5.9948e-04,  2.3589e-03,  4.8049e-03, -2.6633e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.3358e-03, -1.8731e-03,  6.1321e-03,  3.1989e-04, -5.1014e-03],\n",
            "          [ 3.4198e-03,  2.9836e-03,  3.8343e-04,  2.7187e-04,  1.5049e-03],\n",
            "          [-2.2676e-04, -4.1712e-03, -2.5437e-03, -5.7550e-03,  5.3506e-04],\n",
            "          [-1.1228e-03, -5.4995e-04, -5.0375e-04,  5.2259e-03, -1.1765e-04],\n",
            "          [ 8.1713e-05, -5.0184e-04,  1.3561e-03,  4.4354e-03,  3.6110e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0188]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0091]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0188,  0.0091], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 3, 2] = -0.018787458539009094\n",
            " somado na saída em [1, 1, 3, 2] = 0.009129518643021584\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 3\n",
            " alvo do kernel em x: x[1,0,9:14, 9:14]\n",
            " \n",
            " tensor([[0.0401, 0.5533, 0.1137, 0.3734, 0.4479],\n",
            "        [0.0660, 0.1810, 0.5789, 0.4243, 0.6723],\n",
            "        [0.8172, 0.8094, 0.1320, 0.6076, 0.0339],\n",
            "        [0.5516, 0.1492, 0.1630, 0.3436, 0.1537],\n",
            "        [0.4978, 0.5905, 0.5245, 0.7699, 0.7739]])\n",
            " produto: tensor([[[[-1.6333e-04,  1.8328e-04, -5.6466e-04,  1.4081e-03, -3.8164e-03],\n",
            "          [ 4.8410e-04, -1.3158e-03, -4.6022e-03, -2.6810e-03,  3.0447e-03],\n",
            "          [-3.0193e-03,  3.0288e-03, -1.1201e-03, -3.6862e-03, -1.2438e-04],\n",
            "          [-1.0840e-03, -1.1378e-03,  1.0674e-03, -8.1042e-04,  4.9338e-04],\n",
            "          [ 3.5201e-03,  1.1002e-03,  1.4343e-03,  7.4314e-03, -3.4904e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2687e-04, -2.4618e-03,  8.1250e-04,  2.9821e-03, -4.1295e-03],\n",
            "          [ 5.6374e-04,  8.6443e-04,  2.5225e-03,  1.7467e-03,  5.5886e-03],\n",
            "          [-1.0790e-03, -6.8450e-03, -3.7869e-04, -4.2789e-03,  2.2394e-05],\n",
            "          [-1.0299e-03, -8.0004e-04, -1.4822e-04,  3.2557e-03, -1.2124e-04],\n",
            "          [ 1.5805e-04, -9.2098e-04,  8.2459e-04,  6.8598e-03,  4.7324e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0044]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0089]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0044,  0.0089], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 3, 3] = -0.004420206882059574\n",
            " somado na saída em [1, 1, 3, 3] = 0.008867211639881134\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 4\n",
            " alvo do kernel em x: x[1,0,9:14, 12:17]\n",
            " \n",
            " tensor([[0.3734, 0.4479, 0.4630, 0.2687, 0.7386],\n",
            "        [0.4243, 0.6723, 0.0261, 0.2146, 0.0651],\n",
            "        [0.6076, 0.0339, 0.5086, 0.5832, 0.3061],\n",
            "        [0.3436, 0.1537, 0.5418, 0.4395, 0.7671],\n",
            "        [0.7699, 0.7739, 0.9466, 0.6837, 0.3717]])\n",
            " produto: tensor([[[[-0.0015,  0.0001, -0.0023,  0.0010, -0.0063],\n",
            "          [ 0.0031, -0.0049, -0.0002, -0.0014,  0.0003],\n",
            "          [-0.0022,  0.0001, -0.0043, -0.0035, -0.0011],\n",
            "          [-0.0007, -0.0012,  0.0035, -0.0010,  0.0025],\n",
            "          [ 0.0054,  0.0014,  0.0026,  0.0066, -0.0017]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0012, -0.0020,  0.0033,  0.0021, -0.0068],\n",
            "          [ 0.0036,  0.0032,  0.0001,  0.0009,  0.0005],\n",
            "          [-0.0008, -0.0003, -0.0015, -0.0041,  0.0002],\n",
            "          [-0.0006, -0.0008, -0.0005,  0.0042, -0.0006],\n",
            "          [ 0.0002, -0.0012,  0.0015,  0.0061,  0.0023]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0056]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0102]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0056,  0.0102], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 3, 4] = -0.005573804024606943\n",
            " somado na saída em [1, 1, 3, 4] = 0.01024252362549305\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 5\n",
            " alvo do kernel em x: x[1,0,9:14, 15:20]\n",
            " \n",
            " tensor([[0.2687, 0.7386, 0.1300, 0.2547, 0.9303],\n",
            "        [0.2146, 0.0651, 0.2332, 0.0755, 0.4111],\n",
            "        [0.5832, 0.3061, 0.9248, 0.3211, 0.9655],\n",
            "        [0.4395, 0.7671, 0.8655, 0.9959, 0.4935],\n",
            "        [0.6837, 0.3717, 0.1778, 0.7179, 0.4353]])\n",
            " produto: tensor([[[[-0.0011,  0.0002, -0.0006,  0.0010, -0.0079],\n",
            "          [ 0.0016, -0.0005, -0.0019, -0.0005,  0.0019],\n",
            "          [-0.0022,  0.0011, -0.0078, -0.0019, -0.0035],\n",
            "          [-0.0009, -0.0059,  0.0057, -0.0023,  0.0016],\n",
            "          [ 0.0048,  0.0007,  0.0005,  0.0069, -0.0020]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0009, -0.0033,  0.0009,  0.0020, -0.0086],\n",
            "          [ 0.0018,  0.0003,  0.0010,  0.0003,  0.0034],\n",
            "          [-0.0008, -0.0026, -0.0027, -0.0023,  0.0006],\n",
            "          [-0.0008, -0.0041, -0.0008,  0.0094, -0.0004],\n",
            "          [ 0.0002, -0.0006,  0.0003,  0.0064,  0.0027]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0130]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0035]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0130,  0.0035], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 3, 5] = -0.01301596686244011\n",
            " somado na saída em [1, 1, 3, 5] = 0.0035003710072487593\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 6\n",
            " alvo do kernel em x: x[1,0,9:14, 18:23]\n",
            " \n",
            " tensor([[0.2547, 0.9303, 0.9065, 0.6617, 0.8802],\n",
            "        [0.0755, 0.4111, 0.2329, 0.5863, 0.2917],\n",
            "        [0.3211, 0.9655, 0.6252, 0.7171, 0.7896],\n",
            "        [0.9959, 0.4935, 0.9691, 0.0372, 0.9032],\n",
            "        [0.7179, 0.4353, 0.4370, 0.8129, 0.4393]])\n",
            " produto: tensor([[[[-1.0385e-03,  3.0815e-04, -4.5021e-03,  2.4955e-03, -7.5001e-03],\n",
            "          [ 5.5311e-04, -2.9881e-03, -1.8520e-03, -3.7046e-03,  1.3213e-03],\n",
            "          [-1.1864e-03,  3.6131e-03, -5.3063e-03, -4.3509e-03, -2.8992e-03],\n",
            "          [-1.9571e-03, -3.7648e-03,  6.3458e-03, -8.7699e-05,  2.8990e-03],\n",
            "          [ 5.0765e-03,  8.1098e-04,  1.1949e-03,  7.8461e-03, -1.9814e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 8.0672e-04, -4.1389e-03,  6.4781e-03,  5.2851e-03, -8.1156e-03],\n",
            "          [ 6.4411e-04,  1.9631e-03,  1.0151e-03,  2.4135e-03,  2.4252e-03],\n",
            "          [-4.2396e-04, -8.1654e-03, -1.7940e-03, -5.0505e-03,  5.2197e-04],\n",
            "          [-1.8594e-03, -2.6471e-03, -8.8115e-04,  3.5231e-04, -7.1237e-04],\n",
            "          [ 2.2793e-04, -6.7889e-04,  6.8694e-04,  7.2426e-03,  2.6864e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0107]]],\n",
            "\n",
            "\n",
            "        [[[-0.0017]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0107, -0.0017], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 3, 6] = -0.010654732584953308\n",
            " somado na saída em [1, 1, 3, 6] = -0.001717977225780487\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 7\n",
            " alvo do kernel em x: x[1,0,9:14, 21:26]\n",
            " \n",
            " tensor([[0.6617, 0.8802, 0.7936, 0.1525, 0.7205],\n",
            "        [0.5863, 0.2917, 0.6405, 0.6309, 0.8607],\n",
            "        [0.7171, 0.7896, 0.2264, 0.8426, 0.3073],\n",
            "        [0.0372, 0.9032, 0.6890, 0.5771, 0.4025],\n",
            "        [0.8129, 0.4393, 0.1373, 0.2292, 0.9033]])\n",
            " produto: tensor([[[[-2.6984e-03,  2.9158e-04, -3.9414e-03,  5.7498e-04, -6.1390e-03],\n",
            "          [ 4.2976e-03, -2.1205e-03, -5.0923e-03, -3.9869e-03,  3.8980e-03],\n",
            "          [-2.6497e-03,  2.9547e-03, -1.9217e-03, -5.1122e-03, -1.1284e-03],\n",
            "          [-7.3080e-05, -6.8898e-03,  4.5116e-03, -1.3609e-03,  1.2921e-03],\n",
            "          [ 5.7480e-03,  8.1848e-04,  3.7553e-04,  2.2128e-03, -4.0741e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.0961e-03, -3.9163e-03,  5.6713e-03,  1.2177e-03, -6.6428e-03],\n",
            "          [ 5.0047e-03,  1.3931e-03,  2.7911e-03,  2.5975e-03,  7.1549e-03],\n",
            "          [-9.4688e-04, -6.6775e-03, -6.4972e-04, -5.9342e-03,  2.0316e-04],\n",
            "          [-6.9432e-05, -4.8444e-03, -6.2645e-04,  5.4670e-03, -3.1751e-04],\n",
            "          [ 2.5808e-04, -6.8517e-04,  2.1589e-04,  2.0426e-03,  5.5238e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0202]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0103]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0202,  0.0103], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 3, 7] = -0.020213037729263306\n",
            " somado na saída em [1, 1, 3, 7] = 0.010326651856303215\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 0\n",
            " alvo do kernel em x: x[1,0,12:17, 0:5]\n",
            " \n",
            " tensor([[0.2726, 0.2797, 0.9908, 0.3172, 0.8545],\n",
            "        [0.8399, 0.3802, 0.4918, 0.8820, 0.5710],\n",
            "        [0.6827, 0.3600, 0.1761, 0.5760, 0.0492],\n",
            "        [0.3376, 0.4097, 0.2738, 0.0748, 0.3008],\n",
            "        [0.8359, 0.9849, 0.0314, 0.3695, 0.7972]])\n",
            " produto: tensor([[[[-1.1116e-03,  9.2633e-05, -4.9209e-03,  1.1963e-03, -7.2807e-03],\n",
            "          [ 6.1570e-03, -2.7637e-03, -3.9103e-03, -5.5732e-03,  2.5860e-03],\n",
            "          [-2.5226e-03,  1.3472e-03, -1.4943e-03, -3.4946e-03, -1.8081e-04],\n",
            "          [-6.6353e-04, -3.1255e-03,  1.7931e-03, -1.7649e-04,  9.6566e-04],\n",
            "          [ 5.9113e-03,  1.8350e-03,  8.5751e-05,  3.5670e-03, -3.5953e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 8.6347e-04, -1.2442e-03,  7.0807e-03,  2.5335e-03, -7.8781e-03],\n",
            "          [ 7.1699e-03,  1.8157e-03,  2.1433e-03,  3.6309e-03,  4.7466e-03],\n",
            "          [-9.0145e-04, -3.0446e-03, -5.0521e-04, -4.0565e-03,  3.2553e-05],\n",
            "          [-6.3040e-04, -2.1976e-03, -2.4898e-04,  7.0900e-04, -2.3729e-04],\n",
            "          [ 2.6541e-04, -1.5361e-03,  4.9298e-05,  3.2926e-03,  4.8746e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0153]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0167]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0153,  0.0167], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 4, 0] = -0.015276635065674782\n",
            " somado na saída em [1, 1, 4, 0] = 0.016727136448025703\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 1\n",
            " alvo do kernel em x: x[1,0,12:17, 3:8]\n",
            " \n",
            " tensor([[0.3172, 0.8545, 0.3639, 0.6014, 0.1025],\n",
            "        [0.8820, 0.5710, 0.9608, 0.2574, 0.3218],\n",
            "        [0.5760, 0.0492, 0.1270, 0.2299, 0.0634],\n",
            "        [0.0748, 0.3008, 0.7768, 0.2174, 0.8908],\n",
            "        [0.3695, 0.7972, 0.8224, 0.7026, 0.0274]])\n",
            " produto: tensor([[[[-1.2935e-03,  2.8304e-04, -1.8071e-03,  2.2679e-03, -8.7360e-04],\n",
            "          [ 6.4654e-03, -4.1502e-03, -7.6389e-03, -1.6263e-03,  1.4573e-03],\n",
            "          [-2.1282e-03,  1.8427e-04, -1.0780e-03, -1.3949e-03, -2.3268e-04],\n",
            "          [-1.4707e-04, -2.2950e-03,  5.0863e-03, -5.1267e-04,  2.8594e-03],\n",
            "          [ 2.6131e-03,  1.4852e-03,  2.2489e-03,  6.7815e-03, -1.2362e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0048e-03, -3.8017e-03,  2.6003e-03,  4.8030e-03, -9.4529e-04],\n",
            "          [ 7.5291e-03,  2.7265e-03,  4.1869e-03,  1.0595e-03,  2.6749e-03],\n",
            "          [-7.6052e-04, -4.1645e-04, -3.6445e-04, -1.6192e-03,  4.1891e-05],\n",
            "          [-1.3972e-04, -1.6137e-03, -7.0626e-04,  2.0595e-03, -7.0263e-04],\n",
            "          [ 1.1733e-04, -1.2433e-03,  1.2929e-03,  6.2599e-03,  1.6760e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[0.0064]]],\n",
            "\n",
            "\n",
            "        [[[0.0242]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([0.0064, 0.0242], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 4, 1] = 0.006430582609027624\n",
            " somado na saída em [1, 1, 4, 1] = 0.024210968986153603\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 2\n",
            " alvo do kernel em x: x[1,0,12:17, 6:11]\n",
            " \n",
            " tensor([[0.6014, 0.1025, 0.5541, 0.5516, 0.1492],\n",
            "        [0.2574, 0.3218, 0.8626, 0.4978, 0.5905],\n",
            "        [0.2299, 0.0634, 0.5779, 0.5465, 0.7795],\n",
            "        [0.2174, 0.8908, 0.3298, 0.7111, 0.4127],\n",
            "        [0.7026, 0.0274, 0.1784, 0.3501, 0.2224]])\n",
            " produto: tensor([[[[-2.4523e-03,  3.3962e-05, -2.7518e-03,  2.0802e-03, -1.2709e-03],\n",
            "          [ 1.8866e-03, -2.3388e-03, -6.8584e-03, -3.1455e-03,  2.6744e-03],\n",
            "          [-8.4951e-04,  2.3714e-04, -4.9052e-03, -3.3158e-03, -2.8620e-03],\n",
            "          [-4.2721e-04, -6.7957e-03,  2.1596e-03, -1.6769e-03,  1.3247e-03],\n",
            "          [ 4.9681e-03,  5.1064e-05,  4.8789e-04,  3.3790e-03, -1.0030e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9049e-03, -4.5617e-04,  3.9595e-03,  4.4054e-03, -1.3752e-03],\n",
            "          [ 2.1970e-03,  1.5365e-03,  3.7591e-03,  2.0493e-03,  4.9090e-03],\n",
            "          [-3.0357e-04, -5.3591e-04, -1.6584e-03, -3.8489e-03,  5.1528e-04],\n",
            "          [-4.0588e-04, -4.7782e-03, -2.9987e-04,  6.7366e-03, -3.2551e-04],\n",
            "          [ 2.2306e-04, -4.2747e-05,  2.8049e-04,  3.1191e-03,  1.3600e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0214]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0229]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0214,  0.0229], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 4, 2] = -0.021370284259319305\n",
            " somado na saída em [1, 1, 4, 2] = 0.022924838587641716\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 3\n",
            " alvo do kernel em x: x[1,0,12:17, 9:14]\n",
            " \n",
            " tensor([[0.5516, 0.1492, 0.1630, 0.3436, 0.1537],\n",
            "        [0.4978, 0.5905, 0.5245, 0.7699, 0.7739],\n",
            "        [0.5465, 0.7795, 0.7811, 0.3611, 0.2002],\n",
            "        [0.7111, 0.4127, 0.5049, 0.9601, 0.2528],\n",
            "        [0.3501, 0.2224, 0.6161, 0.9200, 0.0694]])\n",
            " produto: tensor([[[[-2.2493e-03,  4.9407e-05, -8.0966e-04,  1.2959e-03, -1.3097e-03],\n",
            "          [ 3.6490e-03, -4.2921e-03, -4.1702e-03, -4.8648e-03,  3.5050e-03],\n",
            "          [-2.0193e-03,  2.9169e-03, -6.6296e-03, -2.1906e-03, -7.3492e-04],\n",
            "          [-1.3974e-03, -3.1482e-03,  3.3060e-03, -2.2641e-03,  8.1158e-04],\n",
            "          [ 2.4754e-03,  4.1435e-04,  1.6848e-03,  8.8800e-03, -3.1287e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7472e-03, -6.6361e-04,  1.1650e-03,  2.7445e-03, -1.4171e-03],\n",
            "          [ 4.2493e-03,  2.8198e-03,  2.2857e-03,  3.1694e-03,  6.4336e-03],\n",
            "          [-7.2160e-04, -6.5919e-03, -2.2414e-03, -2.5428e-03,  1.3232e-04],\n",
            "          [-1.3276e-03, -2.2136e-03, -4.5905e-04,  9.0957e-03, -1.9943e-04],\n",
            "          [ 1.1114e-04, -3.4686e-04,  9.6857e-04,  8.1970e-03,  4.2421e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0074]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0248]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0074,  0.0248], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 4, 3] = -0.007404461037367582\n",
            " somado na saída em [1, 1, 4, 3] = 0.02481851540505886\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 4\n",
            " alvo do kernel em x: x[1,0,12:17, 12:17]\n",
            " \n",
            " tensor([[0.3436, 0.1537, 0.5418, 0.4395, 0.7671],\n",
            "        [0.7699, 0.7739, 0.9466, 0.6837, 0.3717],\n",
            "        [0.3611, 0.2002, 0.0695, 0.9485, 0.4718],\n",
            "        [0.9601, 0.2528, 0.6806, 0.1828, 0.7716],\n",
            "        [0.9200, 0.0694, 0.7988, 0.0248, 0.0444]])\n",
            " produto: tensor([[[[-1.4013e-03,  5.0915e-05, -2.6907e-03,  1.6576e-03, -6.5358e-03],\n",
            "          [ 5.6436e-03, -5.6251e-03, -7.5258e-03, -4.3199e-03,  1.6836e-03],\n",
            "          [-1.3341e-03,  7.4901e-04, -5.9004e-04, -5.7546e-03, -1.7324e-03],\n",
            "          [-1.8867e-03, -1.9288e-03,  4.4562e-03, -4.3109e-04,  2.4769e-03],\n",
            "          [ 6.5055e-03,  1.2924e-04,  2.1843e-03,  2.3970e-04, -2.0021e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0885e-03, -6.8387e-04,  3.8718e-03,  3.5104e-03, -7.0721e-03],\n",
            "          [ 6.5721e-03,  3.6956e-03,  4.1249e-03,  2.8144e-03,  3.0903e-03],\n",
            "          [-4.7674e-04, -1.6927e-03, -1.9949e-04, -6.6798e-03,  3.1191e-04],\n",
            "          [-1.7925e-03, -1.3562e-03, -6.1877e-04,  1.7318e-03, -6.0864e-04],\n",
            "          [ 2.9209e-04, -1.0819e-04,  1.2558e-03,  2.2126e-04,  2.7145e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0162]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0116]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0162,  0.0116], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 4, 4] = -0.01617998257279396\n",
            " somado na saída em [1, 1, 4, 4] = 0.011563225649297237\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 5\n",
            " alvo do kernel em x: x[1,0,12:17, 15:20]\n",
            " \n",
            " tensor([[0.4395, 0.7671, 0.8655, 0.9959, 0.4935],\n",
            "        [0.6837, 0.3717, 0.1778, 0.7179, 0.4353],\n",
            "        [0.9485, 0.4718, 0.3759, 0.0127, 0.0650],\n",
            "        [0.1828, 0.7716, 0.4357, 0.8552, 0.5799],\n",
            "        [0.0248, 0.0444, 0.7719, 0.5417, 0.7193]])\n",
            " produto: tensor([[[[-1.7923e-03,  2.5409e-04, -4.2988e-03,  3.7556e-03, -4.2049e-03],\n",
            "          [ 5.0115e-03, -2.7020e-03, -1.4132e-03, -4.5362e-03,  1.9714e-03],\n",
            "          [-3.5045e-03,  1.7656e-03, -3.1900e-03, -7.6829e-05, -2.3879e-04],\n",
            "          [-3.5923e-04, -5.8866e-03,  2.8530e-03, -2.0168e-03,  1.8613e-03],\n",
            "          [ 1.7560e-04,  8.2704e-05,  2.1109e-03,  5.2287e-03, -3.2440e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.3922e-03, -3.4128e-03,  6.1856e-03,  7.9536e-03, -4.5500e-03],\n",
            "          [ 5.8359e-03,  1.7751e-03,  7.7460e-04,  2.9554e-03,  3.6186e-03],\n",
            "          [-1.2523e-03, -3.9902e-03, -1.0785e-03, -8.9182e-05,  4.2991e-05],\n",
            "          [-3.4130e-04, -4.1390e-03, -3.9616e-04,  8.1020e-03, -4.5738e-04],\n",
            "          [ 7.8843e-06, -6.9233e-05,  1.2135e-03,  4.8265e-03,  4.3983e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0124]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0293]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0124,  0.0293], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 4, 5] = -0.012393890880048275\n",
            " somado na saída em [1, 1, 4, 5] = 0.029306352138519287\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 6\n",
            " alvo do kernel em x: x[1,0,12:17, 18:23]\n",
            " \n",
            " tensor([[0.9959, 0.4935, 0.9691, 0.0372, 0.9032],\n",
            "        [0.7179, 0.4353, 0.4370, 0.8129, 0.4393],\n",
            "        [0.0127, 0.0650, 0.6023, 0.9159, 0.9276],\n",
            "        [0.8552, 0.5799, 0.7463, 0.0572, 0.4056],\n",
            "        [0.5417, 0.7193, 0.9744, 0.1135, 0.7239]])\n",
            " produto: tensor([[[[-4.0609e-03,  1.6347e-04, -4.8133e-03,  1.4024e-04, -7.6954e-03],\n",
            "          [ 5.2624e-03, -3.1639e-03, -3.4741e-03, -5.1363e-03,  1.9897e-03],\n",
            "          [-4.6789e-05,  2.4336e-04, -5.1118e-03, -5.5568e-03, -3.4060e-03],\n",
            "          [-1.6806e-03, -4.4236e-03,  4.8866e-03, -1.3486e-04,  1.3019e-03],\n",
            "          [ 3.8305e-03,  1.3400e-03,  2.6646e-03,  1.0951e-03, -3.2647e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 3.1545e-03, -2.1957e-03,  6.9259e-03,  2.9700e-04, -8.3268e-03],\n",
            "          [ 6.1282e-03,  2.0786e-03,  1.9042e-03,  3.3463e-03,  3.6521e-03],\n",
            "          [-1.6720e-05, -5.4999e-04, -1.7283e-03, -6.4502e-03,  6.1321e-04],\n",
            "          [-1.5967e-03, -3.1103e-03, -6.7853e-04,  5.4178e-04, -3.1990e-04],\n",
            "          [ 1.7199e-04, -1.1218e-03,  1.5319e-03,  1.0109e-03,  4.4264e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0291]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0097]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0291,  0.0097], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 4, 6] = -0.02905118651688099\n",
            " somado na saída em [1, 1, 4, 6] = 0.00968792475759983\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 7\n",
            " alvo do kernel em x: x[1,0,12:17, 21:26]\n",
            " \n",
            " tensor([[0.0372, 0.9032, 0.6890, 0.5771, 0.4025],\n",
            "        [0.8129, 0.4393, 0.1373, 0.2292, 0.9033],\n",
            "        [0.9159, 0.9276, 0.5249, 0.3031, 0.6457],\n",
            "        [0.0572, 0.4056, 0.0798, 0.5669, 0.0249],\n",
            "        [0.1135, 0.7239, 0.9314, 0.6564, 0.3146]])\n",
            " produto: tensor([[[[-1.5164e-04,  2.9917e-04, -3.4220e-03,  2.1761e-03, -3.4299e-03],\n",
            "          [ 5.9586e-03, -3.1932e-03, -1.0918e-03, -1.4486e-03,  4.0911e-03],\n",
            "          [-3.3840e-03,  3.4713e-03, -4.4546e-03, -1.8391e-03, -2.3708e-03],\n",
            "          [-1.1238e-04, -3.0940e-03,  5.2263e-04, -1.3370e-03,  7.9843e-05],\n",
            "          [ 8.0228e-04,  1.3486e-03,  2.5469e-03,  6.3363e-03, -1.4188e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1779e-04, -4.0183e-03,  4.9240e-03,  4.6087e-03, -3.7114e-03],\n",
            "          [ 6.9389e-03,  2.0978e-03,  5.9843e-04,  9.4375e-04,  7.5093e-03],\n",
            "          [-1.2093e-03, -7.8448e-03, -1.5061e-03, -2.1348e-03,  4.2684e-04],\n",
            "          [-1.0677e-04, -2.1755e-03, -7.2570e-05,  5.3712e-03, -1.9620e-05],\n",
            "          [ 3.6022e-05, -1.1290e-03,  1.4642e-03,  5.8489e-03,  1.9237e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0031]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0189]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0031,  0.0189], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 4, 7] = -0.0031151273287832737\n",
            " somado na saída em [1, 1, 4, 7] = 0.018881505355238914\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 0\n",
            " alvo do kernel em x: x[1,0,15:20, 0:5]\n",
            " \n",
            " tensor([[0.3376, 0.4097, 0.2738, 0.0748, 0.3008],\n",
            "        [0.8359, 0.9849, 0.0314, 0.3695, 0.7972],\n",
            "        [0.2990, 0.4286, 0.3485, 0.5984, 0.5587],\n",
            "        [0.4562, 0.0250, 0.6630, 0.4426, 0.9079],\n",
            "        [0.1644, 0.2619, 0.0911, 0.9305, 0.8125]])\n",
            " produto: tensor([[[[-1.3768e-03,  1.3572e-04, -1.3601e-03,  2.8222e-04, -2.5633e-03],\n",
            "          [ 6.1279e-03, -7.1589e-03, -2.4931e-04, -2.3350e-03,  3.6103e-03],\n",
            "          [-1.1046e-03,  1.6040e-03, -2.9574e-03, -3.6309e-03, -2.0514e-03],\n",
            "          [-8.9662e-04, -1.9041e-04,  4.3413e-03, -1.0437e-03,  2.9143e-03],\n",
            "          [ 1.1628e-03,  4.8798e-04,  2.4918e-04,  8.9818e-03, -3.6645e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0695e-03, -1.8229e-03,  1.9570e-03,  5.9768e-04, -2.7737e-03],\n",
            "          [ 7.1360e-03,  4.7032e-03,  1.3665e-04,  1.5213e-03,  6.6268e-03],\n",
            "          [-3.9474e-04, -3.6249e-03, -9.9989e-04, -4.2146e-03,  3.6933e-04],\n",
            "          [-8.5185e-04, -1.3388e-04, -6.0281e-04,  4.1929e-03, -7.1611e-04],\n",
            "          [ 5.2211e-05, -4.0849e-04,  1.4325e-04,  8.2909e-03,  4.9685e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0007]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0252]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0007,  0.0252], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 5, 0] = -0.000685577280819416\n",
            " somado na saída em [1, 1, 5, 0] = 0.025221308693289757\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 1\n",
            " alvo do kernel em x: x[1,0,15:20, 3:8]\n",
            " \n",
            " tensor([[0.0748, 0.3008, 0.7768, 0.2174, 0.8908],\n",
            "        [0.3695, 0.7972, 0.8224, 0.7026, 0.0274],\n",
            "        [0.5984, 0.5587, 0.9012, 0.7883, 0.3554],\n",
            "        [0.4426, 0.9079, 0.8746, 0.3589, 0.2200],\n",
            "        [0.9305, 0.8125, 0.6310, 0.7328, 0.2618]])\n",
            " produto: tensor([[[[-3.0516e-04,  9.9652e-05, -3.8579e-03,  8.1980e-04, -7.5902e-03],\n",
            "          [ 2.7088e-03, -5.7941e-03, -6.5384e-03, -4.4394e-03,  1.2413e-04],\n",
            "          [-2.2112e-03,  2.0907e-03, -7.6488e-03, -4.7826e-03, -1.3048e-03],\n",
            "          [-8.6974e-04, -6.9261e-03,  5.7271e-03, -8.4647e-04,  7.0632e-04],\n",
            "          [ 6.5800e-03,  1.5138e-03,  1.7255e-03,  7.0736e-03, -1.1806e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3704e-04, -1.3385e-03,  5.5513e-03,  1.7362e-03, -8.2130e-03],\n",
            "          [ 3.1545e-03,  3.8066e-03,  3.5837e-03,  2.8923e-03,  2.2785e-04],\n",
            "          [-7.9017e-04, -4.7248e-03, -2.5860e-03, -5.5516e-03,  2.3492e-04],\n",
            "          [-8.2631e-04, -4.8699e-03, -7.9524e-04,  3.4005e-03, -1.7356e-04],\n",
            "          [ 2.9544e-04, -1.2672e-03,  9.9201e-04,  6.5295e-03,  1.6007e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0251]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0031]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0251,  0.0031], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 5, 1] = -0.025126097723841667\n",
            " somado na saída em [1, 1, 5, 1] = 0.0031061959452927113\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 2\n",
            " alvo do kernel em x: x[1,0,15:20, 6:11]\n",
            " \n",
            " tensor([[0.2174, 0.8908, 0.3298, 0.7111, 0.4127],\n",
            "        [0.7026, 0.0274, 0.1784, 0.3501, 0.2224],\n",
            "        [0.7883, 0.3554, 0.9039, 0.5736, 0.7832],\n",
            "        [0.3589, 0.2200, 0.7295, 0.3242, 0.4349],\n",
            "        [0.7328, 0.2618, 0.7435, 0.3765, 0.1568]])\n",
            " produto: tensor([[[[-0.0009,  0.0003, -0.0016,  0.0027, -0.0035],\n",
            "          [ 0.0052, -0.0002, -0.0014, -0.0022,  0.0010],\n",
            "          [-0.0029,  0.0013, -0.0077, -0.0035, -0.0029],\n",
            "          [-0.0007, -0.0017,  0.0048, -0.0008,  0.0014],\n",
            "          [ 0.0052,  0.0005,  0.0020,  0.0036, -0.0007]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0007, -0.0040,  0.0024,  0.0057, -0.0038],\n",
            "          [ 0.0060,  0.0001,  0.0008,  0.0014,  0.0018],\n",
            "          [-0.0010, -0.0030, -0.0026, -0.0040,  0.0005],\n",
            "          [-0.0007, -0.0012, -0.0007,  0.0031, -0.0003],\n",
            "          [ 0.0002, -0.0004,  0.0012,  0.0034,  0.0010]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0027]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0065]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0027,  0.0065], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 5, 2] = -0.0026934256311506033\n",
            " somado na saída em [1, 1, 5, 2] = 0.006511067971587181\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 3\n",
            " alvo do kernel em x: x[1,0,15:20, 9:14]\n",
            " \n",
            " tensor([[0.7111, 0.4127, 0.5049, 0.9601, 0.2528],\n",
            "        [0.3501, 0.2224, 0.6161, 0.9200, 0.0694],\n",
            "        [0.5736, 0.7832, 0.2096, 0.4279, 0.4155],\n",
            "        [0.3242, 0.4349, 0.7819, 0.0069, 0.4721],\n",
            "        [0.3765, 0.1568, 0.5079, 0.1057, 0.0388]])\n",
            " produto: tensor([[[[-2.8995e-03,  1.3670e-04, -2.5076e-03,  3.6205e-03, -2.1543e-03],\n",
            "          [ 2.5661e-03, -1.6165e-03, -4.8983e-03, -5.8131e-03,  3.1418e-04],\n",
            "          [-2.1195e-03,  2.9307e-03, -1.7785e-03, -2.5959e-03, -1.5255e-03],\n",
            "          [-6.3714e-04, -3.3176e-03,  5.1198e-03, -1.6352e-05,  1.5153e-03],\n",
            "          [ 2.6624e-03,  2.9206e-04,  1.3888e-03,  1.0204e-03, -1.7484e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 2.2523e-03, -1.8361e-03,  3.6082e-03,  7.6676e-03, -2.3311e-03],\n",
            "          [ 2.9882e-03,  1.0620e-03,  2.6848e-03,  3.7873e-03,  5.7669e-04],\n",
            "          [-7.5742e-04, -6.6231e-03, -6.0131e-04, -3.0133e-03,  2.7465e-04],\n",
            "          [-6.0533e-04, -2.3327e-03, -7.1092e-04,  6.5691e-05, -3.7234e-04],\n",
            "          [ 1.1954e-04, -2.4449e-04,  7.9840e-04,  9.4189e-04,  2.3705e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0105]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0076]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0105,  0.0076], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 5, 3] = -0.010487975552678108\n",
            " somado na saída em [1, 1, 5, 3] = 0.007636252790689468\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 4\n",
            " alvo do kernel em x: x[1,0,15:20, 12:17]\n",
            " \n",
            " tensor([[0.9601, 0.2528, 0.6806, 0.1828, 0.7716],\n",
            "        [0.9200, 0.0694, 0.7988, 0.0248, 0.0444],\n",
            "        [0.4279, 0.4155, 0.4976, 0.6700, 0.4974],\n",
            "        [0.0069, 0.4721, 0.8613, 0.3244, 0.9267],\n",
            "        [0.1057, 0.0388, 0.6141, 0.2151, 0.0072]])\n",
            " produto: tensor([[[[-3.9149e-03,  8.3751e-05, -3.3800e-03,  6.8936e-04, -6.5749e-03],\n",
            "          [ 6.7438e-03, -5.0422e-04, -6.3508e-03, -1.5691e-04,  2.0105e-04],\n",
            "          [-1.5809e-03,  1.5547e-03, -4.2236e-03, -4.0648e-03, -1.8264e-03],\n",
            "          [-1.3626e-05, -3.6012e-03,  5.6400e-03, -7.6511e-04,  2.9747e-03],\n",
            "          [ 7.4752e-04,  7.2223e-05,  1.6791e-03,  2.0762e-03, -3.2650e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 3.0410e-03, -1.1249e-03,  4.8636e-03,  1.4599e-03, -7.1144e-03],\n",
            "          [ 7.8532e-03,  3.3126e-04,  3.4809e-03,  1.0223e-04,  3.6902e-04],\n",
            "          [-5.6494e-04, -3.5136e-03, -1.4280e-03, -4.7183e-03,  3.2882e-04],\n",
            "          [-1.2946e-05, -2.5321e-03, -7.8314e-04,  3.0737e-03, -7.3096e-04],\n",
            "          [ 3.3563e-05, -6.0459e-05,  9.6534e-04,  1.9165e-03,  4.4268e-05]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0145]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0053]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0145,  0.0053], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 5, 4] = -0.014527630060911179\n",
            " somado na saída em [1, 1, 5, 4] = 0.005279677454382181\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 5\n",
            " alvo do kernel em x: x[1,0,15:20, 15:20]\n",
            " \n",
            " tensor([[0.1828, 0.7716, 0.4357, 0.8552, 0.5799],\n",
            "        [0.0248, 0.0444, 0.7719, 0.5417, 0.7193],\n",
            "        [0.6700, 0.4974, 0.5180, 0.3832, 0.9406],\n",
            "        [0.3244, 0.9267, 0.0193, 0.4671, 0.7653],\n",
            "        [0.2151, 0.0072, 0.7561, 0.8901, 0.5780]])\n",
            " produto: tensor([[[[-7.4541e-04,  2.5561e-04, -2.1640e-03,  3.2250e-03, -4.9408e-03],\n",
            "          [ 1.8203e-04, -3.2265e-04, -6.1372e-03, -3.4229e-03,  3.2575e-03],\n",
            "          [-2.4754e-03,  1.8614e-03, -4.3962e-03, -2.3250e-03, -3.4535e-03],\n",
            "          [-6.3757e-04, -7.0696e-03,  1.2660e-04, -1.1015e-03,  2.4566e-03],\n",
            "          [ 1.5210e-03,  1.3487e-05,  2.0674e-03,  8.5916e-03, -2.6067e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 5.7901e-04, -3.4332e-03,  3.1138e-03,  6.8300e-03, -5.3463e-03],\n",
            "          [ 2.1198e-04,  2.1197e-04,  3.3638e-03,  2.2300e-03,  5.9793e-03],\n",
            "          [-8.8461e-04, -4.2065e-03, -1.4863e-03, -2.6988e-03,  6.2177e-04],\n",
            "          [-6.0573e-04, -4.9708e-03, -1.7579e-05,  4.4252e-03, -6.0364e-04],\n",
            "          [ 6.8292e-05, -1.1291e-05,  1.1886e-03,  7.9308e-03,  3.5342e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0182]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0160]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0182,  0.0160], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 5, 5] = -0.018240254372358322\n",
            " somado na saída em [1, 1, 5, 5] = 0.01602386310696602\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 6\n",
            " alvo do kernel em x: x[1,0,15:20, 18:23]\n",
            " \n",
            " tensor([[0.8552, 0.5799, 0.7463, 0.0572, 0.4056],\n",
            "        [0.5417, 0.7193, 0.9744, 0.1135, 0.7239],\n",
            "        [0.3832, 0.9406, 0.9813, 0.2078, 0.7405],\n",
            "        [0.4671, 0.7653, 0.8588, 0.2823, 0.6516],\n",
            "        [0.8901, 0.5780, 0.7080, 0.8103, 0.0088]])\n",
            " produto: tensor([[[[-3.4872e-03,  1.9208e-04, -3.7065e-03,  2.1565e-04, -3.4558e-03],\n",
            "          [ 3.9708e-03, -5.2279e-03, -7.7470e-03, -7.1690e-04,  3.2784e-03],\n",
            "          [-1.4159e-03,  3.5197e-03, -8.3282e-03, -1.2606e-03, -2.7191e-03],\n",
            "          [-9.1791e-04, -5.8383e-03,  5.6233e-03, -6.6578e-04,  2.0916e-03],\n",
            "          [ 6.2942e-03,  1.0768e-03,  1.9361e-03,  7.8216e-03, -3.9773e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 2.7088e-03, -2.5799e-03,  5.3333e-03,  4.5672e-04, -3.7393e-03],\n",
            "          [ 4.6241e-03,  3.4346e-03,  4.2462e-03,  4.6706e-04,  6.0175e-03],\n",
            "          [-5.0598e-04, -7.9543e-03, -2.8157e-03, -1.4633e-03,  4.8955e-04],\n",
            "          [-8.7208e-04, -4.1050e-03, -7.8083e-04,  2.6746e-03, -5.1395e-04],\n",
            "          [ 2.8260e-04, -9.0139e-04,  1.1131e-03,  7.2200e-03,  5.3925e-05]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0095]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0129]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0095,  0.0129], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 5, 6] = -0.009506740607321262\n",
            " somado na saída em [1, 1, 5, 6] = 0.012890370562672615\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 7\n",
            " alvo do kernel em x: x[1,0,15:20, 21:26]\n",
            " \n",
            " tensor([[0.0572, 0.4056, 0.0798, 0.5669, 0.0249],\n",
            "        [0.1135, 0.7239, 0.9314, 0.6564, 0.3146],\n",
            "        [0.2078, 0.7405, 0.7950, 0.6530, 0.2634],\n",
            "        [0.2823, 0.6516, 0.4089, 0.5043, 0.2822],\n",
            "        [0.8103, 0.0088, 0.9568, 0.0946, 0.2494]])\n",
            " produto: tensor([[[[-2.3319e-04,  1.3435e-04, -3.9642e-04,  2.1380e-03, -2.1194e-04],\n",
            "          [ 8.3167e-04, -5.2614e-03, -7.4050e-03, -4.1479e-03,  1.4248e-03],\n",
            "          [-7.6770e-04,  2.7712e-03, -6.7476e-03, -3.9618e-03, -9.6721e-04],\n",
            "          [-5.5480e-04, -4.9708e-03,  2.6775e-03, -1.1894e-03,  9.0588e-04],\n",
            "          [ 5.7301e-03,  1.6430e-05,  2.6163e-03,  9.1321e-04, -1.1248e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8114e-04, -1.8045e-03,  5.7041e-04,  4.5279e-03, -2.2933e-04],\n",
            "          [ 9.6849e-04,  3.4566e-03,  4.0587e-03,  2.7024e-03,  2.6152e-03],\n",
            "          [-2.7434e-04, -6.2628e-03, -2.2813e-03, -4.5988e-03,  1.7414e-04],\n",
            "          [-5.2710e-04, -3.4951e-03, -3.7179e-04,  4.7781e-03, -2.2260e-04],\n",
            "          [ 2.5728e-04, -1.3754e-05,  1.5041e-03,  8.4296e-04,  1.5250e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0178]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0081]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0178,  0.0081], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 5, 7] = -0.017780398949980736\n",
            " somado na saída em [1, 1, 5, 7] = 0.008081123232841492\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 0\n",
            " alvo do kernel em x: x[1,0,18:23, 0:5]\n",
            " \n",
            " tensor([[0.4562, 0.0250, 0.6630, 0.4426, 0.9079],\n",
            "        [0.1644, 0.2619, 0.0911, 0.9305, 0.8125],\n",
            "        [0.8994, 0.0742, 0.7888, 0.3434, 0.0386],\n",
            "        [0.8973, 0.9538, 0.3108, 0.9544, 0.1746],\n",
            "        [0.8151, 0.6029, 0.9388, 0.8085, 0.7096]])\n",
            " produto: tensor([[[[-1.8605e-03,  8.2680e-06, -3.2928e-03,  1.6690e-03, -7.7359e-03],\n",
            "          [ 1.2054e-03, -1.9038e-03, -7.2447e-04, -5.8797e-03,  3.6798e-03],\n",
            "          [-3.3234e-03,  2.7758e-04, -6.6946e-03, -2.0836e-03, -1.4186e-04],\n",
            "          [-1.7633e-03, -7.2758e-03,  2.0353e-03, -2.2508e-03,  5.6056e-04],\n",
            "          [ 5.7643e-03,  1.1232e-03,  2.5672e-03,  7.8039e-03, -3.2003e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4452e-03, -1.1105e-04,  4.7381e-03,  3.5346e-03, -8.3706e-03],\n",
            "          [ 1.4038e-03,  1.2507e-03,  3.9708e-04,  3.8307e-03,  6.7544e-03],\n",
            "          [-1.1876e-03, -6.2732e-04, -2.2634e-03, -2.4186e-03,  2.5540e-05],\n",
            "          [-1.6753e-03, -5.1158e-03, -2.8262e-04,  9.0420e-03, -1.3775e-04],\n",
            "          [ 2.5881e-04, -9.4029e-04,  1.4759e-03,  7.2036e-03,  4.3390e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0214]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0226]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0214,  0.0226], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 6, 0] = -0.021436117589473724\n",
            " somado na saída em [1, 1, 6, 0] = 0.02256922796368599\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 1\n",
            " alvo do kernel em x: x[1,0,18:23, 3:8]\n",
            " \n",
            " tensor([[0.4426, 0.9079, 0.8746, 0.3589, 0.2200],\n",
            "        [0.9305, 0.8125, 0.6310, 0.7328, 0.2618],\n",
            "        [0.3434, 0.0386, 0.3407, 0.1485, 0.7425],\n",
            "        [0.9544, 0.1746, 0.8304, 0.7692, 0.3178],\n",
            "        [0.8085, 0.7096, 0.2874, 0.4965, 0.8900]])\n",
            " produto: tensor([[[[-0.0018,  0.0003, -0.0043,  0.0014, -0.0019],\n",
            "          [ 0.0068, -0.0059, -0.0050, -0.0046,  0.0012],\n",
            "          [-0.0013,  0.0001, -0.0029, -0.0009, -0.0027],\n",
            "          [-0.0019, -0.0013,  0.0054, -0.0018,  0.0010],\n",
            "          [ 0.0057,  0.0013,  0.0008,  0.0048, -0.0040]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0014, -0.0040,  0.0063,  0.0029, -0.0020],\n",
            "          [ 0.0079,  0.0039,  0.0027,  0.0030,  0.0022],\n",
            "          [-0.0005, -0.0003, -0.0010, -0.0010,  0.0005],\n",
            "          [-0.0018, -0.0009, -0.0008,  0.0073, -0.0003],\n",
            "          [ 0.0003, -0.0011,  0.0005,  0.0044,  0.0054]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0115]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0349]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0115,  0.0349], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 6, 1] = -0.01152031496167183\n",
            " somado na saída em [1, 1, 6, 1] = 0.03493446484208107\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 2\n",
            " alvo do kernel em x: x[1,0,18:23, 6:11]\n",
            " \n",
            " tensor([[0.3589, 0.2200, 0.7295, 0.3242, 0.4349],\n",
            "        [0.7328, 0.2618, 0.7435, 0.3765, 0.1568],\n",
            "        [0.1485, 0.7425, 0.9665, 0.9712, 0.1788],\n",
            "        [0.7692, 0.3178, 0.1408, 0.9073, 0.6142],\n",
            "        [0.4965, 0.8900, 0.1082, 0.8165, 0.6151]])\n",
            " produto: tensor([[[[-1.4636e-03,  7.2890e-05, -3.6231e-03,  1.2226e-03, -3.7055e-03],\n",
            "          [ 5.3719e-03, -1.9026e-03, -5.9108e-03, -2.3790e-03,  7.0997e-04],\n",
            "          [-5.4858e-04,  2.7785e-03, -8.2026e-03, -5.8927e-03, -6.5640e-04],\n",
            "          [-1.5116e-03, -2.4246e-03,  9.2193e-04, -2.1398e-03,  1.9715e-03],\n",
            "          [ 3.5107e-03,  1.6581e-03,  2.9589e-04,  7.8816e-03, -2.7740e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1369e-03, -9.7903e-04,  5.2133e-03,  2.5893e-03, -4.0096e-03],\n",
            "          [ 6.2557e-03,  1.2500e-03,  3.2397e-03,  1.5499e-03,  1.3032e-03],\n",
            "          [-1.9604e-04, -6.2793e-03, -2.7732e-03, -6.8401e-03,  1.1818e-04],\n",
            "          [-1.4361e-03, -1.7048e-03, -1.2802e-04,  8.5962e-03, -4.8446e-04],\n",
            "          [ 1.5762e-04, -1.3881e-03,  1.7011e-04,  7.2754e-03,  3.7611e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0167]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0164]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0167,  0.0164], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 6, 2] = -0.01673928089439869\n",
            " somado na saída em [1, 1, 6, 2] = 0.01639794185757637\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 3\n",
            " alvo do kernel em x: x[1,0,18:23, 9:14]\n",
            " \n",
            " tensor([[0.3242, 0.4349, 0.7819, 0.0069, 0.4721],\n",
            "        [0.3765, 0.1568, 0.5079, 0.1057, 0.0388],\n",
            "        [0.9712, 0.1788, 0.8308, 0.6323, 0.9762],\n",
            "        [0.9073, 0.6142, 0.6825, 0.0420, 0.2568],\n",
            "        [0.8165, 0.6151, 0.8746, 0.9342, 0.6523]])\n",
            " produto: tensor([[[[-1.3221e-03,  1.4406e-04, -3.8834e-03,  2.6148e-05, -4.0222e-03],\n",
            "          [ 2.7599e-03, -1.1394e-03, -4.0378e-03, -6.6797e-04,  1.7557e-04],\n",
            "          [-3.5886e-03,  6.6898e-04, -7.0515e-03, -3.8364e-03, -3.5845e-03],\n",
            "          [-1.7831e-03, -4.6856e-03,  4.4691e-03, -9.9146e-05,  8.2422e-04],\n",
            "          [ 5.7740e-03,  1.1459e-03,  2.3915e-03,  9.0175e-03, -2.9421e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0269e-03, -1.9349e-03,  5.5879e-03,  5.5377e-05, -4.3523e-03],\n",
            "          [ 3.2140e-03,  7.4857e-04,  2.2131e-03,  4.3518e-04,  3.2226e-04],\n",
            "          [-1.2824e-03, -1.5118e-03, -2.3840e-03, -4.4532e-03,  6.4535e-04],\n",
            "          [-1.6941e-03, -3.2945e-03, -6.2056e-04,  3.9830e-04, -2.0253e-04],\n",
            "          [ 2.5925e-04, -9.5926e-04,  1.3749e-03,  8.3239e-03,  3.9890e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0152]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0059]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0152,  0.0059], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 6, 3] = -0.015246824361383915\n",
            " somado na saída em [1, 1, 6, 3] = 0.005904363468289375\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 4\n",
            " alvo do kernel em x: x[1,0,18:23, 12:17]\n",
            " \n",
            " tensor([[0.0069, 0.4721, 0.8613, 0.3244, 0.9267],\n",
            "        [0.1057, 0.0388, 0.6141, 0.2151, 0.0072],\n",
            "        [0.6323, 0.9762, 0.5887, 0.1797, 0.3760],\n",
            "        [0.0420, 0.2568, 0.9676, 0.7202, 0.5082],\n",
            "        [0.9342, 0.6523, 0.4646, 0.7987, 0.2579]])\n",
            " produto: tensor([[[[-2.8274e-05,  1.5637e-04, -4.2779e-03,  1.2235e-03, -7.8962e-03],\n",
            "          [ 7.7490e-04, -2.8176e-04, -4.8820e-03, -1.3591e-03,  3.2787e-05],\n",
            "          [-2.3363e-03,  3.6532e-03, -4.9968e-03, -1.0900e-03, -1.3805e-03],\n",
            "          [-8.2619e-05, -1.9588e-03,  6.3356e-03, -1.6985e-03,  1.6312e-03],\n",
            "          [ 6.6062e-03,  1.2154e-03,  1.2705e-03,  7.7091e-03, -1.1633e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.1963e-05, -2.1003e-03,  6.1556e-03,  2.5911e-03, -8.5442e-03],\n",
            "          [ 9.0239e-04,  1.8511e-04,  2.6759e-03,  8.8549e-04,  6.0181e-05],\n",
            "          [-8.3490e-04, -8.2559e-03, -1.6894e-03, -1.2653e-03,  2.4855e-04],\n",
            "          [-7.8494e-05, -1.3773e-03, -8.7974e-04,  6.8235e-03, -4.0083e-04],\n",
            "          [ 2.9661e-04, -1.0174e-03,  7.3043e-04,  7.1161e-03,  1.5773e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0028]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0038]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0028,  0.0038], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 6, 4] = -0.0028236303478479385\n",
            " somado na saída em [1, 1, 6, 4] = 0.0038264733739197254\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 5\n",
            " alvo do kernel em x: x[1,0,18:23, 15:20]\n",
            " \n",
            " tensor([[0.3244, 0.9267, 0.0193, 0.4671, 0.7653],\n",
            "        [0.2151, 0.0072, 0.7561, 0.8901, 0.5780],\n",
            "        [0.1797, 0.3760, 0.1327, 0.8497, 0.7743],\n",
            "        [0.7202, 0.5082, 0.1740, 0.5754, 0.0883],\n",
            "        [0.7987, 0.2579, 0.4187, 0.6946, 0.3583]])\n",
            " produto: tensor([[[[-1.3229e-03,  3.0697e-04, -9.6027e-05,  1.7614e-03, -6.5209e-03],\n",
            "          [ 1.5767e-03, -5.2619e-05, -6.0109e-03, -5.6243e-03,  2.6176e-03],\n",
            "          [-6.6382e-04,  1.4070e-03, -1.1264e-03, -5.1555e-03, -2.8430e-03],\n",
            "          [-1.4154e-03, -3.8768e-03,  1.1391e-03, -1.3569e-03,  2.8340e-04],\n",
            "          [ 5.6476e-03,  4.8055e-04,  1.1450e-03,  6.7043e-03, -1.6159e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0276e-03, -4.1232e-03,  1.3818e-04,  3.7304e-03, -7.0560e-03],\n",
            "          [ 1.8361e-03,  3.4569e-05,  3.2946e-03,  3.6643e-03,  4.8046e-03],\n",
            "          [-2.3722e-04, -3.1796e-03, -3.8082e-04, -5.9844e-03,  5.1185e-04],\n",
            "          [-1.3447e-03, -2.7258e-03, -1.5818e-04,  5.4511e-03, -6.9639e-05],\n",
            "          [ 2.5357e-04, -4.0228e-04,  6.5826e-04,  6.1887e-03,  2.1909e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0146]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0081]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0146,  0.0081], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 6, 5] = -0.01461164839565754\n",
            " somado na saída em [1, 1, 6, 5] = 0.008122865110635757\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 6\n",
            " alvo do kernel em x: x[1,0,18:23, 18:23]\n",
            " \n",
            " tensor([[0.4671, 0.7653, 0.8588, 0.2823, 0.6516],\n",
            "        [0.8901, 0.5780, 0.7080, 0.8103, 0.0088],\n",
            "        [0.8497, 0.7743, 0.5044, 0.7692, 0.9262],\n",
            "        [0.5754, 0.0883, 0.0658, 0.7098, 0.0043],\n",
            "        [0.6946, 0.3583, 0.1805, 0.8592, 0.7009]])\n",
            " produto: tensor([[[[-1.9047e-03,  2.5351e-04, -4.2653e-03,  1.0646e-03, -5.5520e-03],\n",
            "          [ 6.5247e-03, -4.2009e-03, -5.6291e-03, -5.1203e-03,  3.9939e-05],\n",
            "          [-3.1397e-03,  2.8975e-03, -4.2813e-03, -4.6671e-03, -3.4008e-03],\n",
            "          [-1.1307e-03, -6.7353e-04,  4.3091e-04, -1.6740e-03,  1.3725e-05],\n",
            "          [ 4.9116e-03,  6.6750e-04,  4.9351e-04,  8.2938e-03, -3.1610e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4795e-03, -3.4050e-03,  6.1374e-03,  2.2547e-03, -6.0076e-03],\n",
            "          [ 7.5982e-03,  2.7598e-03,  3.0854e-03,  3.3359e-03,  7.3309e-05],\n",
            "          [-1.1220e-03, -6.5481e-03, -1.4475e-03, -5.4175e-03,  6.1227e-04],\n",
            "          [-1.0743e-03, -4.7357e-04, -5.9835e-05,  6.7248e-03, -3.3727e-06],\n",
            "          [ 2.2052e-04, -5.5878e-04,  2.8372e-04,  7.6558e-03,  4.2857e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0232]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0204]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0232,  0.0204], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 6, 6] = -0.023208901286125183\n",
            " somado na saída em [1, 1, 6, 6] = 0.020389653742313385\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 7\n",
            " alvo do kernel em x: x[1,0,18:23, 21:26]\n",
            " \n",
            " tensor([[0.2823, 0.6516, 0.4089, 0.5043, 0.2822],\n",
            "        [0.8103, 0.0088, 0.9568, 0.0946, 0.2494],\n",
            "        [0.7692, 0.9262, 0.2493, 0.7590, 0.9346],\n",
            "        [0.7098, 0.0043, 0.0585, 0.8684, 0.8552],\n",
            "        [0.8592, 0.7009, 0.7482, 0.0032, 0.4081]])\n",
            " produto: tensor([[[[-1.1512e-03,  2.1584e-04, -2.0309e-03,  1.9019e-03, -2.4046e-03],\n",
            "          [ 5.9400e-03, -6.4097e-05, -7.6069e-03, -5.9781e-04,  1.1295e-03],\n",
            "          [-2.8422e-03,  3.4659e-03, -2.1161e-03, -4.6049e-03, -3.4317e-03],\n",
            "          [-1.3949e-03, -3.2620e-05,  3.8273e-04, -2.0478e-03,  2.7450e-03],\n",
            "          [ 6.0760e-03,  1.3058e-03,  2.0461e-03,  3.1346e-05, -1.8408e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 8.9423e-04, -2.8991e-03,  2.9223e-03,  4.0280e-03, -2.6020e-03],\n",
            "          [ 6.9172e-03,  4.2110e-05,  4.1694e-03,  3.8947e-04,  2.0732e-03],\n",
            "          [-1.0157e-03, -7.8328e-03, -7.1543e-04, -5.3452e-03,  6.1784e-04],\n",
            "          [-1.3253e-03, -2.2936e-05, -5.3144e-05,  8.2268e-03, -6.7451e-04],\n",
            "          [ 2.7281e-04, -1.0931e-03,  1.1763e-03,  2.8935e-05,  2.4958e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0069]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0107]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0069,  0.0107], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 6, 7] = -0.006926549598574638\n",
            " somado na saída em [1, 1, 6, 7] = 0.01067516952753067\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 0\n",
            " alvo do kernel em x: x[1,0,21:26, 0:5]\n",
            " \n",
            " tensor([[0.8973, 0.9538, 0.3108, 0.9544, 0.1746],\n",
            "        [0.8151, 0.6029, 0.9388, 0.8085, 0.7096],\n",
            "        [0.3401, 0.6685, 0.2160, 0.0978, 0.6099],\n",
            "        [0.4979, 0.2804, 0.9448, 0.6739, 0.1082],\n",
            "        [0.9189, 0.8832, 0.5742, 0.0350, 0.2386]])\n",
            " produto: tensor([[[[-3.6588e-03,  3.1593e-04, -1.5438e-03,  3.5992e-03, -1.4880e-03],\n",
            "          [ 5.9754e-03, -4.3821e-03, -7.4641e-03, -5.1087e-03,  3.2136e-03],\n",
            "          [-1.2567e-03,  2.5017e-03, -1.8329e-03, -5.9332e-04, -2.2396e-03],\n",
            "          [-9.7851e-04, -2.1388e-03,  6.1864e-03, -1.5893e-03,  3.4734e-04],\n",
            "          [ 6.4983e-03,  1.6455e-03,  1.5701e-03,  3.3813e-04, -1.0760e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.8421e-03, -4.2434e-03,  2.2214e-03,  7.6224e-03, -1.6101e-03],\n",
            "          [ 6.9585e-03,  2.8789e-03,  4.0911e-03,  3.3283e-03,  5.8987e-03],\n",
            "          [-4.4908e-04, -5.6536e-03, -6.1970e-04, -6.8871e-04,  4.0321e-04],\n",
            "          [-9.2965e-04, -1.5038e-03, -8.5901e-04,  6.3847e-03, -8.5350e-05],\n",
            "          [ 2.9177e-04, -1.3774e-03,  9.0263e-04,  3.1212e-04,  1.4589e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0032]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0276]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0032,  0.0276], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 7, 0] = -0.003159188199788332\n",
            " somado na saída em [1, 1, 7, 0] = 0.027574986219406128\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 1\n",
            " alvo do kernel em x: x[1,0,21:26, 3:8]\n",
            " \n",
            " tensor([[0.9544, 0.1746, 0.8304, 0.7692, 0.3178],\n",
            "        [0.8085, 0.7096, 0.2874, 0.4965, 0.8900],\n",
            "        [0.0978, 0.6099, 0.9087, 0.9749, 0.7476],\n",
            "        [0.6739, 0.1082, 0.1412, 0.4241, 0.3089],\n",
            "        [0.0350, 0.2386, 0.9868, 0.8172, 0.6332]])\n",
            " produto: tensor([[[[-3.8918e-03,  5.7848e-05, -4.1242e-03,  2.9007e-03, -2.7081e-03],\n",
            "          [ 5.9265e-03, -5.1575e-03, -2.2849e-03, -3.1370e-03,  4.0308e-03],\n",
            "          [-3.6133e-04,  2.2825e-03, -7.7123e-03, -5.9150e-03, -2.7449e-03],\n",
            "          [-1.3244e-03, -8.2549e-04,  9.2429e-04, -1.0003e-03,  9.9138e-04],\n",
            "          [ 2.4771e-04,  4.4450e-04,  2.6984e-03,  7.8884e-03, -2.8559e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 3.0231e-03, -7.7699e-04,  5.9344e-03,  6.1430e-03, -2.9303e-03],\n",
            "          [ 6.9015e-03,  3.3884e-03,  1.2524e-03,  2.0438e-03,  7.3987e-03],\n",
            "          [-1.2912e-04, -5.1583e-03, -2.6075e-03, -6.8661e-03,  4.9420e-04],\n",
            "          [-1.2583e-03, -5.8042e-04, -1.2834e-04,  4.0184e-03, -2.4361e-04],\n",
            "          [ 1.1122e-05, -3.7210e-04,  1.5513e-03,  7.2816e-03,  3.8721e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0157]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0323]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0157,  0.0323], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 7, 1] = -0.015650277957320213\n",
            " somado na saída em [1, 1, 7, 1] = 0.03226306661963463\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 2\n",
            " alvo do kernel em x: x[1,0,21:26, 6:11]\n",
            " \n",
            " tensor([[0.7692, 0.3178, 0.1408, 0.9073, 0.6142],\n",
            "        [0.4965, 0.8900, 0.1082, 0.8165, 0.6151],\n",
            "        [0.9749, 0.7476, 0.6766, 0.3303, 0.0556],\n",
            "        [0.4241, 0.3089, 0.1599, 0.9973, 0.3766],\n",
            "        [0.8172, 0.6332, 0.3143, 0.4726, 0.6962]])\n",
            " produto: tensor([[[[-3.1365e-03,  1.0528e-04, -6.9929e-04,  3.4217e-03, -5.2334e-03],\n",
            "          [ 3.6392e-03, -6.4690e-03, -8.6029e-04, -5.1595e-03,  2.7856e-03],\n",
            "          [-3.6022e-03,  2.7976e-03, -5.7421e-03, -2.0039e-03, -2.0416e-04],\n",
            "          [-8.3353e-04, -2.3561e-03,  1.0472e-03, -2.3520e-03,  1.2089e-03],\n",
            "          [ 5.7790e-03,  1.1797e-03,  8.5934e-04,  4.5621e-03, -3.1399e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.4364e-03, -1.4141e-03,  1.0062e-03,  7.2466e-03, -5.6628e-03],\n",
            "          [ 4.2380e-03,  4.2499e-03,  4.7153e-04,  3.3614e-03,  5.1130e-03],\n",
            "          [-1.2873e-03, -6.3223e-03, -1.9414e-03, -2.3261e-03,  3.6757e-05],\n",
            "          [-7.9191e-04, -1.6566e-03, -1.4541e-04,  9.4487e-03, -2.9705e-04],\n",
            "          [ 2.5947e-04, -9.8758e-04,  4.9404e-04,  4.2112e-03,  4.2571e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0144]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0240]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0144,  0.0240], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 7, 2] = -0.014406196773052216\n",
            " somado na saída em [1, 1, 7, 2] = 0.023997856304049492\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 3\n",
            " alvo do kernel em x: x[1,0,21:26, 9:14]\n",
            " \n",
            " tensor([[0.9073, 0.6142, 0.6825, 0.0420, 0.2568],\n",
            "        [0.8165, 0.6151, 0.8746, 0.9342, 0.6523],\n",
            "        [0.3303, 0.0556, 0.4487, 0.1111, 0.3366],\n",
            "        [0.9973, 0.3766, 0.2258, 0.2014, 0.0348],\n",
            "        [0.4726, 0.6962, 0.1218, 0.1617, 0.0277]])\n",
            " produto: tensor([[[[-3.6999e-03,  2.0345e-04, -3.3898e-03,  1.5854e-04, -2.1879e-03],\n",
            "          [ 5.9855e-03, -4.4706e-03, -6.9532e-03, -5.9031e-03,  2.9544e-03],\n",
            "          [-1.2204e-03,  2.0807e-04, -3.8083e-03, -6.7422e-04, -1.2360e-03],\n",
            "          [-1.9599e-03, -2.8730e-03,  1.4783e-03, -4.7496e-04,  1.1157e-04],\n",
            "          [ 3.3422e-03,  1.2970e-03,  3.3319e-04,  1.5613e-03, -1.2489e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 2.8740e-03, -2.7327e-03,  4.8776e-03,  3.3577e-04, -2.3674e-03],\n",
            "          [ 6.9702e-03,  2.9370e-03,  3.8111e-03,  3.8459e-03,  5.4229e-03],\n",
            "          [-4.3611e-04, -4.7023e-04, -1.2875e-03, -7.8262e-04,  2.2253e-04],\n",
            "          [-1.8621e-03, -2.0201e-03, -2.0526e-04,  1.9080e-03, -2.7415e-05],\n",
            "          [ 1.5006e-04, -1.0858e-03,  1.9155e-04,  1.4412e-03,  1.6933e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0213]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0219]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0213,  0.0219], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 7, 3] = -0.021342625841498375\n",
            " somado na saída em [1, 1, 7, 3] = 0.02188003994524479\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 4\n",
            " alvo do kernel em x: x[1,0,21:26, 12:17]\n",
            " \n",
            " tensor([[0.0420, 0.2568, 0.9676, 0.7202, 0.5082],\n",
            "        [0.9342, 0.6523, 0.4646, 0.7987, 0.2579],\n",
            "        [0.1111, 0.3366, 0.0320, 0.4704, 0.8029],\n",
            "        [0.2014, 0.0348, 0.2912, 0.9828, 0.2797],\n",
            "        [0.1617, 0.0277, 0.8153, 0.2786, 0.2210]])\n",
            " produto: tensor([[[[-1.7143e-04,  8.5056e-05, -4.8056e-03,  2.7161e-03, -4.3300e-03],\n",
            "          [ 6.8481e-03, -4.7415e-03, -3.6940e-03, -5.0466e-03,  1.1682e-03],\n",
            "          [-4.1060e-04,  1.2597e-03, -2.7172e-04, -2.8541e-03, -2.9482e-03],\n",
            "          [-3.9579e-04, -2.6515e-04,  1.9068e-03, -2.3178e-03,  8.9785e-04],\n",
            "          [ 1.1438e-03,  5.1589e-05,  2.2296e-03,  2.6889e-03, -9.9682e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.3317e-04, -1.1424e-03,  6.9148e-03,  5.7522e-03, -4.6853e-03],\n",
            "          [ 7.9748e-03,  3.1150e-03,  2.0247e-03,  3.2879e-03,  2.1442e-03],\n",
            "          [-1.4673e-04, -2.8468e-03, -9.1867e-05, -3.3130e-03,  5.3080e-04],\n",
            "          [-3.7602e-04, -1.8643e-04, -2.6477e-04,  9.3111e-03, -2.2063e-04],\n",
            "          [ 5.1354e-05, -4.3186e-05,  1.2818e-03,  2.4821e-03,  1.3515e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0123]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0330]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0123,  0.0330], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 7, 4] = -0.01225360669195652\n",
            " somado na saída em [1, 1, 7, 4] = 0.03303837031126022\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 5\n",
            " alvo do kernel em x: x[1,0,21:26, 15:20]\n",
            " \n",
            " tensor([[0.7202, 0.5082, 0.1740, 0.5754, 0.0883],\n",
            "        [0.7987, 0.2579, 0.4187, 0.6946, 0.3583],\n",
            "        [0.4704, 0.8029, 0.0925, 0.6409, 0.5518],\n",
            "        [0.9828, 0.2797, 0.4701, 0.4818, 0.2889],\n",
            "        [0.2786, 0.2210, 0.1738, 0.3018, 0.7090]])\n",
            " produto: tensor([[[[-2.9370e-03,  1.6833e-04, -8.6404e-04,  2.1698e-03, -7.5228e-04],\n",
            "          [ 5.8545e-03, -1.8748e-03, -3.3290e-03, -4.3889e-03,  1.6226e-03],\n",
            "          [-1.7381e-03,  3.0047e-03, -7.8535e-04, -3.8883e-03, -2.0262e-03],\n",
            "          [-1.9314e-03, -2.1338e-03,  3.0779e-03, -1.1363e-03,  9.2749e-04],\n",
            "          [ 1.9699e-03,  4.1177e-04,  4.7536e-04,  2.9133e-03, -3.1977e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.2814e-03, -2.2610e-03,  1.2433e-03,  4.5953e-03, -8.1401e-04],\n",
            "          [ 6.8177e-03,  1.2317e-03,  1.8246e-03,  2.8593e-03,  2.9784e-03],\n",
            "          [-6.2113e-04, -6.7905e-03, -2.6552e-04, -4.5134e-03,  3.6479e-04],\n",
            "          [-1.8350e-03, -1.5003e-03, -4.2738e-04,  4.5648e-03, -2.2791e-04],\n",
            "          [ 8.8447e-05, -3.4470e-04,  2.7329e-04,  2.6892e-03,  4.3355e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0084]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0165]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0084,  0.0165], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 7, 5] = -0.008387355133891106\n",
            " somado na saída em [1, 1, 7, 5] = 0.01654678024351597\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 6\n",
            " alvo do kernel em x: x[1,0,21:26, 18:23]\n",
            " \n",
            " tensor([[0.5754, 0.0883, 0.0658, 0.7098, 0.0043],\n",
            "        [0.6946, 0.3583, 0.1805, 0.8592, 0.7009],\n",
            "        [0.6409, 0.5518, 0.0818, 0.6906, 0.3006],\n",
            "        [0.4818, 0.2889, 0.8966, 0.0113, 0.3566],\n",
            "        [0.3018, 0.7090, 0.5203, 0.8039, 0.8531]])\n",
            " produto: tensor([[[[-2.3462e-03,  2.9246e-05, -3.2685e-04,  2.6768e-03, -3.6434e-05],\n",
            "          [ 5.0915e-03, -2.6041e-03, -1.4348e-03, -5.4294e-03,  3.1742e-03],\n",
            "          [-2.3679e-03,  2.0650e-03, -6.9415e-04, -4.1900e-03, -1.1039e-03],\n",
            "          [-9.4688e-04, -2.2043e-03,  5.8706e-03, -2.6546e-05,  1.1448e-03],\n",
            "          [ 2.1342e-03,  1.3209e-03,  1.4228e-03,  7.7598e-03, -3.8478e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8225e-03, -3.9282e-04,  4.7031e-04,  5.6690e-03, -3.9423e-05],\n",
            "          [ 5.9291e-03,  1.7108e-03,  7.8645e-04,  3.5372e-03,  5.8263e-03],\n",
            "          [-8.4619e-04, -4.6668e-03, -2.3469e-04, -4.8637e-03,  1.9874e-04],\n",
            "          [-8.9960e-04, -1.5499e-03, -8.1516e-04,  1.0664e-04, -2.8130e-04],\n",
            "          [ 9.5825e-05, -1.1058e-03,  8.1799e-04,  7.1629e-03,  5.2169e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[0.0051]]],\n",
            "\n",
            "\n",
            "        [[[0.0237]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([0.0051, 0.0237], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 7, 6] = 0.005130533128976822\n",
            " somado na saída em [1, 1, 7, 6] = 0.02365545928478241\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 7\n",
            " alvo do kernel em x: x[1,0,21:26, 21:26]\n",
            " \n",
            " tensor([[0.7098, 0.0043, 0.0585, 0.8684, 0.8552],\n",
            "        [0.8592, 0.7009, 0.7482, 0.0032, 0.4081],\n",
            "        [0.6906, 0.3006, 0.8242, 0.7300, 0.9439],\n",
            "        [0.0113, 0.3566, 0.2510, 0.6119, 0.4922],\n",
            "        [0.8039, 0.8531, 0.6324, 0.5807, 0.8215]])\n",
            " produto: tensor([[[[-2.8945e-03,  1.4164e-06, -2.9030e-04,  3.2747e-03, -7.2864e-03],\n",
            "          [ 6.2985e-03, -5.0942e-03, -5.9488e-03, -2.0520e-05,  1.8485e-03],\n",
            "          [-2.5517e-03,  1.1250e-03, -6.9953e-03, -4.4293e-03, -3.4658e-03],\n",
            "          [-2.2121e-05, -2.7207e-03,  1.6437e-03, -1.4431e-03,  1.5799e-03],\n",
            "          [ 5.6848e-03,  1.5895e-03,  1.7294e-03,  5.6056e-03, -3.7048e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.2484e-03, -1.9025e-05,  4.1772e-04,  6.9351e-03, -7.8843e-03],\n",
            "          [ 7.3348e-03,  3.3467e-03,  3.2606e-03,  1.3369e-05,  3.3929e-03],\n",
            "          [-9.1186e-04, -2.5425e-03, -2.3651e-03, -5.1414e-03,  6.2399e-04],\n",
            "          [-2.1016e-05, -1.9129e-03, -2.2824e-04,  5.7975e-03, -3.8822e-04],\n",
            "          [ 2.5524e-04, -1.3306e-03,  9.9422e-04,  5.1744e-03,  5.0231e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0165]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0221]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0165,  0.0221], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 7, 7] = -0.016486570239067078\n",
            " somado na saída em [1, 1, 7, 7] = 0.022072896361351013\n",
            " saida: tensor([[[[-0.0120, -0.0211, -0.0201, -0.0118, -0.0145, -0.0192, -0.0205,\n",
            "           -0.0253],\n",
            "          [-0.0081,  0.0004, -0.0137, -0.0252, -0.0152, -0.0040, -0.0115,\n",
            "           -0.0299],\n",
            "          [-0.0092, -0.0144, -0.0160, -0.0053, -0.0139, -0.0156, -0.0062,\n",
            "            0.0015],\n",
            "          [-0.0191, -0.0082, -0.0131, -0.0134, -0.0155, -0.0194, -0.0083,\n",
            "           -0.0116],\n",
            "          [-0.0122, -0.0261, -0.0082, -0.0316, -0.0083, -0.0166, -0.0231,\n",
            "           -0.0014],\n",
            "          [ 0.0011, -0.0261, -0.0063,  0.0045, -0.0253, -0.0209, -0.0048,\n",
            "           -0.0292],\n",
            "          [-0.0144, -0.0207, -0.0225, -0.0208, -0.0192, -0.0107, -0.0074,\n",
            "           -0.0245],\n",
            "          [-0.0143, -0.0024, -0.0117, -0.0293, -0.0183, -0.0188,  0.0026,\n",
            "            0.0002]],\n",
            "\n",
            "         [[ 0.0187,  0.0131,  0.0214,  0.0076,  0.0083,  0.0187,  0.0141,\n",
            "            0.0005],\n",
            "          [ 0.0034,  0.0328,  0.0025,  0.0122,  0.0183,  0.0177,  0.0109,\n",
            "            0.0007],\n",
            "          [ 0.0135,  0.0109,  0.0163,  0.0290,  0.0151,  0.0196,  0.0096,\n",
            "            0.0100],\n",
            "          [ 0.0224,  0.0271,  0.0156,  0.0199,  0.0118,  0.0262,  0.0148,\n",
            "            0.0248],\n",
            "          [ 0.0271,  0.0229,  0.0265,  0.0211,  0.0102,  0.0305,  0.0252,\n",
            "            0.0226],\n",
            "          [ 0.0176,  0.0238,  0.0109,  0.0162,  0.0164,  0.0060,  0.0195,\n",
            "            0.0124],\n",
            "          [ 0.0059,  0.0162,  0.0158,  0.0065,  0.0063, -0.0045,  0.0201,\n",
            "            0.0237],\n",
            "          [ 0.0064,  0.0107,  0.0089,  0.0074,  0.0097,  0.0156,  0.0192,\n",
            "            0.0208]]],\n",
            "\n",
            "\n",
            "        [[[-0.0090,  0.0007, -0.0078, -0.0152, -0.0175, -0.0171, -0.0107,\n",
            "           -0.0131],\n",
            "          [-0.0101, -0.0179, -0.0057, -0.0204, -0.0053, -0.0102, -0.0129,\n",
            "           -0.0143],\n",
            "          [-0.0133, -0.0160, -0.0158, -0.0112, -0.0075, -0.0159, -0.0170,\n",
            "           -0.0068],\n",
            "          [ 0.0007, -0.0149, -0.0188, -0.0044, -0.0056, -0.0130, -0.0107,\n",
            "           -0.0202],\n",
            "          [-0.0153,  0.0064, -0.0214, -0.0074, -0.0162, -0.0124, -0.0291,\n",
            "           -0.0031],\n",
            "          [-0.0007, -0.0251, -0.0027, -0.0105, -0.0145, -0.0182, -0.0095,\n",
            "           -0.0178],\n",
            "          [-0.0214, -0.0115, -0.0167, -0.0152, -0.0028, -0.0146, -0.0232,\n",
            "           -0.0069],\n",
            "          [-0.0032, -0.0157, -0.0144, -0.0213, -0.0123, -0.0084,  0.0051,\n",
            "           -0.0165]],\n",
            "\n",
            "         [[ 0.0342,  0.0040,  0.0190,  0.0061,  0.0103,  0.0095, -0.0071,\n",
            "            0.0180],\n",
            "          [ 0.0365,  0.0196,  0.0201,  0.0142,  0.0094,  0.0141,  0.0022,\n",
            "            0.0093],\n",
            "          [ 0.0043,  0.0171,  0.0077,  0.0214,  0.0056,  0.0172,  0.0101,\n",
            "            0.0192],\n",
            "          [ 0.0159,  0.0092,  0.0091,  0.0089,  0.0102,  0.0035, -0.0017,\n",
            "            0.0103],\n",
            "          [ 0.0167,  0.0242,  0.0229,  0.0248,  0.0116,  0.0293,  0.0097,\n",
            "            0.0189],\n",
            "          [ 0.0252,  0.0031,  0.0065,  0.0076,  0.0053,  0.0160,  0.0129,\n",
            "            0.0081],\n",
            "          [ 0.0226,  0.0349,  0.0164,  0.0059,  0.0038,  0.0081,  0.0204,\n",
            "            0.0107],\n",
            "          [ 0.0276,  0.0323,  0.0240,  0.0219,  0.0330,  0.0165,  0.0237,\n",
            "            0.0221]]]], grad_fn=<CopySlices>)\n",
            "\n",
            "ndx_amostra: 0\n",
            "\n",
            "ndx_amostra: 1\n",
            " saida apos somar bias: tensor([[[[-0.0085, -0.0176, -0.0165, -0.0083, -0.0109, -0.0156, -0.0169,\n",
            "           -0.0218],\n",
            "          [-0.0045,  0.0039, -0.0101, -0.0216, -0.0116, -0.0005, -0.0080,\n",
            "           -0.0263],\n",
            "          [-0.0057, -0.0108, -0.0125, -0.0018, -0.0104, -0.0121, -0.0026,\n",
            "            0.0050],\n",
            "          [-0.0155, -0.0046, -0.0095, -0.0099, -0.0119, -0.0158, -0.0048,\n",
            "           -0.0081],\n",
            "          [-0.0087, -0.0225, -0.0046, -0.0281, -0.0047, -0.0130, -0.0196,\n",
            "            0.0022],\n",
            "          [ 0.0046, -0.0225, -0.0027,  0.0080, -0.0217, -0.0174, -0.0012,\n",
            "           -0.0256],\n",
            "          [-0.0108, -0.0172, -0.0190, -0.0173, -0.0157, -0.0072, -0.0039,\n",
            "           -0.0209],\n",
            "          [-0.0107,  0.0011, -0.0082, -0.0258, -0.0148, -0.0152,  0.0062,\n",
            "            0.0038]],\n",
            "\n",
            "         [[ 0.0209,  0.0153,  0.0236,  0.0097,  0.0105,  0.0208,  0.0162,\n",
            "            0.0026],\n",
            "          [ 0.0056,  0.0349,  0.0047,  0.0144,  0.0205,  0.0198,  0.0131,\n",
            "            0.0029],\n",
            "          [ 0.0157,  0.0131,  0.0185,  0.0312,  0.0172,  0.0218,  0.0117,\n",
            "            0.0122],\n",
            "          [ 0.0245,  0.0293,  0.0178,  0.0220,  0.0140,  0.0283,  0.0170,\n",
            "            0.0269],\n",
            "          [ 0.0293,  0.0251,  0.0287,  0.0232,  0.0123,  0.0326,  0.0274,\n",
            "            0.0248],\n",
            "          [ 0.0198,  0.0259,  0.0131,  0.0184,  0.0186,  0.0081,  0.0217,\n",
            "            0.0146],\n",
            "          [ 0.0081,  0.0184,  0.0180,  0.0087,  0.0085, -0.0023,  0.0222,\n",
            "            0.0259],\n",
            "          [ 0.0086,  0.0129,  0.0111,  0.0096,  0.0118,  0.0178,  0.0214,\n",
            "            0.0230]]],\n",
            "\n",
            "\n",
            "        [[[-0.0055,  0.0043, -0.0042, -0.0117, -0.0140, -0.0135, -0.0071,\n",
            "           -0.0095],\n",
            "          [-0.0065, -0.0144, -0.0022, -0.0168, -0.0017, -0.0067, -0.0094,\n",
            "           -0.0108],\n",
            "          [-0.0097, -0.0124, -0.0123, -0.0076, -0.0039, -0.0124, -0.0135,\n",
            "           -0.0033],\n",
            "          [ 0.0043, -0.0113, -0.0152, -0.0009, -0.0020, -0.0095, -0.0071,\n",
            "           -0.0167],\n",
            "          [-0.0117,  0.0100, -0.0178, -0.0039, -0.0126, -0.0088, -0.0255,\n",
            "            0.0004],\n",
            "          [ 0.0029, -0.0216,  0.0009, -0.0069, -0.0110, -0.0147, -0.0060,\n",
            "           -0.0142],\n",
            "          [-0.0179, -0.0080, -0.0132, -0.0117,  0.0007, -0.0111, -0.0197,\n",
            "           -0.0034],\n",
            "          [ 0.0004, -0.0121, -0.0109, -0.0178, -0.0087, -0.0048,  0.0087,\n",
            "           -0.0129]],\n",
            "\n",
            "         [[ 0.0364,  0.0061,  0.0212,  0.0083,  0.0125,  0.0117, -0.0049,\n",
            "            0.0202],\n",
            "          [ 0.0387,  0.0218,  0.0223,  0.0164,  0.0116,  0.0163,  0.0044,\n",
            "            0.0115],\n",
            "          [ 0.0065,  0.0193,  0.0099,  0.0236,  0.0078,  0.0194,  0.0123,\n",
            "            0.0213],\n",
            "          [ 0.0181,  0.0114,  0.0113,  0.0110,  0.0124,  0.0057,  0.0005,\n",
            "            0.0125],\n",
            "          [ 0.0189,  0.0264,  0.0251,  0.0270,  0.0137,  0.0315,  0.0119,\n",
            "            0.0211],\n",
            "          [ 0.0274,  0.0053,  0.0087,  0.0098,  0.0075,  0.0182,  0.0151,\n",
            "            0.0103],\n",
            "          [ 0.0247,  0.0371,  0.0186,  0.0081,  0.0060,  0.0103,  0.0226,\n",
            "            0.0128],\n",
            "          [ 0.0297,  0.0344,  0.0262,  0.0241,  0.0352,  0.0187,  0.0258,\n",
            "            0.0242]]]], grad_fn=<CopySlices>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSTrD1WRnGng",
        "outputId": "2201c260-75a9-4283-99e0-02b54ec17b44"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Usa os mesmos pesos para minha implementação e a do pytorch\n",
        "pytorch_conv_layer = torch.nn.Conv2d( in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=0)\n",
        "pytorch_conv_layer.load_state_dict(dict(weight=initial_conv_weight, bias=initial_conv_bias))\n",
        "\n",
        "target_out = pytorch_conv_layer(x)"
      ],
      "metadata": {
        "id": "HzIjuGpWlbIM"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2Sesz6onCEw",
        "outputId": "b7a0ea20-67e0-4eb4-afed-ed96d806086f"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert torch.allclose(out, target_out, atol=1e-6)"
      ],
      "metadata": {
        "id": "noWWzeCumRIY"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQA9Zg7GQT2G"
      },
      "source": [
        "## Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:10.802708Z",
          "start_time": "2018-08-20T21:03:10.793287Z"
        },
        "id": "_8Eg4h_kQT2H"
      },
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, height_in: int, width_in: int, in_channels: int, out_channels: int, kernel_size: int, stride: int):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv_layer = MyConv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride)\n",
        "   \n",
        "        height_out = (height_in - kernel_size) // stride + 1\n",
        "        width_out = (width_in - kernel_size) // stride + 1\n",
        "        self.classification_layer = torch.nn.Linear(out_channels * height_out * width_out, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        hidden = self.conv_layer(x)\n",
        "        hidden = torch.nn.functional.relu(hidden)\n",
        "        hidden = hidden.reshape(x.shape[0], -1)\n",
        "        logits = self.classification_layer(hidden)\n",
        "        return logits"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NHQB4wGQT2K"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqs2JhJoQT2L"
      },
      "source": [
        "### Definição dos hiperparâmetros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:14.146259Z",
          "start_time": "2018-08-20T21:03:14.139515Z"
        },
        "id": "oZuYEkn_QT2M"
      },
      "source": [
        "n_epochs = 50\n",
        "lr = 0.1"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmXarXeIQT2O"
      },
      "source": [
        "### Laço de treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:40.796410Z",
          "start_time": "2018-08-20T21:03:39.771981Z"
        },
        "id": "L5T_jZZPQT2P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "029019a6-2a0b-445b-83b9-55e699399619"
      },
      "source": [
        "model = Net(height_in=height_in, width_in=width_in, in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride)\n",
        "\n",
        "# Usa pesos iniciais pré-difinidos\n",
        "model.classification_layer.load_state_dict(dict(weight=initial_classification_weight, bias=initial_classification_bias))\n",
        "model.conv_layer.weight.data = initial_conv_weight\n",
        "model.conv_layer.bias.data = initial_conv_bias\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr)\n",
        "\n",
        "epochs = []\n",
        "loss_history = []\n",
        "loss_epoch_end = []\n",
        "total_trained_samples = 0\n",
        "for i in range(n_epochs):\n",
        "    for x_train, y_train in loader_train:\n",
        "        # predict da rede\n",
        "        outputs = model(x_train)\n",
        "\n",
        "        # calcula a perda\n",
        "        loss = criterion(outputs, y_train)\n",
        "\n",
        "        # zero, backpropagation, ajusta parâmetros pelo gradiente descendente\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_trained_samples += x_train.size(0)\n",
        "        epochs.append(total_trained_samples / len(dataset_train))\n",
        "        loss_history.append(loss.item())\n",
        "\n",
        "    loss_epoch_end.append(loss.item())\n",
        "    print(f'Epoch: {i:d}/{n_epochs - 1:d} Loss: {loss.item()}')\n"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0/49 Loss: 0.9586364030838013\n",
            "Epoch: 1/49 Loss: 0.565815269947052\n",
            "Epoch: 2/49 Loss: 0.4770318567752838\n",
            "Epoch: 3/49 Loss: 0.42453765869140625\n",
            "Epoch: 4/49 Loss: 0.38708603382110596\n",
            "Epoch: 5/49 Loss: 0.35843756794929504\n",
            "Epoch: 6/49 Loss: 0.336288183927536\n",
            "Epoch: 7/49 Loss: 0.31845659017562866\n",
            "Epoch: 8/49 Loss: 0.3037392497062683\n",
            "Epoch: 9/49 Loss: 0.2910858988761902\n",
            "Epoch: 10/49 Loss: 0.2799944579601288\n",
            "Epoch: 11/49 Loss: 0.270416259765625\n",
            "Epoch: 12/49 Loss: 0.2619065046310425\n",
            "Epoch: 13/49 Loss: 0.25361135601997375\n",
            "Epoch: 14/49 Loss: 0.24582411348819733\n",
            "Epoch: 15/49 Loss: 0.23841428756713867\n",
            "Epoch: 16/49 Loss: 0.23117700219154358\n",
            "Epoch: 17/49 Loss: 0.2241152971982956\n",
            "Epoch: 18/49 Loss: 0.2175927609205246\n",
            "Epoch: 19/49 Loss: 0.21121275424957275\n",
            "Epoch: 20/49 Loss: 0.2050437331199646\n",
            "Epoch: 21/49 Loss: 0.19928722083568573\n",
            "Epoch: 22/49 Loss: 0.1938953399658203\n",
            "Epoch: 23/49 Loss: 0.1882905215024948\n",
            "Epoch: 24/49 Loss: 0.1828724443912506\n",
            "Epoch: 25/49 Loss: 0.1776149421930313\n",
            "Epoch: 26/49 Loss: 0.17248651385307312\n",
            "Epoch: 27/49 Loss: 0.16733810305595398\n",
            "Epoch: 28/49 Loss: 0.16254152357578278\n",
            "Epoch: 29/49 Loss: 0.15758882462978363\n",
            "Epoch: 30/49 Loss: 0.1527339220046997\n",
            "Epoch: 31/49 Loss: 0.14789022505283356\n",
            "Epoch: 32/49 Loss: 0.14303667843341827\n",
            "Epoch: 33/49 Loss: 0.1380799561738968\n",
            "Epoch: 34/49 Loss: 0.13330009579658508\n",
            "Epoch: 35/49 Loss: 0.12855049967765808\n",
            "Epoch: 36/49 Loss: 0.12378916144371033\n",
            "Epoch: 37/49 Loss: 0.119150809943676\n",
            "Epoch: 38/49 Loss: 0.11474869400262833\n",
            "Epoch: 39/49 Loss: 0.110462486743927\n",
            "Epoch: 40/49 Loss: 0.10636704415082932\n",
            "Epoch: 41/49 Loss: 0.10245434939861298\n",
            "Epoch: 42/49 Loss: 0.09870947152376175\n",
            "Epoch: 43/49 Loss: 0.09508325904607773\n",
            "Epoch: 44/49 Loss: 0.09160909056663513\n",
            "Epoch: 45/49 Loss: 0.08813302963972092\n",
            "Epoch: 46/49 Loss: 0.08475378155708313\n",
            "Epoch: 47/49 Loss: 0.08139956742525101\n",
            "Epoch: 48/49 Loss: 0.07817484438419342\n",
            "Epoch: 49/49 Loss: 0.07505226880311966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLL-GQlKQT2Y"
      },
      "source": [
        "### Visualização usual da perda, somente no final de cada minibatch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:55.246851Z",
          "start_time": "2018-08-20T21:03:54.994428Z"
        },
        "id": "w38EtNxhQT2Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "84af62c3-9825-4d81-e6e9-85c3d6389609"
      },
      "source": [
        "n_batches_train = len(loader_train)\n",
        "plt.plot(epochs[::n_batches_train], loss_history[::n_batches_train])\n",
        "plt.xlabel('época')"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'época')"
            ]
          },
          "metadata": {},
          "execution_count": 167
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_epoch_end"
      ],
      "metadata": {
        "id": "ToktJu4CK94z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecd61d51-0172-464c-cc0b-d023eabc5622"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9586364030838013,\n",
              " 0.565815269947052,\n",
              " 0.4770318567752838,\n",
              " 0.42453765869140625,\n",
              " 0.38708603382110596,\n",
              " 0.35843756794929504,\n",
              " 0.336288183927536,\n",
              " 0.31845659017562866,\n",
              " 0.3037392497062683,\n",
              " 0.2910858988761902,\n",
              " 0.2799944579601288,\n",
              " 0.270416259765625,\n",
              " 0.2619065046310425,\n",
              " 0.25361135601997375,\n",
              " 0.24582411348819733,\n",
              " 0.23841428756713867,\n",
              " 0.23117700219154358,\n",
              " 0.2241152971982956,\n",
              " 0.2175927609205246,\n",
              " 0.21121275424957275,\n",
              " 0.2050437331199646,\n",
              " 0.19928722083568573,\n",
              " 0.1938953399658203,\n",
              " 0.1882905215024948,\n",
              " 0.1828724443912506,\n",
              " 0.1776149421930313,\n",
              " 0.17248651385307312,\n",
              " 0.16733810305595398,\n",
              " 0.16254152357578278,\n",
              " 0.15758882462978363,\n",
              " 0.1527339220046997,\n",
              " 0.14789022505283356,\n",
              " 0.14303667843341827,\n",
              " 0.1380799561738968,\n",
              " 0.13330009579658508,\n",
              " 0.12855049967765808,\n",
              " 0.12378916144371033,\n",
              " 0.119150809943676,\n",
              " 0.11474869400262833,\n",
              " 0.110462486743927,\n",
              " 0.10636704415082932,\n",
              " 0.10245434939861298,\n",
              " 0.09870947152376175,\n",
              " 0.09508325904607773,\n",
              " 0.09160909056663513,\n",
              " 0.08813302963972092,\n",
              " 0.08475378155708313,\n",
              " 0.08139956742525101,\n",
              " 0.07817484438419342,\n",
              " 0.07505226880311966]"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:48.786969Z",
          "start_time": "2018-08-20T21:03:48.781787Z"
        },
        "id": "PiuMsjYtQT2R"
      },
      "source": [
        "# Assert do histórico de losses\n",
        "target_loss_epoch_end = np.array([\n",
        "    2.303267478942871,\n",
        "    2.227701187133789,\n",
        "    1.0923893451690674,\n",
        "    0.5867354869842529,\n",
        "    0.5144089460372925,\n",
        "    0.45026642084121704,\n",
        "    0.4075140357017517,\n",
        "    0.37713879346847534,\n",
        "    0.3534485101699829,\n",
        "    0.3341451585292816,\n",
        "    0.3181140422821045,\n",
        "    0.30457887053489685,\n",
        "    0.29283496737480164,\n",
        "    0.2827608287334442,\n",
        "    0.2738332152366638,\n",
        "    0.2657742500305176,\n",
        "    0.2583288848400116,\n",
        "    0.25117507576942444,\n",
        "    0.24439716339111328,\n",
        "    0.23789969086647034,\n",
        "    0.23167723417282104,\n",
        "    0.22562651336193085,\n",
        "    0.21984536945819855,\n",
        "    0.2142913043498993,\n",
        "    0.20894232392311096,\n",
        "    0.203872948884964,\n",
        "    0.19903430342674255,\n",
        "    0.19439971446990967,\n",
        "    0.18994088470935822,\n",
        "    0.18563991785049438,\n",
        "    0.18147490918636322,\n",
        "    0.17744913697242737,\n",
        "    0.17347246408462524,\n",
        "    0.16947467625141144,\n",
        "    0.16547319293022156,\n",
        "    0.16150487959384918,\n",
        "    0.1574639081954956,\n",
        "    0.1534043848514557,\n",
        "    0.14926929771900177,\n",
        "    0.1452063024044037,\n",
        "    0.1412365883588791,\n",
        "    0.13712672889232635,\n",
        "    0.1331038922071457,\n",
        "    0.1291467249393463,\n",
        "    0.1251506358385086,\n",
        "    0.12116757035255432,\n",
        "    0.11731722950935364,\n",
        "    0.11364627629518509,\n",
        "    0.11001908034086227,\n",
        "    0.10655981302261353])\n",
        "\n",
        "assert np.allclose(np.array(loss_epoch_end), target_loss_epoch_end, atol=1e-6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rascunho"
      ],
      "metadata": {
        "id": "yy2fvfxRnWDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_channels_dummy = 1\n",
        "out_channels_dummy = 2\n",
        "kernel_size_dummy = 3\n",
        "stride_dummy = 2\n",
        "num_amostras_dummy = 1\n",
        "x = torch.arange(30).float().reshape(num_amostras_dummy, 1, 5, 6)"
      ],
      "metadata": {
        "id": "eHg1E0xkGn-F"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dfc7424-fe9d-4b9b-dbc8-63eef6638f0b",
        "id": "GLcaZY0nGn-F"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
            "          [ 6.,  7.,  8.,  9., 10., 11.],\n",
            "          [12., 13., 14., 15., 16., 17.],\n",
            "          [18., 19., 20., 21., 22., 23.],\n",
            "          [24., 25., 26., 27., 28., 29.]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# falta stride e tratar out_channels > 1"
      ],
      "metadata": {
        "id": "G4-z1oWfI5j8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "conv_layer = MyConv2d( in_channels=in_channels_dummy,out_channels=out_channels_dummy, kernel_size=kernel_size_dummy, stride=stride_dummy, verbose=True)\n",
        "\n",
        "# Usa os mesmos pesos para minha implementação e a do pytorch\n",
        "initial_weights_dummy = torch.arange(in_channels_dummy * out_channels_dummy * kernel_size_dummy * kernel_size_dummy).float()\n",
        "initial_weights_dummy = initial_weights_dummy.reshape(out_channels_dummy, in_channels_dummy,  kernel_size_dummy, kernel_size_dummy)\n",
        "initial_bias_dummy = torch.arange(out_channels_dummy,).float()\n",
        "print(f\"initial_bias_dummy.shape {initial_bias_dummy.shape}, initial_weights_dummy.shape {initial_weights_dummy.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05cc0a62-a67c-4d07-a76a-6b039f15dcdf",
        "id": "m5oMLsHsGn-G"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inicializado MyConv2d\n",
            "in_channels: 1 \n",
            "out_channels: 2 \n",
            "kernel_size: 3 \n",
            "stride: 2 \n",
            "weight.shape: torch.Size([2, 1, 3, 3]) \n",
            "weight: Parameter containing:\n",
            "tensor([[[[-0.0082, -0.0041, -0.0035],\n",
            "          [ 0.0023, -0.0072,  0.0030],\n",
            "          [-0.0095,  0.0072, -0.0016]]],\n",
            "\n",
            "\n",
            "        [[[-0.0069, -0.0036,  0.0015],\n",
            "          [ 0.0053, -0.0033, -0.0039],\n",
            "          [ 0.0075,  0.0062, -0.0042]]]], requires_grad=True) \n",
            "bias.shape: torch.Size([2]) \n",
            "bias: Parameter containing:\n",
            "tensor([ 0.0033, -0.0044], requires_grad=True) \n",
            "initial_bias_dummy.shape torch.Size([2]), initial_weights_dummy.shape torch.Size([2, 1, 3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_layer.weight.data = initial_weights_dummy\n",
        "conv_layer.bias.data = initial_bias_dummy\n",
        "print(f\"conv_layer.weight.data: {conv_layer.weight.data}\")\n",
        "print(f\"conv_layer.bias.data: {conv_layer.bias.data}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5Gr8N8vXkkv",
        "outputId": "95ef5782-bb28-489d-bf51-9e630cd1748d"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv_layer.weight.data: tensor([[[[ 0.,  1.,  2.],\n",
            "          [ 3.,  4.,  5.],\n",
            "          [ 6.,  7.,  8.]]],\n",
            "\n",
            "\n",
            "        [[[ 9., 10., 11.],\n",
            "          [12., 13., 14.],\n",
            "          [15., 16., 17.]]]])\n",
            "conv_layer.bias.data: tensor([0., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW1S0eXhYQ21",
        "outputId": "fa0288df-0420-4e37-e1a5-d10709c8c0e5"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
            "          [ 6.,  7.,  8.,  9., 10., 11.],\n",
            "          [12., 13., 14., 15., 16., 17.],\n",
            "          [18., 19., 20., 21., 22., 23.],\n",
            "          [24., 25., 26., 27., 28., 29.]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = conv_layer(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVysHnpYX4O2",
        "outputId": "23a3dca3-fb28-4aa2-f2b3-c2d0170fb999"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " num_amostras: 1, self.out_channels: 2, num_linhas_entrada: 5, num_colunas_entrada: 6, num_linhas_saida: 2, num_colunas_saida: 2\n",
            "saida.shape: torch.Size([1, 2, 2, 2])\n",
            "\n",
            "ndx_amostra: 0\n",
            "\n",
            "ndx_in_channels: 0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 0\n",
            " alvo do kernel em x: x[0,0,0:3, 0:3]\n",
            " \n",
            " tensor([[ 0.,  1.,  2.],\n",
            "        [ 6.,  7.,  8.],\n",
            "        [12., 13., 14.]])\n",
            " produto: tensor([[[[  0.,   1.,   4.],\n",
            "          [ 18.,  28.,  40.],\n",
            "          [ 72.,  91., 112.]]],\n",
            "\n",
            "\n",
            "        [[[  0.,  10.,  22.],\n",
            "          [ 72.,  91., 112.],\n",
            "          [180., 208., 238.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[366.]]],\n",
            "\n",
            "\n",
            "        [[[933.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([366., 933.], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 0] = 366.0\n",
            " somado na saída em [0, 1, 0, 0] = 933.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 1\n",
            " alvo do kernel em x: x[0,0,0:3, 2:5]\n",
            " \n",
            " tensor([[ 2.,  3.,  4.],\n",
            "        [ 8.,  9., 10.],\n",
            "        [14., 15., 16.]])\n",
            " produto: tensor([[[[  0.,   3.,   8.],\n",
            "          [ 24.,  36.,  50.],\n",
            "          [ 84., 105., 128.]]],\n",
            "\n",
            "\n",
            "        [[[ 18.,  30.,  44.],\n",
            "          [ 96., 117., 140.],\n",
            "          [210., 240., 272.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[ 438.]]],\n",
            "\n",
            "\n",
            "        [[[1167.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([ 438., 1167.], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 1] = 438.0\n",
            " somado na saída em [0, 1, 0, 1] = 1167.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 0\n",
            " alvo do kernel em x: x[0,0,2:5, 0:3]\n",
            " \n",
            " tensor([[12., 13., 14.],\n",
            "        [18., 19., 20.],\n",
            "        [24., 25., 26.]])\n",
            " produto: tensor([[[[  0.,  13.,  28.],\n",
            "          [ 54.,  76., 100.],\n",
            "          [144., 175., 208.]]],\n",
            "\n",
            "\n",
            "        [[[108., 130., 154.],\n",
            "          [216., 247., 280.],\n",
            "          [360., 400., 442.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[ 798.]]],\n",
            "\n",
            "\n",
            "        [[[2337.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([ 798., 2337.], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 0] = 798.0\n",
            " somado na saída em [0, 1, 1, 0] = 2337.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 1\n",
            " alvo do kernel em x: x[0,0,2:5, 2:5]\n",
            " \n",
            " tensor([[14., 15., 16.],\n",
            "        [20., 21., 22.],\n",
            "        [26., 27., 28.]])\n",
            " produto: tensor([[[[  0.,  15.,  32.],\n",
            "          [ 60.,  84., 110.],\n",
            "          [156., 189., 224.]]],\n",
            "\n",
            "\n",
            "        [[[126., 150., 176.],\n",
            "          [240., 273., 308.],\n",
            "          [390., 432., 476.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[ 870.]]],\n",
            "\n",
            "\n",
            "        [[[2571.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([ 870., 2571.], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 1] = 870.0\n",
            " somado na saída em [0, 1, 1, 1] = 2571.0\n",
            " saida: tensor([[[[ 366.,  438.],\n",
            "          [ 798.,  870.]],\n",
            "\n",
            "         [[ 933., 1167.],\n",
            "          [2337., 2571.]]]], grad_fn=<CopySlices>)\n",
            "\n",
            "ndx_amostra: 0\n",
            " saida apos somar bias: tensor([[[[ 366.,  438.],\n",
            "          [ 798.,  870.]],\n",
            "\n",
            "         [[ 934., 1168.],\n",
            "          [2338., 2572.]]]], grad_fn=<CopySlices>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ED6gJjl7GonF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2Vcc7RvMGo2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp = torch.tensor([[[[34.]]]])"
      ],
      "metadata": {
        "id": "JZUW6dbGeULx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp.squeeze()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8ATxh3DkQlS",
        "outputId": "6dea88af-1ef6-410b-d2e1-772f55b58de1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(34.)"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp.squeeze().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijHjn6Fwk_6S",
        "outputId": "fc8bbe28-ae31-472d-d2bd-50cfaa6eae0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([])"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp.squeeze().reshape(1,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrEMRgHxk7UK",
        "outputId": "d9d8d83d-cb40-4844-8e21-c1170d9417b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([34.])"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp.view(1,-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dx_BICd-kVsC",
        "outputId": "7242672c-05da-4aeb-b8bd-e72aadfa04c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[34.]])"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp = torch.tensor([[[[ 46.]], [[134.]]]])"
      ],
      "metadata": {
        "id": "xK5LO9EikKLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp.squeeze()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zgWxyfKeYhZ",
        "outputId": "758c69e0-7669-4021-b5b7-3f364d0222e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 46., 134.])"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp.squeeze().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74ouMw6ClWhp",
        "outputId": "f7e23e94-af1e-4251-b57a-ffc992ddede0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp.squeeze().reshape(2,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVj0YgbZknZE",
        "outputId": "634e9b79-0ca4-4b6c-cb05-903b27262855"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 46., 134.])"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp.squeeze().shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NKOwsD_eYsI",
        "outputId": "8bade88a-be35-4a88-ba2c-cb85f05613e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    }
  ]
}