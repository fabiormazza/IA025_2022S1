{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "toc": {
      "nav_menu": {
        "height": "318px",
        "width": "252px"
      },
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "Aula 5 - Exercício - Marcus Borela",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "45e2e026b6d7445b8d75ba076f7cef76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9fa67b8bfcff4063a1aaa428a39ea04b",
              "IPY_MODEL_34598cc254b94f37bd4d36d3db0b70c6",
              "IPY_MODEL_75bd38c38af743dd8cb4dce2423ef9a6"
            ],
            "layout": "IPY_MODEL_e35e33455c954313a099292e5149b450"
          }
        },
        "9fa67b8bfcff4063a1aaa428a39ea04b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd61154231714402a980cf9b253867a3",
            "placeholder": "​",
            "style": "IPY_MODEL_d0e5bf6df534436e8dec130c58b101c3",
            "value": ""
          }
        },
        "34598cc254b94f37bd4d36d3db0b70c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a60f6f24a6cb41158af378672e65aa81",
            "max": 9912422,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a9b6cd0b70b4385a001b96c1a391804",
            "value": 9912422
          }
        },
        "75bd38c38af743dd8cb4dce2423ef9a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a872fc461974834b1eff3e776371ab9",
            "placeholder": "​",
            "style": "IPY_MODEL_95b878a3890649f1a910de15b3564beb",
            "value": " 9913344/? [00:00&lt;00:00, 19693052.20it/s]"
          }
        },
        "e35e33455c954313a099292e5149b450": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd61154231714402a980cf9b253867a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0e5bf6df534436e8dec130c58b101c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a60f6f24a6cb41158af378672e65aa81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a9b6cd0b70b4385a001b96c1a391804": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a872fc461974834b1eff3e776371ab9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95b878a3890649f1a910de15b3564beb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da5f91d1d0f24942857852564cd0489d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_addd7d0b33c44a788dba51d41ff78318",
              "IPY_MODEL_42be1f44f9c149ad8d2f7b151a3202fa",
              "IPY_MODEL_65bc1c149d8a4465b6b8d6672273b670"
            ],
            "layout": "IPY_MODEL_129e829dfde6456fbb5963a6e69081ea"
          }
        },
        "addd7d0b33c44a788dba51d41ff78318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37012e981bf740cf97545255d7b7f2c0",
            "placeholder": "​",
            "style": "IPY_MODEL_4a8d52af7fff46a7bbc022bcbe29c099",
            "value": ""
          }
        },
        "42be1f44f9c149ad8d2f7b151a3202fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_919520832a5848ea850ca7dbe339581e",
            "max": 28881,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b334d329eaaf4d1387afd32181274d95",
            "value": 28881
          }
        },
        "65bc1c149d8a4465b6b8d6672273b670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81ff02cb4bd9447c9cb5aef8393e1fa1",
            "placeholder": "​",
            "style": "IPY_MODEL_d5a074aaed4e4d8c8d2568b638b5a8a7",
            "value": " 29696/? [00:00&lt;00:00, 5636.58it/s]"
          }
        },
        "129e829dfde6456fbb5963a6e69081ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37012e981bf740cf97545255d7b7f2c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a8d52af7fff46a7bbc022bcbe29c099": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "919520832a5848ea850ca7dbe339581e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b334d329eaaf4d1387afd32181274d95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "81ff02cb4bd9447c9cb5aef8393e1fa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5a074aaed4e4d8c8d2568b638b5a8a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9286bbf29a934f8e878d52261e98ad61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a086fb1d1cdd4a878e26e97fd5b0b593",
              "IPY_MODEL_494e42937cfd4ef190e832774e6dfd49",
              "IPY_MODEL_e062530b9df249a1b852a681665a3fa7"
            ],
            "layout": "IPY_MODEL_8f632382fc9f45f7be897ef418a00d8f"
          }
        },
        "a086fb1d1cdd4a878e26e97fd5b0b593": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82ae37e9858848e19b9190cb7d98758b",
            "placeholder": "​",
            "style": "IPY_MODEL_15048f031d8e4f1384759df714ad6ab2",
            "value": ""
          }
        },
        "494e42937cfd4ef190e832774e6dfd49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3231b4b6edde479da550ab3ff2f3878b",
            "max": 1648877,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8cc38880d38f4a15a34f1afa2d3206e8",
            "value": 1648877
          }
        },
        "e062530b9df249a1b852a681665a3fa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec4841cfc86c41ff9bc176bac9bd51ad",
            "placeholder": "​",
            "style": "IPY_MODEL_2cfb8ac015534c3fa8d5e5c0ca922661",
            "value": " 1649664/? [00:00&lt;00:00, 5009841.84it/s]"
          }
        },
        "8f632382fc9f45f7be897ef418a00d8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82ae37e9858848e19b9190cb7d98758b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15048f031d8e4f1384759df714ad6ab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3231b4b6edde479da550ab3ff2f3878b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cc38880d38f4a15a34f1afa2d3206e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec4841cfc86c41ff9bc176bac9bd51ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cfb8ac015534c3fa8d5e5c0ca922661": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e790426ddb604da59b05dfbab166193c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2f472256b2d4d029e95a074f119db4c",
              "IPY_MODEL_39cb686158944e3488374b6da41a9234",
              "IPY_MODEL_945b3de9f4694c07ace4d20308aafe36"
            ],
            "layout": "IPY_MODEL_efaaad3a7e5a4858aaf23812de17d89e"
          }
        },
        "b2f472256b2d4d029e95a074f119db4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_000e21cd740249839ef27832c3342425",
            "placeholder": "​",
            "style": "IPY_MODEL_7b887b03983c43f9a2ef542b816d2f86",
            "value": ""
          }
        },
        "39cb686158944e3488374b6da41a9234": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8782b175373c4bc99e1309a7b39fabc1",
            "max": 4542,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6819e47c4255490781b2937e0b64e431",
            "value": 4542
          }
        },
        "945b3de9f4694c07ace4d20308aafe36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40d8fdcaa27b479e8734ade13f9186d3",
            "placeholder": "​",
            "style": "IPY_MODEL_1262edd1236741cbb1fc0f2af459e98a",
            "value": " 5120/? [00:00&lt;00:00, 7941.94it/s]"
          }
        },
        "efaaad3a7e5a4858aaf23812de17d89e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "000e21cd740249839ef27832c3342425": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b887b03983c43f9a2ef542b816d2f86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8782b175373c4bc99e1309a7b39fabc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6819e47c4255490781b2937e0b64e431": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40d8fdcaa27b479e8734ade13f9186d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1262edd1236741cbb1fc0f2af459e98a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unicamp-dl/IA025_2022S1/blob/main/ex05/Marcus_Vinicius_Borela_de_Castro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nome = 'Marcus Vinícius Borela de CAstro'\n",
        "\n",
        "print(f'Meu nome é {nome}')"
      ],
      "metadata": {
        "id": "CdORg7oe68oq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68cab2c5-3125-428d-db89-01e863efc7ac"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meu nome é Marcus Vinícius Borela de CAstro\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkfGTqMVQT1u"
      },
      "source": [
        "Este exercicío consiste em treinar no MNIST um modelo de duas camadas, sendo a primeira uma camada convolucional e a segunda uma camada linear de classificação.\n",
        "\n",
        "Não podemos usar as funções torch.nn.Conv{1,2,3}d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFNf4RPxQT1w"
      },
      "source": [
        "## Importação das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-21T14:08:14.033692Z",
          "start_time": "2018-08-21T14:08:11.179981Z"
        },
        "id": "-fLUSHaCQT1x"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fixando as seeds"
      ],
      "metadata": {
        "id": "achvQ78sa3p3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkETIyWGkbOf"
      },
      "source": [
        "def inicializa_seed(num_semente:int=123):\n",
        "  \"\"\"\n",
        "  É recomendado reiniciar as seeds antes de inicializar o modelo, pois assim\n",
        "  garantimos que os pesos vao ser sempre os mesmos.\n",
        "  fontes de apoio: \n",
        "      http://nlp.seas.harvard.edu/2018/04/03/attention.html\n",
        "      https://github.com/CyberZHG/torch-multi-head-attention/blob/master/torch_multi_head_attention/multi_head_attention.py#L15\n",
        "  \"\"\"\n",
        "  random.seed(num_semente)\n",
        "  np.random.seed(num_semente)\n",
        "  torch.manual_seed(num_semente)\n",
        "  #torch.cuda.manual_seed(num_semente)\n",
        "  #Cuda algorithms\n",
        "  #torch.backends.cudnn.deterministic = True "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViMcw_kVkbOf"
      },
      "source": [
        "inicializa_seed(123)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define pesos iniciais"
      ],
      "metadata": {
        "id": "fzurMVpHxcNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_channels = 1\n",
        "out_channels = 2\n",
        "kernel_size = 5\n",
        "stride = 3\n",
        "\n",
        "# Input image size\n",
        "height_in = 28  \n",
        "width_in = 28\n",
        "\n",
        "# Image size after the first convolutional layer.\n",
        "height_out = (height_in - kernel_size - 1) // stride + 1\n",
        "width_out = (width_in - kernel_size - 1) // stride + 1\n",
        "\n",
        "\n",
        "initial_conv_weight = torch.FloatTensor(out_channels, in_channels, kernel_size, kernel_size).uniform_(-0.01, 0.01)\n",
        "initial_conv_bias = torch.FloatTensor(out_channels,).uniform_(-0.01, 0.01)\n",
        "\n",
        "initial_classification_weight = torch.FloatTensor(10, out_channels * height_out * width_out).uniform_(-0.01, 0.01)\n",
        "initial_classification_bias = torch.FloatTensor(10,).uniform_(-0.01, 0.01)"
      ],
      "metadata": {
        "id": "9a6jQJLLlfF3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\" height_out {height_out}, width_out {width_out}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Y2-ILXqbE1d",
        "outputId": "dea31115-dd1a-4249-fea8-099e69e45709"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " height_out 8, width_out 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEMUsfJpQT11"
      },
      "source": [
        "## Dataset e dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHoQjDs_QT12"
      },
      "source": [
        "### Definição do tamanho do minibatch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-21T14:08:20.282474Z",
          "start_time": "2018-08-21T14:08:20.275450Z"
        },
        "id": "tEQYUr4TQT13"
      },
      "source": [
        "batch_size = 50"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc7Rv_2BQT16"
      },
      "source": [
        "### Carregamento, criação dataset e do dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-21T14:10:45.430605Z",
          "start_time": "2018-08-21T14:10:04.953051Z"
        },
        "id": "G0dEKCn-QT17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474,
          "referenced_widgets": [
            "45e2e026b6d7445b8d75ba076f7cef76",
            "9fa67b8bfcff4063a1aaa428a39ea04b",
            "34598cc254b94f37bd4d36d3db0b70c6",
            "75bd38c38af743dd8cb4dce2423ef9a6",
            "e35e33455c954313a099292e5149b450",
            "cd61154231714402a980cf9b253867a3",
            "d0e5bf6df534436e8dec130c58b101c3",
            "a60f6f24a6cb41158af378672e65aa81",
            "2a9b6cd0b70b4385a001b96c1a391804",
            "7a872fc461974834b1eff3e776371ab9",
            "95b878a3890649f1a910de15b3564beb",
            "da5f91d1d0f24942857852564cd0489d",
            "addd7d0b33c44a788dba51d41ff78318",
            "42be1f44f9c149ad8d2f7b151a3202fa",
            "65bc1c149d8a4465b6b8d6672273b670",
            "129e829dfde6456fbb5963a6e69081ea",
            "37012e981bf740cf97545255d7b7f2c0",
            "4a8d52af7fff46a7bbc022bcbe29c099",
            "919520832a5848ea850ca7dbe339581e",
            "b334d329eaaf4d1387afd32181274d95",
            "81ff02cb4bd9447c9cb5aef8393e1fa1",
            "d5a074aaed4e4d8c8d2568b638b5a8a7",
            "9286bbf29a934f8e878d52261e98ad61",
            "a086fb1d1cdd4a878e26e97fd5b0b593",
            "494e42937cfd4ef190e832774e6dfd49",
            "e062530b9df249a1b852a681665a3fa7",
            "8f632382fc9f45f7be897ef418a00d8f",
            "82ae37e9858848e19b9190cb7d98758b",
            "15048f031d8e4f1384759df714ad6ab2",
            "3231b4b6edde479da550ab3ff2f3878b",
            "8cc38880d38f4a15a34f1afa2d3206e8",
            "ec4841cfc86c41ff9bc176bac9bd51ad",
            "2cfb8ac015534c3fa8d5e5c0ca922661",
            "e790426ddb604da59b05dfbab166193c",
            "b2f472256b2d4d029e95a074f119db4c",
            "39cb686158944e3488374b6da41a9234",
            "945b3de9f4694c07ace4d20308aafe36",
            "efaaad3a7e5a4858aaf23812de17d89e",
            "000e21cd740249839ef27832c3342425",
            "7b887b03983c43f9a2ef542b816d2f86",
            "8782b175373c4bc99e1309a7b39fabc1",
            "6819e47c4255490781b2937e0b64e431",
            "40d8fdcaa27b479e8734ade13f9186d3",
            "1262edd1236741cbb1fc0f2af459e98a"
          ]
        },
        "outputId": "4904a11a-4163-4e38-84fe-38493baf6c99"
      },
      "source": [
        "dataset_dir = '../data/'\n",
        "\n",
        "dataset_train_full = MNIST(dataset_dir, train=True, download=True,\n",
        "                           transform=torchvision.transforms.ToTensor())\n",
        "print(dataset_train_full.data.shape)\n",
        "print(dataset_train_full.targets.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/9912422 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45e2e026b6d7445b8d75ba076f7cef76"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/28881 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da5f91d1d0f24942857852564cd0489d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1648877 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9286bbf29a934f8e878d52261e98ad61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4542 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e790426ddb604da59b05dfbab166193c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "torch.Size([60000, 28, 28])\n",
            "torch.Size([60000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rOy9ntrQT2D"
      },
      "source": [
        "### Usando apenas 1000 amostras do MNIST\n",
        "\n",
        "Neste exercício utilizaremos 1000 amostras de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNF2XjLBWWe7"
      },
      "source": [
        "indices = torch.randperm(len(dataset_train_full))[:1000]\n",
        "dataset_train = torch.utils.data.Subset(dataset_train_full, indices)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define os pesos iniciais"
      ],
      "metadata": {
        "id": "wYqj_oeSliYj"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSNLD2JyA2e-"
      },
      "source": [
        "loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-21T13:30:35.209157Z",
          "start_time": "2018-08-21T13:30:34.757103Z"
        },
        "id": "w52KGYlIQT2A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9731ce30-387b-490f-d05a-bc9a2484d8b4"
      },
      "source": [
        "print('Número de minibatches de trenamento:', len(loader_train))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de minibatches de trenamento: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = next(iter(loader_train))\n",
        "print(\"\\nDimensões dos dados de um minibatch:\", x_train.size())\n",
        "print(\"Valores mínimo e máximo dos pixels: \", torch.min(x_train), torch.max(x_train))\n",
        "print(\"Tipo dos dados das imagens:         \", type(x_train))\n",
        "print(\"Tipo das classes das imagens:       \", type(y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7vPdWoIbwht",
        "outputId": "ef89fa4c-0d78-4517-9be0-c963d64e57a6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dimensões dos dados de um minibatch: torch.Size([50, 1, 28, 28])\n",
            "Valores mínimo e máximo dos pixels:  tensor(0.) tensor(1.)\n",
            "Tipo dos dados das imagens:          <class 'torch.Tensor'>\n",
            "Tipo das classes das imagens:        <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYw9dR89b3Is",
        "outputId": "67c3ddaf-6967-4cbd-9fec-9a6c53bc7ed3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([50, 1, 28, 28]), torch.Size([50]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0, 0, 0, ] # 1a linha da 1a amostra"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6g_7GhLcJak",
        "outputId": "8da62fda-4844-43e0-c5d2-a0aa90f08fea"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0, 0,] # 28 linhas da 1a amostra"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7J64G0oDcYed",
        "outputId": "233007c9-9d9f-4821-c6af-c1ca6a0d8c52"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2980, 0.9922, 0.9922, 0.6235,\n",
              "         0.3373, 0.0431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0667, 0.0196, 0.0353, 0.3608, 0.4824, 0.8745,\n",
              "         0.9882, 0.7569, 0.1490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.3255, 0.8196, 0.4196, 0.0000, 0.0000, 0.0000, 0.0980,\n",
              "         0.6784, 0.9922, 0.9412, 0.3216, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0667, 0.8196, 0.6902, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.4588, 0.9882, 0.9412, 0.1451, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.2902, 0.9176, 0.9882, 0.4235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0118, 0.4588, 0.9882, 0.7529, 0.0431, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4980,\n",
              "         1.0000, 0.9765, 0.4510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.1686, 0.9686, 0.9922, 0.3373, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9569,\n",
              "         0.9765, 0.4588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.4353, 0.9882, 0.5373, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3255, 0.9412, 0.9882,\n",
              "         0.4510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0745, 0.8588, 0.8667, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1490, 0.9412, 0.9882, 0.6157,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.8118, 0.9882, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5922, 0.9882, 0.9882, 0.1255,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.8118, 0.9882, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.3412, 0.9922, 0.9922, 0.1804, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.2745, 0.9922, 0.9529, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.5412, 0.9882, 0.8157, 0.0667, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.3569, 0.9882, 0.5373, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.5412, 0.9882, 0.5922, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.1333, 0.9176, 0.9882, 0.4157, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.5412, 0.9882, 0.2706, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0353, 0.4784, 0.9882, 0.8549, 0.0549, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.9529, 0.8235, 0.0235, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.5020, 0.9882, 0.9882, 0.2196, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.8275, 0.0275, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0353,\n",
              "         0.5020, 1.0000, 0.9765, 0.4510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.7059, 0.9882, 0.6039, 0.0353, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2588, 0.7608,\n",
              "         0.9882, 0.8941, 0.4588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.3961, 0.8902, 0.9882, 0.6039, 0.2745,\n",
              "         0.2510, 0.1255, 0.2000, 0.2745, 0.2745, 0.5176, 0.7216, 0.9176, 0.9882,\n",
              "         0.7412, 0.1255, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1961, 0.6275, 0.9255, 0.9882,\n",
              "         0.9765, 0.8941, 0.9412, 0.9882, 0.9882, 0.9922, 0.9216, 0.6275, 0.2588,\n",
              "         0.0157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0745, 0.0863,\n",
              "         0.5373, 0.5373, 0.6588, 0.8235, 0.5373, 0.2941, 0.0706, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape[1] # canais"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yo8ov5QdUNk",
        "outputId": "a6597bc7-406c-45d4-c8b3-c89b2f570a06"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Camada Convolucional"
      ],
      "metadata": {
        "id": "dfU_v7aPfq40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.zeros((4,1,4,5),  dtype=torch.float, requires_grad=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWnT39vv2UFk",
        "outputId": "cc86de8a-4307-49a0-a18d-3a8d3fc8e064"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "        [[[0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "        [[[0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "        [[[0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.],\n",
              "          [0., 0., 0., 0., 0.]]]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saida = torch.empty((4,1,4,5),  dtype=torch.float, requires_grad=True)"
      ],
      "metadata": {
        "id": "uR3td8Fn7KZZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saida.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BwNMw6q7Q6I",
        "outputId": "55eb68f2-721e-422e-e240-fa72b6b85c3e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 1, 4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saida[0,0,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8PB0cWe92X-",
        "outputId": "620494b0-3a95-4dd0-b9ed-a0cec5423d42"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0943e-35, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.cat((saida[0,0,0], torch.tensor([[12]])), dim=-1)"
      ],
      "metadata": {
        "id": "-FebDt7c__d1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saida"
      ],
      "metadata": {
        "id": "1Qi-eoW97Sp_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyConv2d(torch.nn.Module):\n",
        "  def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int):\n",
        "    super(MyConv2d, self).__init__()\n",
        "\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.kernel_size = kernel_size  # The same for height and width.\n",
        "    self.stride = stride  # The same for height and width.\n",
        "    self.weight = torch.nn.Parameter(torch.FloatTensor(out_channels, in_channels, kernel_size, kernel_size).uniform_(-0.01, 0.01))\n",
        "    self.bias = torch.nn.Parameter(torch.FloatTensor(out_channels,).uniform_(-0.01, 0.01))\n",
        "    print(f\"Inicializado MyConv2d\")\n",
        "    print(f\"in_channels: {self.in_channels} \")\n",
        "    print(f\"out_channels: {self.out_channels} \")\n",
        "    print(f\"kernel_size: {self.kernel_size} \")\n",
        "    print(f\"stride: {self.stride} \")\n",
        "    print(f\"weight.shape: {self.weight.shape} \")\n",
        "    print(f\"weight: {self.weight} \")\n",
        "    print(f\"bias.shape: {self.bias.shape} \")\n",
        "    print(f\"bias: {self.bias} \")\n",
        "\n",
        "  def forward(self, x):\n",
        "    assert x.dim() == 4, f'x must have 4 dimensions, not {x.shape}'\n",
        "    assert x.shape[1] == 1, f'x must have only 1 channel, not {x.shape[1]}' # Num_canais sempre 1 (mnist, preto/branco)\n",
        "\n",
        "    # print(f\"kernel.shape: {self.weight.shape}, kernel: {self.weight}\")\n",
        "    # Escreva seu código aqui.\n",
        "    # versão com for nas dimensões de X\n",
        "    num_amostras = x.shape[0]\n",
        "    num_linhas_entrada = x.shape[2]\n",
        "    num_colunas_entrada = x.shape[3]\n",
        "    num_linhas_saida = (num_linhas_entrada - self.kernel_size) // self.stride + 1\n",
        "    num_colunas_saida = (num_colunas_entrada - self.kernel_size) // self.stride + 1\n",
        "    print(f\" num_amostras: {num_amostras}, self.out_channels: {self.out_channels}, num_linhas_entrada: {num_linhas_entrada}, num_colunas_entrada: {num_colunas_entrada}, num_linhas_saida: {num_linhas_saida}, num_colunas_saida: {num_colunas_saida}\")\n",
        "    saida = torch.zeros((num_amostras,self.out_channels,num_linhas_saida,num_colunas_saida), dtype=torch.float, requires_grad=False)        \n",
        "    print(f\"saida.shape: {saida.shape}\")\n",
        "    for ndx_amostra in range(num_amostras):\n",
        "      print(f\"\\nndx_amostra: {ndx_amostra}\")\n",
        "      # for ndx_out_channels in range(self.out_channels):\n",
        "      #   print(f\"\\nndx_out_channels: {ndx_out_channels}\")\n",
        "      for ndx_in_channels in range(self.in_channels):\n",
        "        print(f\"\\nndx_in_channels: {ndx_in_channels}\")\n",
        "        ndx_linhas_entrada = 0\n",
        "        for ndx_linhas_saida in range(num_linhas_saida):\n",
        "          ndx_colunas_entrada = 0\n",
        "          for ndx_colunas_saida in range(num_colunas_saida):\n",
        "            print(f\"\\nndx_linhas_saida, ndx_colunas_saida: {ndx_linhas_saida}, {ndx_colunas_saida}\")\n",
        "            print(f\" alvo do kernel em x: x[{ndx_amostra},{ndx_in_channels},{ndx_linhas_entrada}:{ndx_linhas_entrada+self.kernel_size}, {ndx_colunas_entrada}:{ndx_colunas_entrada+self.kernel_size}]\")\n",
        "            print(f\" \\n {x[ndx_amostra, ndx_in_channels, ndx_linhas_entrada:ndx_linhas_entrada+self.kernel_size, ndx_colunas_entrada:ndx_colunas_entrada+self.kernel_size]}\")\n",
        "            produto = torch.mul(x[ndx_amostra, ndx_in_channels, ndx_linhas_entrada:ndx_linhas_entrada+self.kernel_size, ndx_colunas_entrada:ndx_colunas_entrada+self.kernel_size], self.weight)\n",
        "            print(f\" produto: {produto}\")\n",
        "            soma = torch.sum(produto, dim=(2,3), keepdim=True )\n",
        "            print(f\" soma: {soma}\")\n",
        "            valor_soma = soma.squeeze()\n",
        "            print(f\" valor_soma: {valor_soma}\")\n",
        "            # saida = torch.cat((saida, soma))\n",
        "            if self.out_channels > 1:  # soma é um com dimensões, como em torch.tensor([[[[ 46.]], [[134.]]]])\n",
        "              for ndx_out_channels in range(self.out_channels):\n",
        "                saida[ndx_amostra, ndx_out_channels, ndx_linhas_saida, ndx_colunas_saida] += valor_soma[ndx_out_channels]\n",
        "                print(f\" somado na saída em [{ndx_amostra}, {ndx_out_channels}, {ndx_linhas_saida}, {ndx_colunas_saida}] = {saida[ndx_amostra, ndx_out_channels, ndx_linhas_saida, ndx_colunas_saida]}\")\n",
        "            else: # soma é um tensor escalar, como em tensor(34.)\n",
        "                saida[ndx_amostra, 0, ndx_linhas_saida, ndx_colunas_saida] += valor_soma\n",
        "                print(f\" somado na saída em [{ndx_amostra}, 0, {ndx_linhas_saida}, {ndx_colunas_saida}] = {saida[ndx_amostra, 0, ndx_linhas_saida, ndx_colunas_saida]}\")\n",
        "            ndx_colunas_entrada += self.stride\n",
        "          ndx_linhas_entrada += self.stride\n",
        "    print(f\" saida: {saida}\")\n",
        "    # somando bias\n",
        "    for ndx_amostra in range(num_amostras):\n",
        "      print(f\"\\nndx_amostra: {ndx_amostra}\")\n",
        "      for ndx_out_channels in range(self.out_channels):\n",
        "        saida[ndx_amostra, ndx_out_channels] += self.bias[ndx_out_channels]\n",
        "    print(f\" saida apos somar bias: {saida}\")\n",
        "    # versão com for no kernel\n",
        "\n",
        "    return saida"
      ],
      "metadata": {
        "id": "wRtpLJSFfsf8"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare se sua implementação está igual à do pytorch usando um exemplo simples"
      ],
      "metadata": {
        "id": "ROizI33sqE79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_channels_dummy = 1\n",
        "out_channels_dummy = 1\n",
        "kernel_size_dummy = 2\n",
        "stride_dummy = 1\n",
        "x = torch.arange(30).float().reshape(1, 1, 5, 6)"
      ],
      "metadata": {
        "id": "i1TuxWbkqMJc"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-FSsEC9icLX",
        "outputId": "55b37203-f4f0-4d25-c30d-86ce03a9de54"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
            "          [ 6.,  7.,  8.,  9., 10., 11.],\n",
            "          [12., 13., 14., 15., 16., 17.],\n",
            "          [18., 19., 20., 21., 22., 23.],\n",
            "          [24., 25., 26., 27., 28., 29.]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "conv_layer = MyConv2d( out_channels=out_channels_dummy, in_channels=in_channels_dummy, kernel_size=kernel_size_dummy, stride=stride_dummy)\n",
        "\n",
        "# Usa os mesmos pesos para minha implementação e a do pytorch\n",
        "initial_weights_dummy = torch.arange(in_channels_dummy * out_channels_dummy * kernel_size_dummy * kernel_size_dummy).float()\n",
        "initial_weights_dummy = initial_weights_dummy.reshape(in_channels_dummy, out_channels_dummy, kernel_size_dummy, kernel_size_dummy)\n",
        "initial_bias_dummy = torch.arange(out_channels_dummy,).float()\n",
        "\n",
        "conv_layer.weight.data = initial_weights_dummy\n",
        "conv_layer.bias.data = initial_bias_dummy\n",
        "\n",
        "out = conv_layer(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASbzrpDHiaxm",
        "outputId": "802ddcef-3a16-4ff6-a771-6de40f83c2f0"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inicializado MyConv2d\n",
            "in_channels: 1 \n",
            "out_channels: 1 \n",
            "kernel_size: 2 \n",
            "stride: 1 \n",
            "weight.shape: torch.Size([1, 1, 2, 2]) \n",
            "weight: Parameter containing:\n",
            "tensor([[[[-0.0053,  0.0004],\n",
            "          [ 0.0034,  0.0005]]]], requires_grad=True) \n",
            "bias.shape: torch.Size([1]) \n",
            "bias: Parameter containing:\n",
            "tensor([0.0042], requires_grad=True) \n",
            " num_amostras: 1, self.out_channels: 1, num_linhas_entrada: 5, num_colunas_entrada: 6, num_linhas_saida: 4, num_colunas_saida: 5\n",
            "saida.shape: torch.Size([1, 1, 4, 5])\n",
            "\n",
            "ndx_amostra: 0\n",
            "\n",
            "ndx_in_channels: 0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 0\n",
            " alvo do kernel em x: x[0,0,0:2, 0:2]\n",
            " \n",
            " tensor([[0., 1.],\n",
            "        [6., 7.]])\n",
            " produto: tensor([[[[ 0.,  1.],\n",
            "          [12., 21.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[34.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 34.0\n",
            " somado na saída em [0, 0, 0, 0] = 34.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 1\n",
            " alvo do kernel em x: x[0,0,0:2, 1:3]\n",
            " \n",
            " tensor([[1., 2.],\n",
            "        [7., 8.]])\n",
            " produto: tensor([[[[ 0.,  2.],\n",
            "          [14., 24.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[40.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 40.0\n",
            " somado na saída em [0, 0, 0, 1] = 40.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 2\n",
            " alvo do kernel em x: x[0,0,0:2, 2:4]\n",
            " \n",
            " tensor([[2., 3.],\n",
            "        [8., 9.]])\n",
            " produto: tensor([[[[ 0.,  3.],\n",
            "          [16., 27.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[46.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 46.0\n",
            " somado na saída em [0, 0, 0, 2] = 46.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 3\n",
            " alvo do kernel em x: x[0,0,0:2, 3:5]\n",
            " \n",
            " tensor([[ 3.,  4.],\n",
            "        [ 9., 10.]])\n",
            " produto: tensor([[[[ 0.,  4.],\n",
            "          [18., 30.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[52.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 52.0\n",
            " somado na saída em [0, 0, 0, 3] = 52.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 4\n",
            " alvo do kernel em x: x[0,0,0:2, 4:6]\n",
            " \n",
            " tensor([[ 4.,  5.],\n",
            "        [10., 11.]])\n",
            " produto: tensor([[[[ 0.,  5.],\n",
            "          [20., 33.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[58.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 58.0\n",
            " somado na saída em [0, 0, 0, 4] = 58.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 0\n",
            " alvo do kernel em x: x[0,0,1:3, 0:2]\n",
            " \n",
            " tensor([[ 6.,  7.],\n",
            "        [12., 13.]])\n",
            " produto: tensor([[[[ 0.,  7.],\n",
            "          [24., 39.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[70.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 70.0\n",
            " somado na saída em [0, 0, 1, 0] = 70.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 1\n",
            " alvo do kernel em x: x[0,0,1:3, 1:3]\n",
            " \n",
            " tensor([[ 7.,  8.],\n",
            "        [13., 14.]])\n",
            " produto: tensor([[[[ 0.,  8.],\n",
            "          [26., 42.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[76.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 76.0\n",
            " somado na saída em [0, 0, 1, 1] = 76.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 2\n",
            " alvo do kernel em x: x[0,0,1:3, 2:4]\n",
            " \n",
            " tensor([[ 8.,  9.],\n",
            "        [14., 15.]])\n",
            " produto: tensor([[[[ 0.,  9.],\n",
            "          [28., 45.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[82.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 82.0\n",
            " somado na saída em [0, 0, 1, 2] = 82.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 3\n",
            " alvo do kernel em x: x[0,0,1:3, 3:5]\n",
            " \n",
            " tensor([[ 9., 10.],\n",
            "        [15., 16.]])\n",
            " produto: tensor([[[[ 0., 10.],\n",
            "          [30., 48.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[88.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 88.0\n",
            " somado na saída em [0, 0, 1, 3] = 88.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 4\n",
            " alvo do kernel em x: x[0,0,1:3, 4:6]\n",
            " \n",
            " tensor([[10., 11.],\n",
            "        [16., 17.]])\n",
            " produto: tensor([[[[ 0., 11.],\n",
            "          [32., 51.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[94.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 94.0\n",
            " somado na saída em [0, 0, 1, 4] = 94.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 0\n",
            " alvo do kernel em x: x[0,0,2:4, 0:2]\n",
            " \n",
            " tensor([[12., 13.],\n",
            "        [18., 19.]])\n",
            " produto: tensor([[[[ 0., 13.],\n",
            "          [36., 57.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[106.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 106.0\n",
            " somado na saída em [0, 0, 2, 0] = 106.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 1\n",
            " alvo do kernel em x: x[0,0,2:4, 1:3]\n",
            " \n",
            " tensor([[13., 14.],\n",
            "        [19., 20.]])\n",
            " produto: tensor([[[[ 0., 14.],\n",
            "          [38., 60.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[112.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 112.0\n",
            " somado na saída em [0, 0, 2, 1] = 112.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 2\n",
            " alvo do kernel em x: x[0,0,2:4, 2:4]\n",
            " \n",
            " tensor([[14., 15.],\n",
            "        [20., 21.]])\n",
            " produto: tensor([[[[ 0., 15.],\n",
            "          [40., 63.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[118.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 118.0\n",
            " somado na saída em [0, 0, 2, 2] = 118.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 3\n",
            " alvo do kernel em x: x[0,0,2:4, 3:5]\n",
            " \n",
            " tensor([[15., 16.],\n",
            "        [21., 22.]])\n",
            " produto: tensor([[[[ 0., 16.],\n",
            "          [42., 66.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[124.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 124.0\n",
            " somado na saída em [0, 0, 2, 3] = 124.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 4\n",
            " alvo do kernel em x: x[0,0,2:4, 4:6]\n",
            " \n",
            " tensor([[16., 17.],\n",
            "        [22., 23.]])\n",
            " produto: tensor([[[[ 0., 17.],\n",
            "          [44., 69.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[130.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 130.0\n",
            " somado na saída em [0, 0, 2, 4] = 130.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 0\n",
            " alvo do kernel em x: x[0,0,3:5, 0:2]\n",
            " \n",
            " tensor([[18., 19.],\n",
            "        [24., 25.]])\n",
            " produto: tensor([[[[ 0., 19.],\n",
            "          [48., 75.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[142.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 142.0\n",
            " somado na saída em [0, 0, 3, 0] = 142.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 1\n",
            " alvo do kernel em x: x[0,0,3:5, 1:3]\n",
            " \n",
            " tensor([[19., 20.],\n",
            "        [25., 26.]])\n",
            " produto: tensor([[[[ 0., 20.],\n",
            "          [50., 78.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[148.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 148.0\n",
            " somado na saída em [0, 0, 3, 1] = 148.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 2\n",
            " alvo do kernel em x: x[0,0,3:5, 2:4]\n",
            " \n",
            " tensor([[20., 21.],\n",
            "        [26., 27.]])\n",
            " produto: tensor([[[[ 0., 21.],\n",
            "          [52., 81.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[154.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 154.0\n",
            " somado na saída em [0, 0, 3, 2] = 154.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 3\n",
            " alvo do kernel em x: x[0,0,3:5, 3:5]\n",
            " \n",
            " tensor([[21., 22.],\n",
            "        [27., 28.]])\n",
            " produto: tensor([[[[ 0., 22.],\n",
            "          [54., 84.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[160.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 160.0\n",
            " somado na saída em [0, 0, 3, 3] = 160.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 4\n",
            " alvo do kernel em x: x[0,0,3:5, 4:6]\n",
            " \n",
            " tensor([[22., 23.],\n",
            "        [28., 29.]])\n",
            " produto: tensor([[[[ 0., 23.],\n",
            "          [56., 87.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[166.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 166.0\n",
            " somado na saída em [0, 0, 3, 4] = 166.0\n",
            " saida: tensor([[[[ 34.,  40.,  46.,  52.,  58.],\n",
            "          [ 70.,  76.,  82.,  88.,  94.],\n",
            "          [106., 112., 118., 124., 130.],\n",
            "          [142., 148., 154., 160., 166.]]]], grad_fn=<CopySlices>)\n",
            "\n",
            "ndx_amostra: 0\n",
            " saida apos somar bias: tensor([[[[ 34.,  40.,  46.,  52.,  58.],\n",
            "          [ 70.,  76.,  82.,  88.,  94.],\n",
            "          [106., 112., 118., 124., 130.],\n",
            "          [142., 148., 154., 160., 166.]]]], grad_fn=<CopySlices>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pytorch_conv_layer = torch.nn.Conv2d(out_channels=out_channels_dummy, in_channels=in_channels_dummy, kernel_size=kernel_size_dummy, stride=stride_dummy, padding=0)\n",
        "pytorch_conv_layer.load_state_dict(dict(weight=initial_weights_dummy, bias=initial_bias_dummy))\n",
        "target_out = pytorch_conv_layer(x)"
      ],
      "metadata": {
        "id": "xN--jid1fn-p"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blRMn_9hgIGZ",
        "outputId": "24cf2cb8-09b8-4290-8129-bd2f0c3c755b"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert torch.allclose(out, target_out, atol=1e-6)"
      ],
      "metadata": {
        "id": "FUgUwtXPgGaD"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare se sua implementação está igual à do pytorch usando um exemplo aleatório"
      ],
      "metadata": {
        "id": "_75UnRhdd_MW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2, in_channels, height_in, width_in)\n",
        "print(f\"x.shape: {x.shape}, x:{x}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7X_A2jeDs4f",
        "outputId": "cff06470-cdc4-4a28-a90f-c9581c7c9bb4"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.shape: torch.Size([2, 1, 28, 28]), x:tensor([[[[8.4142e-01, 3.5439e-01, 6.1172e-02,  ..., 9.2555e-01,\n",
            "           4.1156e-01, 8.8787e-01],\n",
            "          [4.8619e-01, 1.7892e-01, 3.3761e-01,  ..., 5.3331e-01,\n",
            "           3.6692e-01, 9.4743e-01],\n",
            "          [7.5571e-01, 6.5270e-01, 5.4962e-01,  ..., 7.7583e-01,\n",
            "           8.8931e-01, 3.1293e-01],\n",
            "          ...,\n",
            "          [4.5140e-01, 3.3445e-01, 7.1822e-01,  ..., 8.7009e-01,\n",
            "           7.1349e-01, 3.1192e-02],\n",
            "          [8.1161e-01, 9.2543e-01, 9.9241e-02,  ..., 3.7423e-01,\n",
            "           6.6530e-01, 8.5440e-01],\n",
            "          [2.9395e-01, 9.4599e-01, 2.9556e-01,  ..., 5.0896e-01,\n",
            "           6.3630e-02, 1.5010e-02]]],\n",
            "\n",
            "\n",
            "        [[[3.0296e-01, 8.4186e-01, 5.7012e-01,  ..., 3.3977e-01,\n",
            "           1.2933e-01, 8.4123e-01],\n",
            "          [2.3678e-01, 2.8399e-01, 7.9764e-01,  ..., 9.5889e-01,\n",
            "           8.6574e-01, 5.4478e-02],\n",
            "          [2.8048e-01, 3.1483e-01, 9.7353e-02,  ..., 6.4659e-01,\n",
            "           8.4145e-01, 1.3383e-02],\n",
            "          ...,\n",
            "          [5.8661e-01, 3.9886e-01, 9.3305e-01,  ..., 6.6283e-01,\n",
            "           2.1807e-01, 7.1026e-02],\n",
            "          [3.0721e-01, 2.5379e-02, 1.4791e-01,  ..., 7.1585e-04,\n",
            "           2.3191e-01, 6.5498e-01],\n",
            "          [9.1261e-01, 8.3988e-01, 6.5348e-01,  ..., 1.1922e-01,\n",
            "           5.9737e-01, 8.0728e-01]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_layer = MyConv2d(out_channels=out_channels, in_channels=in_channels, kernel_size=kernel_size, stride=stride)\n",
        "conv_layer.weight.data = initial_conv_weight\n",
        "conv_layer.bias.data = initial_conv_bias\n",
        "print(f\"conv_layer.weight.data.shape: {conv_layer.weight.data.shape}, conv_layer.bias.data.shape: {conv_layer.bias.data.shape}\")\n",
        "print(f\"conv_layer.weight.data: {conv_layer.weight.data}, conv_layer.bias.data: {conv_layer.bias.data}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPL18MC-Ed9x",
        "outputId": "a702512e-d472-4cc1-b074-f9c2fa9634d8"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inicializado MyConv2d\n",
            "in_channels: 1 \n",
            "out_channels: 2 \n",
            "kernel_size: 5 \n",
            "stride: 3 \n",
            "weight.shape: torch.Size([2, 1, 5, 5]) \n",
            "weight: Parameter containing:\n",
            "tensor([[[[-7.6017e-03, -6.1803e-03,  9.0250e-03, -7.5432e-03, -5.4495e-03],\n",
            "          [-3.7104e-03,  6.3617e-03,  7.5090e-03,  5.0867e-03,  7.0336e-03],\n",
            "          [-6.1566e-04,  6.0817e-03,  7.7439e-03,  7.2776e-03,  2.3919e-03],\n",
            "          [-7.1268e-03,  4.6978e-03,  9.3515e-03,  7.4757e-05,  3.2798e-03],\n",
            "          [-5.5757e-03, -4.2965e-04,  5.5089e-03,  8.3744e-03, -6.4920e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 3.6035e-03,  8.8664e-04, -4.1927e-03, -5.6483e-03, -7.1350e-03],\n",
            "          [ 7.4180e-03,  7.4519e-04, -5.4948e-03,  6.1529e-03,  9.1575e-03],\n",
            "          [-4.1499e-03, -9.4623e-03, -6.7755e-03,  7.9669e-03,  1.8236e-03],\n",
            "          [-9.1121e-03, -6.2279e-03, -9.6819e-03, -9.7706e-03,  4.3225e-04],\n",
            "          [-7.6296e-03,  4.2595e-03, -7.7148e-03, -2.7186e-04,  9.5596e-03]]]],\n",
            "       requires_grad=True) \n",
            "bias.shape: torch.Size([2]) \n",
            "bias: Parameter containing:\n",
            "tensor([0.0033, 0.0042], requires_grad=True) \n",
            "conv_layer.weight.data.shape: torch.Size([2, 1, 5, 5]), conv_layer.bias.data.shape: torch.Size([2])\n",
            "conv_layer.weight.data: tensor([[[[-0.0041,  0.0003, -0.0050,  0.0038, -0.0085],\n",
            "          [ 0.0073, -0.0073, -0.0080, -0.0063,  0.0045],\n",
            "          [-0.0037,  0.0037, -0.0085, -0.0061, -0.0037],\n",
            "          [-0.0020, -0.0076,  0.0065, -0.0024,  0.0032],\n",
            "          [ 0.0071,  0.0019,  0.0027,  0.0097, -0.0045]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0032, -0.0044,  0.0071,  0.0080, -0.0092],\n",
            "          [ 0.0085,  0.0048,  0.0044,  0.0041,  0.0083],\n",
            "          [-0.0013, -0.0085, -0.0029, -0.0070,  0.0007],\n",
            "          [-0.0019, -0.0054, -0.0009,  0.0095, -0.0008],\n",
            "          [ 0.0003, -0.0016,  0.0016,  0.0089,  0.0061]]]]), conv_layer.bias.data: tensor([0.0035, 0.0022])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = conv_layer(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fs0iR9kb0Vy",
        "outputId": "bd725d3a-743c-464c-a41a-e49e822f692a"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " num_amostras: 2, self.out_channels: 2, num_linhas_entrada: 28, num_colunas_entrada: 28, num_linhas_saida: 8, num_colunas_saida: 8\n",
            "saida.shape: torch.Size([2, 2, 8, 8])\n",
            "\n",
            "ndx_amostra: 0\n",
            "\n",
            "ndx_in_channels: 0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 0\n",
            " alvo do kernel em x: x[0,0,0:5, 0:5]\n",
            " \n",
            " tensor([[0.8414, 0.3544, 0.0612, 0.1211, 0.3592],\n",
            "        [0.4862, 0.1789, 0.3376, 0.7700, 0.6488],\n",
            "        [0.7557, 0.6527, 0.5496, 0.0573, 0.4063],\n",
            "        [0.0170, 0.2940, 0.4368, 0.0756, 0.9769],\n",
            "        [0.8789, 0.5654, 0.0743, 0.1479, 0.3093]])\n",
            " produto: tensor([[[[-3.4311e-03,  1.1739e-04, -3.0382e-04,  4.5678e-04, -3.0602e-03],\n",
            "          [ 3.5640e-03, -1.3005e-03, -2.6842e-03, -4.8654e-03,  2.9386e-03],\n",
            "          [-2.7923e-03,  2.4425e-03, -4.6648e-03, -3.4753e-04, -1.4918e-03],\n",
            "          [-3.3431e-05, -2.2425e-03,  2.8604e-03, -1.7836e-04,  3.1356e-03],\n",
            "          [ 6.2151e-03,  1.0533e-03,  2.0317e-04,  1.4277e-03, -1.3948e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.6652e-03, -1.5767e-03,  4.3716e-04,  9.6738e-04, -3.3113e-03],\n",
            "          [ 4.1503e-03,  8.5438e-04,  1.4712e-03,  3.1698e-03,  5.3938e-03],\n",
            "          [-9.9784e-04, -5.5199e-03, -1.5771e-03, -4.0341e-04,  2.6859e-04],\n",
            "          [-3.1762e-05, -1.5767e-03, -3.9718e-04,  7.1654e-04, -7.7051e-04],\n",
            "          [ 2.7905e-04, -8.8177e-04,  1.1680e-04,  1.3179e-03,  1.8912e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0044]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0067]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0044,  0.0067], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 0] = -0.004376259632408619\n",
            " somado na saída em [0, 1, 0, 0] = 0.0066550495103001595\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 1\n",
            " alvo do kernel em x: x[0,0,0:5, 3:8]\n",
            " \n",
            " tensor([[0.1211, 0.3592, 0.8401, 0.5850, 0.9881],\n",
            "        [0.7700, 0.6488, 0.4803, 0.2264, 0.3593],\n",
            "        [0.0573, 0.4063, 0.7312, 0.3368, 0.7014],\n",
            "        [0.0756, 0.9769, 0.1442, 0.5208, 0.5028],\n",
            "        [0.1479, 0.3093, 0.0308, 0.7145, 0.6671]])\n",
            " produto: tensor([[[[-4.9392e-04,  1.1897e-04, -4.1724e-03,  2.2060e-03, -8.4190e-03],\n",
            "          [ 5.6443e-03, -4.7160e-03, -3.8186e-03, -1.4307e-03,  1.6272e-03],\n",
            "          [-2.1165e-04,  1.5204e-03, -6.2056e-03, -2.0433e-03, -2.5753e-03],\n",
            "          [-1.4863e-04, -7.4522e-03,  9.4445e-04, -1.2282e-03,  1.6140e-03],\n",
            "          [ 1.0459e-03,  5.7619e-04,  8.4311e-05,  6.8972e-03, -3.0085e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 3.8367e-04, -1.5979e-03,  6.0037e-03,  4.6720e-03, -9.1099e-03],\n",
            "          [ 6.5729e-03,  3.0983e-03,  2.0930e-03,  9.3209e-04,  2.9868e-03],\n",
            "          [-7.5633e-05, -3.4361e-03, -2.0981e-03, -2.3719e-03,  4.6365e-04],\n",
            "          [-1.4121e-04, -5.2398e-03, -1.3114e-04,  4.9340e-03, -3.9659e-04],\n",
            "          [ 4.6962e-05, -4.8234e-04,  4.8471e-05,  6.3666e-03,  4.0791e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0236]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0176]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0236,  0.0176], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 1] = -0.02364521473646164\n",
            " somado na saída em [0, 1, 0, 1] = 0.017600692808628082\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 2\n",
            " alvo do kernel em x: x[0,0,0:5, 6:11]\n",
            " \n",
            " tensor([[0.5850, 0.9881, 0.9902, 0.1372, 0.4048],\n",
            "        [0.2264, 0.3593, 0.1105, 0.3222, 0.9756],\n",
            "        [0.3368, 0.7014, 0.3855, 0.3083, 0.5692],\n",
            "        [0.5208, 0.5028, 0.1314, 0.2702, 0.6402],\n",
            "        [0.7145, 0.6671, 0.4565, 0.9920, 0.0389]])\n",
            " produto: tensor([[[[-0.0024,  0.0003, -0.0049,  0.0005, -0.0034],\n",
            "          [ 0.0017, -0.0026, -0.0009, -0.0020,  0.0044],\n",
            "          [-0.0012,  0.0026, -0.0033, -0.0019, -0.0021],\n",
            "          [-0.0010, -0.0038,  0.0009, -0.0006,  0.0021],\n",
            "          [ 0.0051,  0.0012,  0.0012,  0.0096, -0.0002]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0019, -0.0044,  0.0071,  0.0011, -0.0037],\n",
            "          [ 0.0019,  0.0017,  0.0005,  0.0013,  0.0081],\n",
            "          [-0.0004, -0.0059, -0.0011, -0.0022,  0.0004],\n",
            "          [-0.0010, -0.0027, -0.0001,  0.0026, -0.0005],\n",
            "          [ 0.0002, -0.0010,  0.0007,  0.0088,  0.0002]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0008]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0134]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0008,  0.0134], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 2] = -0.0008438383229076862\n",
            " somado na saída em [0, 1, 0, 2] = 0.013434519059956074\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 3\n",
            " alvo do kernel em x: x[0,0,0:5, 9:14]\n",
            " \n",
            " tensor([[0.1372, 0.4048, 0.9651, 0.1398, 0.3736],\n",
            "        [0.3222, 0.9756, 0.7480, 0.9187, 0.2357],\n",
            "        [0.3083, 0.5692, 0.0849, 0.8390, 0.6802],\n",
            "        [0.2702, 0.6402, 0.5467, 0.3687, 0.1598],\n",
            "        [0.9920, 0.0389, 0.9156, 0.4248, 0.0722]])\n",
            " produto: tensor([[[[-5.5966e-04,  1.3408e-04, -4.7935e-03,  5.2717e-04, -3.1830e-03],\n",
            "          [ 2.3617e-03, -7.0908e-03, -5.9470e-03, -5.8054e-03,  1.0673e-03],\n",
            "          [-1.1390e-03,  2.1301e-03, -7.2080e-04, -5.0907e-03, -2.4977e-03],\n",
            "          [-5.3103e-04, -4.8840e-03,  3.5795e-03, -8.6960e-04,  5.1294e-04],\n",
            "          [ 7.0151e-03,  7.2557e-05,  2.5036e-03,  4.1008e-03, -3.2541e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 4.3473e-04, -1.8008e-03,  6.8974e-03,  1.1164e-03, -3.4442e-03],\n",
            "          [ 2.7503e-03,  4.6585e-03,  3.2596e-03,  3.7822e-03,  1.9591e-03],\n",
            "          [-4.0701e-04, -4.8139e-03, -2.4370e-04, -5.9091e-03,  4.4968e-04],\n",
            "          [-5.0451e-04, -3.4341e-03, -4.9703e-04,  3.4934e-03, -1.2604e-04],\n",
            "          [ 3.1497e-04, -6.0739e-05,  1.4393e-03,  3.7854e-03,  4.4120e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0194]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0135]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0194,  0.0135], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 3] = -0.019432472065091133\n",
            " somado na saída em [0, 1, 0, 3] = 0.013541081920266151\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 4\n",
            " alvo do kernel em x: x[0,0,0:5, 12:17]\n",
            " \n",
            " tensor([[0.1398, 0.3736, 0.1571, 0.4066, 0.9208],\n",
            "        [0.9187, 0.2357, 0.1321, 0.5005, 0.3151],\n",
            "        [0.8390, 0.6802, 0.7554, 0.0085, 0.4376],\n",
            "        [0.3687, 0.1598, 0.0752, 0.1873, 0.6163],\n",
            "        [0.4248, 0.0722, 0.2967, 0.3702, 0.7406]])\n",
            " produto: tensor([[[[-5.7003e-04,  1.2374e-04, -7.8028e-04,  1.5332e-03, -7.8453e-03],\n",
            "          [ 6.7348e-03, -1.7130e-03, -1.0500e-03, -3.1628e-03,  1.4269e-03],\n",
            "          [-3.1002e-03,  2.5455e-03, -6.4111e-03, -5.1792e-05, -1.6069e-03],\n",
            "          [-7.2464e-04, -1.2191e-03,  4.9260e-04, -4.4183e-04,  1.9782e-03],\n",
            "          [ 3.0042e-03,  1.3442e-04,  8.1145e-04,  3.5735e-03, -3.3402e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 4.4279e-04, -1.6621e-03,  1.1228e-03,  3.2471e-03, -8.4891e-03],\n",
            "          [ 7.8428e-03,  1.1254e-03,  5.7551e-04,  2.0605e-03,  2.6191e-03],\n",
            "          [-1.1079e-03, -5.7527e-03, -2.1675e-03, -6.0120e-05,  2.8931e-04],\n",
            "          [-6.8846e-04, -8.5715e-04, -6.8400e-05,  1.7749e-03, -4.8611e-04],\n",
            "          [ 1.3489e-04, -1.1253e-04,  4.6651e-04,  3.2987e-03,  4.5288e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0097]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0081]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0097,  0.0081], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 4] = -0.009658392518758774\n",
            " somado na saída em [0, 1, 0, 4] = 0.008076954632997513\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 5\n",
            " alvo do kernel em x: x[0,0,0:5, 15:20]\n",
            " \n",
            " tensor([[0.4066, 0.9208, 0.8564, 0.2287, 0.8001],\n",
            "        [0.5005, 0.3151, 0.5486, 0.0101, 0.2574],\n",
            "        [0.0085, 0.4376, 0.1439, 0.6157, 0.2890],\n",
            "        [0.1873, 0.6163, 0.5038, 0.7934, 0.6719],\n",
            "        [0.3702, 0.7406, 0.0584, 0.6260, 0.1905]])\n",
            " produto: tensor([[[[-1.6579e-03,  3.0500e-04, -4.2535e-03,  8.6234e-04, -6.8174e-03],\n",
            "          [ 3.6691e-03, -2.2900e-03, -4.3614e-03, -6.4125e-05,  1.1659e-03],\n",
            "          [-3.1541e-05,  1.6377e-03, -1.2213e-03, -3.7355e-03, -1.0611e-03],\n",
            "          [-3.6818e-04, -4.7015e-03,  3.2992e-03, -1.8711e-03,  2.1567e-03],\n",
            "          [ 2.6180e-03,  1.3798e-03,  1.5964e-04,  6.0421e-03, -8.5899e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2878e-03, -4.0966e-03,  6.1204e-03,  1.8263e-03, -7.3768e-03],\n",
            "          [ 4.2727e-03,  1.5045e-03,  2.3905e-03,  4.1777e-05,  2.1400e-03],\n",
            "          [-1.1271e-05, -3.7011e-03, -4.1291e-04, -4.3361e-03,  1.9104e-04],\n",
            "          [-3.4979e-04, -3.3057e-03, -4.5811e-04,  7.5169e-03, -5.2996e-04],\n",
            "          [ 1.1754e-04, -1.1551e-03,  9.1778e-05,  5.5774e-03,  1.1646e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0100]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0085]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0100,  0.0085], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 5] = -0.00999821163713932\n",
            " somado na saída em [0, 1, 0, 5] = 0.008509778417646885\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 6\n",
            " alvo do kernel em x: x[0,0,0:5, 18:23]\n",
            " \n",
            " tensor([[0.2287, 0.8001, 0.7269, 0.2497, 0.9512],\n",
            "        [0.0101, 0.2574, 0.1638, 0.5828, 0.9290],\n",
            "        [0.6157, 0.2890, 0.8002, 0.6820, 0.3361],\n",
            "        [0.7934, 0.6719, 0.3124, 0.5274, 0.4189],\n",
            "        [0.6260, 0.1905, 0.4192, 0.7320, 0.6987]])\n",
            " produto: tensor([[[[-9.3246e-04,  2.6503e-04, -3.6100e-03,  9.4183e-04, -8.1047e-03],\n",
            "          [ 7.4390e-05, -1.8711e-03, -1.3023e-03, -3.6826e-03,  4.2076e-03],\n",
            "          [-2.2749e-03,  1.0815e-03, -6.7916e-03, -4.1377e-03, -1.2340e-03],\n",
            "          [-1.5592e-03, -5.1256e-03,  2.0459e-03, -1.2438e-03,  1.3447e-03],\n",
            "          [ 4.4264e-03,  3.5484e-04,  1.1462e-03,  7.0655e-03, -3.1510e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 7.2431e-04, -3.5598e-03,  5.1945e-03,  1.9946e-03, -8.7698e-03],\n",
            "          [ 8.6629e-05,  1.2292e-03,  7.1379e-04,  2.3992e-03,  7.7231e-03],\n",
            "          [-8.1295e-04, -2.4440e-03, -2.2962e-03, -4.8030e-03,  2.2217e-04],\n",
            "          [-1.4814e-03, -3.6039e-03, -2.8408e-04,  4.9966e-03, -3.3043e-04],\n",
            "          [ 1.9874e-04, -2.9704e-04,  6.5896e-04,  6.5220e-03,  4.2722e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0221]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0083]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0221,  0.0083], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 6] = -0.022067122161388397\n",
            " somado na saída em [0, 1, 0, 6] = 0.008253499865531921\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 7\n",
            " alvo do kernel em x: x[0,0,0:5, 21:26]\n",
            " \n",
            " tensor([[0.2497, 0.9512, 0.2025, 0.0509, 0.9255],\n",
            "        [0.5828, 0.9290, 0.2793, 0.5568, 0.5333],\n",
            "        [0.6820, 0.3361, 0.8708, 0.7490, 0.7758],\n",
            "        [0.5274, 0.4189, 0.1057, 0.5674, 0.8609],\n",
            "        [0.7320, 0.6987, 0.1590, 0.8913, 0.0412]])\n",
            " produto: tensor([[[[-1.0184e-03,  3.1508e-04, -1.0059e-03,  1.9191e-04, -7.8862e-03],\n",
            "          [ 4.2721e-03, -6.7526e-03, -2.2208e-03, -3.5182e-03,  2.4153e-03],\n",
            "          [-2.5198e-03,  1.2576e-03, -7.3906e-03, -4.5442e-03, -2.8487e-03],\n",
            "          [-1.0364e-03, -3.1959e-03,  6.9223e-04, -1.3380e-03,  2.7632e-03],\n",
            "          [ 5.1761e-03,  1.3016e-03,  4.3484e-04,  8.6030e-03, -1.8566e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 7.9107e-04, -4.2320e-03,  1.4474e-03,  4.0642e-04, -8.5333e-03],\n",
            "          [ 4.9750e-03,  4.4363e-03,  1.2172e-03,  2.2921e-03,  4.4334e-03],\n",
            "          [-9.0048e-04, -2.8422e-03, -2.4987e-03, -5.2748e-03,  5.1288e-04],\n",
            "          [-9.8469e-04, -2.2471e-03, -9.6120e-05,  5.3752e-03, -6.7900e-04],\n",
            "          [ 2.3240e-04, -1.0896e-03,  2.4999e-04,  7.9413e-03,  2.5172e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0180]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0052]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0180,  0.0052], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 7] = -0.01803811639547348\n",
            " somado na saída em [0, 1, 0, 7] = 0.005184352397918701\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 0\n",
            " alvo do kernel em x: x[0,0,3:8, 0:5]\n",
            " \n",
            " tensor([[0.0170, 0.2940, 0.4368, 0.0756, 0.9769],\n",
            "        [0.8789, 0.5654, 0.0743, 0.1479, 0.3093],\n",
            "        [0.6181, 0.7763, 0.1743, 0.3932, 0.3654],\n",
            "        [0.0049, 0.7451, 0.5310, 0.7164, 0.1032],\n",
            "        [0.1155, 0.6429, 0.6804, 0.3265, 0.4702]])\n",
            " produto: tensor([[[[-6.9370e-05,  9.7372e-05, -2.1696e-03,  2.8522e-04, -8.3235e-03],\n",
            "          [ 6.4427e-03, -4.1094e-03, -5.9070e-04, -9.3463e-04,  1.4007e-03],\n",
            "          [-2.2839e-03,  2.9051e-03, -1.4789e-03, -2.3856e-03, -1.3416e-03],\n",
            "          [-9.6456e-06, -5.6842e-03,  3.4771e-03, -1.6894e-03,  3.3120e-04],\n",
            "          [ 8.1705e-04,  1.1977e-03,  1.8605e-03,  3.1514e-03, -2.1206e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 5.3885e-05, -1.3079e-03,  3.1219e-03,  6.0404e-04, -9.0065e-03],\n",
            "          [ 7.5027e-03,  2.6998e-03,  3.2377e-04,  6.0891e-04,  2.5710e-03],\n",
            "          [-8.1615e-04, -6.5653e-03, -5.0001e-04, -2.7691e-03,  2.4154e-04],\n",
            "          [-9.1640e-06, -3.9967e-03, -4.8282e-04,  6.7870e-03, -8.1384e-05],\n",
            "          [ 3.6685e-05, -1.0026e-03,  1.0696e-03,  2.9090e-03,  2.8752e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0112]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0049]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0112,  0.0049], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 0] = -0.011224906891584396\n",
            " somado na saída em [0, 1, 1, 0] = 0.004867420066148043\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 1\n",
            " alvo do kernel em x: x[0,0,3:8, 3:8]\n",
            " \n",
            " tensor([[0.0756, 0.9769, 0.1442, 0.5208, 0.5028],\n",
            "        [0.1479, 0.3093, 0.0308, 0.7145, 0.6671],\n",
            "        [0.3932, 0.3654, 0.1338, 0.1813, 0.2959],\n",
            "        [0.7164, 0.1032, 0.2063, 0.2872, 0.8837],\n",
            "        [0.3265, 0.4702, 0.7526, 0.5779, 0.0915]])\n",
            " produto: tensor([[[[-0.0003,  0.0003, -0.0007,  0.0020, -0.0043],\n",
            "          [ 0.0011, -0.0022, -0.0002, -0.0045,  0.0030],\n",
            "          [-0.0015,  0.0014, -0.0011, -0.0011, -0.0011],\n",
            "          [-0.0014, -0.0008,  0.0014, -0.0007,  0.0028],\n",
            "          [ 0.0023,  0.0009,  0.0021,  0.0056, -0.0004]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0002, -0.0043,  0.0010,  0.0042, -0.0046],\n",
            "          [ 0.0013,  0.0015,  0.0001,  0.0029,  0.0055],\n",
            "          [-0.0005, -0.0031, -0.0004, -0.0013,  0.0002],\n",
            "          [-0.0013, -0.0006, -0.0002,  0.0027, -0.0007],\n",
            "          [ 0.0001, -0.0007,  0.0012,  0.0051,  0.0006]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[0.0024]]],\n",
            "\n",
            "\n",
            "        [[[0.0089]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([0.0024, 0.0089], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 1] = 0.0023914193734526634\n",
            " somado na saída em [0, 1, 1, 1] = 0.008941203355789185\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 2\n",
            " alvo do kernel em x: x[0,0,3:8, 6:11]\n",
            " \n",
            " tensor([[0.5208, 0.5028, 0.1314, 0.2702, 0.6402],\n",
            "        [0.7145, 0.6671, 0.4565, 0.9920, 0.0389],\n",
            "        [0.1813, 0.2959, 0.5535, 0.3086, 0.5610],\n",
            "        [0.2872, 0.8837, 0.0558, 0.5879, 0.5851],\n",
            "        [0.5779, 0.0915, 0.4913, 0.8039, 0.4815]])\n",
            " produto: tensor([[[[-2.1236e-03,  1.6655e-04, -6.5265e-04,  1.0190e-03, -5.4550e-03],\n",
            "          [ 5.2379e-03, -4.8485e-03, -3.6294e-03, -6.2686e-03,  1.7638e-04],\n",
            "          [-6.6995e-04,  1.1072e-03, -4.6975e-03, -1.8722e-03, -2.0597e-03],\n",
            "          [-5.6431e-04, -6.7413e-03,  3.6519e-04, -1.3864e-03,  1.8780e-03],\n",
            "          [ 4.0865e-03,  1.7055e-04,  1.3435e-03,  7.7598e-03, -2.1715e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6496e-03, -2.2371e-03,  9.3910e-04,  2.1581e-03, -5.9027e-03],\n",
            "          [ 6.0996e-03,  3.1853e-03,  1.9893e-03,  4.0840e-03,  3.2375e-04],\n",
            "          [-2.3941e-04, -2.5022e-03, -1.5882e-03, -2.1733e-03,  3.7083e-04],\n",
            "          [-5.3614e-04, -4.7400e-03, -5.0708e-05,  5.5695e-03, -4.6148e-04],\n",
            "          [ 1.8348e-04, -1.4277e-04,  7.7238e-04,  7.1630e-03,  2.9442e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0198]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0169]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0198,  0.0169], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 2] = -0.019830191507935524\n",
            " somado na saída em [0, 1, 1, 2] = 0.016858287155628204\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 3\n",
            " alvo do kernel em x: x[0,0,3:8, 9:14]\n",
            " \n",
            " tensor([[0.2702, 0.6402, 0.5467, 0.3687, 0.1598],\n",
            "        [0.9920, 0.0389, 0.9156, 0.4248, 0.0722],\n",
            "        [0.3086, 0.5610, 0.8431, 0.3401, 0.2028],\n",
            "        [0.5879, 0.5851, 0.5907, 0.0110, 0.1758],\n",
            "        [0.8039, 0.4815, 0.9230, 0.8262, 0.9584]])\n",
            " produto: tensor([[[[-1.1019e-03,  2.1207e-04, -2.7150e-03,  1.3906e-03, -1.3616e-03],\n",
            "          [ 7.2721e-03, -2.8307e-04, -7.2792e-03, -2.6845e-03,  3.2677e-04],\n",
            "          [-1.1402e-03,  2.0992e-03, -7.1561e-03, -2.0632e-03, -7.4462e-04],\n",
            "          [-1.1553e-03, -4.4633e-03,  3.8680e-03, -2.5838e-05,  5.6432e-04],\n",
            "          [ 5.6848e-03,  8.9703e-04,  2.5238e-03,  7.9746e-03, -4.3225e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 8.5591e-04, -2.8484e-03,  3.9067e-03,  2.9449e-03, -1.4733e-03],\n",
            "          [ 8.4685e-03,  1.8597e-04,  3.9898e-03,  1.7490e-03,  5.9980e-04],\n",
            "          [-4.0745e-04, -4.7440e-03, -2.4194e-03, -2.3949e-03,  1.3406e-04],\n",
            "          [-1.0976e-03, -3.1382e-03, -5.3709e-04,  1.0380e-04, -1.3867e-04],\n",
            "          [ 2.5524e-04, -7.5093e-04,  1.4510e-03,  7.3612e-03,  5.8605e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0037]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0179]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0037,  0.0179], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 3] = -0.0036829509772360325\n",
            " somado na saída em [0, 1, 1, 3] = 0.017916301265358925\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 4\n",
            " alvo do kernel em x: x[0,0,3:8, 12:17]\n",
            " \n",
            " tensor([[0.3687, 0.1598, 0.0752, 0.1873, 0.6163],\n",
            "        [0.4248, 0.0722, 0.2967, 0.3702, 0.7406],\n",
            "        [0.3401, 0.2028, 0.1847, 0.0749, 0.8779],\n",
            "        [0.0110, 0.1758, 0.4507, 0.6482, 0.7909],\n",
            "        [0.8262, 0.9584, 0.0942, 0.4995, 0.6061]])\n",
            " produto: tensor([[[[-1.5036e-03,  5.2933e-05, -3.7364e-04,  7.0652e-04, -5.2512e-03],\n",
            "          [ 3.1143e-03, -5.2443e-04, -2.3593e-03, -2.3393e-03,  3.3542e-03],\n",
            "          [-1.2565e-03,  7.5889e-04, -1.5677e-03, -4.5437e-04, -3.2236e-03],\n",
            "          [-2.1531e-05, -1.3412e-03,  2.9513e-03, -1.5287e-03,  2.5388e-03],\n",
            "          [ 5.8422e-03,  1.7855e-03,  2.5748e-04,  4.8216e-03, -2.7336e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1680e-03, -7.1098e-04,  5.3763e-04,  1.4963e-03, -5.6821e-03],\n",
            "          [ 3.6267e-03,  3.4454e-04,  1.2931e-03,  1.5241e-03,  6.1566e-03],\n",
            "          [-4.4901e-04, -1.7151e-03, -5.3003e-04, -5.2743e-04,  5.8038e-04],\n",
            "          [-2.0456e-05, -9.4300e-04, -4.0981e-04,  6.1412e-03, -6.2385e-04],\n",
            "          [ 2.6231e-04, -1.4947e-03,  1.4803e-04,  4.4507e-03,  3.7062e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[0.0017]]],\n",
            "\n",
            "\n",
            "        [[[0.0183]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([0.0017, 0.0183], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 4] = 0.001705074217170477\n",
            " somado na saída em [0, 1, 1, 4] = 0.018329430371522903\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 5\n",
            " alvo do kernel em x: x[0,0,3:8, 15:20]\n",
            " \n",
            " tensor([[0.1873, 0.6163, 0.5038, 0.7934, 0.6719],\n",
            "        [0.3702, 0.7406, 0.0584, 0.6260, 0.1905],\n",
            "        [0.0749, 0.8779, 0.5358, 0.6640, 0.4424],\n",
            "        [0.6482, 0.7909, 0.3696, 0.0791, 0.7299],\n",
            "        [0.4995, 0.6061, 0.9676, 0.7315, 0.1153]])\n",
            " produto: tensor([[[[-7.6396e-04,  2.0415e-04, -2.5024e-03,  2.9921e-03, -5.7249e-03],\n",
            "          [ 2.7138e-03, -5.3830e-03, -4.6415e-04, -3.9554e-03,  8.6258e-04],\n",
            "          [-2.7671e-04,  3.2854e-03, -4.5473e-03, -4.0286e-03, -1.6242e-03],\n",
            "          [-1.2739e-03, -6.0337e-03,  2.4200e-03, -1.8651e-04,  2.3429e-03],\n",
            "          [ 3.5323e-03,  1.1292e-03,  2.6459e-03,  7.0605e-03, -5.2005e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 5.9343e-04, -2.7420e-03,  3.6008e-03,  6.3367e-03, -6.1947e-03],\n",
            "          [ 3.1603e-03,  3.5365e-03,  2.5440e-04,  2.5769e-03,  1.5833e-03],\n",
            "          [-9.8884e-05, -7.4248e-03, -1.5374e-03, -4.6763e-03,  2.9243e-04],\n",
            "          [-1.2103e-03, -4.2424e-03, -3.3603e-04,  7.4926e-04, -5.7571e-04],\n",
            "          [ 1.5860e-04, -9.4527e-04,  1.5211e-03,  6.5174e-03,  7.0510e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0081]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0016]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0081,  0.0016], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 5] = -0.008096078410744667\n",
            " somado na saída em [0, 1, 1, 5] = 0.0016023917123675346\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 6\n",
            " alvo do kernel em x: x[0,0,3:8, 18:23]\n",
            " \n",
            " tensor([[0.7934, 0.6719, 0.3124, 0.5274, 0.4189],\n",
            "        [0.6260, 0.1905, 0.4192, 0.7320, 0.6987],\n",
            "        [0.6640, 0.4424, 0.0088, 0.7985, 0.4518],\n",
            "        [0.0791, 0.7299, 0.8768, 0.1186, 0.1648],\n",
            "        [0.7315, 0.1153, 0.2254, 0.9171, 0.3104]])\n",
            " produto: tensor([[[[-3.2354e-03,  2.2256e-04, -1.5518e-03,  1.9889e-03, -3.5695e-03],\n",
            "          [ 4.5886e-03, -1.3843e-03, -3.3326e-03, -4.6253e-03,  3.1642e-03],\n",
            "          [-2.4534e-03,  1.6554e-03, -7.4292e-05, -4.8445e-03, -1.6588e-03],\n",
            "          [-1.5542e-04, -5.5681e-03,  5.7411e-03, -2.7958e-04,  5.2890e-04],\n",
            "          [ 5.1725e-03,  2.1483e-04,  6.1635e-04,  8.8528e-03, -1.4001e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.5132e-03, -2.9894e-03,  2.2329e-03,  4.2121e-03, -3.8624e-03],\n",
            "          [ 5.3435e-03,  9.0947e-04,  1.8266e-03,  3.0134e-03,  5.8079e-03],\n",
            "          [-8.7673e-04, -3.7410e-03, -2.5117e-05, -5.6234e-03,  2.9866e-04],\n",
            "          [-1.4766e-04, -3.9150e-03, -7.9719e-04,  1.1232e-03, -1.2996e-04],\n",
            "          [ 2.3224e-04, -1.7983e-04,  3.5434e-04,  8.1719e-03,  1.8983e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0014]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0156]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0014,  0.0156], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 6] = -0.0013870242983102798\n",
            " somado na saída em [0, 1, 1, 6] = 0.015649884939193726\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 7\n",
            " alvo do kernel em x: x[0,0,3:8, 21:26]\n",
            " \n",
            " tensor([[0.5274, 0.4189, 0.1057, 0.5674, 0.8609],\n",
            "        [0.7320, 0.6987, 0.1590, 0.8913, 0.0412],\n",
            "        [0.7985, 0.4518, 0.5817, 0.8890, 0.2150],\n",
            "        [0.1186, 0.1648, 0.7253, 0.4087, 0.7894],\n",
            "        [0.9171, 0.3104, 0.9554, 0.2170, 0.9451]])\n",
            " produto: tensor([[[[-0.0022,  0.0001, -0.0005,  0.0021, -0.0073],\n",
            "          [ 0.0054, -0.0051, -0.0013, -0.0056,  0.0002],\n",
            "          [-0.0030,  0.0017, -0.0049, -0.0054, -0.0008],\n",
            "          [-0.0002, -0.0013,  0.0047, -0.0010,  0.0025],\n",
            "          [ 0.0065,  0.0006,  0.0026,  0.0021, -0.0043]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0017, -0.0019,  0.0008,  0.0045, -0.0079],\n",
            "          [ 0.0062,  0.0033,  0.0007,  0.0037,  0.0003],\n",
            "          [-0.0011, -0.0038, -0.0017, -0.0063,  0.0001],\n",
            "          [-0.0002, -0.0009, -0.0007,  0.0039, -0.0006],\n",
            "          [ 0.0003, -0.0005,  0.0015,  0.0019,  0.0058]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0142]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0093]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0142,  0.0093], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 7] = -0.014195777475833893\n",
            " somado na saída em [0, 1, 1, 7] = 0.009289668872952461\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 0\n",
            " alvo do kernel em x: x[0,0,6:11, 0:5]\n",
            " \n",
            " tensor([[0.0049, 0.7451, 0.5310, 0.7164, 0.1032],\n",
            "        [0.1155, 0.6429, 0.6804, 0.3265, 0.4702],\n",
            "        [0.7093, 0.1940, 0.8848, 0.4701, 0.9635],\n",
            "        [0.2850, 0.3001, 0.2721, 0.6407, 0.3547],\n",
            "        [0.4631, 0.2340, 0.8517, 0.7669, 0.8688]])\n",
            " produto: tensor([[[[-2.0014e-05,  2.4682e-04, -2.6374e-03,  2.7016e-03, -8.7916e-04],\n",
            "          [ 8.4698e-04, -4.6727e-03, -5.4094e-03, -2.0630e-03,  2.1295e-03],\n",
            "          [-2.6208e-03,  7.2597e-04, -7.5096e-03, -2.8525e-03, -3.5376e-03],\n",
            "          [-5.6011e-04, -2.2893e-03,  1.7819e-03, -1.5110e-03,  1.1387e-03],\n",
            "          [ 3.2747e-03,  4.3594e-04,  2.3290e-03,  7.4030e-03, -3.9182e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5547e-05, -3.3151e-03,  3.7950e-03,  5.7214e-03, -9.5130e-04],\n",
            "          [ 9.8633e-04,  3.0699e-03,  2.9649e-03,  1.3440e-03,  3.9087e-03],\n",
            "          [-9.3654e-04, -1.6406e-03, -2.5389e-03, -3.3111e-03,  6.3692e-04],\n",
            "          [-5.3215e-04, -1.6097e-03, -2.4742e-04,  6.0699e-03, -2.7980e-04],\n",
            "          [ 1.4703e-04, -3.6494e-04,  1.3389e-03,  6.8336e-03,  5.3125e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0175]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0264]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0175,  0.0264], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 0] = -0.017466869205236435\n",
            " somado na saída em [0, 1, 2, 0] = 0.026417085900902748\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 1\n",
            " alvo do kernel em x: x[0,0,6:11, 3:8]\n",
            " \n",
            " tensor([[0.7164, 0.1032, 0.2063, 0.2872, 0.8837],\n",
            "        [0.3265, 0.4702, 0.7526, 0.5779, 0.0915],\n",
            "        [0.4701, 0.9635, 0.3845, 0.0656, 0.0596],\n",
            "        [0.6407, 0.3547, 0.3613, 0.0409, 0.6469],\n",
            "        [0.7669, 0.8688, 0.2762, 0.7178, 0.8366]])\n",
            " produto: tensor([[[[-2.9212e-03,  3.4178e-05, -1.0245e-03,  1.0829e-03, -7.5295e-03],\n",
            "          [ 2.3933e-03, -3.4175e-03, -5.9833e-03, -3.6516e-03,  4.1460e-04],\n",
            "          [-1.7372e-03,  3.6054e-03, -3.2638e-03, -3.9776e-04, -2.1901e-04],\n",
            "          [-1.2591e-03, -2.7062e-03,  2.3658e-03, -9.6403e-05,  2.0766e-03],\n",
            "          [ 5.4234e-03,  1.6186e-03,  7.5524e-04,  6.9286e-03, -3.7733e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.2691e-03, -4.5907e-04,  1.4741e-03,  2.2934e-03, -8.1474e-03],\n",
            "          [ 2.7870e-03,  2.2452e-03,  3.2795e-03,  2.3790e-03,  7.6101e-04],\n",
            "          [-6.2078e-04, -8.1480e-03, -1.1035e-03, -4.6171e-04,  3.9430e-05],\n",
            "          [-1.1962e-03, -1.9028e-03, -3.2850e-04,  3.8728e-04, -5.1027e-04],\n",
            "          [ 2.4351e-04, -1.3549e-03,  4.3419e-04,  6.3956e-03,  5.1159e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0113]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0059]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0113,  0.0059], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 1] = -0.011281772516667843\n",
            " somado na saída em [0, 1, 2, 1] = 0.005871214903891087\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 2\n",
            " alvo do kernel em x: x[0,0,6:11, 6:11]\n",
            " \n",
            " tensor([[0.2872, 0.8837, 0.0558, 0.5879, 0.5851],\n",
            "        [0.5779, 0.0915, 0.4913, 0.8039, 0.4815],\n",
            "        [0.0656, 0.0596, 0.3820, 0.9015, 0.2903],\n",
            "        [0.0409, 0.6469, 0.9696, 0.4115, 0.3365],\n",
            "        [0.7178, 0.8366, 0.7488, 0.7390, 0.1508]])\n",
            " produto: tensor([[[[-1.1709e-03,  2.9272e-04, -2.7700e-04,  2.2169e-03, -4.9851e-03],\n",
            "          [ 4.2361e-03, -6.6538e-04, -3.9061e-03, -5.0798e-03,  2.1806e-03],\n",
            "          [-2.4223e-04,  2.2321e-04, -3.2420e-03, -5.4695e-03, -1.0658e-03],\n",
            "          [-8.0333e-05, -4.9352e-03,  6.3487e-03, -9.7042e-04,  1.0802e-03],\n",
            "          [ 5.0758e-03,  1.5587e-03,  2.0476e-03,  7.1330e-03, -6.7994e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 9.0956e-04, -3.9317e-03,  3.9857e-04,  4.6950e-03, -5.3942e-03],\n",
            "          [ 4.9331e-03,  4.3714e-04,  2.1410e-03,  3.3095e-03,  4.0026e-03],\n",
            "          [-8.6562e-05, -5.0443e-04, -1.0961e-03, -6.3489e-03,  1.9188e-04],\n",
            "          [-7.6322e-05, -3.4700e-03, -8.8155e-04,  3.8985e-03, -2.6544e-04],\n",
            "          [ 2.2790e-04, -1.3048e-03,  1.1771e-03,  6.5843e-03,  9.2189e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0004]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0105]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0004,  0.0105], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 2] = -0.000376259908080101\n",
            " somado na saída em [0, 1, 2, 2] = 0.010468036867678165\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 3\n",
            " alvo do kernel em x: x[0,0,6:11, 9:14]\n",
            " \n",
            " tensor([[0.5879, 0.5851, 0.5907, 0.0110, 0.1758],\n",
            "        [0.8039, 0.4815, 0.9230, 0.8262, 0.9584],\n",
            "        [0.9015, 0.2903, 0.5851, 0.3413, 0.6317],\n",
            "        [0.4115, 0.3365, 0.6303, 0.2307, 0.5619],\n",
            "        [0.7390, 0.1508, 0.5374, 0.9998, 0.5317]])\n",
            " produto: tensor([[[[-2.3972e-03,  1.9380e-04, -2.9338e-03,  4.1317e-05, -1.4980e-03],\n",
            "          [ 5.8930e-03, -3.4996e-03, -7.3379e-03, -5.2204e-03,  4.3405e-03],\n",
            "          [-3.3309e-03,  1.0862e-03, -4.9660e-03, -2.0709e-03, -2.3196e-03],\n",
            "          [-8.0866e-04, -2.5672e-03,  4.1271e-03, -5.4408e-04,  1.8036e-03],\n",
            "          [ 5.2256e-03,  2.8087e-04,  1.4695e-03,  9.6509e-03, -2.3981e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8621e-03, -2.6031e-03,  4.2215e-03,  8.7503e-05, -1.6209e-03],\n",
            "          [ 6.8626e-03,  2.2992e-03,  4.0220e-03,  3.4011e-03,  7.9671e-03],\n",
            "          [-1.1903e-03, -2.4547e-03, -1.6790e-03, -2.4039e-03,  4.1762e-04],\n",
            "          [-7.6828e-04, -1.8051e-03, -5.7307e-04,  2.1857e-03, -4.4319e-04],\n",
            "          [ 2.3462e-04, -2.3513e-04,  8.4483e-04,  8.9086e-03,  3.2515e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0078]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0308]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0078,  0.0308], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 3] = -0.007780092768371105\n",
            " somado na saída em [0, 1, 2, 3] = 0.030789345502853394\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 4\n",
            " alvo do kernel em x: x[0,0,6:11, 12:17]\n",
            " \n",
            " tensor([[0.0110, 0.1758, 0.4507, 0.6482, 0.7909],\n",
            "        [0.8262, 0.9584, 0.0942, 0.4995, 0.6061],\n",
            "        [0.3413, 0.6317, 0.1160, 0.2986, 0.3527],\n",
            "        [0.2307, 0.5619, 0.1499, 0.8092, 0.6317],\n",
            "        [0.9998, 0.5317, 0.2387, 0.2875, 0.6833]])\n",
            " produto: tensor([[[[-4.4677e-05,  5.8235e-05, -2.2386e-03,  2.4445e-03, -6.7391e-03],\n",
            "          [ 6.0561e-03, -6.9660e-03, -7.4862e-04, -3.1564e-03,  2.7450e-03],\n",
            "          [-1.2612e-03,  2.3641e-03, -9.8429e-04, -1.8117e-03, -1.2951e-03],\n",
            "          [-4.5338e-04, -4.2865e-03,  9.8171e-04, -1.9082e-03,  2.0278e-03],\n",
            "          [ 7.0702e-03,  9.9064e-04,  6.5274e-04,  2.7748e-03, -3.0819e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 3.4704e-05, -7.8219e-04,  3.2211e-03,  5.1770e-03, -7.2921e-03],\n",
            "          [ 7.0525e-03,  4.5765e-03,  4.1032e-04,  2.0564e-03,  5.0385e-03],\n",
            "          [-4.5069e-04, -5.3426e-03, -3.3278e-04, -2.1030e-03,  2.3317e-04],\n",
            "          [-4.3075e-04, -3.0139e-03, -1.3632e-04,  7.6660e-03, -4.9828e-04],\n",
            "          [ 3.1745e-04, -8.2928e-04,  3.7526e-04,  2.5614e-03,  4.1786e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0068]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0217]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0068,  0.0217], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 4] = -0.006809780839830637\n",
            " somado na saída em [0, 1, 2, 4] = 0.02168687991797924\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 5\n",
            " alvo do kernel em x: x[0,0,6:11, 15:20]\n",
            " \n",
            " tensor([[0.6482, 0.7909, 0.3696, 0.0791, 0.7299],\n",
            "        [0.4995, 0.6061, 0.9676, 0.7315, 0.1153],\n",
            "        [0.2986, 0.3527, 0.5793, 0.7488, 0.0926],\n",
            "        [0.8092, 0.6317, 0.8905, 0.8083, 0.4624],\n",
            "        [0.2875, 0.6833, 0.0830, 0.3437, 0.6728]])\n",
            " produto: tensor([[[[-2.6433e-03,  2.6199e-04, -1.8356e-03,  2.9824e-04, -6.2191e-03],\n",
            "          [ 3.6617e-03, -4.4054e-03, -7.6927e-03, -4.6220e-03,  5.2222e-04],\n",
            "          [-1.1033e-03,  1.3199e-03, -4.9169e-03, -4.5434e-03, -3.4008e-04],\n",
            "          [-1.5901e-03, -4.8192e-03,  5.8312e-03, -1.9063e-03,  1.4841e-03],\n",
            "          [ 2.0328e-03,  1.2731e-03,  2.2683e-04,  3.3174e-03, -3.0343e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.0532e-03, -3.5190e-03,  2.6412e-03,  6.3162e-04, -6.7294e-03],\n",
            "          [ 4.2641e-03,  2.8942e-03,  4.2164e-03,  3.0112e-03,  9.5855e-04],\n",
            "          [-3.9428e-04, -2.9829e-03, -1.6623e-03, -5.2739e-03,  6.1228e-05],\n",
            "          [-1.5108e-03, -3.3885e-03, -8.0969e-04,  7.6581e-03, -3.6469e-04],\n",
            "          [ 9.1272e-05, -1.0657e-03,  1.3041e-04,  3.0623e-03,  4.1139e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0294]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0081]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0294,  0.0081], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 5] = -0.02944203093647957\n",
            " somado na saída em [0, 1, 2, 5] = 0.008086535148322582\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 6\n",
            " alvo do kernel em x: x[0,0,6:11, 18:23]\n",
            " \n",
            " tensor([[0.0791, 0.7299, 0.8768, 0.1186, 0.1648],\n",
            "        [0.7315, 0.1153, 0.2254, 0.9171, 0.3104],\n",
            "        [0.7488, 0.0926, 0.7905, 0.5923, 0.3845],\n",
            "        [0.8083, 0.4624, 0.3165, 0.5468, 0.8367],\n",
            "        [0.3437, 0.6728, 0.4628, 0.2755, 0.0555]])\n",
            " produto: tensor([[[[-0.0003,  0.0002, -0.0044,  0.0004, -0.0014],\n",
            "          [ 0.0054, -0.0008, -0.0018, -0.0058,  0.0014],\n",
            "          [-0.0028,  0.0003, -0.0067, -0.0036, -0.0014],\n",
            "          [-0.0016, -0.0035,  0.0021, -0.0013,  0.0027],\n",
            "          [ 0.0024,  0.0013,  0.0013,  0.0027, -0.0003]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0003, -0.0032,  0.0063,  0.0009, -0.0015],\n",
            "          [ 0.0062,  0.0006,  0.0010,  0.0038,  0.0026],\n",
            "          [-0.0010, -0.0008, -0.0023, -0.0042,  0.0003],\n",
            "          [-0.0015, -0.0025, -0.0003,  0.0052, -0.0007],\n",
            "          [ 0.0001, -0.0010,  0.0007,  0.0025,  0.0003]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0155]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0117]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0155,  0.0117], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 6] = -0.015473190695047379\n",
            " somado na saída em [0, 1, 2, 6] = 0.011696971021592617\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 7\n",
            " alvo do kernel em x: x[0,0,6:11, 21:26]\n",
            " \n",
            " tensor([[0.1186, 0.1648, 0.7253, 0.4087, 0.7894],\n",
            "        [0.9171, 0.3104, 0.9554, 0.2170, 0.9451],\n",
            "        [0.5923, 0.3845, 0.5681, 0.2286, 0.0444],\n",
            "        [0.5468, 0.8367, 0.0693, 0.9691, 0.0880],\n",
            "        [0.2755, 0.0555, 0.3774, 0.3081, 0.8736]])\n",
            " produto: tensor([[[[-4.8343e-04,  5.4580e-05, -3.6023e-03,  1.5413e-03, -6.7264e-03],\n",
            "          [ 6.7231e-03, -2.2564e-03, -7.5960e-03, -1.3714e-03,  4.2805e-03],\n",
            "          [-2.1887e-03,  1.4390e-03, -4.8220e-03, -1.3868e-03, -1.6302e-04],\n",
            "          [-1.0746e-03, -6.3831e-03,  4.5367e-04, -2.2855e-03,  2.8251e-04],\n",
            "          [ 1.9481e-03,  1.0333e-04,  1.0320e-03,  2.9738e-03, -3.9398e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 3.7552e-04, -7.3309e-04,  5.1835e-03,  3.2641e-03, -7.2783e-03],\n",
            "          [ 7.8292e-03,  1.4824e-03,  4.1634e-03,  8.9345e-04,  7.8570e-03],\n",
            "          [-7.8213e-04, -3.2520e-03, -1.6303e-03, -1.6098e-03,  2.9350e-05],\n",
            "          [-1.0210e-03, -4.4881e-03, -6.2995e-05,  9.1814e-03, -6.9421e-05],\n",
            "          [ 8.7466e-05, -8.6498e-05,  5.9327e-04,  2.7451e-03,  5.3417e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0234]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0280]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0234,  0.0280], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 7] = -0.023447636514902115\n",
            " somado na saída em [0, 1, 2, 7] = 0.028013259172439575\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 0\n",
            " alvo do kernel em x: x[0,0,9:14, 0:5]\n",
            " \n",
            " tensor([[0.2850, 0.3001, 0.2721, 0.6407, 0.3547],\n",
            "        [0.4631, 0.2340, 0.8517, 0.7669, 0.8688],\n",
            "        [0.3105, 0.3907, 0.4657, 0.7162, 0.8158],\n",
            "        [0.0841, 0.9153, 0.0797, 0.5722, 0.6932],\n",
            "        [0.7785, 0.3239, 0.1895, 0.4538, 0.1802]])\n",
            " produto: tensor([[[[-1.1622e-03,  9.9405e-05, -1.3515e-03,  2.4161e-03, -3.0225e-03],\n",
            "          [ 3.3946e-03, -1.7008e-03, -6.7714e-03, -4.8462e-03,  3.9346e-03],\n",
            "          [-1.1474e-03,  1.4620e-03, -3.9529e-03, -4.3453e-03, -2.9953e-03],\n",
            "          [-1.6529e-04, -6.9821e-03,  5.2215e-04, -1.3495e-03,  2.2251e-03],\n",
            "          [ 5.5051e-03,  6.0342e-04,  5.1831e-04,  4.3807e-03, -8.1249e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 9.0279e-04, -1.3352e-03,  1.9448e-03,  5.1169e-03, -3.2706e-03],\n",
            "          [ 3.9531e-03,  1.1173e-03,  3.7114e-03,  3.1573e-03,  7.2221e-03],\n",
            "          [-4.1003e-04, -3.3041e-03, -1.3364e-03, -5.0439e-03,  5.3928e-04],\n",
            "          [-1.5703e-04, -4.9093e-03, -7.2503e-05,  5.4214e-03, -5.4676e-04],\n",
            "          [ 2.4717e-04, -5.0514e-04,  2.9797e-04,  4.0437e-03,  1.1016e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0155]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0179]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0155,  0.0179], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 0] = -0.015543486922979355\n",
            " somado na saída em [0, 1, 3, 0] = 0.01788601279258728\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 1\n",
            " alvo do kernel em x: x[0,0,9:14, 3:8]\n",
            " \n",
            " tensor([[0.6407, 0.3547, 0.3613, 0.0409, 0.6469],\n",
            "        [0.7669, 0.8688, 0.2762, 0.7178, 0.8366],\n",
            "        [0.7162, 0.8158, 0.9571, 0.1965, 0.1151],\n",
            "        [0.5722, 0.6932, 0.9242, 0.4100, 0.7908],\n",
            "        [0.4538, 0.1802, 0.6754, 0.8354, 0.1136]])\n",
            " produto: tensor([[[[-2.6126e-03,  1.1750e-04, -1.7944e-03,  1.5416e-04, -5.5122e-03],\n",
            "          [ 5.6221e-03, -6.3146e-03, -2.1958e-03, -4.5356e-03,  3.7890e-03],\n",
            "          [-2.6463e-03,  3.0527e-03, -8.1235e-03, -1.1919e-03, -4.2248e-04],\n",
            "          [-1.1246e-03, -5.2881e-03,  6.0518e-03, -9.6699e-04,  2.5385e-03],\n",
            "          [ 3.2093e-03,  3.3563e-04,  1.8469e-03,  8.0637e-03, -5.1253e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 2.0294e-03, -1.5783e-03,  2.5820e-03,  3.2648e-04, -5.9645e-03],\n",
            "          [ 6.5470e-03,  4.1485e-03,  1.2035e-03,  2.9550e-03,  6.9549e-03],\n",
            "          [-9.4565e-04, -6.8989e-03, -2.7465e-03, -1.3836e-03,  7.6064e-05],\n",
            "          [-1.0684e-03, -3.7182e-03, -8.4032e-04,  3.8847e-03, -6.2377e-04],\n",
            "          [ 1.4409e-04, -2.8096e-04,  1.0618e-03,  7.4435e-03,  6.9491e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0085]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0140]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0085,  0.0140], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 1] = -0.008460402488708496\n",
            " somado na saída em [0, 1, 3, 1] = 0.014002775773406029\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 2\n",
            " alvo do kernel em x: x[0,0,9:14, 6:11]\n",
            " \n",
            " tensor([[0.0409, 0.6469, 0.9696, 0.4115, 0.3365],\n",
            "        [0.7178, 0.8366, 0.7488, 0.7390, 0.1508],\n",
            "        [0.1965, 0.1151, 0.4732, 0.5237, 0.0194],\n",
            "        [0.4100, 0.7908, 0.6377, 0.5731, 0.0211],\n",
            "        [0.8354, 0.1136, 0.5182, 0.0032, 0.3701]])\n",
            " produto: tensor([[[[-1.6669e-04,  2.1429e-04, -4.8155e-03,  1.5518e-03, -2.8674e-03],\n",
            "          [ 5.2617e-03, -6.0810e-03, -5.9531e-03, -4.6695e-03,  6.8278e-04],\n",
            "          [-7.2588e-04,  4.3058e-04, -4.0161e-03, -3.1774e-03, -7.1223e-05],\n",
            "          [-8.0580e-04, -6.0329e-03,  4.1756e-03, -1.3515e-03,  6.7599e-05],\n",
            "          [ 5.9074e-03,  2.1172e-04,  1.4171e-03,  3.1270e-05, -1.6693e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2948e-04, -2.8783e-03,  6.9290e-03,  3.2864e-03, -3.1027e-03],\n",
            "          [ 6.1274e-03,  3.9950e-03,  3.2629e-03,  3.0422e-03,  1.2533e-03],\n",
            "          [-2.5940e-04, -9.7308e-04, -1.3578e-03, -3.6883e-03,  1.2823e-05],\n",
            "          [-7.6557e-04, -4.2419e-03, -5.7981e-04,  5.4293e-03, -1.6611e-05],\n",
            "          [ 2.6524e-04, -1.7724e-04,  8.1467e-04,  2.8865e-05,  2.2634e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0225]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0188]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0225,  0.0188], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 2] = -0.022451356053352356\n",
            " somado na saída em [0, 1, 3, 2] = 0.01879931427538395\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 3\n",
            " alvo do kernel em x: x[0,0,9:14, 9:14]\n",
            " \n",
            " tensor([[0.4115, 0.3365, 0.6303, 0.2307, 0.5619],\n",
            "        [0.7390, 0.1508, 0.5374, 0.9998, 0.5317],\n",
            "        [0.5237, 0.0194, 0.9228, 0.8793, 0.5879],\n",
            "        [0.5731, 0.0211, 0.8125, 0.5403, 0.8650],\n",
            "        [0.0032, 0.3701, 0.9764, 0.2896, 0.0990]])\n",
            " produto: tensor([[[[-1.6780e-03,  1.1147e-04, -3.1304e-03,  8.7003e-04, -4.7876e-03],\n",
            "          [ 5.4170e-03, -1.0958e-03, -4.2726e-03, -6.3178e-03,  2.4082e-03],\n",
            "          [-1.9351e-03,  7.2588e-05, -7.8318e-03, -5.3352e-03, -2.1585e-03],\n",
            "          [-1.1262e-03, -1.6066e-04,  5.3202e-03, -1.2743e-03,  2.7766e-03],\n",
            "          [ 2.2908e-05,  6.8958e-04,  2.6700e-03,  2.7952e-03, -4.4672e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.3034e-03, -1.4973e-03,  4.5044e-03,  1.8426e-03, -5.1805e-03],\n",
            "          [ 6.3082e-03,  7.1990e-04,  2.3418e-03,  4.1160e-03,  4.4202e-03],\n",
            "          [-6.9150e-04, -1.6404e-04, -2.6479e-03, -6.1930e-03,  3.8861e-04],\n",
            "          [-1.0700e-03, -1.1296e-04, -7.3873e-04,  5.1192e-03, -6.8229e-04],\n",
            "          [ 1.0286e-06, -5.7727e-04,  1.5350e-03,  2.5802e-03,  6.0568e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0184]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0162]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0184,  0.0162], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 3] = -0.018396807834506035\n",
            " somado na saída em [0, 1, 3, 3] = 0.016230875626206398\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 4\n",
            " alvo do kernel em x: x[0,0,9:14, 12:17]\n",
            " \n",
            " tensor([[0.2307, 0.5619, 0.1499, 0.8092, 0.6317],\n",
            "        [0.9998, 0.5317, 0.2387, 0.2875, 0.6833],\n",
            "        [0.8793, 0.5879, 0.7199, 0.9438, 0.4792],\n",
            "        [0.5403, 0.8650, 0.6952, 0.5486, 0.5801],\n",
            "        [0.2896, 0.0990, 0.7747, 0.8225, 0.7629]])\n",
            " produto: tensor([[[[-9.4077e-04,  1.8612e-04, -7.4462e-04,  3.0514e-03, -5.3827e-03],\n",
            "          [ 7.3292e-03, -3.8648e-03, -1.8978e-03, -1.8165e-03,  3.0948e-03],\n",
            "          [-3.2491e-03,  2.1998e-03, -6.1097e-03, -5.7264e-03, -1.7596e-03],\n",
            "          [-1.0619e-03, -6.5989e-03,  4.5521e-03, -1.2937e-03,  1.8620e-03],\n",
            "          [ 2.0478e-03,  1.8453e-04,  2.1184e-03,  7.9394e-03, -3.4409e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 7.3077e-04, -2.4999e-03,  1.0715e-03,  6.4624e-03, -5.8244e-03],\n",
            "          [ 8.5350e-03,  2.5391e-03,  1.0402e-03,  1.1834e-03,  5.6806e-03],\n",
            "          [-1.1611e-03, -4.9715e-03, -2.0656e-03, -6.6471e-03,  3.1679e-04],\n",
            "          [-1.0089e-03, -4.6398e-03, -6.3208e-04,  5.1973e-03, -4.5754e-04],\n",
            "          [ 9.1944e-05, -1.5448e-04,  1.2179e-03,  7.3287e-03,  4.6653e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0093]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0160]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0093,  0.0160], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 4] = -0.009321746416389942\n",
            " somado na saída em [0, 1, 3, 4] = 0.015998441725969315\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 5\n",
            " alvo do kernel em x: x[0,0,9:14, 15:20]\n",
            " \n",
            " tensor([[0.8092, 0.6317, 0.8905, 0.8083, 0.4624],\n",
            "        [0.2875, 0.6833, 0.0830, 0.3437, 0.6728],\n",
            "        [0.9438, 0.4792, 0.4219, 0.8835, 0.7401],\n",
            "        [0.5486, 0.5801, 0.7487, 0.1414, 0.6298],\n",
            "        [0.8225, 0.7629, 0.4504, 0.0141, 0.1243]])\n",
            " produto: tensor([[[[-0.0033,  0.0002, -0.0044,  0.0030, -0.0039],\n",
            "          [ 0.0021, -0.0050, -0.0007, -0.0022,  0.0030],\n",
            "          [-0.0035,  0.0018, -0.0036, -0.0054, -0.0027],\n",
            "          [-0.0011, -0.0044,  0.0049, -0.0003,  0.0020],\n",
            "          [ 0.0058,  0.0014,  0.0012,  0.0001, -0.0006]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0026, -0.0028,  0.0064,  0.0065, -0.0043],\n",
            "          [ 0.0025,  0.0033,  0.0004,  0.0014,  0.0056],\n",
            "          [-0.0012, -0.0041, -0.0012, -0.0062,  0.0005],\n",
            "          [-0.0010, -0.0031, -0.0007,  0.0013, -0.0005],\n",
            "          [ 0.0003, -0.0012,  0.0007,  0.0001,  0.0008]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0153]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0058]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0153,  0.0058], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 5] = -0.01526822242885828\n",
            " somado na saída em [0, 1, 3, 5] = 0.005845339968800545\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 6\n",
            " alvo do kernel em x: x[0,0,9:14, 18:23]\n",
            " \n",
            " tensor([[0.8083, 0.4624, 0.3165, 0.5468, 0.8367],\n",
            "        [0.3437, 0.6728, 0.4628, 0.2755, 0.0555],\n",
            "        [0.8835, 0.7401, 0.6048, 0.1566, 0.7877],\n",
            "        [0.1414, 0.6298, 0.7290, 0.7093, 0.4780],\n",
            "        [0.0141, 0.1243, 0.3377, 0.8222, 0.5210]])\n",
            " produto: tensor([[[[-3.2962e-03,  1.5316e-04, -1.5721e-03,  2.0621e-03, -7.1294e-03],\n",
            "          [ 2.5193e-03, -4.8900e-03, -3.6798e-03, -1.7407e-03,  2.5118e-04],\n",
            "          [-3.2643e-03,  2.7694e-03, -5.1332e-03, -9.5033e-04, -2.8924e-03],\n",
            "          [-2.7797e-04, -4.8048e-03,  4.7733e-03, -1.6728e-03,  1.5344e-03],\n",
            "          [ 9.9998e-05,  2.3154e-04,  9.2357e-04,  7.9361e-03, -2.3498e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.5604e-03, -2.0571e-03,  2.2622e-03,  4.3672e-03, -7.7145e-03],\n",
            "          [ 2.9338e-03,  3.2126e-03,  2.0169e-03,  1.1341e-03,  4.6105e-04],\n",
            "          [-1.1665e-03, -6.2586e-03, -1.7355e-03, -1.1031e-03,  5.2075e-04],\n",
            "          [-2.6409e-04, -3.3784e-03, -6.6280e-04,  6.7202e-03, -3.7706e-04],\n",
            "          [ 4.4898e-06, -1.9383e-04,  5.3096e-04,  7.3256e-03,  3.1860e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0204]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0123]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0204,  0.0123], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 6] = -0.0203996729105711\n",
            " somado na saída em [0, 1, 3, 6] = 0.012324787676334381\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 7\n",
            " alvo do kernel em x: x[0,0,9:14, 21:26]\n",
            " \n",
            " tensor([[0.5468, 0.8367, 0.0693, 0.9691, 0.0880],\n",
            "        [0.2755, 0.0555, 0.3774, 0.3081, 0.8736],\n",
            "        [0.1566, 0.7877, 0.6048, 0.6916, 0.9918],\n",
            "        [0.7093, 0.4780, 0.3846, 0.4213, 0.7035],\n",
            "        [0.8222, 0.5210, 0.0252, 0.1556, 0.1993]])\n",
            " produto: tensor([[[[-2.2298e-03,  2.7716e-04, -3.4411e-04,  3.6547e-03, -7.4993e-04],\n",
            "          [ 2.0194e-03, -4.0312e-04, -3.0004e-03, -1.9468e-03,  3.9563e-03],\n",
            "          [-5.7875e-04,  2.9478e-03, -5.1335e-03, -4.1961e-03, -3.6416e-03],\n",
            "          [-1.3940e-03, -3.6468e-03,  2.5181e-03, -9.9358e-04,  2.2583e-03],\n",
            "          [ 5.8139e-03,  9.7068e-04,  6.8836e-05,  1.5017e-03, -8.9906e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7321e-03, -3.7228e-03,  4.9514e-04,  7.7399e-03, -8.1146e-04],\n",
            "          [ 2.3516e-03,  2.6484e-04,  1.6445e-03,  1.2683e-03,  7.2619e-03],\n",
            "          [-2.0682e-04, -6.6619e-03, -1.7356e-03, -4.8707e-03,  6.5564e-04],\n",
            "          [-1.3244e-03, -2.5641e-03, -3.4965e-04,  3.9915e-03, -5.5492e-04],\n",
            "          [ 2.6104e-04, -8.1258e-04,  3.9574e-05,  1.3862e-03,  1.2190e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0032]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0067]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0032,  0.0067], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 7] = -0.0031705256551504135\n",
            " somado na saída em [0, 1, 3, 7] = 0.006696263328194618\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 0\n",
            " alvo do kernel em x: x[0,0,12:17, 0:5]\n",
            " \n",
            " tensor([[0.0841, 0.9153, 0.0797, 0.5722, 0.6932],\n",
            "        [0.7785, 0.3239, 0.1895, 0.4538, 0.1802],\n",
            "        [0.5801, 0.9591, 0.5688, 0.6623, 0.1400],\n",
            "        [0.7549, 0.7396, 0.9856, 0.8581, 0.1219],\n",
            "        [0.7331, 0.3958, 0.1237, 0.6711, 0.2643]])\n",
            " produto: tensor([[[[-3.4297e-04,  3.0317e-04, -3.9605e-04,  2.1580e-03, -5.9064e-03],\n",
            "          [ 5.7067e-03, -2.3541e-03, -1.5069e-03, -2.8677e-03,  8.1589e-04],\n",
            "          [-2.1433e-03,  3.5890e-03, -4.8274e-03, -4.0183e-03, -5.1416e-04],\n",
            "          [-1.4835e-03, -5.6418e-03,  6.4533e-03, -2.0238e-03,  3.9116e-04],\n",
            "          [ 5.1837e-03,  7.3736e-04,  3.3827e-04,  6.4774e-03, -1.1918e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.6641e-04, -4.0721e-03,  5.6988e-04,  4.5703e-03, -6.3910e-03],\n",
            "          [ 6.6456e-03,  1.5466e-03,  8.2596e-04,  1.8683e-03,  1.4976e-03],\n",
            "          [-7.6592e-04, -8.1109e-03, -1.6321e-03, -4.6643e-03,  9.2569e-05],\n",
            "          [-1.4095e-03, -3.9668e-03, -8.9608e-04,  8.1301e-03, -9.6119e-05],\n",
            "          [ 2.3274e-04, -6.1726e-04,  1.9447e-04,  5.9792e-03,  1.6159e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0031]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0014]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0031,  0.0014], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 4, 0] = -0.0030642349738627672\n",
            " somado na saída em [0, 1, 4, 0] = 0.0014134529046714306\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 1\n",
            " alvo do kernel em x: x[0,0,12:17, 3:8]\n",
            " \n",
            " tensor([[0.5722, 0.6932, 0.9242, 0.4100, 0.7908],\n",
            "        [0.4538, 0.1802, 0.6754, 0.8354, 0.1136],\n",
            "        [0.6623, 0.1400, 0.0574, 0.6484, 0.8830],\n",
            "        [0.8581, 0.1219, 0.0557, 0.5499, 0.9027],\n",
            "        [0.6711, 0.2643, 0.9658, 0.6505, 0.6202]])\n",
            " produto: tensor([[[[-2.3335e-03,  2.2962e-04, -4.5903e-03,  1.5463e-03, -6.7383e-03],\n",
            "          [ 3.3268e-03, -1.3094e-03, -5.3699e-03, -5.2788e-03,  5.1467e-04],\n",
            "          [-2.4471e-03,  5.2401e-04, -4.8753e-04, -3.9337e-03, -3.2423e-03],\n",
            "          [-1.6864e-03, -9.2964e-04,  3.6480e-04, -1.2968e-03,  2.8976e-03],\n",
            "          [ 4.7453e-03,  4.9233e-04,  2.6411e-03,  6.2793e-03, -2.7973e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8126e-03, -3.0841e-03,  6.6050e-03,  3.2748e-03, -7.2912e-03],\n",
            "          [ 3.8742e-03,  8.6024e-04,  2.9432e-03,  3.4391e-03,  9.4470e-04],\n",
            "          [-8.7448e-04, -1.1842e-03, -1.6483e-04, -4.5662e-03,  5.8375e-04],\n",
            "          [-1.6022e-03, -6.5365e-04, -5.0654e-05,  5.2094e-03, -7.1203e-04],\n",
            "          [ 2.1306e-04, -4.1214e-04,  1.5184e-03,  5.7963e-03,  3.7927e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0189]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0203]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0189,  0.0203], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 4, 1] = -0.01887899823486805\n",
            " somado na saída em [0, 1, 4, 1] = 0.02027163654565811\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 2\n",
            " alvo do kernel em x: x[0,0,12:17, 6:11]\n",
            " \n",
            " tensor([[0.4100, 0.7908, 0.6377, 0.5731, 0.0211],\n",
            "        [0.8354, 0.1136, 0.5182, 0.0032, 0.3701],\n",
            "        [0.6484, 0.8830, 0.8777, 0.4877, 0.0564],\n",
            "        [0.5499, 0.9027, 0.1973, 0.6754, 0.4120],\n",
            "        [0.6505, 0.6202, 0.6802, 0.5589, 0.7552]])\n",
            " produto: tensor([[[[-1.6720e-03,  2.6196e-04, -3.1672e-03,  2.1611e-03, -1.7944e-04],\n",
            "          [ 6.1238e-03, -8.2599e-04, -4.1200e-03, -2.0470e-05,  1.6763e-03],\n",
            "          [-2.3956e-03,  3.3045e-03, -7.4494e-03, -2.9588e-03, -2.0706e-04],\n",
            "          [-1.0806e-03, -6.8865e-03,  1.2922e-03, -1.5929e-03,  1.3223e-03],\n",
            "          [ 4.6002e-03,  1.1555e-03,  1.8599e-03,  5.3951e-03, -3.4061e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2988e-03, -3.5185e-03,  4.5573e-03,  4.5769e-03, -1.9416e-04],\n",
            "          [ 7.1313e-03,  5.4265e-04,  2.2582e-03,  1.3337e-05,  3.0769e-03],\n",
            "          [-8.5608e-04, -7.4679e-03, -2.5186e-03, -3.4345e-03,  3.7278e-05],\n",
            "          [-1.0266e-03, -4.8421e-03, -1.7942e-04,  6.3991e-03, -3.2493e-04],\n",
            "          [ 2.0654e-04, -9.6732e-04,  1.0693e-03,  4.9802e-03,  4.6180e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0068]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0154]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0068,  0.0154], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 4, 2] = -0.0068091414868831635\n",
            " somado na saída em [0, 1, 4, 2] = 0.015435677021741867\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 3\n",
            " alvo do kernel em x: x[0,0,12:17, 9:14]\n",
            " \n",
            " tensor([[0.5731, 0.0211, 0.8125, 0.5403, 0.8650],\n",
            "        [0.0032, 0.3701, 0.9764, 0.2896, 0.0990],\n",
            "        [0.4877, 0.0564, 0.0681, 0.0149, 0.2089],\n",
            "        [0.6754, 0.4120, 0.6860, 0.7997, 0.8139],\n",
            "        [0.5589, 0.7552, 0.9101, 0.9682, 0.0189]])\n",
            " produto: tensor([[[[-2.3368e-03,  6.9759e-06, -4.0353e-03,  2.0377e-03, -7.3704e-03],\n",
            "          [ 2.3747e-05, -2.6903e-03, -7.7628e-03, -1.8299e-03,  4.4858e-04],\n",
            "          [-1.8019e-03,  2.1102e-04, -5.7762e-04, -9.0267e-05, -7.6719e-04],\n",
            "          [-1.3274e-03, -3.1426e-03,  4.4920e-03, -1.8860e-03,  2.6126e-03],\n",
            "          [ 3.9525e-03,  1.4070e-03,  2.4887e-03,  9.3453e-03, -8.5048e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8152e-03, -9.3698e-05,  5.8065e-03,  4.3155e-03, -7.9752e-03],\n",
            "          [ 2.7654e-05,  1.7674e-03,  4.2549e-03,  1.1921e-03,  8.2339e-04],\n",
            "          [-6.4392e-04, -4.7690e-04, -1.9529e-04, -1.0478e-04,  1.3813e-04],\n",
            "          [-1.2611e-03, -2.2096e-03, -6.2373e-04,  7.5768e-03, -6.4198e-04],\n",
            "          [ 1.7746e-04, -1.1778e-03,  1.4308e-03,  8.6265e-03,  1.1531e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0087]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0227]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0087,  0.0227], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 4, 3] = -0.008677642792463303\n",
            " somado na saída em [0, 1, 4, 3] = 0.022663503885269165\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 4\n",
            " alvo do kernel em x: x[0,0,12:17, 12:17]\n",
            " \n",
            " tensor([[0.5403, 0.8650, 0.6952, 0.5486, 0.5801],\n",
            "        [0.2896, 0.0990, 0.7747, 0.8225, 0.7629],\n",
            "        [0.0149, 0.2089, 0.4644, 0.1985, 0.6833],\n",
            "        [0.7997, 0.8139, 0.4169, 0.5365, 0.1929],\n",
            "        [0.9682, 0.0189, 0.2878, 0.6523, 0.0883]])\n",
            " produto: tensor([[[[-2.2034e-03,  2.8653e-04, -3.4527e-03,  2.0688e-03, -4.9426e-03],\n",
            "          [ 2.1228e-03, -7.1993e-04, -6.1591e-03, -5.1974e-03,  3.4553e-03],\n",
            "          [-5.4973e-05,  7.8190e-04, -3.9415e-03, -1.2042e-03, -2.5089e-03],\n",
            "          [-1.5717e-03, -6.2091e-03,  2.7296e-03, -1.2653e-03,  6.1915e-04],\n",
            "          [ 6.8463e-03,  3.5132e-05,  7.8697e-04,  6.2961e-03, -3.9805e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7115e-03, -3.8486e-03,  4.9682e-03,  4.3813e-03, -5.3481e-03],\n",
            "          [ 2.4720e-03,  4.7297e-04,  3.3758e-03,  3.3861e-03,  6.3423e-03],\n",
            "          [-1.9645e-05, -1.7670e-03, -1.3326e-03, -1.3978e-03,  4.5170e-04],\n",
            "          [-1.4932e-03, -4.3657e-03, -3.7903e-04,  5.0830e-03, -1.5214e-04],\n",
            "          [ 3.0739e-04, -2.9410e-05,  4.5243e-04,  5.8118e-03,  5.3970e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0138]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0196]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0138,  0.0196], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 4, 4] = -0.013800137676298618\n",
            " somado na saída em [0, 1, 4, 4] = 0.019623059779405594\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 5\n",
            " alvo do kernel em x: x[0,0,12:17, 15:20]\n",
            " \n",
            " tensor([[0.5486, 0.5801, 0.7487, 0.1414, 0.6298],\n",
            "        [0.8225, 0.7629, 0.4504, 0.0141, 0.1243],\n",
            "        [0.1985, 0.6833, 0.5864, 0.9573, 0.2803],\n",
            "        [0.5365, 0.1929, 0.5150, 0.2373, 0.6306],\n",
            "        [0.6523, 0.0883, 0.5147, 0.2970, 0.4479]])\n",
            " produto: tensor([[[[-2.2370e-03,  1.9215e-04, -3.7184e-03,  5.3341e-04, -5.3666e-03],\n",
            "          [ 6.0294e-03, -5.5453e-03, -3.5806e-03, -8.9356e-05,  5.6286e-04],\n",
            "          [-7.3334e-04,  2.5570e-03, -4.9768e-03, -5.8082e-03, -1.0291e-03],\n",
            "          [-1.0544e-03, -1.4715e-03,  3.3722e-03, -5.5959e-04,  2.0242e-03],\n",
            "          [ 4.6125e-03,  1.6443e-04,  1.4074e-03,  2.8670e-03, -2.0202e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7377e-03, -2.5808e-03,  5.3504e-03,  1.1297e-03, -5.8070e-03],\n",
            "          [ 7.0214e-03,  3.6431e-03,  1.9625e-03,  5.8215e-05,  1.0331e-03],\n",
            "          [-2.6206e-04, -5.7786e-03, -1.6826e-03, -6.7420e-03,  1.8528e-04],\n",
            "          [-1.0017e-03, -1.0346e-03, -4.6825e-04,  2.2480e-03, -4.9741e-04],\n",
            "          [ 2.0710e-04, -1.3765e-04,  8.0911e-04,  2.6464e-03,  2.7391e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0139]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0048]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0139,  0.0048], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 4, 5] = -0.013867809437215328\n",
            " somado na saída em [0, 1, 4, 5] = 0.004778349306434393\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 6\n",
            " alvo do kernel em x: x[0,0,12:17, 18:23]\n",
            " \n",
            " tensor([[0.1414, 0.6298, 0.7290, 0.7093, 0.4780],\n",
            "        [0.0141, 0.1243, 0.3377, 0.8222, 0.5210],\n",
            "        [0.9573, 0.2803, 0.1933, 0.9132, 0.9203],\n",
            "        [0.2373, 0.6306, 0.1470, 0.5588, 0.7160],\n",
            "        [0.2970, 0.4479, 0.5520, 0.5526, 0.5129]])\n",
            " produto: tensor([[[[-5.7678e-04,  2.0863e-04, -3.6206e-03,  2.6750e-03, -4.0732e-03],\n",
            "          [ 1.0366e-04, -9.0332e-04, -2.6852e-03, -5.1952e-03,  2.3596e-03],\n",
            "          [-3.5371e-03,  1.0488e-03, -1.6409e-03, -5.5403e-03, -3.3792e-03],\n",
            "          [-4.6631e-04, -4.8108e-03,  9.6266e-04, -1.3178e-03,  2.2982e-03],\n",
            "          [ 2.1003e-03,  8.3453e-04,  1.5094e-03,  5.3337e-03, -2.3132e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 4.4803e-04, -2.8023e-03,  5.2097e-03,  5.6651e-03, -4.4074e-03],\n",
            "          [ 1.2071e-04,  5.9346e-04,  1.4718e-03,  3.3847e-03,  4.3312e-03],\n",
            "          [-1.2640e-03, -2.3703e-03, -5.5477e-04, -6.4311e-03,  6.0840e-04],\n",
            "          [-4.4303e-04, -3.3826e-03, -1.3367e-04,  5.2940e-03, -5.6473e-04],\n",
            "          [ 9.4303e-05, -6.9860e-04,  8.6773e-04,  4.9234e-03,  3.1363e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0206]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0131]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0206,  0.0131], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 4, 6] = -0.020625364035367966\n",
            " somado na saída em [0, 1, 4, 6] = 0.01309624221175909\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 7\n",
            " alvo do kernel em x: x[0,0,12:17, 21:26]\n",
            " \n",
            " tensor([[0.7093, 0.4780, 0.3846, 0.4213, 0.7035],\n",
            "        [0.8222, 0.5210, 0.0252, 0.1556, 0.1993],\n",
            "        [0.9132, 0.9203, 0.4889, 0.9288, 0.0927],\n",
            "        [0.5588, 0.7160, 0.1038, 0.0078, 0.1808],\n",
            "        [0.5526, 0.5129, 0.5690, 0.0176, 0.7910]])\n",
            " produto: tensor([[[[-2.8925e-03,  1.5835e-04, -1.9100e-03,  1.5888e-03, -5.9946e-03],\n",
            "          [ 6.0269e-03, -3.7869e-03, -2.0014e-04, -9.8304e-04,  9.0282e-04],\n",
            "          [-3.3740e-03,  3.4440e-03, -4.1493e-03, -5.6351e-03, -3.4032e-04],\n",
            "          [-1.0981e-03, -5.4619e-03,  6.7991e-04, -1.8467e-05,  5.8020e-04],\n",
            "          [ 3.9074e-03,  9.5554e-04,  1.5559e-03,  1.6964e-04, -3.5675e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.2468e-03, -2.1269e-03,  2.7483e-03,  3.3648e-03, -6.4865e-03],\n",
            "          [ 7.0184e-03,  2.4879e-03,  1.0970e-04,  6.4045e-04,  1.6571e-03],\n",
            "          [-1.2057e-03, -7.7832e-03, -1.4029e-03, -6.5412e-03,  6.1272e-05],\n",
            "          [-1.0433e-03, -3.8404e-03, -9.4409e-05,  7.4187e-05, -1.4257e-04],\n",
            "          [ 1.7544e-04, -7.9990e-04,  8.9448e-04,  1.5659e-04,  4.8369e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0194]]],\n",
            "\n",
            "\n",
            "        [[[-0.0050]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0194, -0.0050], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 4, 7] = -0.01944250985980034\n",
            " somado na saída em [0, 1, 4, 7] = -0.00499442033469677\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 0\n",
            " alvo do kernel em x: x[0,0,15:20, 0:5]\n",
            " \n",
            " tensor([[0.7549, 0.7396, 0.9856, 0.8581, 0.1219],\n",
            "        [0.7331, 0.3958, 0.1237, 0.6711, 0.2643],\n",
            "        [0.9205, 0.6745, 0.2290, 0.0843, 0.2611],\n",
            "        [0.0184, 0.0221, 0.7344, 0.2282, 0.7989],\n",
            "        [0.6245, 0.5530, 0.1763, 0.3770, 0.4093]])\n",
            " produto: tensor([[[[-3.0783e-03,  2.4497e-04, -4.8949e-03,  3.2362e-03, -1.0383e-03],\n",
            "          [ 5.3736e-03, -2.8767e-03, -9.8349e-04, -4.2403e-03,  1.1968e-03],\n",
            "          [-3.4012e-03,  2.5241e-03, -1.9436e-03, -5.1154e-04, -9.5853e-04],\n",
            "          [-3.6079e-05, -1.6873e-04,  4.8085e-03, -5.3815e-04,  2.5645e-03],\n",
            "          [ 4.4158e-03,  1.0304e-03,  4.8223e-04,  3.6388e-03, -1.8458e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3912e-03, -3.2904e-03,  7.0433e-03,  6.8537e-03, -1.1235e-03],\n",
            "          [ 6.2577e-03,  1.8899e-03,  5.3906e-04,  2.7625e-03,  2.1968e-03],\n",
            "          [-1.2154e-03, -5.7043e-03, -6.5713e-04, -5.9378e-04,  1.7257e-04],\n",
            "          [-3.4278e-05, -1.1864e-04, -6.6768e-04,  2.1619e-03, -6.3016e-04],\n",
            "          [ 1.9826e-04, -8.6253e-04,  2.7723e-04,  3.3589e-03,  2.5026e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[0.0030]]],\n",
            "\n",
            "\n",
            "        [[[0.0237]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([0.0030, 0.0237], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 5, 0] = 0.0030001611448824406\n",
            " somado na saída em [0, 1, 5, 0] = 0.023707641288638115\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 1\n",
            " alvo do kernel em x: x[0,0,15:20, 3:8]\n",
            " \n",
            " tensor([[0.8581, 0.1219, 0.0557, 0.5499, 0.9027],\n",
            "        [0.6711, 0.2643, 0.9658, 0.6505, 0.6202],\n",
            "        [0.0843, 0.2611, 0.5458, 0.6308, 0.2272],\n",
            "        [0.2282, 0.7989, 0.8896, 0.1865, 0.3340],\n",
            "        [0.3770, 0.4093, 0.7472, 0.1104, 0.0010]])\n",
            " produto: tensor([[[[-3.4993e-03,  4.0366e-05, -2.7670e-04,  2.0736e-03, -7.6917e-03],\n",
            "          [ 4.9191e-03, -1.9207e-03, -7.6788e-03, -4.1106e-03,  2.8090e-03],\n",
            "          [-3.1152e-04,  9.7690e-04, -4.6324e-03, -3.8271e-03, -8.3427e-04],\n",
            "          [-4.4844e-04, -6.0947e-03,  5.8249e-03, -4.3981e-04,  1.0722e-03],\n",
            "          [ 2.6658e-03,  7.6247e-04,  2.0433e-03,  1.0656e-03, -4.4990e-06]]],\n",
            "\n",
            "\n",
            "        [[[ 2.7182e-03, -5.4218e-04,  3.9815e-04,  4.3915e-03, -8.3229e-03],\n",
            "          [ 5.7284e-03,  1.2619e-03,  4.2088e-03,  2.6781e-03,  5.1560e-03],\n",
            "          [-1.1132e-04, -2.2077e-03, -1.5662e-03, -4.4425e-03,  1.5020e-04],\n",
            "          [-4.2605e-04, -4.2853e-03, -8.0882e-04,  1.7669e-03, -2.6348e-04],\n",
            "          [ 1.1969e-04, -6.3828e-04,  1.1747e-03,  9.8364e-04,  6.0999e-06]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0175]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0071]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0175,  0.0071], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 5, 1] = -0.017517410218715668\n",
            " somado na saída em [0, 1, 5, 1] = 0.007127430289983749\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 2\n",
            " alvo do kernel em x: x[0,0,15:20, 6:11]\n",
            " \n",
            " tensor([[0.5499, 0.9027, 0.1973, 0.6754, 0.4120],\n",
            "        [0.6505, 0.6202, 0.6802, 0.5589, 0.7552],\n",
            "        [0.6308, 0.2272, 0.3883, 0.6688, 0.6660],\n",
            "        [0.1865, 0.3340, 0.9183, 0.0079, 0.4664],\n",
            "        [0.1104, 0.0010, 0.1092, 0.9901, 0.4898]])\n",
            " produto: tensor([[[[-2.2422e-03,  2.9902e-04, -9.8010e-04,  2.5472e-03, -3.5100e-03],\n",
            "          [ 4.7686e-03, -4.5081e-03, -5.4077e-03, -3.5318e-03,  3.4203e-03],\n",
            "          [-2.3307e-03,  8.5026e-04, -3.2953e-03, -4.0577e-03, -2.4455e-03],\n",
            "          [-3.6650e-04, -2.5483e-03,  6.0127e-03, -1.8730e-05,  1.4971e-03],\n",
            "          [ 7.8066e-04,  1.8585e-06,  2.9873e-04,  9.5569e-03, -2.2092e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7417e-03, -4.0164e-03,  1.4103e-03,  5.3944e-03, -3.7981e-03],\n",
            "          [ 5.5532e-03,  2.9617e-03,  2.9640e-03,  2.3010e-03,  6.2780e-03],\n",
            "          [-8.3289e-04, -1.9215e-03, -1.1141e-03, -4.7102e-03,  4.4029e-04],\n",
            "          [-3.4820e-04, -1.7918e-03, -8.3490e-04,  7.5244e-05, -3.6787e-04],\n",
            "          [ 3.5051e-05, -1.5558e-06,  1.7174e-04,  8.8218e-03,  2.9954e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0074]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0214]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0074,  0.0214], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 5, 2] = -0.007418668828904629\n",
            " somado na saída em [0, 1, 5, 2] = 0.021406320855021477\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 3\n",
            " alvo do kernel em x: x[0,0,15:20, 9:14]\n",
            " \n",
            " tensor([[0.6754, 0.4120, 0.6860, 0.7997, 0.8139],\n",
            "        [0.5589, 0.7552, 0.9101, 0.9682, 0.0189],\n",
            "        [0.6688, 0.6660, 0.9725, 0.0718, 0.2061],\n",
            "        [0.0079, 0.4664, 0.3068, 0.7460, 0.7440],\n",
            "        [0.9901, 0.4898, 0.0345, 0.3825, 0.4953]])\n",
            " produto: tensor([[[[-2.7543e-03,  1.3646e-04, -3.4072e-03,  3.0159e-03, -6.9350e-03],\n",
            "          [ 4.0972e-03, -5.4891e-03, -7.2358e-03, -6.1177e-03,  8.5404e-05],\n",
            "          [-2.4712e-03,  2.4924e-03, -8.2543e-03, -4.3592e-04, -7.5657e-04],\n",
            "          [-1.5608e-05, -3.5580e-03,  2.0092e-03, -1.7594e-03,  2.3880e-03],\n",
            "          [ 7.0014e-03,  9.1261e-04,  9.4466e-05,  3.6922e-03, -2.2339e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.1394e-03, -1.8328e-03,  4.9026e-03,  6.3872e-03, -7.5041e-03],\n",
            "          [ 4.7713e-03,  3.6062e-03,  3.9660e-03,  3.9857e-03,  1.5676e-04],\n",
            "          [-8.8308e-04, -5.6326e-03, -2.7907e-03, -5.0601e-04,  1.3621e-04],\n",
            "          [-1.4828e-05, -2.5017e-03, -2.7899e-04,  7.0679e-03, -5.8680e-04],\n",
            "          [ 3.1435e-04, -7.6396e-04,  5.4309e-05,  3.4082e-03,  3.0288e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0255]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0206]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0255,  0.0206], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 5, 3] = -0.025498589500784874\n",
            " somado na saída em [0, 1, 5, 3] = 0.020629409700632095\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 4\n",
            " alvo do kernel em x: x[0,0,15:20, 12:17]\n",
            " \n",
            " tensor([[0.7997, 0.8139, 0.4169, 0.5365, 0.1929],\n",
            "        [0.9682, 0.0189, 0.2878, 0.6523, 0.0883],\n",
            "        [0.0718, 0.2061, 0.6003, 0.6091, 0.9044],\n",
            "        [0.7460, 0.7440, 0.7520, 0.8707, 0.1276],\n",
            "        [0.3825, 0.4953, 0.1418, 0.5614, 0.8420]])\n",
            " produto: tensor([[[[-3.2612e-03,  2.6961e-04, -2.0704e-03,  2.0233e-03, -1.6435e-03],\n",
            "          [ 7.0971e-03, -1.3706e-04, -2.2881e-03, -4.1216e-03,  3.9972e-04],\n",
            "          [-2.6547e-04,  7.7107e-04, -5.0951e-03, -3.6956e-03, -3.3209e-03],\n",
            "          [-1.4661e-03, -5.6754e-03,  4.9241e-03, -2.0533e-03,  4.0972e-04],\n",
            "          [ 2.7049e-03,  9.2281e-04,  3.8779e-04,  5.4192e-03, -3.7973e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.5332e-03, -3.6213e-03,  2.9792e-03,  4.2850e-03, -1.7784e-03],\n",
            "          [ 8.2647e-03,  9.0047e-05,  1.2541e-03,  2.6852e-03,  7.3369e-04],\n",
            "          [-9.4868e-05, -1.7426e-03, -1.7226e-03, -4.2898e-03,  5.9789e-04],\n",
            "          [-1.3929e-03, -3.9905e-03, -6.8374e-04,  8.2489e-03, -1.0068e-04],\n",
            "          [ 1.2145e-04, -7.7250e-04,  2.2294e-04,  5.0023e-03,  5.1485e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0136]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0220]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0136,  0.0220], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 5, 4] = -0.013561772182583809\n",
            " somado na saída em [0, 1, 5, 4] = 0.021977204829454422\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 5\n",
            " alvo do kernel em x: x[0,0,15:20, 15:20]\n",
            " \n",
            " tensor([[0.5365, 0.1929, 0.5150, 0.2373, 0.6306],\n",
            "        [0.6523, 0.0883, 0.5147, 0.2970, 0.4479],\n",
            "        [0.6091, 0.9044, 0.0496, 0.0059, 0.1399],\n",
            "        [0.8707, 0.1276, 0.4551, 0.4770, 0.5130],\n",
            "        [0.5614, 0.8420, 0.1307, 0.0203, 0.5835]])\n",
            " produto: tensor([[[[-2.1878e-03,  6.3894e-05, -2.5578e-03,  8.9483e-04, -5.3733e-03],\n",
            "          [ 4.7814e-03, -6.4150e-04, -4.0919e-03, -1.8768e-03,  2.0287e-03],\n",
            "          [-2.2506e-03,  3.3845e-03, -4.2119e-04, -3.6060e-05, -5.1381e-04],\n",
            "          [-1.7111e-03, -9.7375e-04,  2.9799e-03, -1.1248e-03,  1.6467e-03],\n",
            "          [ 3.9701e-03,  1.5686e-03,  3.5747e-04,  1.9584e-04, -2.6314e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6994e-03, -8.5820e-04,  3.6805e-03,  1.8951e-03, -5.8142e-03],\n",
            "          [ 5.5681e-03,  4.2145e-04,  2.2428e-03,  1.2227e-03,  3.7237e-03],\n",
            "          [-8.0427e-04, -7.6488e-03, -1.4240e-04, -4.1858e-05,  9.2506e-05],\n",
            "          [-1.6256e-03, -6.8466e-04, -4.1378e-04,  4.5188e-03, -4.0463e-04],\n",
            "          [ 1.7825e-04, -1.3131e-03,  2.0551e-04,  1.8078e-04,  3.5678e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0045]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0094]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0045,  0.0094], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 5, 5] = -0.004520081914961338\n",
            " somado na saída em [0, 1, 5, 5] = 0.009445826523005962\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 6\n",
            " alvo do kernel em x: x[0,0,15:20, 18:23]\n",
            " \n",
            " tensor([[0.2373, 0.6306, 0.1470, 0.5588, 0.7160],\n",
            "        [0.2970, 0.4479, 0.5520, 0.5526, 0.5129],\n",
            "        [0.0059, 0.1399, 0.7139, 0.4614, 0.8693],\n",
            "        [0.4770, 0.5130, 0.6959, 0.2413, 0.9608],\n",
            "        [0.0203, 0.5835, 0.7803, 0.7196, 0.8925]])\n",
            " produto: tensor([[[[-9.6759e-04,  2.0889e-04, -7.3018e-04,  2.1073e-03, -6.1005e-03],\n",
            "          [ 2.1773e-03, -3.2558e-03, -4.3884e-03, -3.4916e-03,  2.3228e-03],\n",
            "          [-2.1960e-05,  5.2365e-04, -6.0592e-03, -2.7992e-03, -3.1918e-03],\n",
            "          [-9.3733e-04, -3.9135e-03,  4.5566e-03, -5.6910e-04,  3.0840e-03],\n",
            "          [ 1.4347e-04,  1.0870e-03,  2.1338e-03,  6.9462e-03, -4.0255e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 7.5160e-04, -2.8058e-03,  1.0507e-03,  4.4628e-03, -6.6011e-03],\n",
            "          [ 2.5355e-03,  2.1390e-03,  2.4053e-03,  2.2748e-03,  4.2636e-03],\n",
            "          [-7.8476e-06, -1.1834e-03, -2.0486e-03, -3.2493e-03,  5.7466e-04],\n",
            "          [-8.9053e-04, -2.7516e-03, -6.3271e-04,  2.2863e-03, -7.5781e-04],\n",
            "          [ 6.4417e-06, -9.0996e-04,  1.2267e-03,  6.4119e-03,  5.4579e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0152]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0140]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0152,  0.0140], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 5, 6] = -0.01516077108681202\n",
            " somado na saída em [0, 1, 5, 6] = 0.014008380472660065\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 7\n",
            " alvo do kernel em x: x[0,0,15:20, 21:26]\n",
            " \n",
            " tensor([[0.5588, 0.7160, 0.1038, 0.0078, 0.1808],\n",
            "        [0.5526, 0.5129, 0.5690, 0.0176, 0.7910],\n",
            "        [0.4614, 0.8693, 0.7289, 0.6179, 0.9365],\n",
            "        [0.2413, 0.9608, 0.7334, 0.6312, 0.0052],\n",
            "        [0.7196, 0.8925, 0.0875, 0.6904, 0.5361]])\n",
            " produto: tensor([[[[-2.2786e-03,  2.3716e-04, -5.1571e-04,  2.9530e-05, -1.5401e-03],\n",
            "          [ 4.0506e-03, -3.7279e-03, -4.5237e-03, -1.1105e-04,  3.5824e-03],\n",
            "          [-1.7047e-03,  3.2530e-03, -6.1862e-03, -3.7488e-03, -3.4385e-03],\n",
            "          [-4.7424e-04, -7.3294e-03,  4.8022e-03, -1.4885e-03,  1.6752e-05],\n",
            "          [ 5.0887e-03,  1.6629e-03,  2.3917e-04,  6.6639e-03, -2.4177e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7700e-03, -3.1855e-03,  7.4206e-04,  6.2539e-05, -1.6665e-03],\n",
            "          [ 4.7170e-03,  2.4491e-03,  2.4794e-03,  7.2351e-05,  6.5756e-03],\n",
            "          [-6.0918e-04, -7.3516e-03, -2.0915e-03, -4.3516e-03,  6.1907e-04],\n",
            "          [-4.5056e-04, -5.1534e-03, -6.6682e-04,  5.9799e-03, -4.1163e-06],\n",
            "          [ 2.2848e-04, -1.3920e-03,  1.3750e-04,  6.1513e-03,  3.2780e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0099]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0083]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0099,  0.0083], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 5, 7] = -0.009858738631010056\n",
            " somado na saída em [0, 1, 5, 7] = 0.008339561522006989\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 0\n",
            " alvo do kernel em x: x[0,0,18:23, 0:5]\n",
            " \n",
            " tensor([[0.0184, 0.0221, 0.7344, 0.2282, 0.7989],\n",
            "        [0.6245, 0.5530, 0.1763, 0.3770, 0.4093],\n",
            "        [0.0087, 0.2447, 0.8908, 0.7364, 0.1343],\n",
            "        [0.3215, 0.3025, 0.7401, 0.3590, 0.3345],\n",
            "        [0.5425, 0.2388, 0.7928, 0.3097, 0.9087]])\n",
            " produto: tensor([[[[-7.4863e-05,  7.3264e-06, -3.6472e-03,  8.6054e-04, -6.8073e-03],\n",
            "          [ 4.5775e-03, -4.0197e-03, -1.4020e-03, -2.3821e-03,  1.8535e-03],\n",
            "          [-3.1964e-05,  9.1565e-04, -7.5605e-03, -4.4679e-03, -4.9308e-04],\n",
            "          [-6.3187e-04, -2.3080e-03,  4.8463e-03, -8.4659e-04,  1.0736e-03],\n",
            "          [ 3.8363e-03,  4.4484e-04,  2.1680e-03,  2.9894e-03, -4.0985e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 5.8152e-05, -9.8406e-05,  5.2480e-03,  1.8225e-03, -7.3659e-03],\n",
            "          [ 5.3306e-03,  2.6409e-03,  7.6847e-04,  1.5519e-03,  3.4022e-03],\n",
            "          [-1.1422e-05, -2.0693e-03, -2.5562e-03, -5.1862e-03,  8.8775e-05],\n",
            "          [-6.0032e-04, -1.6228e-03, -6.7294e-04,  3.4010e-03, -2.6380e-04],\n",
            "          [ 1.7224e-04, -3.7239e-04,  1.2464e-03,  2.7594e-03,  5.5569e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0152]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0132]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0152,  0.0132], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 6, 0] = -0.015198775567114353\n",
            " somado na saída em [0, 1, 6, 0] = 0.013227766379714012\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 1\n",
            " alvo do kernel em x: x[0,0,18:23, 3:8]\n",
            " \n",
            " tensor([[0.2282, 0.7989, 0.8896, 0.1865, 0.3340],\n",
            "        [0.3770, 0.4093, 0.7472, 0.1104, 0.0010],\n",
            "        [0.7364, 0.1343, 0.5291, 0.5914, 0.4787],\n",
            "        [0.3590, 0.3345, 0.7012, 0.7275, 0.4852],\n",
            "        [0.3097, 0.9087, 0.9762, 0.1656, 0.1708]])\n",
            " produto: tensor([[[[-9.3051e-04,  2.6464e-04, -4.4182e-03,  7.0330e-04, -2.8462e-03],\n",
            "          [ 2.7634e-03, -2.9747e-03, -5.9409e-03, -6.9758e-04,  4.5178e-06],\n",
            "          [-2.7209e-03,  5.0253e-04, -4.4904e-03, -3.5883e-03, -1.7578e-03],\n",
            "          [-7.0547e-04, -2.5514e-03,  4.5911e-03, -1.7156e-03,  1.5575e-03],\n",
            "          [ 2.1900e-03,  1.6930e-03,  2.6695e-03,  1.5981e-03, -7.7049e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 7.2280e-04, -3.5546e-03,  6.3574e-03,  1.4895e-03, -3.0798e-03],\n",
            "          [ 3.2181e-03,  1.9543e-03,  3.2562e-03,  4.5447e-04,  8.2926e-06],\n",
            "          [-9.7233e-04, -1.1357e-03, -1.5182e-03, -4.1652e-03,  3.1648e-04],\n",
            "          [-6.7025e-04, -1.7940e-03, -6.3750e-04,  6.8920e-03, -3.8273e-04],\n",
            "          [ 9.8329e-05, -1.4173e-03,  1.5347e-03,  1.4751e-03,  1.0447e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0176]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0095]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0176,  0.0095], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 6, 1] = -0.01757071353495121\n",
            " somado na saída em [0, 1, 6, 1] = 0.009494774043560028\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 2\n",
            " alvo do kernel em x: x[0,0,18:23, 6:11]\n",
            " \n",
            " tensor([[0.1865, 0.3340, 0.9183, 0.0079, 0.4664],\n",
            "        [0.1104, 0.0010, 0.1092, 0.9901, 0.4898],\n",
            "        [0.5914, 0.4787, 0.3266, 0.1217, 0.3702],\n",
            "        [0.7275, 0.4852, 0.4534, 0.3125, 0.6602],\n",
            "        [0.1656, 0.1708, 0.0982, 0.1987, 0.2535]])\n",
            " produto: tensor([[[[-7.6048e-04,  1.1065e-04, -4.5607e-03,  2.9951e-05, -3.9740e-03],\n",
            "          [ 8.0925e-04, -7.2505e-06, -8.6853e-04, -6.2562e-03,  2.2185e-03],\n",
            "          [-2.1852e-03,  1.7915e-03, -2.7720e-03, -7.3825e-04, -1.3591e-03],\n",
            "          [-1.4296e-03, -3.7017e-03,  2.9691e-03, -7.3690e-04,  2.1192e-03],\n",
            "          [ 1.1707e-03,  3.1828e-04,  2.6842e-04,  1.9181e-03, -1.1434e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 5.9073e-04, -1.4862e-03,  6.5624e-03,  6.3430e-05, -4.3001e-03],\n",
            "          [ 9.4239e-04,  4.7634e-06,  4.7605e-04,  4.0759e-03,  4.0721e-03],\n",
            "          [-7.8090e-04, -4.0487e-03, -9.3719e-04, -8.5695e-04,  2.4470e-04],\n",
            "          [-1.3582e-03, -2.6027e-03, -4.1228e-04,  2.9604e-03, -5.2075e-04],\n",
            "          [ 5.2564e-05, -2.6644e-04,  1.5431e-04,  1.7706e-03,  1.5502e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0168]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0060]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0168,  0.0060], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 6, 2] = -0.016769621521234512\n",
            " somado na saída em [0, 1, 6, 2] = 0.005950102582573891\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 3\n",
            " alvo do kernel em x: x[0,0,18:23, 9:14]\n",
            " \n",
            " tensor([[0.0079, 0.4664, 0.3068, 0.7460, 0.7440],\n",
            "        [0.9901, 0.4898, 0.0345, 0.3825, 0.4953],\n",
            "        [0.1217, 0.3702, 0.4565, 0.0154, 0.3126],\n",
            "        [0.3125, 0.6602, 0.2522, 0.1846, 0.6083],\n",
            "        [0.1987, 0.2535, 0.3375, 0.5823, 0.5814]])\n",
            " produto: tensor([[[[-3.2386e-05,  1.5449e-04, -1.5240e-03,  2.8134e-03, -6.3390e-03],\n",
            "          [ 7.2578e-03, -3.5604e-03, -2.7465e-04, -2.4170e-03,  2.2433e-03],\n",
            "          [-4.4959e-04,  1.3852e-03, -3.8746e-03, -9.3584e-05, -1.1477e-03],\n",
            "          [-6.1407e-04, -5.0365e-03,  1.6512e-03, -4.3526e-04,  1.9525e-03],\n",
            "          [ 1.4052e-03,  4.7231e-04,  9.2284e-04,  5.6209e-03, -2.6222e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.5157e-05, -2.0751e-03,  2.1929e-03,  5.9582e-03, -6.8591e-03],\n",
            "          [ 8.4519e-03,  2.3391e-03,  1.5054e-04,  1.5747e-03,  4.1176e-03],\n",
            "          [-1.6066e-04, -3.1305e-03, -1.3100e-03, -1.0863e-04,  2.0664e-04],\n",
            "          [-5.8341e-04, -3.5413e-03, -2.2927e-04,  1.7486e-03, -4.7979e-04],\n",
            "          [ 6.3092e-05, -3.9538e-04,  5.3054e-04,  5.1885e-03,  3.5553e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0025]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0172]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0025,  0.0172], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 6, 3] = -0.0025419630110263824\n",
            " somado na saída em [0, 1, 6, 3] = 0.017229538410902023\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 4\n",
            " alvo do kernel em x: x[0,0,18:23, 12:17]\n",
            " \n",
            " tensor([[0.7460, 0.7440, 0.7520, 0.8707, 0.1276],\n",
            "        [0.3825, 0.4953, 0.1418, 0.5614, 0.8420],\n",
            "        [0.0154, 0.3126, 0.5854, 0.4706, 0.8857],\n",
            "        [0.1846, 0.6083, 0.6321, 0.0706, 0.1144],\n",
            "        [0.5823, 0.5814, 0.1491, 0.6036, 0.1891]])\n",
            " produto: tensor([[[[-3.0421e-03,  2.4643e-04, -3.7349e-03,  3.2835e-03, -1.0876e-03],\n",
            "          [ 2.8040e-03, -3.6002e-03, -1.1275e-03, -3.5475e-03,  3.8131e-03],\n",
            "          [-5.6992e-05,  1.1697e-03, -4.9683e-03, -2.8555e-03, -3.2520e-03],\n",
            "          [-3.6270e-04, -4.6404e-03,  4.1388e-03, -1.6657e-04,  3.6736e-04],\n",
            "          [ 4.1178e-03,  1.0832e-03,  4.0758e-04,  5.8267e-03, -8.5265e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3630e-03, -3.3100e-03,  5.3743e-03,  6.9538e-03, -1.1768e-03],\n",
            "          [ 3.2653e-03,  2.3652e-03,  6.1797e-04,  2.3112e-03,  6.9991e-03],\n",
            "          [-2.0366e-05, -2.6436e-03, -1.6798e-03, -3.3146e-03,  5.8549e-04],\n",
            "          [-3.4459e-04, -3.2628e-03, -5.7470e-04,  6.6917e-04, -9.0270e-05],\n",
            "          [ 1.8489e-04, -9.0677e-04,  2.3432e-04,  5.3785e-03,  1.1560e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0060]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0211]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0060,  0.0211], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 6, 4] = -0.006036743987351656\n",
            " somado na saída em [0, 1, 6, 4] = 0.021134108304977417\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 5\n",
            " alvo do kernel em x: x[0,0,18:23, 15:20]\n",
            " \n",
            " tensor([[0.8707, 0.1276, 0.4551, 0.4770, 0.5130],\n",
            "        [0.5614, 0.8420, 0.1307, 0.0203, 0.5835],\n",
            "        [0.4706, 0.8857, 0.7847, 0.7649, 0.0043],\n",
            "        [0.0706, 0.1144, 0.4796, 0.8107, 0.9761],\n",
            "        [0.6036, 0.1891, 0.1329, 0.3781, 0.9854]])\n",
            " produto: tensor([[[[-3.5504e-03,  4.2282e-05, -2.2603e-03,  1.7987e-03, -4.3710e-03],\n",
            "          [ 4.1155e-03, -6.1196e-03, -1.0393e-03, -1.2820e-04,  2.6424e-03],\n",
            "          [-1.7390e-03,  3.3143e-03, -6.6597e-03, -4.6410e-03, -1.5757e-05],\n",
            "          [-1.3881e-04, -8.7307e-04,  3.1402e-03, -1.9119e-03,  3.1332e-03],\n",
            "          [ 4.2686e-03,  3.5222e-04,  3.6345e-04,  3.6495e-03, -4.4441e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.7579e-03, -5.6791e-04,  3.2523e-03,  3.8093e-03, -4.7297e-03],\n",
            "          [ 4.7925e-03,  4.0204e-03,  5.6966e-04,  8.3524e-05,  4.8503e-03],\n",
            "          [-6.2142e-04, -7.4902e-03, -2.2516e-03, -5.3872e-03,  2.8370e-06],\n",
            "          [-1.3188e-04, -6.1387e-04, -4.3604e-04,  7.6806e-03, -7.6992e-04],\n",
            "          [ 1.9166e-04, -2.9485e-04,  2.0895e-04,  3.3687e-03,  6.0255e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0111]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0183]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0111,  0.0183], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 6, 5] = -0.01107177883386612\n",
            " somado na saída em [0, 1, 6, 5] = 0.018319781869649887\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 6\n",
            " alvo do kernel em x: x[0,0,18:23, 18:23]\n",
            " \n",
            " tensor([[0.4770, 0.5130, 0.6959, 0.2413, 0.9608],\n",
            "        [0.0203, 0.5835, 0.7803, 0.7196, 0.8925],\n",
            "        [0.7649, 0.0043, 0.8066, 0.3103, 0.2968],\n",
            "        [0.8107, 0.9761, 0.3266, 0.0882, 0.0468],\n",
            "        [0.3781, 0.9854, 0.8493, 0.1296, 0.3724]])\n",
            " produto: tensor([[[[-1.9450e-03,  1.6993e-04, -3.4562e-03,  9.1005e-04, -8.1863e-03],\n",
            "          [ 1.4873e-04, -4.2408e-03, -6.2038e-03, -4.5472e-03,  4.0423e-03],\n",
            "          [-2.8263e-03,  1.6059e-05, -6.8455e-03, -1.8826e-03, -1.0896e-03],\n",
            "          [-1.5932e-03, -7.4465e-03,  2.1384e-03, -2.0799e-04,  1.5012e-04],\n",
            "          [ 2.6736e-03,  1.8358e-03,  2.3225e-03,  1.2508e-03, -1.6794e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5108e-03, -2.2824e-03,  4.9731e-03,  1.9273e-03, -8.8580e-03],\n",
            "          [ 1.7319e-04,  2.7861e-03,  3.4004e-03,  2.9625e-03,  7.4197e-03],\n",
            "          [-1.0100e-03, -3.6293e-05, -2.3144e-03, -2.1853e-03,  1.9618e-04],\n",
            "          [-1.5136e-03, -5.2358e-03, -2.9693e-04,  8.3558e-04, -3.6890e-05],\n",
            "          [ 1.2004e-04, -1.5368e-03,  1.3352e-03,  1.1546e-03,  2.2770e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0365]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0058]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0365,  0.0058], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 6, 6] = -0.03649197518825531\n",
            " somado na saída em [0, 1, 6, 6] = 0.005765304900705814\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 7\n",
            " alvo do kernel em x: x[0,0,18:23, 21:26]\n",
            " \n",
            " tensor([[0.2413, 0.9608, 0.7334, 0.6312, 0.0052],\n",
            "        [0.7196, 0.8925, 0.0875, 0.6904, 0.5361],\n",
            "        [0.3103, 0.2968, 0.2864, 0.5178, 0.4373],\n",
            "        [0.0882, 0.0468, 0.2248, 0.3028, 0.5228],\n",
            "        [0.1296, 0.3724, 0.5016, 0.2179, 0.8230]])\n",
            " produto: tensor([[[[-9.8404e-04,  3.1825e-04, -3.6425e-03,  2.3803e-03, -4.4467e-05],\n",
            "          [ 5.2751e-03, -6.4874e-03, -6.9538e-04, -4.3624e-03,  2.4278e-03],\n",
            "          [-1.1465e-03,  1.1105e-03, -2.4303e-03, -3.1418e-03, -1.6056e-03],\n",
            "          [-1.7332e-04, -3.5679e-04,  1.4722e-03, -7.1419e-04,  1.6782e-03],\n",
            "          [ 9.1636e-04,  6.9374e-04,  1.3715e-03,  2.1029e-03, -3.7119e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 7.6438e-04, -4.2746e-03,  5.2412e-03,  5.0410e-03, -4.8115e-05],\n",
            "          [ 6.1430e-03,  4.2620e-03,  3.8114e-04,  2.8421e-03,  4.4563e-03],\n",
            "          [-4.0970e-04, -2.5097e-03, -8.2168e-04, -3.6470e-03,  2.8907e-04],\n",
            "          [-1.6467e-04, -2.5086e-04, -2.0443e-04,  2.8691e-03, -4.1237e-04],\n",
            "          [ 4.1144e-05, -5.8075e-04,  7.8848e-04,  1.9412e-03,  5.0328e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0097]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0268]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0097,  0.0268], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 6, 7] = -0.009749697521328926\n",
            " somado na saída em [0, 1, 6, 7] = 0.026769185438752174\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 0\n",
            " alvo do kernel em x: x[0,0,21:26, 0:5]\n",
            " \n",
            " tensor([[0.3215, 0.3025, 0.7401, 0.3590, 0.3345],\n",
            "        [0.5425, 0.2388, 0.7928, 0.3097, 0.9087],\n",
            "        [0.4739, 0.3396, 0.7721, 0.8556, 0.1195],\n",
            "        [0.6625, 0.5381, 0.8754, 0.9724, 0.9117],\n",
            "        [0.4514, 0.3344, 0.7182, 0.1932, 0.5187]])\n",
            " produto: tensor([[[[-1.3111e-03,  1.0022e-04, -3.6759e-03,  1.3538e-03, -2.8497e-03],\n",
            "          [ 3.9768e-03, -1.7355e-03, -6.3033e-03, -1.9569e-03,  4.1156e-03],\n",
            "          [-1.7510e-03,  1.2710e-03, -6.5532e-03, -5.1912e-03, -4.3877e-04],\n",
            "          [-1.3019e-03, -4.1052e-03,  5.7318e-03, -2.2932e-03,  2.9265e-03],\n",
            "          [ 3.1920e-03,  6.2309e-04,  1.9640e-03,  1.8653e-03, -2.3393e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0185e-03, -1.3460e-03,  5.2893e-03,  2.8670e-03, -3.0836e-03],\n",
            "          [ 4.6310e-03,  1.1402e-03,  3.4548e-03,  1.2749e-03,  7.5544e-03],\n",
            "          [-6.2574e-04, -2.8723e-03, -2.2156e-03, -6.0258e-03,  7.8997e-05],\n",
            "          [-1.2369e-03, -2.8864e-03, -7.9590e-04,  9.2125e-03, -7.1911e-04],\n",
            "          [ 1.4332e-04, -5.2161e-04,  1.1291e-03,  1.7218e-03,  3.1717e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0147]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0204]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0147,  0.0204], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 7, 0] = -0.014686320908367634\n",
            " somado na saída em [0, 1, 7, 0] = 0.0203586183488369\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 1\n",
            " alvo do kernel em x: x[0,0,21:26, 3:8]\n",
            " \n",
            " tensor([[0.3590, 0.3345, 0.7012, 0.7275, 0.4852],\n",
            "        [0.3097, 0.9087, 0.9762, 0.1656, 0.1708],\n",
            "        [0.8556, 0.1195, 0.2777, 0.5679, 0.7414],\n",
            "        [0.9724, 0.9117, 0.5682, 0.2926, 0.0124],\n",
            "        [0.1932, 0.5187, 0.3803, 0.1442, 0.8154]])\n",
            " produto: tensor([[[[-1.4638e-03,  1.1079e-04, -3.4823e-03,  2.7434e-03, -4.1344e-03],\n",
            "          [ 2.2702e-03, -6.6051e-03, -7.7614e-03, -1.0461e-03,  7.7371e-04],\n",
            "          [-3.1614e-03,  4.4718e-04, -2.3573e-03, -3.4454e-03, -2.7222e-03],\n",
            "          [-1.9109e-03, -6.9550e-03,  3.7204e-03, -6.8993e-04,  3.9763e-05],\n",
            "          [ 1.3665e-03,  9.6635e-04,  1.0400e-03,  1.3915e-03, -3.6774e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1371e-03, -1.4880e-03,  5.0108e-03,  5.8099e-03, -4.4737e-03],\n",
            "          [ 2.6437e-03,  4.3394e-03,  4.2541e-03,  6.8156e-04,  1.4202e-03],\n",
            "          [-1.1297e-03, -1.0106e-03, -7.9698e-04, -3.9993e-03,  4.9010e-04],\n",
            "          [-1.8155e-03, -4.8902e-03, -5.1660e-04,  2.7717e-03, -9.7708e-06],\n",
            "          [ 6.1353e-05, -8.0895e-04,  5.9787e-04,  1.2845e-03,  4.9860e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0345]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0145]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0345,  0.0145], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 7, 1] = -0.03454315662384033\n",
            " somado na saída em [0, 1, 7, 1] = 0.014548616483807564\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 2\n",
            " alvo do kernel em x: x[0,0,21:26, 6:11]\n",
            " \n",
            " tensor([[0.7275, 0.4852, 0.4534, 0.3125, 0.6602],\n",
            "        [0.1656, 0.1708, 0.0982, 0.1987, 0.2535],\n",
            "        [0.5679, 0.7414, 0.5131, 0.8022, 0.9203],\n",
            "        [0.2926, 0.0124, 0.6138, 0.4180, 0.7705],\n",
            "        [0.1442, 0.8154, 0.1690, 0.1481, 0.3718]])\n",
            " produto: tensor([[[[-2.9664e-03,  1.6073e-04, -2.2521e-03,  1.1784e-03, -5.6254e-03],\n",
            "          [ 1.2136e-03, -1.2417e-03, -7.8041e-04, -1.2557e-03,  1.1481e-03],\n",
            "          [-2.0982e-03,  2.7743e-03, -4.3550e-03, -4.8671e-03, -3.3793e-03],\n",
            "          [-5.7493e-04, -9.4500e-05,  4.0191e-03, -9.8581e-04,  2.4731e-03],\n",
            "          [ 1.0194e-03,  1.5191e-03,  4.6225e-04,  1.4297e-03, -1.6769e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3042e-03, -2.1589e-03,  3.2405e-03,  2.4956e-03, -6.0870e-03],\n",
            "          [ 1.4133e-03,  8.1577e-04,  4.2775e-04,  8.1806e-04,  2.1074e-03],\n",
            "          [-7.4981e-04, -6.2698e-03, -1.4724e-03, -5.6496e-03,  6.0841e-04],\n",
            "          [-5.4622e-04, -6.6445e-05, -5.5808e-04,  3.9603e-03, -6.0771e-04],\n",
            "          [ 4.5770e-05, -1.2717e-03,  2.6575e-04,  1.3197e-03,  2.2736e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0148]]],\n",
            "\n",
            "\n",
            "        [[[-0.0033]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0148, -0.0033], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 7, 2] = -0.01475559826940298\n",
            " somado na saída em [0, 1, 7, 2] = -0.003341478295624256\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 3\n",
            " alvo do kernel em x: x[0,0,21:26, 9:14]\n",
            " \n",
            " tensor([[0.3125, 0.6602, 0.2522, 0.1846, 0.6083],\n",
            "        [0.1987, 0.2535, 0.3375, 0.5823, 0.5814],\n",
            "        [0.8022, 0.9203, 0.0060, 0.5056, 0.8930],\n",
            "        [0.4180, 0.7705, 0.4796, 0.4277, 0.8659],\n",
            "        [0.1481, 0.3718, 0.9581, 0.8412, 0.3005]])\n",
            " produto: tensor([[[[-1.2742e-03,  2.1869e-04, -1.2524e-03,  6.9601e-04, -5.1829e-03],\n",
            "          [ 1.4567e-03, -1.8426e-03, -2.6831e-03, -3.6796e-03,  2.6332e-03],\n",
            "          [-2.9640e-03,  3.4440e-03, -5.0562e-05, -3.0677e-03, -3.2789e-03],\n",
            "          [-8.2148e-04, -5.8776e-03,  3.1401e-03, -1.0088e-03,  2.7795e-03],\n",
            "          [ 1.0474e-03,  6.9271e-04,  2.6199e-03,  8.1202e-03, -1.3551e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 9.8975e-04, -2.9374e-03,  1.8021e-03,  1.4740e-03, -5.6082e-03],\n",
            "          [ 1.6963e-03,  1.2105e-03,  1.4706e-03,  2.3973e-03,  4.8333e-03],\n",
            "          [-1.0592e-03, -7.7833e-03, -1.7095e-05, -3.5609e-03,  5.9034e-04],\n",
            "          [-7.8047e-04, -4.1327e-03, -4.3603e-04,  4.0525e-03, -6.8299e-04],\n",
            "          [ 4.7026e-05, -5.7988e-04,  1.5062e-03,  7.4956e-03,  1.8373e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0075]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0038]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0075,  0.0038], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 7, 3] = -0.007490592543035746\n",
            " somado na saída em [0, 1, 7, 3] = 0.0038246079348027706\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 4\n",
            " alvo do kernel em x: x[0,0,21:26, 12:17]\n",
            " \n",
            " tensor([[0.1846, 0.6083, 0.6321, 0.0706, 0.1144],\n",
            "        [0.5823, 0.5814, 0.1491, 0.6036, 0.1891],\n",
            "        [0.5056, 0.8930, 0.7072, 0.6690, 0.7589],\n",
            "        [0.4277, 0.8659, 0.5290, 0.8437, 0.8504],\n",
            "        [0.8412, 0.3005, 0.4444, 0.9269, 0.0636]])\n",
            " produto: tensor([[[[-0.0008,  0.0002, -0.0031,  0.0003, -0.0010],\n",
            "          [ 0.0043, -0.0042, -0.0012, -0.0038,  0.0009],\n",
            "          [-0.0019,  0.0033, -0.0060, -0.0041, -0.0028],\n",
            "          [-0.0008, -0.0066,  0.0035, -0.0020,  0.0027],\n",
            "          [ 0.0059,  0.0006,  0.0012,  0.0089, -0.0003]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0006, -0.0027,  0.0045,  0.0006, -0.0011],\n",
            "          [ 0.0050,  0.0028,  0.0006,  0.0025,  0.0016],\n",
            "          [-0.0007, -0.0076, -0.0020, -0.0047,  0.0005],\n",
            "          [-0.0008, -0.0046, -0.0005,  0.0080, -0.0007],\n",
            "          [ 0.0003, -0.0005,  0.0007,  0.0083,  0.0004]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0067]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0104]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0067,  0.0104], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 7, 4] = -0.006732503417879343\n",
            " somado na saída em [0, 1, 7, 4] = 0.010441175661981106\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 5\n",
            " alvo do kernel em x: x[0,0,21:26, 15:20]\n",
            " \n",
            " tensor([[0.0706, 0.1144, 0.4796, 0.8107, 0.9761],\n",
            "        [0.6036, 0.1891, 0.1329, 0.3781, 0.9854],\n",
            "        [0.6690, 0.7589, 0.0340, 0.1307, 0.4438],\n",
            "        [0.8437, 0.8504, 0.7255, 0.9779, 0.6455],\n",
            "        [0.9269, 0.0636, 0.2445, 0.3338, 0.0068]])\n",
            " produto: tensor([[[[-2.8802e-04,  3.7910e-05, -2.3819e-03,  3.0573e-03, -8.3171e-03],\n",
            "          [ 4.4249e-03, -1.3741e-03, -1.0567e-03, -2.3890e-03,  4.4627e-03],\n",
            "          [-2.4718e-03,  2.8397e-03, -2.8890e-04, -7.9290e-04, -1.6296e-03],\n",
            "          [-1.6580e-03, -6.4875e-03,  4.7508e-03, -2.3061e-03,  2.0719e-03],\n",
            "          [ 6.5543e-03,  1.1856e-04,  6.6864e-04,  3.2222e-03, -3.0534e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 2.2373e-04, -5.0919e-04,  3.4273e-03,  6.4747e-03, -8.9996e-03],\n",
            "          [ 5.1529e-03,  9.0275e-04,  5.7919e-04,  1.5565e-03,  8.1914e-03],\n",
            "          [-8.8333e-04, -6.4177e-03, -9.7675e-05, -9.2039e-04,  2.9339e-04],\n",
            "          [-1.5752e-03, -4.5615e-03, -6.5968e-04,  9.2642e-03, -5.0911e-04],\n",
            "          [ 2.9428e-04, -9.9248e-05,  3.8440e-04,  2.9744e-03,  4.1399e-05]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[0.0007]]],\n",
            "\n",
            "\n",
            "        [[[0.0145]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([0.0007, 0.0145], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 7, 5] = 0.0007367383223026991\n",
            " somado na saída em [0, 1, 7, 5] = 0.014527963474392891\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 6\n",
            " alvo do kernel em x: x[0,0,21:26, 18:23]\n",
            " \n",
            " tensor([[0.8107, 0.9761, 0.3266, 0.0882, 0.0468],\n",
            "        [0.3781, 0.9854, 0.8493, 0.1296, 0.3724],\n",
            "        [0.1307, 0.4438, 0.7018, 0.4124, 0.6167],\n",
            "        [0.9779, 0.6455, 0.7217, 0.9585, 0.8973],\n",
            "        [0.3338, 0.0068, 0.7245, 0.4732, 0.3467]])\n",
            " produto: tensor([[[[-3.3058e-03,  3.2334e-04, -1.6220e-03,  3.3260e-04, -3.9850e-04],\n",
            "          [ 2.7715e-03, -7.1621e-03, -6.7525e-03, -8.1884e-04,  1.6864e-03],\n",
            "          [-4.8287e-04,  1.6608e-03, -5.9562e-03, -2.5021e-03, -2.2642e-03],\n",
            "          [-1.9217e-03, -4.9240e-03,  4.7257e-03, -2.2604e-03,  2.8801e-03],\n",
            "          [ 2.3606e-03,  1.2613e-05,  1.9813e-03,  4.5680e-03, -1.5635e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.5679e-03, -4.3429e-03,  2.3339e-03,  7.0439e-04, -4.3120e-04],\n",
            "          [ 3.2275e-03,  4.7053e-03,  3.7011e-03,  5.3347e-04,  3.0955e-03],\n",
            "          [-1.7256e-04, -3.7533e-03, -2.0138e-03, -2.9044e-03,  4.0765e-04],\n",
            "          [-1.8257e-03, -3.4622e-03, -6.5619e-04,  9.0805e-03, -7.0772e-04],\n",
            "          [ 1.0599e-04, -1.0559e-05,  1.1390e-03,  4.2166e-03,  2.1199e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0186]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0177]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0186,  0.0177], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 7, 6] = -0.0186318326741457\n",
            " somado na saída em [0, 1, 7, 6] = 0.017658140510320663\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 7\n",
            " alvo do kernel em x: x[0,0,21:26, 21:26]\n",
            " \n",
            " tensor([[0.0882, 0.0468, 0.2248, 0.3028, 0.5228],\n",
            "        [0.1296, 0.3724, 0.5016, 0.2179, 0.8230],\n",
            "        [0.4124, 0.6167, 0.9567, 0.3398, 0.0011],\n",
            "        [0.9585, 0.8973, 0.8568, 0.6784, 0.1929],\n",
            "        [0.4732, 0.3467, 0.9201, 0.7388, 0.8701]])\n",
            " produto: tensor([[[[-3.5964e-04,  1.5492e-05, -1.1167e-03,  1.1421e-03, -4.4546e-03],\n",
            "          [ 9.4992e-04, -2.7065e-03, -3.9876e-03, -1.3766e-03,  3.7275e-03],\n",
            "          [-1.5238e-03,  2.3076e-03, -8.1202e-03, -2.0616e-03, -4.0945e-06],\n",
            "          [-1.8836e-03, -6.8449e-03,  5.6101e-03, -1.6000e-03,  6.1916e-04],\n",
            "          [ 3.3465e-03,  6.4587e-04,  2.5161e-03,  7.1312e-03, -3.9242e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.7936e-04, -2.0809e-04,  1.6068e-03,  2.4187e-03, -4.8202e-03],\n",
            "          [ 1.1062e-03,  1.7781e-03,  2.1856e-03,  8.9689e-04,  6.8418e-03],\n",
            "          [-5.4453e-04, -5.2151e-03, -2.7454e-03, -2.3930e-03,  7.3718e-07],\n",
            "          [-1.7895e-03, -4.8128e-03, -7.7900e-04,  6.4276e-03, -1.5215e-04],\n",
            "          [ 1.5025e-04, -5.4067e-04,  1.4465e-03,  6.5827e-03,  5.3205e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0120]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0130]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0120,  0.0130], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 7, 7] = -0.011952545493841171\n",
            " somado na saída em [0, 1, 7, 7] = 0.01304141990840435\n",
            "\n",
            "ndx_amostra: 1\n",
            "\n",
            "ndx_in_channels: 0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 0\n",
            " alvo do kernel em x: x[1,0,0:5, 0:5]\n",
            " \n",
            " tensor([[0.3030, 0.8419, 0.5701, 0.6761, 0.7507],\n",
            "        [0.2368, 0.2840, 0.7976, 0.3120, 0.9290],\n",
            "        [0.2805, 0.3148, 0.0974, 0.9182, 0.9942],\n",
            "        [0.0672, 0.8734, 0.7310, 0.8898, 0.4528],\n",
            "        [0.4935, 0.6181, 0.1109, 0.4415, 0.7771]])\n",
            " produto: tensor([[[[-0.0012,  0.0003, -0.0028,  0.0025, -0.0064],\n",
            "          [ 0.0017, -0.0021, -0.0063, -0.0020,  0.0042],\n",
            "          [-0.0010,  0.0012, -0.0008, -0.0056, -0.0037],\n",
            "          [-0.0001, -0.0067,  0.0048, -0.0021,  0.0015],\n",
            "          [ 0.0035,  0.0012,  0.0003,  0.0043, -0.0035]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0010, -0.0037,  0.0041,  0.0054, -0.0069],\n",
            "          [ 0.0020,  0.0014,  0.0035,  0.0013,  0.0077],\n",
            "          [-0.0004, -0.0027, -0.0003, -0.0065,  0.0007],\n",
            "          [-0.0001, -0.0047, -0.0007,  0.0084, -0.0004],\n",
            "          [ 0.0002, -0.0010,  0.0002,  0.0039,  0.0048]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0189]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0172]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0189,  0.0172], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 0, 0] = -0.01892545446753502\n",
            " somado na saída em [1, 1, 0, 0] = 0.017157770693302155\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 1\n",
            " alvo do kernel em x: x[1,0,0:5, 3:8]\n",
            " \n",
            " tensor([[0.6761, 0.7507, 0.3284, 0.5511, 0.8638],\n",
            "        [0.3120, 0.9290, 0.8850, 0.6736, 0.2249],\n",
            "        [0.9182, 0.9942, 0.8760, 0.7155, 0.1515],\n",
            "        [0.8898, 0.4528, 0.6056, 0.6489, 0.9578],\n",
            "        [0.4415, 0.7771, 0.0533, 0.4689, 0.6625]])\n",
            " produto: tensor([[[[-2.7570e-03,  2.4866e-04, -1.6310e-03,  2.0782e-03, -7.3600e-03],\n",
            "          [ 2.2870e-03, -6.7521e-03, -7.0363e-03, -4.2564e-03,  1.0184e-03],\n",
            "          [-3.3925e-03,  3.7203e-03, -7.4350e-03, -4.3409e-03, -5.5620e-04],\n",
            "          [-1.7487e-03, -3.4544e-03,  3.9654e-03, -1.5304e-03,  3.0744e-03],\n",
            "          [ 3.1223e-03,  1.4478e-03,  1.4582e-04,  4.5256e-03, -2.9880e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.1416e-03, -3.3399e-03,  2.3469e-03,  4.4011e-03, -7.9640e-03],\n",
            "          [ 2.6632e-03,  4.4360e-03,  3.8566e-03,  2.7731e-03,  1.8693e-03],\n",
            "          [-1.2123e-03, -8.4077e-03, -2.5137e-03, -5.0388e-03,  1.0014e-04],\n",
            "          [-1.6614e-03, -2.4289e-03, -5.5062e-04,  6.1479e-03, -7.5546e-04],\n",
            "          [ 1.4019e-04, -1.2120e-03,  8.3834e-05,  4.1775e-03,  4.0512e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0296]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0041]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0296,  0.0041], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 0, 1] = -0.02960509993135929\n",
            " somado na saída em [1, 1, 0, 1] = 0.004103993531316519\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 2\n",
            " alvo do kernel em x: x[1,0,0:5, 6:11]\n",
            " \n",
            " tensor([[0.5511, 0.8638, 0.9985, 0.4987, 0.7042],\n",
            "        [0.6736, 0.2249, 0.4760, 0.3502, 0.6523],\n",
            "        [0.7155, 0.1515, 0.5754, 0.2339, 0.1690],\n",
            "        [0.6489, 0.9578, 0.0698, 0.9007, 0.1515],\n",
            "        [0.4689, 0.6625, 0.1408, 0.8542, 0.1857]])\n",
            " produto: tensor([[[[-2.2471e-03,  2.8613e-04, -4.9590e-03,  1.8806e-03, -6.0001e-03],\n",
            "          [ 4.9378e-03, -1.6344e-03, -3.7845e-03, -2.2131e-03,  2.9544e-03],\n",
            "          [-2.6436e-03,  5.6686e-04, -4.8836e-03, -1.4193e-03, -6.2036e-04],\n",
            "          [-1.2753e-03, -7.3066e-03,  4.5693e-04, -2.1242e-03,  4.8644e-04],\n",
            "          [ 3.3155e-03,  1.2343e-03,  3.8508e-04,  8.2455e-03, -8.3757e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7455e-03, -3.8432e-03,  7.1356e-03,  3.9827e-03, -6.4925e-03],\n",
            "          [ 5.7502e-03,  1.0737e-03,  2.0743e-03,  1.4418e-03,  5.4230e-03],\n",
            "          [-9.4469e-04, -1.2811e-03, -1.6511e-03, -1.6475e-03,  1.1169e-04],\n",
            "          [-1.2116e-03, -5.1375e-03, -6.3447e-05,  8.5334e-03, -1.1953e-04],\n",
            "          [ 1.4886e-04, -1.0333e-03,  2.2138e-04,  7.6112e-03,  1.1356e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0172]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0230]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0172,  0.0230], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 0, 2] = -0.01719927415251732\n",
            " somado na saída em [1, 1, 0, 2] = 0.02296375297009945\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 3\n",
            " alvo do kernel em x: x[1,0,0:5, 9:14]\n",
            " \n",
            " tensor([[0.4987, 0.7042, 0.3662, 0.9734, 0.7886],\n",
            "        [0.3502, 0.6523, 0.0975, 0.7579, 0.3768],\n",
            "        [0.2339, 0.1690, 0.5848, 0.8684, 0.8909],\n",
            "        [0.9007, 0.1515, 0.9542, 0.8000, 0.2342],\n",
            "        [0.8542, 0.1857, 0.6214, 0.4531, 0.9663]])\n",
            " produto: tensor([[[[-0.0020,  0.0002, -0.0018,  0.0037, -0.0067],\n",
            "          [ 0.0026, -0.0047, -0.0008, -0.0048,  0.0017],\n",
            "          [-0.0009,  0.0006, -0.0050, -0.0053, -0.0033],\n",
            "          [-0.0018, -0.0012,  0.0062, -0.0019,  0.0008],\n",
            "          [ 0.0060,  0.0003,  0.0017,  0.0044, -0.0044]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0016, -0.0031,  0.0026,  0.0078, -0.0073],\n",
            "          [ 0.0030,  0.0031,  0.0004,  0.0031,  0.0031],\n",
            "          [-0.0003, -0.0014, -0.0017, -0.0061,  0.0006],\n",
            "          [-0.0017, -0.0008, -0.0009,  0.0076, -0.0002],\n",
            "          [ 0.0003, -0.0003,  0.0010,  0.0040,  0.0059]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0161]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0203]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0161,  0.0203], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 0, 3] = -0.016145721077919006\n",
            " somado na saída em [1, 1, 0, 3] = 0.020343679934740067\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 4\n",
            " alvo do kernel em x: x[1,0,0:5, 12:17]\n",
            " \n",
            " tensor([[0.9734, 0.7886, 0.6764, 0.6166, 0.5791],\n",
            "        [0.7579, 0.3768, 0.9719, 0.5425, 0.3223],\n",
            "        [0.8684, 0.8909, 0.2353, 0.5892, 0.1863],\n",
            "        [0.8000, 0.2342, 0.7129, 0.2613, 0.6533],\n",
            "        [0.4531, 0.9663, 0.9181, 0.4664, 0.2201]])\n",
            " produto: tensor([[[[-0.0040,  0.0003, -0.0034,  0.0023, -0.0049],\n",
            "          [ 0.0056, -0.0027, -0.0077, -0.0034,  0.0015],\n",
            "          [-0.0032,  0.0033, -0.0020, -0.0036, -0.0007],\n",
            "          [-0.0016, -0.0018,  0.0047, -0.0006,  0.0021],\n",
            "          [ 0.0032,  0.0018,  0.0025,  0.0045, -0.0010]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0031, -0.0035,  0.0048,  0.0049, -0.0053],\n",
            "          [ 0.0065,  0.0018,  0.0042,  0.0022,  0.0027],\n",
            "          [-0.0011, -0.0075, -0.0007, -0.0041,  0.0001],\n",
            "          [-0.0015, -0.0013, -0.0006,  0.0025, -0.0005],\n",
            "          [ 0.0001, -0.0015,  0.0014,  0.0042,  0.0013]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0089]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0122]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0089,  0.0122], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 0, 4] = -0.008871199563145638\n",
            " somado na saída em [1, 1, 0, 4] = 0.012172194197773933\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 5\n",
            " alvo do kernel em x: x[1,0,0:5, 15:20]\n",
            " \n",
            " tensor([[0.6166, 0.5791, 0.9339, 0.6982, 0.5340],\n",
            "        [0.5425, 0.3223, 0.2741, 0.6610, 0.0744],\n",
            "        [0.5892, 0.1863, 0.6379, 0.0327, 0.6528],\n",
            "        [0.2613, 0.6533, 0.6201, 0.1450, 0.6851],\n",
            "        [0.4664, 0.2201, 0.2724, 0.9321, 0.0059]])\n",
            " produto: tensor([[[[-2.5142e-03,  1.9183e-04, -4.6385e-03,  2.6330e-03, -4.5497e-03],\n",
            "          [ 3.9770e-03, -2.3429e-03, -2.1793e-03, -4.1770e-03,  3.3702e-04],\n",
            "          [-2.1772e-03,  6.9727e-04, -5.4137e-03, -1.9859e-04, -2.3968e-03],\n",
            "          [-5.1344e-04, -4.9838e-03,  4.0603e-03, -3.4206e-04,  2.1991e-03],\n",
            "          [ 3.2984e-03,  4.1004e-04,  7.4483e-04,  8.9976e-03, -2.6752e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9530e-03, -2.5765e-03,  6.6744e-03,  5.5763e-03, -4.9230e-03],\n",
            "          [ 4.6313e-03,  1.5392e-03,  1.1945e-03,  2.7213e-03,  6.1860e-04],\n",
            "          [-7.7802e-04, -1.5758e-03, -1.8303e-03, -2.3052e-04,  4.3152e-04],\n",
            "          [-4.8780e-04, -3.5042e-03, -5.6379e-04,  1.3741e-03, -5.4039e-04],\n",
            "          [ 1.4810e-04, -3.4325e-04,  4.2820e-04,  8.3056e-03,  3.6271e-05]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0089]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0183]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0089,  0.0183], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 0, 5] = -0.008907425217330456\n",
            " somado na saída em [1, 1, 0, 5] = 0.018278826028108597\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 6\n",
            " alvo do kernel em x: x[1,0,0:5, 18:23]\n",
            " \n",
            " tensor([[0.6982, 0.5340, 0.7917, 0.3530, 0.7519],\n",
            "        [0.6610, 0.0744, 0.5703, 0.8154, 0.4849],\n",
            "        [0.0327, 0.6528, 0.3338, 0.7499, 0.9454],\n",
            "        [0.1450, 0.6851, 0.4116, 0.3604, 0.0342],\n",
            "        [0.9321, 0.0059, 0.9561, 0.7033, 0.8461]])\n",
            " produto: tensor([[[[-2.8471e-03,  1.7687e-04, -3.9320e-03,  1.3312e-03, -6.4068e-03],\n",
            "          [ 4.8457e-03, -5.4087e-04, -4.5341e-03, -5.1524e-03,  2.1959e-03],\n",
            "          [-1.2094e-04,  2.4428e-03, -2.8329e-03, -4.5500e-03, -3.4713e-03],\n",
            "          [-2.8504e-04, -5.2265e-03,  2.6954e-03, -8.4985e-04,  1.0985e-04],\n",
            "          [ 6.5916e-03,  1.1051e-05,  2.6145e-03,  6.7890e-03, -3.8158e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.2116e-03, -2.3757e-03,  5.6578e-03,  2.8192e-03, -6.9325e-03],\n",
            "          [ 5.6429e-03,  3.5534e-04,  2.4852e-03,  3.3568e-03,  4.0307e-03],\n",
            "          [-4.3218e-05, -5.5205e-03, -9.5779e-04, -5.2815e-03,  6.2498e-04],\n",
            "          [-2.7081e-04, -3.6748e-03, -3.7427e-04,  3.4141e-03, -2.6993e-05],\n",
            "          [ 2.9596e-04, -9.2509e-06,  1.5030e-03,  6.2668e-03,  5.1736e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0148]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0184]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0148,  0.0184], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 0, 6] = -0.014761833474040031\n",
            " somado na saída em [1, 1, 0, 6] = 0.01837056502699852\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 7\n",
            " alvo do kernel em x: x[1,0,0:5, 21:26]\n",
            " \n",
            " tensor([[0.3530, 0.7519, 0.1881, 0.2234, 0.3398],\n",
            "        [0.8154, 0.4849, 0.4264, 0.9845, 0.9589],\n",
            "        [0.7499, 0.9454, 0.0988, 0.0526, 0.6466],\n",
            "        [0.3604, 0.0342, 0.9727, 0.8177, 0.0794],\n",
            "        [0.7033, 0.8461, 0.1233, 0.0291, 0.8610]])\n",
            " produto: tensor([[[[-1.4394e-03,  2.4907e-04, -9.3412e-04,  8.4262e-04, -2.8950e-03],\n",
            "          [ 5.9772e-03, -3.5242e-03, -3.3903e-03, -6.2207e-03,  4.3427e-03],\n",
            "          [-2.7709e-03,  3.5378e-03, -8.3820e-04, -3.1915e-04, -2.3741e-03],\n",
            "          [-7.0819e-04, -2.6107e-04,  6.3689e-03, -1.9283e-03,  2.5488e-04],\n",
            "          [ 4.9736e-03,  1.5763e-03,  3.3716e-04,  2.8095e-04, -3.8831e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1181e-03, -3.3454e-03,  1.3441e-03,  1.7845e-03, -3.1326e-03],\n",
            "          [ 6.9606e-03,  2.3153e-03,  1.8582e-03,  4.0528e-03,  7.9712e-03],\n",
            "          [-9.9019e-04, -7.9953e-03, -2.8339e-04, -3.7046e-04,  4.2744e-04],\n",
            "          [-6.7283e-04, -1.8356e-04, -8.8436e-04,  7.7465e-03, -6.2631e-05],\n",
            "          [ 2.2331e-04, -1.3195e-03,  1.9384e-04,  2.5934e-04,  5.2648e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0027]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0223]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0027,  0.0223], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 0, 7] = -0.0027455464005470276\n",
            " somado na saída em [1, 1, 0, 7] = 0.022279830649495125\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 0\n",
            " alvo do kernel em x: x[1,0,3:8, 0:5]\n",
            " \n",
            " tensor([[0.0672, 0.8734, 0.7310, 0.8898, 0.4528],\n",
            "        [0.4935, 0.6181, 0.1109, 0.4415, 0.7771],\n",
            "        [0.0795, 0.6216, 0.4124, 0.3677, 0.5837],\n",
            "        [0.8083, 0.5978, 0.4485, 0.0850, 0.3619],\n",
            "        [0.8911, 0.6452, 0.7377, 0.7835, 0.0581]])\n",
            " produto: tensor([[[[-0.0003,  0.0003, -0.0036,  0.0034, -0.0039],\n",
            "          [ 0.0036, -0.0045, -0.0009, -0.0028,  0.0035],\n",
            "          [-0.0003,  0.0023, -0.0035, -0.0022, -0.0021],\n",
            "          [-0.0016, -0.0046,  0.0029, -0.0002,  0.0012],\n",
            "          [ 0.0063,  0.0012,  0.0020,  0.0076, -0.0003]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0002, -0.0039,  0.0052,  0.0071, -0.0042],\n",
            "          [ 0.0042,  0.0030,  0.0005,  0.0018,  0.0065],\n",
            "          [-0.0001, -0.0053, -0.0012, -0.0026,  0.0004],\n",
            "          [-0.0015, -0.0032, -0.0004,  0.0008, -0.0003],\n",
            "          [ 0.0003, -0.0010,  0.0012,  0.0070,  0.0004]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[0.0036]]],\n",
            "\n",
            "\n",
            "        [[[0.0148]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([0.0036, 0.0148], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 1, 0] = 0.0035822750069200993\n",
            " somado na saída em [1, 1, 1, 0] = 0.014827653765678406\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 1\n",
            " alvo do kernel em x: x[1,0,3:8, 3:8]\n",
            " \n",
            " tensor([[0.8898, 0.4528, 0.6056, 0.6489, 0.9578],\n",
            "        [0.4415, 0.7771, 0.0533, 0.4689, 0.6625],\n",
            "        [0.3677, 0.5837, 0.4377, 0.0467, 0.8608],\n",
            "        [0.0850, 0.3619, 0.8273, 0.1917, 0.0610],\n",
            "        [0.7835, 0.0581, 0.6306, 0.3292, 0.7840]])\n",
            " produto: tensor([[[[-3.6286e-03,  1.4999e-04, -3.0078e-03,  2.4472e-03, -8.1609e-03],\n",
            "          [ 3.2367e-03, -5.6482e-03, -4.2397e-04, -2.9626e-03,  3.0005e-03],\n",
            "          [-1.3587e-03,  2.1843e-03, -3.7148e-03, -2.8340e-04, -3.1608e-03],\n",
            "          [-1.6709e-04, -2.7608e-03,  5.4170e-03, -4.5199e-04,  1.9574e-04],\n",
            "          [ 5.5403e-03,  1.0823e-04,  1.7243e-03,  3.1772e-03, -3.5357e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.8186e-03, -2.0147e-03,  4.3279e-03,  5.1826e-03, -8.8306e-03],\n",
            "          [ 3.7692e-03,  3.7107e-03,  2.3238e-04,  1.9301e-03,  5.5075e-03],\n",
            "          [-4.8553e-04, -4.9363e-03, -1.2559e-03, -3.2896e-04,  5.6907e-04],\n",
            "          [-1.5875e-04, -1.9412e-03, -7.5218e-04,  1.8158e-03, -4.8099e-05],\n",
            "          [ 2.4875e-04, -9.0602e-05,  9.9133e-04,  2.9328e-03,  4.7938e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0121]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0180]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0121,  0.0180], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 1, 1] = -0.012083826586604118\n",
            " somado na saída em [1, 1, 1, 1] = 0.017987899482250214\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 2\n",
            " alvo do kernel em x: x[1,0,3:8, 6:11]\n",
            " \n",
            " tensor([[0.6489, 0.9578, 0.0698, 0.9007, 0.1515],\n",
            "        [0.4689, 0.6625, 0.1408, 0.8542, 0.1857],\n",
            "        [0.0467, 0.8608, 0.1886, 0.6656, 0.3417],\n",
            "        [0.1917, 0.0610, 0.2301, 0.4493, 0.3979],\n",
            "        [0.3292, 0.7840, 0.1429, 0.8907, 0.0188]])\n",
            " produto: tensor([[[[-2.6461e-03,  3.1726e-04, -3.4658e-04,  3.3967e-03, -1.2912e-03],\n",
            "          [ 3.4369e-03, -4.8154e-03, -1.1196e-03, -5.3977e-03,  8.4107e-04],\n",
            "          [-1.7259e-04,  3.2213e-03, -1.6011e-03, -4.0386e-03, -1.2547e-03],\n",
            "          [-3.7664e-04, -4.6521e-04,  1.5069e-03, -1.0595e-03,  1.2773e-03],\n",
            "          [ 2.3276e-03,  1.4606e-03,  3.9074e-04,  8.5975e-03, -8.4866e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 2.0555e-03, -4.2614e-03,  4.9870e-04,  7.1936e-03, -1.3972e-03],\n",
            "          [ 4.0023e-03,  3.1636e-03,  6.1366e-04,  3.5166e-03,  1.5438e-03],\n",
            "          [-6.1675e-05, -7.2800e-03, -5.4133e-04, -4.6880e-03,  2.2590e-04],\n",
            "          [-3.5784e-04, -3.2710e-04, -2.0924e-04,  4.2563e-03, -3.1386e-04],\n",
            "          [ 1.0451e-04, -1.2227e-03,  2.2464e-04,  7.9362e-03,  1.1506e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[0.0021]]],\n",
            "\n",
            "\n",
            "        [[[0.0148]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([0.0021, 0.0148], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 1, 2] = 0.002103934995830059\n",
            " somado na saída em [1, 1, 1, 2] = 0.01479008886963129\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 3\n",
            " alvo do kernel em x: x[1,0,3:8, 9:14]\n",
            " \n",
            " tensor([[0.9007, 0.1515, 0.9542, 0.8000, 0.2342],\n",
            "        [0.8542, 0.1857, 0.6214, 0.4531, 0.9663],\n",
            "        [0.6656, 0.3417, 0.4580, 0.9041, 0.3212],\n",
            "        [0.4493, 0.3979, 0.0605, 0.7104, 0.4545],\n",
            "        [0.8907, 0.0188, 0.5050, 0.2157, 0.4644]])\n",
            " produto: tensor([[[[-3.6729e-03,  5.0198e-05, -4.7393e-03,  3.0171e-03, -1.9953e-03],\n",
            "          [ 6.2618e-03, -1.3498e-03, -4.9402e-03, -2.8633e-03,  4.3762e-03],\n",
            "          [-2.4595e-03,  1.2788e-03, -3.8875e-03, -5.4851e-03, -1.1793e-03],\n",
            "          [-8.8287e-04, -3.0356e-03,  3.9623e-04, -1.6753e-03,  1.4588e-03],\n",
            "          [ 6.2985e-03,  3.5057e-05,  1.3810e-03,  2.0823e-03, -2.0945e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.8530e-03, -6.7424e-04,  6.8194e-03,  6.3896e-03, -2.1590e-03],\n",
            "          [ 7.2920e-03,  8.8679e-04,  2.7077e-03,  1.8654e-03,  8.0327e-03],\n",
            "          [-8.7892e-04, -2.8899e-03, -1.3143e-03, -6.3671e-03,  2.1232e-04],\n",
            "          [-8.3879e-04, -2.1344e-03, -5.5018e-05,  6.7303e-03, -3.5847e-04],\n",
            "          [ 2.8280e-04, -2.9347e-05,  7.9396e-04,  1.9222e-03,  2.8398e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0136]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0319]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0136,  0.0319], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 1, 3] = -0.013624312356114388\n",
            " somado na saída em [1, 1, 1, 3] = 0.031928617507219315\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 4\n",
            " alvo do kernel em x: x[1,0,3:8, 12:17]\n",
            " \n",
            " tensor([[0.8000, 0.2342, 0.7129, 0.2613, 0.6533],\n",
            "        [0.4531, 0.9663, 0.9181, 0.4664, 0.2201],\n",
            "        [0.9041, 0.3212, 0.1261, 0.6273, 0.8730],\n",
            "        [0.7104, 0.4545, 0.4016, 0.2949, 0.3005],\n",
            "        [0.2157, 0.4644, 0.1182, 0.4960, 0.0630]])\n",
            " produto: tensor([[[[-3.2624e-03,  7.7568e-05, -3.5405e-03,  9.8527e-04, -5.5665e-03],\n",
            "          [ 3.3216e-03, -7.0233e-03, -7.2989e-03, -2.9474e-03,  9.9676e-04],\n",
            "          [-3.3404e-03,  1.2019e-03, -1.0700e-03, -3.8058e-03, -3.2055e-03],\n",
            "          [-1.3961e-03, -3.4671e-03,  2.6294e-03, -6.9547e-04,  9.6459e-04],\n",
            "          [ 1.5255e-03,  8.6521e-04,  3.2311e-04,  4.7880e-03, -2.8419e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 2.5341e-03, -1.0419e-03,  5.0945e-03,  2.0866e-03, -6.0232e-03],\n",
            "          [ 3.8681e-03,  4.6141e-03,  4.0006e-03,  1.9202e-03,  1.8296e-03],\n",
            "          [-1.1937e-03, -2.7163e-03, -3.6176e-04, -4.4177e-03,  5.7712e-04],\n",
            "          [-1.3264e-03, -2.4378e-03, -3.6511e-04,  2.7939e-03, -2.3703e-04],\n",
            "          [ 6.8494e-05, -7.2429e-04,  1.8575e-04,  4.4197e-03,  3.8532e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0292]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0135]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0292,  0.0135], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 1, 4] = -0.029224473983049393\n",
            " somado na saída em [1, 1, 1, 4] = 0.013533101417124271\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 5\n",
            " alvo do kernel em x: x[1,0,3:8, 15:20]\n",
            " \n",
            " tensor([[0.2613, 0.6533, 0.6201, 0.1450, 0.6851],\n",
            "        [0.4664, 0.2201, 0.2724, 0.9321, 0.0059],\n",
            "        [0.6273, 0.8730, 0.2411, 0.8774, 0.3191],\n",
            "        [0.2949, 0.3005, 0.0797, 0.3272, 0.9915],\n",
            "        [0.4960, 0.0630, 0.0903, 0.8380, 0.6932]])\n",
            " produto: tensor([[[[-1.0654e-03,  2.1640e-04, -3.0797e-03,  5.4698e-04, -5.8375e-03],\n",
            "          [ 3.4192e-03, -1.5997e-03, -2.1655e-03, -5.8901e-03,  2.6864e-05],\n",
            "          [-2.3177e-03,  3.2669e-03, -2.0461e-03, -5.3235e-03, -1.1716e-03],\n",
            "          [-5.7954e-04, -2.2925e-03,  5.2156e-04, -7.7156e-04,  3.1826e-03],\n",
            "          [ 3.5077e-03,  1.1740e-04,  2.4696e-04,  8.0891e-03, -3.1266e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 8.2756e-04, -2.9066e-03,  4.4315e-03,  1.1584e-03, -6.3166e-03],\n",
            "          [ 3.9817e-03,  1.0509e-03,  1.1869e-03,  3.8374e-03,  4.9309e-05],\n",
            "          [-8.2824e-04, -7.3830e-03, -6.9176e-04, -6.1795e-03,  2.1093e-04],\n",
            "          [-5.5060e-04, -1.6119e-03, -7.2421e-05,  3.0996e-03, -7.8205e-04],\n",
            "          [ 1.5749e-04, -9.8275e-05,  1.4198e-04,  7.4669e-03,  4.2392e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0141]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0044]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0141,  0.0044], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 1, 5] = -0.014125471003353596\n",
            " somado na saída em [1, 1, 1, 5] = 0.004418895114213228\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 6\n",
            " alvo do kernel em x: x[1,0,3:8, 18:23]\n",
            " \n",
            " tensor([[0.1450, 0.6851, 0.4116, 0.3604, 0.0342],\n",
            "        [0.9321, 0.0059, 0.9561, 0.7033, 0.8461],\n",
            "        [0.8774, 0.3191, 0.4302, 0.9388, 0.3377],\n",
            "        [0.3272, 0.9915, 0.4731, 0.1782, 0.8269],\n",
            "        [0.8380, 0.6932, 0.2226, 0.9734, 0.1444]])\n",
            " produto: tensor([[[[-5.9145e-04,  2.2694e-04, -2.0445e-03,  1.3590e-03, -2.9159e-04],\n",
            "          [ 6.8331e-03, -4.3113e-05, -7.6014e-03, -4.4443e-03,  3.8318e-03],\n",
            "          [-3.2420e-03,  1.1940e-03, -3.6516e-03, -5.6956e-03, -1.2400e-03],\n",
            "          [-6.4295e-04, -7.5637e-03,  3.0981e-03, -4.2033e-04,  2.6542e-03],\n",
            "          [ 5.9260e-03,  1.2916e-03,  6.0873e-04,  9.3960e-03, -6.5138e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 4.5943e-04, -3.0482e-03,  2.9418e-03,  2.8781e-03, -3.1552e-04],\n",
            "          [ 7.9572e-03,  2.8324e-05,  4.1664e-03,  2.8954e-03,  7.0333e-03],\n",
            "          [-1.1585e-03, -2.6984e-03, -1.2346e-03, -6.6114e-03,  2.2325e-04],\n",
            "          [-6.1085e-04, -5.3182e-03, -4.3019e-04,  1.6886e-03, -6.5222e-04],\n",
            "          [ 2.6607e-04, -1.0812e-03,  3.4996e-04,  8.6733e-03,  8.8316e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0017]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0173]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0017,  0.0173], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 1, 6] = -0.0017044907435774803\n",
            " somado na saída em [1, 1, 1, 6] = 0.017284996807575226\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 7\n",
            " alvo do kernel em x: x[1,0,3:8, 21:26]\n",
            " \n",
            " tensor([[0.3604, 0.0342, 0.9727, 0.8177, 0.0794],\n",
            "        [0.7033, 0.8461, 0.1233, 0.0291, 0.8610],\n",
            "        [0.9388, 0.3377, 0.2943, 0.1059, 0.7284],\n",
            "        [0.1782, 0.8269, 0.7198, 0.0577, 0.5868],\n",
            "        [0.9734, 0.1444, 0.9207, 0.5316, 0.1786]])\n",
            " produto: tensor([[[[-1.4695e-03,  1.1336e-05, -4.8308e-03,  3.0835e-03, -6.7657e-04],\n",
            "          [ 5.1557e-03, -6.1495e-03, -9.8028e-04, -1.8392e-04,  3.8993e-03],\n",
            "          [-3.4686e-03,  1.2638e-03, -2.4979e-03, -6.4276e-04, -2.6746e-03],\n",
            "          [-3.5026e-04, -6.3081e-03,  4.7130e-03, -1.3613e-04,  1.8835e-03],\n",
            "          [ 6.8835e-03,  2.6908e-04,  2.5178e-03,  5.1316e-03, -8.0563e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1415e-03, -1.5226e-04,  6.9511e-03,  6.5302e-03, -7.3209e-04],\n",
            "          [ 6.0040e-03,  4.0401e-03,  5.3730e-04,  1.1982e-04,  7.1572e-03],\n",
            "          [-1.2395e-03, -2.8560e-03, -8.4453e-04, -7.4611e-04,  4.8154e-04],\n",
            "          [-3.3278e-04, -4.4353e-03, -6.5443e-04,  5.4688e-04, -4.6284e-04],\n",
            "          [ 3.0906e-04, -2.2525e-04,  1.4475e-03,  4.7369e-03,  1.0923e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[0.0036]]],\n",
            "\n",
            "\n",
            "        [[[0.0284]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([0.0036, 0.0284], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 1, 7] = 0.0036375513300299644\n",
            " somado na saída em [1, 1, 1, 7] = 0.028414243832230568\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 0\n",
            " alvo do kernel em x: x[1,0,6:11, 0:5]\n",
            " \n",
            " tensor([[0.8083, 0.5978, 0.4485, 0.0850, 0.3619],\n",
            "        [0.8911, 0.6452, 0.7377, 0.7835, 0.0581],\n",
            "        [0.0490, 0.1895, 0.9780, 0.9538, 0.7730],\n",
            "        [0.0543, 0.0931, 0.8857, 0.5984, 0.1778],\n",
            "        [0.9955, 0.6835, 0.7345, 0.5007, 0.9572]])\n",
            " produto: tensor([[[[-3.2961e-03,  1.9803e-04, -2.2277e-03,  3.2064e-04, -3.0836e-03],\n",
            "          [ 6.5318e-03, -4.6898e-03, -5.8648e-03, -4.9507e-03,  2.6310e-04],\n",
            "          [-1.8088e-04,  7.0909e-04, -8.3010e-03, -5.7867e-03, -2.8384e-03],\n",
            "          [-1.0680e-04, -7.1041e-04,  5.7994e-03, -1.4112e-03,  5.7076e-04],\n",
            "          [ 7.0396e-03,  1.2734e-03,  2.0086e-03,  4.8331e-03, -4.3172e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.5604e-03, -2.6599e-03,  3.2055e-03,  6.7905e-04, -3.3366e-03],\n",
            "          [ 7.6064e-03,  3.0810e-03,  3.2145e-03,  3.2254e-03,  4.8292e-04],\n",
            "          [-6.4637e-05, -1.6025e-03, -2.8065e-03, -6.7172e-03,  5.1102e-04],\n",
            "          [-1.0147e-04, -4.9951e-04, -8.0528e-04,  5.6692e-03, -1.4025e-04],\n",
            "          [ 3.1607e-04, -1.0660e-03,  1.1548e-03,  4.4613e-03,  5.8534e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0182]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0222]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0182,  0.0222], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 2, 0] = -0.018217770382761955\n",
            " somado na saída em [1, 1, 2, 0] = 0.02222122810781002\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 1\n",
            " alvo do kernel em x: x[1,0,6:11, 3:8]\n",
            " \n",
            " tensor([[0.0850, 0.3619, 0.8273, 0.1917, 0.0610],\n",
            "        [0.7835, 0.0581, 0.6306, 0.3292, 0.7840],\n",
            "        [0.9538, 0.7730, 0.4475, 0.9718, 0.5142],\n",
            "        [0.5984, 0.1778, 0.7476, 0.0821, 0.0014],\n",
            "        [0.5007, 0.9572, 0.8816, 0.7116, 0.7944]])\n",
            " produto: tensor([[[[-3.4671e-04,  1.1988e-04, -4.1088e-03,  7.2276e-04, -5.1960e-04],\n",
            "          [ 5.7432e-03, -4.2224e-04, -5.0134e-03, -2.0799e-03,  3.5505e-03],\n",
            "          [-3.5241e-03,  2.8928e-03, -3.7983e-03, -5.8960e-03, -1.8881e-03],\n",
            "          [-1.1760e-03, -1.3565e-03,  4.8952e-03, -1.9351e-04,  4.5284e-06],\n",
            "          [ 3.5407e-03,  1.7834e-03,  2.4106e-03,  6.8684e-03, -3.5828e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.6931e-04, -1.6102e-03,  5.9122e-03,  1.5307e-03, -5.6223e-04],\n",
            "          [ 6.6881e-03,  2.7740e-04,  2.7479e-03,  1.3551e-03,  6.5170e-03],\n",
            "          [-1.2594e-03, -6.5375e-03, -1.2842e-03, -6.8440e-03,  3.3994e-04],\n",
            "          [-1.1172e-03, -9.5377e-04, -6.7973e-04,  7.7737e-04, -1.1128e-06],\n",
            "          [ 1.5897e-04, -1.4929e-03,  1.3859e-03,  6.3401e-03,  4.8577e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0014]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0168]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0014,  0.0168], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 2, 1] = -0.0013741387519985437\n",
            " somado na saída em [1, 1, 2, 1] = 0.016815369948744774\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 2\n",
            " alvo do kernel em x: x[1,0,6:11, 6:11]\n",
            " \n",
            " tensor([[0.1917, 0.0610, 0.2301, 0.4493, 0.3979],\n",
            "        [0.3292, 0.7840, 0.1429, 0.8907, 0.0188],\n",
            "        [0.9718, 0.5142, 0.1482, 0.7326, 0.0956],\n",
            "        [0.0821, 0.0014, 0.1120, 0.3570, 0.3751],\n",
            "        [0.7116, 0.7944, 0.4835, 0.8367, 0.9943]])\n",
            " produto: tensor([[[[-7.8153e-04,  2.0200e-05, -1.1430e-03,  1.6942e-03, -3.3905e-03],\n",
            "          [ 2.4129e-03, -5.6981e-03, -1.1360e-03, -5.6282e-03,  8.5220e-05],\n",
            "          [-3.5906e-03,  1.9243e-03, -1.2580e-03, -4.4446e-03, -3.5084e-04],\n",
            "          [-1.6125e-04, -1.0762e-05,  7.3365e-04, -8.4192e-04,  1.2041e-03],\n",
            "          [ 5.0317e-03,  1.4800e-03,  1.3221e-03,  8.0766e-03, -4.4843e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 6.0707e-04, -2.7132e-04,  1.6446e-03,  3.5880e-03, -3.6687e-03],\n",
            "          [ 2.8098e-03,  3.7435e-03,  6.2267e-04,  3.6668e-03,  1.5642e-04],\n",
            "          [-1.2831e-03, -4.3488e-03, -4.2531e-04, -5.1592e-03,  6.3166e-05],\n",
            "          [-1.5320e-04, -7.5672e-06, -1.0187e-04,  3.3822e-03, -2.9587e-04],\n",
            "          [ 2.2592e-04, -1.2390e-03,  7.6010e-04,  7.4554e-03,  6.0800e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0089]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0179]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0089,  0.0179], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 2, 2] = -0.0089346244931221\n",
            " somado na saída em [1, 1, 2, 2] = 0.01785171777009964\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 3\n",
            " alvo do kernel em x: x[1,0,6:11, 9:14]\n",
            " \n",
            " tensor([[0.4493, 0.3979, 0.0605, 0.7104, 0.4545],\n",
            "        [0.8907, 0.0188, 0.5050, 0.2157, 0.4644],\n",
            "        [0.7326, 0.0956, 0.6667, 0.9171, 0.4519],\n",
            "        [0.3570, 0.3751, 0.6018, 0.5859, 0.1199],\n",
            "        [0.8367, 0.9943, 0.5707, 0.9222, 0.2935]])\n",
            " produto: tensor([[[[-1.8320e-03,  1.3181e-04, -3.0054e-04,  2.6790e-03, -3.8724e-03],\n",
            "          [ 6.5292e-03, -1.3677e-04, -4.0153e-03, -1.3632e-03,  2.1033e-03],\n",
            "          [-2.7068e-03,  3.5757e-04, -5.6583e-03, -5.5643e-03, -1.6591e-03],\n",
            "          [-7.0158e-04, -2.8616e-03,  3.9404e-03, -1.3818e-03,  3.8475e-04],\n",
            "          [ 5.9169e-03,  1.8524e-03,  1.5605e-03,  8.9021e-03, -1.3239e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4230e-03, -1.7704e-03,  4.3245e-04,  5.6736e-03, -4.1902e-03],\n",
            "          [ 7.6034e-03,  8.9853e-05,  2.2008e-03,  8.8810e-04,  3.8606e-03],\n",
            "          [-9.6727e-04, -8.0808e-04, -1.9130e-03, -6.4590e-03,  2.9871e-04],\n",
            "          [-6.6655e-04, -2.0121e-03, -5.4714e-04,  5.5512e-03, -9.4544e-05],\n",
            "          [ 2.6566e-04, -1.5507e-03,  8.9712e-04,  8.2174e-03,  1.7949e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[0.0010]]],\n",
            "\n",
            "\n",
            "        [[[0.0182]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([0.0010, 0.0182], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 2, 3] = 0.000980250770226121\n",
            " somado na saída em [1, 1, 2, 3] = 0.018217837437987328\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 4\n",
            " alvo do kernel em x: x[1,0,6:11, 12:17]\n",
            " \n",
            " tensor([[0.7104, 0.4545, 0.4016, 0.2949, 0.3005],\n",
            "        [0.2157, 0.4644, 0.1182, 0.4960, 0.0630],\n",
            "        [0.9171, 0.4519, 0.2407, 0.0766, 0.2844],\n",
            "        [0.5859, 0.1199, 0.5156, 0.9173, 0.1331],\n",
            "        [0.9222, 0.2935, 0.1966, 0.1831, 0.0840]])\n",
            " produto: tensor([[[[-0.0029,  0.0002, -0.0020,  0.0011, -0.0026],\n",
            "          [ 0.0016, -0.0034, -0.0009, -0.0031,  0.0003],\n",
            "          [-0.0034,  0.0017, -0.0020, -0.0005, -0.0010],\n",
            "          [-0.0012, -0.0009,  0.0034, -0.0022,  0.0004],\n",
            "          [ 0.0065,  0.0005,  0.0005,  0.0018, -0.0004]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0023, -0.0020,  0.0029,  0.0024, -0.0028],\n",
            "          [ 0.0018,  0.0022,  0.0005,  0.0020,  0.0005],\n",
            "          [-0.0012, -0.0038, -0.0007, -0.0005,  0.0002],\n",
            "          [-0.0011, -0.0006, -0.0005,  0.0087, -0.0001],\n",
            "          [ 0.0003, -0.0005,  0.0003,  0.0016,  0.0005]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0085]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0124]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0085,  0.0124], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 2, 4] = -0.008452566340565681\n",
            " somado na saída em [1, 1, 2, 4] = 0.01241724006831646\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 5\n",
            " alvo do kernel em x: x[1,0,6:11, 15:20]\n",
            " \n",
            " tensor([[0.2949, 0.3005, 0.0797, 0.3272, 0.9915],\n",
            "        [0.4960, 0.0630, 0.0903, 0.8380, 0.6932],\n",
            "        [0.0766, 0.2844, 0.0841, 0.5745, 0.5544],\n",
            "        [0.9173, 0.1331, 0.3147, 0.3702, 0.5951],\n",
            "        [0.1831, 0.0840, 0.3535, 0.5999, 0.0537]])\n",
            " produto: tensor([[[[-1.2025e-03,  9.9542e-05, -3.9560e-04,  1.2338e-03, -8.4481e-03],\n",
            "          [ 3.6361e-03, -4.5800e-04, -7.1803e-04, -5.2953e-03,  3.1397e-03],\n",
            "          [-2.8315e-04,  1.0643e-03, -7.1392e-04, -3.4856e-03, -2.0357e-03],\n",
            "          [-1.8026e-03, -1.0155e-03,  2.0603e-03, -8.7301e-04,  1.9101e-03],\n",
            "          [ 1.2951e-03,  1.5659e-04,  9.6660e-04,  5.7902e-03, -2.4208e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 9.3410e-04, -1.3370e-03,  5.6923e-04,  2.6129e-03, -9.1413e-03],\n",
            "          [ 4.2344e-03,  3.0090e-04,  3.9356e-04,  3.4499e-03,  5.7630e-03],\n",
            "          [-1.0118e-04, -2.4053e-03, -2.4137e-04, -4.0461e-03,  3.6652e-04],\n",
            "          [-1.7126e-03, -7.1404e-04, -2.8609e-04,  3.5071e-03, -4.6936e-04],\n",
            "          [ 5.8147e-05, -1.3108e-04,  5.5570e-04,  5.3448e-03,  3.2822e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0056]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0078]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0056,  0.0078], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 2, 5] = -0.005617011338472366\n",
            " somado na saída em [1, 1, 2, 5] = 0.007833096198737621\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 6\n",
            " alvo do kernel em x: x[1,0,6:11, 18:23]\n",
            " \n",
            " tensor([[0.3272, 0.9915, 0.4731, 0.1782, 0.8269],\n",
            "        [0.8380, 0.6932, 0.2226, 0.9734, 0.1444],\n",
            "        [0.5745, 0.5544, 0.5024, 0.1933, 0.7889],\n",
            "        [0.3702, 0.5951, 0.7624, 0.6166, 0.3215],\n",
            "        [0.5999, 0.0537, 0.3590, 0.9260, 0.2168]])\n",
            " produto: tensor([[[[-1.3341e-03,  3.2843e-04, -2.3499e-03,  6.7214e-04, -7.0456e-03],\n",
            "          [ 6.1431e-03, -5.0388e-03, -1.7698e-03, -6.1509e-03,  6.5410e-04],\n",
            "          [-2.1227e-03,  2.0748e-03, -4.2641e-03, -1.1727e-03, -2.8967e-03],\n",
            "          [-7.2748e-04, -4.5395e-03,  4.9923e-03, -1.4542e-03,  1.0319e-03],\n",
            "          [ 4.2418e-03,  9.9999e-05,  9.8174e-04,  8.9378e-03, -9.7759e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0363e-03, -4.4113e-03,  3.3813e-03,  1.4235e-03, -7.6237e-03],\n",
            "          [ 7.1537e-03,  3.3104e-03,  9.7006e-04,  4.0073e-03,  1.2006e-03],\n",
            "          [-7.5857e-04, -4.6888e-03, -1.4416e-03, -1.3612e-03,  5.2152e-04],\n",
            "          [-6.9116e-04, -3.1918e-03, -6.9321e-04,  5.8419e-03, -2.5357e-04],\n",
            "          [ 1.9045e-04, -8.3711e-05,  5.6441e-04,  8.2504e-03,  1.3254e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0117]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0140]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0117,  0.0140], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 2, 6] = -0.011685958132147789\n",
            " somado na saída em [1, 1, 2, 6] = 0.013978514820337296\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 7\n",
            " alvo do kernel em x: x[1,0,6:11, 21:26]\n",
            " \n",
            " tensor([[0.1782, 0.8269, 0.7198, 0.0577, 0.5868],\n",
            "        [0.9734, 0.1444, 0.9207, 0.5316, 0.1786],\n",
            "        [0.1933, 0.7889, 0.8733, 0.4732, 0.9406],\n",
            "        [0.6166, 0.3215, 0.4485, 0.0842, 0.8173],\n",
            "        [0.9260, 0.2168, 0.0323, 0.3477, 0.1220]])\n",
            " produto: tensor([[[[-7.2679e-04,  2.7391e-04, -3.5748e-03,  2.1769e-04, -4.9998e-03],\n",
            "          [ 7.1356e-03, -1.0498e-03, -7.3203e-03, -3.3593e-03,  8.0899e-04],\n",
            "          [-7.1414e-04,  2.9522e-03, -7.4121e-03, -2.8713e-03, -3.4536e-03],\n",
            "          [-1.2118e-03, -2.4525e-03,  2.9370e-03, -1.9853e-04,  2.6236e-03],\n",
            "          [ 6.5478e-03,  4.0383e-04,  8.8321e-05,  3.3563e-03, -5.5035e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 5.6456e-04, -3.6790e-03,  5.1439e-03,  4.6102e-04, -5.4101e-03],\n",
            "          [ 8.3096e-03,  6.8966e-04,  4.0123e-03,  2.1886e-03,  1.4849e-03],\n",
            "          [-2.5520e-04, -6.6718e-03, -2.5060e-03, -3.3329e-03,  6.2179e-04],\n",
            "          [-1.1513e-03, -1.7244e-03, -4.0783e-04,  7.9757e-04, -6.4468e-04],\n",
            "          [ 2.9399e-04, -3.3805e-04,  5.0776e-05,  3.0981e-03,  7.4618e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0125]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0023]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0125,  0.0023], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 2, 7] = -0.01254967413842678\n",
            " somado na saída em [1, 1, 2, 7] = 0.0023417139891535044\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 0\n",
            " alvo do kernel em x: x[1,0,9:14, 0:5]\n",
            " \n",
            " tensor([[0.0543, 0.0931, 0.8857, 0.5984, 0.1778],\n",
            "        [0.9955, 0.6835, 0.7345, 0.5007, 0.9572],\n",
            "        [0.8899, 0.1866, 0.0452, 0.0504, 0.2624],\n",
            "        [0.7403, 0.1069, 0.3195, 0.9671, 0.8857],\n",
            "        [0.8090, 0.7196, 0.7402, 0.2883, 0.1608]])\n",
            " produto: tensor([[[[-2.2161e-04,  3.0847e-05, -4.3988e-03,  2.2566e-03, -1.5151e-03],\n",
            "          [ 7.2974e-03, -4.9680e-03, -5.8400e-03, -3.1639e-03,  4.3353e-03],\n",
            "          [-3.2879e-03,  6.9831e-04, -3.8333e-04, -3.0572e-04, -9.6334e-04],\n",
            "          [-1.4548e-03, -8.1548e-04,  2.0919e-03, -2.2807e-03,  2.8430e-03],\n",
            "          [ 5.7208e-03,  1.3406e-03,  2.0240e-03,  2.7827e-03, -7.2530e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7215e-04, -4.1433e-04,  6.3295e-03,  4.7791e-03, -1.6394e-03],\n",
            "          [ 8.4980e-03,  3.2638e-03,  3.2009e-03,  2.0613e-03,  7.9575e-03],\n",
            "          [-1.1750e-03, -1.5781e-03, -1.2960e-04, -3.5488e-04,  1.7344e-04],\n",
            "          [-1.3822e-03, -5.7338e-04, -2.9047e-04,  9.1622e-03, -6.9860e-04],\n",
            "          [ 2.5686e-04, -1.1223e-03,  1.1636e-03,  2.5687e-03,  9.8338e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[0.0011]]],\n",
            "\n",
            "\n",
            "        [[[0.0412]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([0.0011, 0.0412], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 3, 0] = 0.0010975119657814503\n",
            " somado na saída em [1, 1, 3, 0] = 0.04121217876672745\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 1\n",
            " alvo do kernel em x: x[1,0,9:14, 3:8]\n",
            " \n",
            " tensor([[0.5984, 0.1778, 0.7476, 0.0821, 0.0014],\n",
            "        [0.5007, 0.9572, 0.8816, 0.7116, 0.7944],\n",
            "        [0.0504, 0.2624, 0.7089, 0.4949, 0.3803],\n",
            "        [0.9671, 0.8857, 0.0358, 0.1863, 0.4983],\n",
            "        [0.2883, 0.1608, 0.4279, 0.1649, 0.0478]])\n",
            " produto: tensor([[[[-2.4401e-03,  5.8900e-05, -3.7130e-03,  3.0943e-04, -1.2021e-05],\n",
            "          [ 3.6704e-03, -6.9576e-03, -7.0087e-03, -4.4962e-03,  3.5978e-03],\n",
            "          [-1.8618e-04,  9.8181e-04, -6.0163e-03, -3.0024e-03, -1.3963e-03],\n",
            "          [-1.9005e-03, -6.7567e-03,  2.3463e-04, -4.3940e-04,  1.5993e-03],\n",
            "          [ 2.0386e-03,  2.9961e-04,  1.1702e-03,  1.5913e-03, -2.1554e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8954e-03, -7.9113e-04,  5.3427e-03,  6.5532e-04, -1.3007e-05],\n",
            "          [ 4.2742e-03,  4.5709e-03,  3.8415e-03,  2.9293e-03,  6.6039e-03],\n",
            "          [-6.6534e-05, -2.2188e-03, -2.0341e-03, -3.4852e-03,  2.5138e-04],\n",
            "          [-1.8056e-03, -4.7508e-03, -3.2580e-05,  1.7652e-03, -3.9300e-04],\n",
            "          [ 9.1531e-05, -2.5081e-04,  6.7275e-04,  1.4689e-03,  2.9223e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0290]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0188]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0290,  0.0188], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 3, 1] = -0.02898908033967018\n",
            " somado na saída em [1, 1, 3, 1] = 0.01881382241845131\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 2\n",
            " alvo do kernel em x: x[1,0,9:14, 6:11]\n",
            " \n",
            " tensor([[0.0821, 0.0014, 0.1120, 0.3570, 0.3751],\n",
            "        [0.7116, 0.7944, 0.4835, 0.8367, 0.9943],\n",
            "        [0.4949, 0.3803, 0.7096, 0.7709, 0.2780],\n",
            "        [0.1863, 0.4983, 0.7049, 0.6953, 0.9844],\n",
            "        [0.1649, 0.0478, 0.8602, 0.6275, 0.7910]])\n",
            " produto: tensor([[[[-3.3459e-04,  4.6732e-07, -5.5647e-04,  1.3463e-03, -3.1962e-03],\n",
            "          [ 5.2160e-03, -5.7741e-03, -3.8440e-03, -5.2872e-03,  4.5031e-03],\n",
            "          [-1.8285e-03,  1.4230e-03, -6.0228e-03, -4.6771e-03, -1.0209e-03],\n",
            "          [-3.6615e-04, -3.8010e-03,  4.6156e-03, -1.6398e-03,  3.1599e-03],\n",
            "          [ 1.1658e-03,  8.9036e-05,  2.3523e-03,  6.0567e-03, -3.5674e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.5990e-04, -6.2768e-06,  8.0071e-04,  2.8512e-03, -3.4585e-03],\n",
            "          [ 6.0742e-03,  3.7934e-03,  2.1069e-03,  3.4446e-03,  8.2655e-03],\n",
            "          [-6.5341e-04, -3.2159e-03, -2.0363e-03, -5.4291e-03,  1.8380e-04],\n",
            "          [-3.4787e-04, -2.6726e-03, -6.4090e-04,  6.5875e-03, -7.7648e-04],\n",
            "          [ 5.2342e-05, -7.4533e-05,  1.3523e-03,  5.5909e-03,  4.8368e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0120]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0269]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0120,  0.0269], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 3, 2] = -0.011987969279289246\n",
            " somado na saída em [1, 1, 3, 2] = 0.02688828855752945\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 3\n",
            " alvo do kernel em x: x[1,0,9:14, 9:14]\n",
            " \n",
            " tensor([[0.3570, 0.3751, 0.6018, 0.5859, 0.1199],\n",
            "        [0.8367, 0.9943, 0.5707, 0.9222, 0.2935],\n",
            "        [0.7709, 0.2780, 0.2285, 0.9187, 0.6591],\n",
            "        [0.6953, 0.9844, 0.9275, 0.5155, 0.5938],\n",
            "        [0.6275, 0.7910, 0.7004, 0.4859, 0.4073]])\n",
            " produto: tensor([[[[-0.0015,  0.0001, -0.0030,  0.0022, -0.0010],\n",
            "          [ 0.0061, -0.0072, -0.0045, -0.0058,  0.0013],\n",
            "          [-0.0028,  0.0010, -0.0019, -0.0056, -0.0024],\n",
            "          [-0.0014, -0.0075,  0.0061, -0.0012,  0.0019],\n",
            "          [ 0.0044,  0.0015,  0.0019,  0.0047, -0.0018]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0011, -0.0017,  0.0043,  0.0047, -0.0011],\n",
            "          [ 0.0071,  0.0047,  0.0025,  0.0038,  0.0024],\n",
            "          [-0.0010, -0.0024, -0.0007, -0.0065,  0.0004],\n",
            "          [-0.0013, -0.0053, -0.0008,  0.0049, -0.0005],\n",
            "          [ 0.0002, -0.0012,  0.0011,  0.0043,  0.0025]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0164]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0218]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0164,  0.0218], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 3, 3] = -0.016435308381915092\n",
            " somado na saída em [1, 1, 3, 3] = 0.021771693602204323\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 4\n",
            " alvo do kernel em x: x[1,0,9:14, 12:17]\n",
            " \n",
            " tensor([[0.5859, 0.1199, 0.5156, 0.9173, 0.1331],\n",
            "        [0.9222, 0.2935, 0.1966, 0.1831, 0.0840],\n",
            "        [0.9187, 0.6591, 0.3121, 0.5830, 0.5593],\n",
            "        [0.5155, 0.5938, 0.2634, 0.9215, 0.2312],\n",
            "        [0.4859, 0.4073, 0.2924, 0.8439, 0.3926]])\n",
            " produto: tensor([[[[-2.3893e-03,  3.9705e-05, -2.5606e-03,  3.4592e-03, -1.1343e-03],\n",
            "          [ 6.7605e-03, -2.1335e-03, -1.5631e-03, -1.1572e-03,  3.8065e-04],\n",
            "          [-3.3945e-03,  2.4664e-03, -2.6485e-03, -3.5373e-03, -2.0537e-03],\n",
            "          [-1.0131e-03, -4.5300e-03,  1.7248e-03, -2.1733e-03,  7.4201e-04],\n",
            "          [ 3.4358e-03,  7.5873e-04,  7.9949e-04,  8.1458e-03, -1.7706e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8560e-03, -5.3330e-04,  3.6845e-03,  7.3259e-03, -1.2273e-03],\n",
            "          [ 7.8727e-03,  1.4017e-03,  8.5676e-04,  7.5394e-04,  6.9870e-04],\n",
            "          [-1.2130e-03, -5.5739e-03, -8.9544e-04, -4.1060e-03,  3.6974e-04],\n",
            "          [-9.6248e-04, -3.1851e-03, -2.3950e-04,  8.7307e-03, -1.8233e-04],\n",
            "          [ 1.5426e-04, -6.3515e-04,  4.5963e-04,  7.5192e-03,  2.4007e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0033]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0253]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0033,  0.0253], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 3, 4] = -0.003345996607095003\n",
            " somado na saída em [1, 1, 3, 4] = 0.02533077821135521\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 5\n",
            " alvo do kernel em x: x[1,0,9:14, 15:20]\n",
            " \n",
            " tensor([[0.9173, 0.1331, 0.3147, 0.3702, 0.5951],\n",
            "        [0.1831, 0.0840, 0.3535, 0.5999, 0.0537],\n",
            "        [0.5830, 0.5593, 0.0834, 0.3137, 0.0137],\n",
            "        [0.9215, 0.2312, 0.1405, 0.7415, 0.5427],\n",
            "        [0.8439, 0.3926, 0.9697, 0.4874, 0.8111]])\n",
            " produto: tensor([[[[-3.7404e-03,  4.4096e-05, -1.5628e-03,  1.3960e-03, -5.0702e-03],\n",
            "          [ 1.3425e-03, -6.1090e-04, -2.8103e-03, -3.7904e-03,  2.4309e-04],\n",
            "          [-2.1542e-03,  2.0930e-03, -7.0765e-04, -1.9031e-03, -5.0452e-05],\n",
            "          [-1.8110e-03, -1.7635e-03,  9.2008e-04, -1.7486e-03,  1.7419e-03],\n",
            "          [ 5.9676e-03,  7.3143e-04,  2.6515e-03,  4.7051e-03, -3.6579e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.9055e-03, -5.9227e-04,  2.2487e-03,  2.9565e-03, -5.4863e-03],\n",
            "          [ 1.5634e-03,  4.0134e-04,  1.5404e-03,  2.4695e-03,  4.4620e-04],\n",
            "          [-7.6981e-04, -4.7301e-03, -2.3925e-04, -2.2091e-03,  9.0835e-06],\n",
            "          [-1.7206e-03, -1.2399e-03, -1.2776e-04,  7.0246e-03, -4.2804e-04],\n",
            "          [ 2.6794e-04, -6.1229e-04,  1.5244e-03,  4.3432e-03,  4.9595e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0095]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0145]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0095,  0.0145], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 3, 5] = -0.00954516977071762\n",
            " somado na saída em [1, 1, 3, 5] = 0.01450468972325325\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 6\n",
            " alvo do kernel em x: x[1,0,9:14, 18:23]\n",
            " \n",
            " tensor([[0.3702, 0.5951, 0.7624, 0.6166, 0.3215],\n",
            "        [0.5999, 0.0537, 0.3590, 0.9260, 0.2168],\n",
            "        [0.3137, 0.0137, 0.9245, 0.4738, 0.7452],\n",
            "        [0.7415, 0.5427, 0.3163, 0.0950, 0.0805],\n",
            "        [0.4874, 0.8111, 0.5170, 0.9016, 0.7601]])\n",
            " produto: tensor([[[[-1.5095e-03,  1.9711e-04, -3.7866e-03,  2.3253e-03, -2.7392e-03],\n",
            "          [ 4.3972e-03, -3.9013e-04, -2.8544e-03, -5.8510e-03,  9.8168e-04],\n",
            "          [-1.1590e-03,  5.1419e-05, -7.8462e-03, -2.8749e-03, -2.7361e-03],\n",
            "          [-1.4571e-03, -4.1399e-03,  2.0709e-03, -2.2407e-04,  2.5842e-04],\n",
            "          [ 3.4469e-03,  1.5110e-03,  1.4136e-03,  8.7032e-03, -3.4282e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1726e-03, -2.6475e-03,  5.4487e-03,  4.9247e-03, -2.9640e-03],\n",
            "          [ 5.1206e-03,  2.5630e-04,  1.5645e-03,  3.8119e-03,  1.8019e-03],\n",
            "          [-4.1417e-04, -1.1620e-04, -2.6527e-03, -3.3371e-03,  4.9260e-04],\n",
            "          [-1.3844e-03, -2.9109e-03, -2.8756e-04,  9.0017e-04, -6.3502e-05],\n",
            "          [ 1.5476e-04, -1.2649e-03,  8.1270e-04,  8.0338e-03,  4.6481e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0156]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0211]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0156,  0.0211], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 3, 6] = -0.015639370307326317\n",
            " somado na saída em [1, 1, 3, 6] = 0.021100282669067383\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 7\n",
            " alvo do kernel em x: x[1,0,9:14, 21:26]\n",
            " \n",
            " tensor([[0.6166, 0.3215, 0.4485, 0.0842, 0.8173],\n",
            "        [0.9260, 0.2168, 0.0323, 0.3477, 0.1220],\n",
            "        [0.4738, 0.7452, 0.9606, 0.8523, 0.0314],\n",
            "        [0.0950, 0.0805, 0.7483, 0.1298, 0.3677],\n",
            "        [0.9016, 0.7601, 0.1463, 0.2756, 0.2510]])\n",
            " produto: tensor([[[[-2.5144e-03,  1.0649e-04, -2.2277e-03,  3.1747e-04, -6.9642e-03],\n",
            "          [ 6.7876e-03, -1.5755e-03, -2.5679e-04, -2.1971e-03,  5.5265e-04],\n",
            "          [-1.7508e-03,  2.7885e-03, -8.1526e-03, -5.1710e-03, -1.1515e-04],\n",
            "          [-1.8672e-04, -6.1417e-04,  4.8999e-03, -3.0622e-04,  1.1804e-03],\n",
            "          [ 6.3759e-03,  1.4162e-03,  4.0000e-04,  2.6602e-03, -1.1323e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9531e-03, -1.4303e-03,  3.2055e-03,  6.7235e-04, -7.5357e-03],\n",
            "          [ 7.9044e-03,  1.0350e-03,  1.4075e-04,  1.4314e-03,  1.0144e-03],\n",
            "          [-6.2565e-04, -6.3018e-03, -2.7563e-03, -6.0024e-03,  2.0732e-05],\n",
            "          [-1.7740e-04, -4.3184e-04, -6.8038e-04,  1.2302e-03, -2.9006e-04],\n",
            "          [ 2.8627e-04, -1.1855e-03,  2.2996e-04,  2.4556e-03,  1.5352e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0057]]],\n",
            "\n",
            "\n",
            "        [[[-0.0043]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0057, -0.0043], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 3, 7] = -0.0056793102994561195\n",
            " somado na saída em [1, 1, 3, 7] = -0.004302452318370342\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 0\n",
            " alvo do kernel em x: x[1,0,12:17, 0:5]\n",
            " \n",
            " tensor([[0.7403, 0.1069, 0.3195, 0.9671, 0.8857],\n",
            "        [0.8090, 0.7196, 0.7402, 0.2883, 0.1608],\n",
            "        [0.4299, 0.0971, 0.8078, 0.3748, 0.4881],\n",
            "        [0.3620, 0.9749, 0.7914, 0.5122, 0.5378],\n",
            "        [0.0305, 0.7417, 0.8169, 0.9171, 0.2335]])\n",
            " produto: tensor([[[[-3.0188e-03,  3.5409e-05, -1.5867e-03,  3.6470e-03, -7.5467e-03],\n",
            "          [ 5.9303e-03, -5.2302e-03, -5.8845e-03, -1.8216e-03,  7.2833e-04],\n",
            "          [-1.5886e-03,  3.6354e-04, -6.8558e-03, -2.2742e-03, -1.7921e-03],\n",
            "          [-7.1148e-04, -7.4374e-03,  5.1823e-03, -1.2080e-03,  1.7262e-03],\n",
            "          [ 2.1582e-04,  1.3819e-03,  2.2338e-03,  8.8524e-03, -1.0530e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3449e-03, -4.7560e-04,  2.2831e-03,  7.7237e-03, -8.1659e-03],\n",
            "          [ 6.9060e-03,  3.4361e-03,  3.2253e-03,  1.1868e-03,  1.3369e-03],\n",
            "          [-5.6768e-04, -8.2157e-04, -2.3179e-03, -2.6399e-03,  3.2265e-04],\n",
            "          [-6.7595e-04, -5.2294e-03, -7.1959e-04,  4.8529e-03, -4.2417e-04],\n",
            "          [ 9.6900e-06, -1.1568e-03,  1.2842e-03,  8.1715e-03,  1.4277e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0177]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0213]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0177,  0.0213], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 4, 0] = -0.017712103202939034\n",
            " somado na saída em [1, 1, 4, 0] = 0.021317027509212494\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 1\n",
            " alvo do kernel em x: x[1,0,12:17, 3:8]\n",
            " \n",
            " tensor([[0.9671, 0.8857, 0.0358, 0.1863, 0.4983],\n",
            "        [0.2883, 0.1608, 0.4279, 0.1649, 0.0478],\n",
            "        [0.3748, 0.4881, 0.7625, 0.2814, 0.2053],\n",
            "        [0.5122, 0.5378, 0.0620, 0.3366, 0.5878],\n",
            "        [0.9171, 0.2335, 0.7274, 0.1365, 0.9368]])\n",
            " produto: tensor([[[[-3.9435e-03,  2.9339e-04, -1.7797e-04,  7.0263e-04, -4.2454e-03],\n",
            "          [ 2.1133e-03, -1.1689e-03, -3.4023e-03, -1.0417e-03,  2.1644e-04],\n",
            "          [-1.3850e-03,  1.8265e-03, -6.4718e-03, -1.7074e-03, -7.5391e-04],\n",
            "          [-1.0066e-03, -4.1024e-03,  4.0573e-04, -7.9380e-04,  1.8868e-03],\n",
            "          [ 6.4852e-03,  4.3497e-04,  1.9890e-03,  1.3172e-03, -4.2252e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 3.0632e-03, -3.9406e-03,  2.5608e-04,  1.4880e-03, -4.5938e-03],\n",
            "          [ 2.4609e-03,  7.6792e-04,  1.8648e-03,  6.7867e-04,  3.9728e-04],\n",
            "          [-4.9493e-04, -4.1277e-03, -2.1881e-03, -1.9819e-03,  1.3574e-04],\n",
            "          [-9.5638e-04, -2.8845e-03, -5.6337e-05,  3.1889e-03, -4.6363e-04],\n",
            "          [ 2.9118e-04, -3.6412e-04,  1.1435e-03,  1.2159e-03,  5.7286e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0168]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0006]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0168,  0.0006], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 4, 1] = -0.016754839569330215\n",
            " somado na saída em [1, 1, 4, 1] = 0.0006288744043558836\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 2\n",
            " alvo do kernel em x: x[1,0,12:17, 6:11]\n",
            " \n",
            " tensor([[0.1863, 0.4983, 0.7049, 0.6953, 0.9844],\n",
            "        [0.1649, 0.0478, 0.8602, 0.6275, 0.7910],\n",
            "        [0.2814, 0.2053, 0.0732, 0.1452, 0.6395],\n",
            "        [0.3366, 0.5878, 0.7652, 0.7493, 0.3024],\n",
            "        [0.1365, 0.9368, 0.8312, 0.7617, 0.9230]])\n",
            " produto: tensor([[[[-7.5976e-04,  1.6504e-04, -3.5009e-03,  2.6222e-03, -8.3880e-03],\n",
            "          [ 1.2085e-03, -3.4736e-04, -6.8392e-03, -3.9649e-03,  3.5823e-03],\n",
            "          [-1.0398e-03,  7.6836e-04, -6.2090e-04, -8.8076e-04, -2.3482e-03],\n",
            "          [-6.6148e-04, -4.4841e-03,  5.0102e-03, -1.7671e-03,  9.7062e-04],\n",
            "          [ 9.6500e-04,  1.7454e-03,  2.2730e-03,  7.3520e-03, -4.1629e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 5.9016e-04, -2.2168e-03,  5.0375e-03,  5.5532e-03, -9.0763e-03],\n",
            "          [ 1.4073e-03,  2.2820e-04,  3.7486e-03,  2.5832e-03,  6.5754e-03],\n",
            "          [-3.7158e-04, -1.7365e-03, -2.0992e-04, -1.0224e-03,  4.2277e-04],\n",
            "          [-6.2846e-04, -3.1529e-03, -6.9570e-04,  7.0990e-03, -2.3851e-04],\n",
            "          [ 4.3327e-05, -1.4611e-03,  1.3068e-03,  6.7865e-03,  5.6442e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0131]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0262]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0131,  0.0262], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 4, 2] = -0.013102768920361996\n",
            " somado na saída em [1, 1, 4, 2] = 0.02621608041226864\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 3\n",
            " alvo do kernel em x: x[1,0,12:17, 9:14]\n",
            " \n",
            " tensor([[0.6953, 0.9844, 0.9275, 0.5155, 0.5938],\n",
            "        [0.6275, 0.7910, 0.7004, 0.4859, 0.4073],\n",
            "        [0.1452, 0.6395, 0.1206, 0.9641, 0.4060],\n",
            "        [0.7493, 0.3024, 0.5412, 0.5388, 0.9174],\n",
            "        [0.7617, 0.9230, 0.9100, 0.4673, 0.1622]])\n",
            " produto: tensor([[[[-0.0028,  0.0003, -0.0046,  0.0019, -0.0051],\n",
            "          [ 0.0046, -0.0057, -0.0056, -0.0031,  0.0018],\n",
            "          [-0.0005,  0.0024, -0.0010, -0.0058, -0.0015],\n",
            "          [-0.0015, -0.0023,  0.0035, -0.0013,  0.0029],\n",
            "          [ 0.0054,  0.0017,  0.0025,  0.0045, -0.0007]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0022, -0.0044,  0.0066,  0.0041, -0.0055],\n",
            "          [ 0.0054,  0.0038,  0.0031,  0.0020,  0.0034],\n",
            "          [-0.0002, -0.0054, -0.0003, -0.0068,  0.0003],\n",
            "          [-0.0014, -0.0016, -0.0005,  0.0051, -0.0007],\n",
            "          [ 0.0002, -0.0014,  0.0014,  0.0042,  0.0010]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0099]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0145]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0099,  0.0145], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 4, 3] = -0.00986973475664854\n",
            " somado na saída em [1, 1, 4, 3] = 0.014452775940299034\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 4\n",
            " alvo do kernel em x: x[1,0,12:17, 12:17]\n",
            " \n",
            " tensor([[0.5155, 0.5938, 0.2634, 0.9215, 0.2312],\n",
            "        [0.4859, 0.4073, 0.2924, 0.8439, 0.3926],\n",
            "        [0.9641, 0.4060, 0.6879, 0.7406, 0.2484],\n",
            "        [0.5388, 0.9174, 0.8488, 0.2040, 0.4640],\n",
            "        [0.4673, 0.1622, 0.8655, 0.0291, 0.1630]])\n",
            " produto: tensor([[[[-0.0021,  0.0002, -0.0013,  0.0035, -0.0020],\n",
            "          [ 0.0036, -0.0030, -0.0023, -0.0053,  0.0018],\n",
            "          [-0.0036,  0.0015, -0.0058, -0.0045, -0.0009],\n",
            "          [-0.0011, -0.0070,  0.0056, -0.0005,  0.0015],\n",
            "          [ 0.0033,  0.0003,  0.0024,  0.0003, -0.0007]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0016, -0.0026,  0.0019,  0.0074, -0.0021],\n",
            "          [ 0.0041,  0.0019,  0.0013,  0.0035,  0.0033],\n",
            "          [-0.0013, -0.0034, -0.0020, -0.0052,  0.0002],\n",
            "          [-0.0010, -0.0049, -0.0008,  0.0019, -0.0004],\n",
            "          [ 0.0001, -0.0003,  0.0014,  0.0003,  0.0010]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0162]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0059]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0162,  0.0059], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 4, 4] = -0.016244757920503616\n",
            " somado na saída em [1, 1, 4, 4] = 0.005854420363903046\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 5\n",
            " alvo do kernel em x: x[1,0,12:17, 15:20]\n",
            " \n",
            " tensor([[0.9215, 0.2312, 0.1405, 0.7415, 0.5427],\n",
            "        [0.8439, 0.3926, 0.9697, 0.4874, 0.8111],\n",
            "        [0.7406, 0.2484, 0.5340, 0.6439, 0.2444],\n",
            "        [0.2040, 0.4640, 0.2259, 0.1415, 0.7125],\n",
            "        [0.0291, 0.1630, 0.8203, 0.8683, 0.2357]])\n",
            " produto: tensor([[[[-3.7578e-03,  7.6572e-05, -6.9788e-04,  2.7962e-03, -4.6239e-03],\n",
            "          [ 6.1861e-03, -2.8535e-03, -7.7092e-03, -3.0801e-03,  3.6732e-03],\n",
            "          [-2.7365e-03,  9.2941e-04, -4.5319e-03, -3.9067e-03, -8.9755e-04],\n",
            "          [-4.0097e-04, -3.5393e-03,  1.4791e-03, -3.3380e-04,  2.2870e-03],\n",
            "          [ 2.0552e-04,  3.0369e-04,  2.2432e-03,  8.3815e-03, -1.0629e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.9190e-03, -1.0285e-03,  1.0042e-03,  5.9217e-03, -5.0034e-03],\n",
            "          [ 7.2039e-03,  1.8747e-03,  4.2254e-03,  2.0067e-03,  6.7423e-03],\n",
            "          [-9.7789e-04, -2.1004e-03, -1.5322e-03, -4.5348e-03,  1.6160e-04],\n",
            "          [-3.8095e-04, -2.4886e-03, -2.0538e-04,  1.3410e-03, -5.6198e-04],\n",
            "          [ 9.2279e-06, -2.5423e-04,  1.2896e-03,  7.7368e-03,  1.4411e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0116]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0248]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0116,  0.0248], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 4, 5] = -0.011570455506443977\n",
            " somado na saída em [1, 1, 4, 5] = 0.024808846414089203\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 6\n",
            " alvo do kernel em x: x[1,0,12:17, 18:23]\n",
            " \n",
            " tensor([[0.7415, 0.5427, 0.3163, 0.0950, 0.0805],\n",
            "        [0.4874, 0.8111, 0.5170, 0.9016, 0.7601],\n",
            "        [0.6439, 0.2444, 0.5577, 0.3309, 0.1778],\n",
            "        [0.1415, 0.7125, 0.9949, 0.8117, 0.3546],\n",
            "        [0.8683, 0.2357, 0.8573, 0.4013, 0.9959]])\n",
            " produto: tensor([[[[-0.0030,  0.0002, -0.0016,  0.0004, -0.0007],\n",
            "          [ 0.0036, -0.0059, -0.0041, -0.0057,  0.0034],\n",
            "          [-0.0024,  0.0009, -0.0047, -0.0020, -0.0007],\n",
            "          [-0.0003, -0.0054,  0.0065, -0.0019,  0.0011],\n",
            "          [ 0.0061,  0.0004,  0.0023,  0.0039, -0.0045]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0023, -0.0024,  0.0023,  0.0008, -0.0007],\n",
            "          [ 0.0042,  0.0039,  0.0023,  0.0037,  0.0063],\n",
            "          [-0.0009, -0.0021, -0.0016, -0.0023,  0.0001],\n",
            "          [-0.0003, -0.0038, -0.0009,  0.0077, -0.0003],\n",
            "          [ 0.0003, -0.0004,  0.0013,  0.0036,  0.0061]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0140]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0291]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0140,  0.0291], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 4, 6] = -0.013957085087895393\n",
            " somado na saída em [1, 1, 4, 6] = 0.0291387178003788\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 7\n",
            " alvo do kernel em x: x[1,0,12:17, 21:26]\n",
            " \n",
            " tensor([[0.0950, 0.0805, 0.7483, 0.1298, 0.3677],\n",
            "        [0.9016, 0.7601, 0.1463, 0.2756, 0.2510],\n",
            "        [0.3309, 0.1778, 0.3144, 0.4306, 0.2955],\n",
            "        [0.8117, 0.3546, 0.4030, 0.1072, 0.3857],\n",
            "        [0.4013, 0.9959, 0.0347, 0.8220, 0.0749]])\n",
            " produto: tensor([[[[-3.8745e-04,  2.6668e-05, -3.7166e-03,  4.8968e-04, -3.1334e-03],\n",
            "          [ 6.6094e-03, -5.5249e-03, -1.1630e-03, -1.7414e-03,  1.1370e-03],\n",
            "          [-1.2226e-03,  6.6551e-04, -2.6686e-03, -2.6126e-03, -1.0851e-03],\n",
            "          [-1.5952e-03, -2.7052e-03,  2.6390e-03, -2.5288e-04,  1.2381e-03],\n",
            "          [ 2.8375e-03,  1.8554e-03,  9.4810e-05,  7.9343e-03, -3.3780e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 3.0096e-04, -3.5820e-04,  5.3479e-03,  1.0370e-03, -3.3905e-03],\n",
            "          [ 7.6968e-03,  3.6297e-03,  6.3743e-04,  1.1345e-03,  2.0870e-03],\n",
            "          [-4.3690e-04, -1.5040e-03, -9.0222e-04, -3.0327e-03,  1.9537e-04],\n",
            "          [-1.5155e-03, -1.9021e-03, -3.6643e-04,  1.0159e-03, -3.0424e-04],\n",
            "          [ 1.2740e-04, -1.5532e-03,  5.4506e-05,  7.3240e-03,  4.5799e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0026]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0158]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0026,  0.0158], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 4, 7] = -0.0026192660443484783\n",
            " somado na saída em [1, 1, 4, 7] = 0.015780558809638023\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 0\n",
            " alvo do kernel em x: x[1,0,15:20, 0:5]\n",
            " \n",
            " tensor([[0.3620, 0.9749, 0.7914, 0.5122, 0.5378],\n",
            "        [0.0305, 0.7417, 0.8169, 0.9171, 0.2335],\n",
            "        [0.0856, 0.9296, 0.0408, 0.5434, 0.0761],\n",
            "        [0.9051, 0.5905, 0.9654, 0.7053, 0.1326],\n",
            "        [0.5823, 0.7622, 0.5815, 0.4732, 0.4738]])\n",
            " produto: tensor([[[[-1.4763e-03,  3.2294e-04, -3.9308e-03,  1.9317e-03, -4.5821e-03],\n",
            "          [ 2.2372e-04, -5.3911e-03, -6.4946e-03, -5.7951e-03,  1.0574e-03],\n",
            "          [-3.1634e-04,  3.4785e-03, -3.4598e-04, -3.2972e-03, -2.7924e-04],\n",
            "          [-1.7787e-03, -4.5048e-03,  6.3212e-03, -1.6633e-03,  4.2552e-04],\n",
            "          [ 4.1178e-03,  1.4201e-03,  1.5901e-03,  4.5671e-03, -2.1370e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1468e-03, -4.3376e-03,  5.6561e-03,  4.0910e-03, -4.9581e-03],\n",
            "          [ 2.6053e-04,  3.5418e-03,  3.5597e-03,  3.7755e-03,  1.9408e-03],\n",
            "          [-1.1304e-04, -7.8612e-03, -1.1697e-04, -3.8273e-03,  5.0275e-05],\n",
            "          [-1.6899e-03, -3.1674e-03, -8.7773e-04,  6.6818e-03, -1.0456e-04],\n",
            "          [ 1.8488e-04, -1.1888e-03,  9.1416e-04,  4.2158e-03,  2.8974e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0165]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0107]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0165,  0.0107], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 5, 0] = -0.016536405310034752\n",
            " somado na saída em [1, 1, 5, 0] = 0.010673880577087402\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 1\n",
            " alvo do kernel em x: x[1,0,15:20, 3:8]\n",
            " \n",
            " tensor([[0.5122, 0.5378, 0.0620, 0.3366, 0.5878],\n",
            "        [0.9171, 0.2335, 0.7274, 0.1365, 0.9368],\n",
            "        [0.5434, 0.0761, 0.9007, 0.1452, 0.2086],\n",
            "        [0.7053, 0.1326, 0.1570, 0.3371, 0.9130],\n",
            "        [0.4732, 0.4738, 0.5391, 0.6024, 0.9614]])\n",
            " produto: tensor([[[[-0.0021,  0.0002, -0.0003,  0.0013, -0.0050],\n",
            "          [ 0.0067, -0.0017, -0.0058, -0.0009,  0.0042],\n",
            "          [-0.0020,  0.0003, -0.0076, -0.0009, -0.0008],\n",
            "          [-0.0014, -0.0010,  0.0010, -0.0008,  0.0029],\n",
            "          [ 0.0033,  0.0009,  0.0015,  0.0058, -0.0043]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0016, -0.0024,  0.0004,  0.0027, -0.0054],\n",
            "          [ 0.0078,  0.0011,  0.0032,  0.0006,  0.0078],\n",
            "          [-0.0007, -0.0006, -0.0026, -0.0010,  0.0001],\n",
            "          [-0.0013, -0.0007, -0.0001,  0.0032, -0.0007],\n",
            "          [ 0.0002, -0.0007,  0.0008,  0.0054,  0.0059]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0064]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0244]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0064,  0.0244], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 5, 1] = -0.006400544196367264\n",
            " somado na saída em [1, 1, 5, 1] = 0.02438255026936531\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 2\n",
            " alvo do kernel em x: x[1,0,15:20, 6:11]\n",
            " \n",
            " tensor([[0.3366, 0.5878, 0.7652, 0.7493, 0.3024],\n",
            "        [0.1365, 0.9368, 0.8312, 0.7617, 0.9230],\n",
            "        [0.1452, 0.2086, 0.7562, 0.9873, 0.7477],\n",
            "        [0.3371, 0.9130, 0.2598, 0.5101, 0.2706],\n",
            "        [0.6024, 0.9614, 0.0810, 0.5346, 0.4734]])\n",
            " produto: tensor([[[[-0.0014,  0.0002, -0.0038,  0.0028, -0.0026],\n",
            "          [ 0.0010, -0.0068, -0.0066, -0.0048,  0.0042],\n",
            "          [-0.0005,  0.0008, -0.0064, -0.0060, -0.0027],\n",
            "          [-0.0007, -0.0070,  0.0017, -0.0012,  0.0009],\n",
            "          [ 0.0043,  0.0018,  0.0002,  0.0052, -0.0021]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0011, -0.0026,  0.0055,  0.0060, -0.0028],\n",
            "          [ 0.0012,  0.0045,  0.0036,  0.0031,  0.0077],\n",
            "          [-0.0002, -0.0018, -0.0022, -0.0070,  0.0005],\n",
            "          [-0.0006, -0.0049, -0.0002,  0.0048, -0.0002],\n",
            "          [ 0.0002, -0.0015,  0.0001,  0.0048,  0.0029]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0297]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0219]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0297,  0.0219], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 5, 2] = -0.02965143509209156\n",
            " somado na saída em [1, 1, 5, 2] = 0.021933957934379578\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 3\n",
            " alvo do kernel em x: x[1,0,15:20, 9:14]\n",
            " \n",
            " tensor([[0.7493, 0.3024, 0.5412, 0.5388, 0.9174],\n",
            "        [0.7617, 0.9230, 0.9100, 0.4673, 0.1622],\n",
            "        [0.9873, 0.7477, 0.0282, 0.4790, 0.3010],\n",
            "        [0.5101, 0.2706, 0.1931, 0.8164, 0.9838],\n",
            "        [0.5346, 0.4734, 0.4327, 0.1604, 0.5753]])\n",
            " produto: tensor([[[[-3.0555e-03,  1.0016e-04, -2.6878e-03,  2.0317e-03, -7.8165e-03],\n",
            "          [ 5.5833e-03, -6.7089e-03, -7.2349e-03, -2.9530e-03,  7.3465e-04],\n",
            "          [-3.6479e-03,  2.7980e-03, -2.3963e-04, -2.9061e-03, -1.1054e-03],\n",
            "          [-1.0024e-03, -2.0645e-03,  1.2643e-03, -1.9253e-03,  3.1579e-03],\n",
            "          [ 3.7807e-03,  8.8195e-04,  1.1832e-03,  1.5478e-03, -2.5944e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3734e-03, -1.3454e-03,  3.8675e-03,  4.3028e-03, -8.4579e-03],\n",
            "          [ 6.5019e-03,  4.4075e-03,  3.9655e-03,  1.9239e-03,  1.3485e-03],\n",
            "          [-1.3036e-03, -6.3233e-03, -8.1016e-05, -3.3733e-03,  1.9901e-04],\n",
            "          [-9.5236e-04, -1.4516e-03, -1.7556e-04,  7.7346e-03, -7.7599e-04],\n",
            "          [ 1.6975e-04, -7.3830e-04,  6.8021e-04,  1.4288e-03,  3.5176e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0229]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0174]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0229,  0.0174], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 5, 3] = -0.02287854626774788\n",
            " somado na saída em [1, 1, 5, 3] = 0.017442725598812103\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 4\n",
            " alvo do kernel em x: x[1,0,15:20, 12:17]\n",
            " \n",
            " tensor([[0.5388, 0.9174, 0.8488, 0.2040, 0.4640],\n",
            "        [0.4673, 0.1622, 0.8655, 0.0291, 0.1630],\n",
            "        [0.4790, 0.3010, 0.7800, 0.5523, 0.4885],\n",
            "        [0.8164, 0.9838, 0.0672, 0.5311, 0.9403],\n",
            "        [0.1604, 0.5753, 0.3884, 0.4565, 0.1689]])\n",
            " produto: tensor([[[[-2.1969e-03,  3.0387e-04, -4.2155e-03,  7.6944e-04, -3.9531e-03],\n",
            "          [ 3.4258e-03, -1.1790e-03, -6.8811e-03, -1.8365e-04,  7.3825e-04],\n",
            "          [-1.7698e-03,  1.1266e-03, -6.6205e-03, -3.3511e-03, -1.7936e-03],\n",
            "          [-1.6044e-03, -7.5052e-03,  4.4002e-04, -1.2526e-03,  3.0182e-03],\n",
            "          [ 1.1339e-03,  1.0717e-03,  1.0620e-03,  4.4068e-03, -7.6184e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7065e-03, -4.0815e-03,  6.0657e-03,  1.6295e-03, -4.2775e-03],\n",
            "          [ 3.9894e-03,  7.7459e-04,  3.7716e-03,  1.1965e-04,  1.3551e-03],\n",
            "          [-6.3244e-04, -2.5460e-03, -2.2383e-03, -3.8899e-03,  3.2292e-04],\n",
            "          [-1.5243e-03, -5.2771e-03, -6.1100e-05,  5.0321e-03, -7.4165e-04],\n",
            "          [ 5.0913e-05, -8.9717e-04,  6.1057e-04,  4.0679e-03,  1.0329e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0258]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0044]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0258,  0.0044], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 5, 4] = -0.025771595537662506\n",
            " somado na saída em [1, 1, 5, 4] = 0.004362374544143677\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 5\n",
            " alvo do kernel em x: x[1,0,15:20, 15:20]\n",
            " \n",
            " tensor([[0.2040, 0.4640, 0.2259, 0.1415, 0.7125],\n",
            "        [0.0291, 0.1630, 0.8203, 0.8683, 0.2357],\n",
            "        [0.5523, 0.4885, 0.0281, 0.4954, 0.6145],\n",
            "        [0.5311, 0.9403, 0.8093, 0.9694, 0.8891],\n",
            "        [0.4565, 0.1689, 0.0027, 0.9175, 0.7014]])\n",
            " produto: tensor([[[[-8.3200e-04,  1.5368e-04, -1.1219e-03,  5.3377e-04, -6.0708e-03],\n",
            "          [ 2.1305e-04, -1.1848e-03, -6.5218e-03, -5.4868e-03,  1.0673e-03],\n",
            "          [-2.0408e-03,  1.8280e-03, -2.3811e-04, -3.0060e-03, -2.2562e-03],\n",
            "          [-1.0438e-03, -7.1731e-03,  5.2994e-03, -2.2862e-03,  2.8538e-03],\n",
            "          [ 3.2284e-03,  3.1471e-04,  7.4894e-06,  8.8559e-03, -3.1634e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 6.4628e-04, -2.0642e-03,  1.6143e-03,  1.1304e-03, -6.5690e-03],\n",
            "          [ 2.4810e-04,  7.7839e-04,  3.5747e-03,  3.5746e-03,  1.9591e-03],\n",
            "          [-7.2929e-04, -4.1311e-03, -8.0503e-05, -3.4893e-03,  4.0621e-04],\n",
            "          [-9.9168e-04, -5.0435e-03, -7.3584e-04,  9.1844e-03, -7.0126e-04],\n",
            "          [ 1.4495e-04, -2.6345e-04,  4.3056e-06,  8.1747e-03,  4.2890e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0181]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0109]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0181,  0.0109], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 5, 5] = -0.01807018369436264\n",
            " somado na saída em [1, 1, 5, 5] = 0.010930263437330723\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 6\n",
            " alvo do kernel em x: x[1,0,15:20, 18:23]\n",
            " \n",
            " tensor([[0.1415, 0.7125, 0.9949, 0.8117, 0.3546],\n",
            "        [0.8683, 0.2357, 0.8573, 0.4013, 0.9959],\n",
            "        [0.4954, 0.6145, 0.3545, 0.2822, 0.8754],\n",
            "        [0.9694, 0.8891, 0.0332, 0.2045, 0.7685],\n",
            "        [0.9175, 0.7014, 0.0819, 0.3037, 0.4729]])\n",
            " produto: tensor([[[[-5.7717e-04,  2.3601e-04, -4.9410e-03,  3.0611e-03, -3.0215e-03],\n",
            "          [ 6.3651e-03, -1.7129e-03, -6.8159e-03, -2.5356e-03,  4.5103e-03],\n",
            "          [-1.8306e-03,  2.2994e-03, -3.0085e-03, -1.7122e-03, -3.2144e-03],\n",
            "          [-1.9051e-03, -6.7825e-03,  2.1745e-04, -4.8231e-04,  2.4669e-03],\n",
            "          [ 6.4878e-03,  1.3067e-03,  2.2388e-04,  2.9318e-03, -2.1330e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 4.4833e-04, -3.1700e-03,  7.1097e-03,  6.4828e-03, -3.2695e-03],\n",
            "          [ 7.4123e-03,  1.1253e-03,  3.7359e-03,  1.6519e-03,  8.2787e-03],\n",
            "          [-6.5418e-04, -5.1966e-03, -1.0172e-03, -1.9875e-03,  5.7872e-04],\n",
            "          [-1.8100e-03, -4.7689e-03, -3.0194e-05,  1.9376e-03, -6.0618e-04],\n",
            "          [ 2.9130e-04, -1.0939e-03,  1.2871e-04,  2.7063e-03,  2.8921e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0106]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0212]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0106,  0.0212], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 5, 6] = -0.010566306300461292\n",
            " somado na saída em [1, 1, 5, 6] = 0.021175529807806015\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 7\n",
            " alvo do kernel em x: x[1,0,15:20, 21:26]\n",
            " \n",
            " tensor([[0.8117, 0.3546, 0.4030, 0.1072, 0.3857],\n",
            "        [0.4013, 0.9959, 0.0347, 0.8220, 0.0749],\n",
            "        [0.2822, 0.8754, 0.1041, 0.8185, 0.2737],\n",
            "        [0.2045, 0.7685, 0.8834, 0.6605, 0.2349],\n",
            "        [0.3037, 0.4729, 0.0876, 0.0340, 0.0791]])\n",
            " produto: tensor([[[[-3.3100e-03,  1.1746e-04, -2.0016e-03,  4.0437e-04, -3.2866e-03],\n",
            "          [ 2.9415e-03, -7.2384e-03, -2.7565e-04, -5.1940e-03,  3.3921e-04],\n",
            "          [-1.0427e-03,  3.2760e-03, -8.8351e-04, -4.9658e-03, -1.0050e-03],\n",
            "          [-4.0191e-04, -5.8628e-03,  5.7843e-03, -1.5577e-03,  7.5410e-04],\n",
            "          [ 2.1478e-03,  8.8113e-04,  2.3948e-04,  3.2791e-04, -3.5683e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 2.5711e-03, -1.5777e-03,  2.8802e-03,  8.5638e-04, -3.5563e-03],\n",
            "          [ 3.4254e-03,  4.7555e-03,  1.5109e-04,  3.3839e-03,  6.2262e-04],\n",
            "          [-3.7263e-04, -7.4035e-03, -2.9871e-04, -5.7642e-03,  1.8095e-04],\n",
            "          [-3.8185e-04, -4.1223e-03, -8.0318e-04,  6.2577e-03, -1.8530e-04],\n",
            "          [ 9.6436e-05, -7.3761e-04,  1.3768e-04,  3.0269e-04,  4.8380e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0202]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0009]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0202,  0.0009], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 5, 7] = -0.020169472321867943\n",
            " somado na saída em [1, 1, 5, 7] = 0.0009021571604534984\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 0\n",
            " alvo do kernel em x: x[1,0,18:23, 0:5]\n",
            " \n",
            " tensor([[0.9051, 0.5905, 0.9654, 0.7053, 0.1326],\n",
            "        [0.5823, 0.7622, 0.5815, 0.4732, 0.4738],\n",
            "        [0.3872, 0.5131, 0.7835, 0.0949, 0.0744],\n",
            "        [0.7371, 0.6973, 0.9436, 0.9582, 0.2459],\n",
            "        [0.9167, 0.5744, 0.9391, 0.6820, 0.5729]])\n",
            " produto: tensor([[[[-3.6909e-03,  1.9560e-04, -4.7946e-03,  2.6597e-03, -1.1295e-03],\n",
            "          [ 4.2686e-03, -5.5403e-03, -4.6232e-03, -2.9898e-03,  2.1459e-03],\n",
            "          [-1.4308e-03,  1.9203e-03, -6.6502e-03, -5.7549e-04, -2.7305e-04],\n",
            "          [-1.4485e-03, -5.3197e-03,  6.1785e-03, -2.2598e-03,  7.8930e-04],\n",
            "          [ 6.4821e-03,  1.0702e-03,  2.5679e-03,  6.5835e-03, -2.5837e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.8670e-03, -2.6273e-03,  6.8990e-03,  5.6327e-03, -1.2222e-03],\n",
            "          [ 4.9709e-03,  3.6398e-03,  2.5340e-03,  1.9478e-03,  3.9388e-03],\n",
            "          [-5.1131e-04, -4.3396e-03, -2.2484e-03, -6.6802e-04,  4.9159e-05],\n",
            "          [-1.3762e-03, -3.7404e-03, -8.5791e-04,  9.0781e-03, -1.9395e-04],\n",
            "          [ 2.9104e-04, -8.9591e-04,  1.4763e-03,  6.0771e-03,  3.5030e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0084]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0342]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0084,  0.0342], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 6, 0] = -0.008447852917015553\n",
            " somado na saída em [1, 1, 6, 0] = 0.03422357514500618\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 1\n",
            " alvo do kernel em x: x[1,0,18:23, 3:8]\n",
            " \n",
            " tensor([[0.7053, 0.1326, 0.1570, 0.3371, 0.9130],\n",
            "        [0.4732, 0.4738, 0.5391, 0.6024, 0.9614],\n",
            "        [0.0949, 0.0744, 0.9903, 0.5585, 0.2262],\n",
            "        [0.9582, 0.2459, 0.5400, 0.4046, 0.5502],\n",
            "        [0.6820, 0.5729, 0.9902, 0.6471, 0.7243]])\n",
            " produto: tensor([[[[-2.8759e-03,  4.3912e-05, -7.7989e-04,  1.2712e-03, -7.7796e-03],\n",
            "          [ 3.4684e-03, -3.4439e-03, -4.2863e-03, -3.8065e-03,  4.3542e-03],\n",
            "          [-3.5047e-04,  2.7828e-04, -8.4049e-03, -3.3883e-03, -8.3042e-04],\n",
            "          [-1.8831e-03, -1.8759e-03,  3.5356e-03, -9.5413e-04,  1.7661e-03],\n",
            "          [ 4.8230e-03,  1.0673e-03,  2.7076e-03,  6.2459e-03, -3.2665e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.2340e-03, -5.8981e-04,  1.1222e-03,  2.6921e-03, -8.4179e-03],\n",
            "          [ 4.0390e-03,  2.2625e-03,  2.3494e-03,  2.4799e-03,  7.9923e-03],\n",
            "          [-1.2524e-04, -6.2889e-04, -2.8416e-03, -3.9331e-03,  1.4951e-04],\n",
            "          [-1.7890e-03, -1.3190e-03, -4.9094e-04,  3.8330e-03, -4.3398e-04],\n",
            "          [ 2.1655e-04, -8.9344e-04,  1.5566e-03,  5.7655e-03,  4.4288e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0144]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0197]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0144,  0.0197], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 6, 1] = -0.01436430960893631\n",
            " somado na saída em [1, 1, 6, 1] = 0.019658325240015984\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 2\n",
            " alvo do kernel em x: x[1,0,18:23, 6:11]\n",
            " \n",
            " tensor([[0.3371, 0.9130, 0.2598, 0.5101, 0.2706],\n",
            "        [0.6024, 0.9614, 0.0810, 0.5346, 0.4734],\n",
            "        [0.5585, 0.2262, 0.4880, 0.4665, 0.7711],\n",
            "        [0.4046, 0.5502, 0.8006, 0.2618, 0.2237],\n",
            "        [0.6471, 0.7243, 0.0173, 0.1131, 0.4246]])\n",
            " produto: tensor([[[[-1.3745e-03,  3.0244e-04, -1.2901e-03,  1.9236e-03, -2.3059e-03],\n",
            "          [ 4.4159e-03, -6.9880e-03, -6.4389e-04, -3.3783e-03,  2.1439e-03],\n",
            "          [-2.0635e-03,  8.4633e-04, -4.1415e-03, -2.8302e-03, -2.8315e-03],\n",
            "          [-7.9508e-04, -4.1973e-03,  5.2424e-03, -6.1733e-04,  7.1812e-04],\n",
            "          [ 4.5757e-03,  1.3493e-03,  4.7223e-05,  1.0921e-03, -1.9149e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0677e-03, -4.0622e-03,  1.8564e-03,  4.0738e-03, -2.4951e-03],\n",
            "          [ 5.1424e-03,  4.5909e-03,  3.5292e-04,  2.2010e-03,  3.9353e-03],\n",
            "          [-7.3739e-04, -1.9127e-03, -1.4002e-03, -3.2853e-03,  5.0978e-04],\n",
            "          [-7.5538e-04, -2.9512e-03, -7.2794e-04,  2.4800e-03, -1.7646e-04],\n",
            "          [ 2.0545e-04, -1.1296e-03,  2.7148e-05,  1.0081e-03,  2.5963e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0127]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0104]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0127,  0.0104], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 6, 2] = -0.012715005315840244\n",
            " somado na saída em [1, 1, 6, 2] = 0.01041349209845066\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 3\n",
            " alvo do kernel em x: x[1,0,18:23, 9:14]\n",
            " \n",
            " tensor([[0.5101, 0.2706, 0.1931, 0.8164, 0.9838],\n",
            "        [0.5346, 0.4734, 0.4327, 0.1604, 0.5753],\n",
            "        [0.4665, 0.7711, 0.5674, 0.4596, 0.5860],\n",
            "        [0.2618, 0.2237, 0.5450, 0.4361, 0.8774],\n",
            "        [0.1131, 0.4246, 0.3856, 0.6224, 0.1548]])\n",
            " produto: tensor([[[[-2.0800e-03,  8.9645e-05, -9.5897e-04,  3.0788e-03, -8.3827e-03],\n",
            "          [ 3.9191e-03, -3.4408e-03, -3.4400e-03, -1.0133e-03,  2.6053e-03],\n",
            "          [-1.7236e-03,  2.8857e-03, -4.8158e-03, -2.7884e-03, -2.1516e-03],\n",
            "          [-5.1443e-04, -1.7067e-03,  3.5689e-03, -1.0284e-03,  2.8162e-03],\n",
            "          [ 8.0006e-04,  7.9102e-04,  1.0546e-03,  6.0076e-03, -6.9822e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6157e-03, -1.2041e-03,  1.3799e-03,  6.5202e-03, -9.0706e-03],\n",
            "          [ 4.5639e-03,  2.2605e-03,  1.8855e-03,  6.6014e-04,  4.7821e-03],\n",
            "          [-6.1594e-04, -6.5216e-03, -1.6282e-03, -3.2367e-03,  3.8738e-04],\n",
            "          [-4.8874e-04, -1.2000e-03, -4.9557e-04,  4.1312e-03, -6.9201e-04],\n",
            "          [ 3.5922e-05, -6.6218e-04,  6.0627e-04,  5.5455e-03,  9.4668e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0071]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0095]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0071,  0.0095], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 6, 3] = -0.007125835865736008\n",
            " somado na saída em [1, 1, 6, 3] = 0.009505260735750198\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 4\n",
            " alvo do kernel em x: x[1,0,18:23, 12:17]\n",
            " \n",
            " tensor([[0.8164, 0.9838, 0.0672, 0.5311, 0.9403],\n",
            "        [0.1604, 0.5753, 0.3884, 0.4565, 0.1689],\n",
            "        [0.4596, 0.5860, 0.3385, 0.8351, 0.0078],\n",
            "        [0.4361, 0.8774, 0.4679, 0.5275, 0.6963],\n",
            "        [0.6224, 0.1548, 0.9916, 0.3327, 0.4169]])\n",
            " produto: tensor([[[[-3.3291e-03,  3.2589e-04, -3.3376e-04,  2.0030e-03, -8.0117e-03],\n",
            "          [ 1.1755e-03, -4.1812e-03, -3.0878e-03, -2.8848e-03,  7.6503e-04],\n",
            "          [-1.6981e-03,  2.1928e-03, -2.8726e-03, -5.0667e-03, -2.8690e-05],\n",
            "          [-8.5693e-04, -6.6930e-03,  3.0637e-03, -1.2441e-03,  2.2349e-03],\n",
            "          [ 4.4012e-03,  2.8843e-04,  2.7116e-03,  3.2112e-03, -1.8804e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.5860e-03, -4.3772e-03,  4.8025e-04,  4.2420e-03, -8.6692e-03],\n",
            "          [ 1.3689e-03,  2.7469e-03,  1.6925e-03,  1.8795e-03,  1.4042e-03],\n",
            "          [-6.0683e-04, -4.9557e-03, -9.7119e-04, -5.8814e-03,  5.1653e-06],\n",
            "          [-8.1415e-04, -4.7060e-03, -4.2542e-04,  4.9978e-03, -5.4917e-04],\n",
            "          [ 1.9761e-04, -2.4145e-04,  1.5589e-03,  2.9642e-03,  2.5494e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0198]]],\n",
            "\n",
            "\n",
            "        [[[-0.0035]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0198, -0.0035], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 6, 4] = -0.019795572385191917\n",
            " somado na saída em [1, 1, 6, 4] = -0.0035242754966020584\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 5\n",
            " alvo do kernel em x: x[1,0,18:23, 15:20]\n",
            " \n",
            " tensor([[0.5311, 0.9403, 0.8093, 0.9694, 0.8891],\n",
            "        [0.4565, 0.1689, 0.0027, 0.9175, 0.7014],\n",
            "        [0.8351, 0.0078, 0.6264, 0.4766, 0.1517],\n",
            "        [0.5275, 0.6963, 0.1728, 0.2860, 0.4772],\n",
            "        [0.3327, 0.4169, 0.7053, 0.4523, 0.6017]])\n",
            " produto: tensor([[[[-2.1659e-03,  3.1146e-04, -4.0196e-03,  3.6558e-03, -7.5754e-03],\n",
            "          [ 3.3467e-03, -1.2278e-03, -2.1775e-05, -5.7973e-03,  3.1766e-03],\n",
            "          [-3.0856e-03,  2.9240e-05, -5.3167e-03, -2.8914e-03, -5.5686e-04],\n",
            "          [-1.0367e-03, -5.3115e-03,  1.1314e-03, -6.7440e-04,  1.5317e-03],\n",
            "          [ 2.3525e-03,  7.7675e-04,  1.9286e-03,  4.3655e-03, -2.7137e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6824e-03, -4.1835e-03,  5.7838e-03,  7.7424e-03, -8.1971e-03],\n",
            "          [ 3.8973e-03,  8.0662e-04,  1.1935e-05,  3.7770e-03,  5.8307e-03],\n",
            "          [-1.1027e-03, -6.6080e-05, -1.7975e-03, -3.3563e-03,  1.0026e-04],\n",
            "          [-9.8493e-04, -3.7346e-03, -1.5710e-04,  2.7093e-03, -3.7637e-04],\n",
            "          [ 1.0563e-04, -6.5023e-04,  1.1087e-03,  4.0297e-03,  3.6793e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0198]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0167]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0198,  0.0167], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 6, 5] = -0.019788365811109543\n",
            " somado na saída em [1, 1, 6, 5] = 0.016658715903759003\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 6\n",
            " alvo do kernel em x: x[1,0,18:23, 18:23]\n",
            " \n",
            " tensor([[0.9694, 0.8891, 0.0332, 0.2045, 0.7685],\n",
            "        [0.9175, 0.7014, 0.0819, 0.3037, 0.4729],\n",
            "        [0.4766, 0.1517, 0.4811, 0.0428, 0.7721],\n",
            "        [0.2860, 0.4772, 0.9857, 0.7885, 0.7155],\n",
            "        [0.4523, 0.6017, 0.1549, 0.2921, 0.7604]])\n",
            " produto: tensor([[[[-0.0040,  0.0003, -0.0002,  0.0008, -0.0065],\n",
            "          [ 0.0067, -0.0051, -0.0007, -0.0019,  0.0021],\n",
            "          [-0.0018,  0.0006, -0.0041, -0.0003, -0.0028],\n",
            "          [-0.0006, -0.0036,  0.0065, -0.0019,  0.0023],\n",
            "          [ 0.0032,  0.0011,  0.0004,  0.0028, -0.0034]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0031, -0.0040,  0.0002,  0.0016, -0.0071],\n",
            "          [ 0.0078,  0.0033,  0.0004,  0.0013,  0.0039],\n",
            "          [-0.0006, -0.0013, -0.0014, -0.0003,  0.0005],\n",
            "          [-0.0005, -0.0026, -0.0009,  0.0075, -0.0006],\n",
            "          [ 0.0001, -0.0009,  0.0002,  0.0026,  0.0046]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0100]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0172]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0100,  0.0172], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 6, 6] = -0.009950850158929825\n",
            " somado na saída em [1, 1, 6, 6] = 0.017153367400169373\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 7\n",
            " alvo do kernel em x: x[1,0,18:23, 21:26]\n",
            " \n",
            " tensor([[0.2045, 0.7685, 0.8834, 0.6605, 0.2349],\n",
            "        [0.3037, 0.4729, 0.0876, 0.0340, 0.0791],\n",
            "        [0.0428, 0.7721, 0.1772, 0.0154, 0.5534],\n",
            "        [0.7885, 0.7155, 0.4654, 0.4714, 0.8246],\n",
            "        [0.2921, 0.7604, 0.0878, 0.7699, 0.3016]])\n",
            " produto: tensor([[[[-8.3397e-04,  2.5457e-04, -4.3874e-03,  2.4909e-03, -2.0017e-03],\n",
            "          [ 2.2265e-03, -3.4376e-03, -6.9628e-04, -2.1466e-04,  3.5832e-04],\n",
            "          [-1.5833e-04,  2.8893e-03, -1.5042e-03, -9.3647e-05, -2.0318e-03],\n",
            "          [-1.5496e-03, -5.4581e-03,  3.0471e-03, -1.1116e-03,  2.6467e-03],\n",
            "          [ 2.0653e-03,  1.4166e-03,  2.4006e-04,  7.4319e-03, -1.3604e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 6.4781e-04, -3.4193e-03,  6.3131e-03,  5.2752e-03, -2.1660e-03],\n",
            "          [ 2.5928e-03,  2.2584e-03,  3.8164e-04,  1.3985e-04,  6.5771e-04],\n",
            "          [-5.6579e-05, -6.5297e-03, -5.0855e-04, -1.0870e-04,  3.6582e-04],\n",
            "          [-1.4722e-03, -3.8377e-03, -4.2311e-04,  4.4657e-03, -6.5037e-04],\n",
            "          [ 9.2728e-05, -1.1859e-03,  1.3801e-04,  6.8603e-03,  1.8444e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[0.0002]]],\n",
            "\n",
            "\n",
            "        [[[0.0117]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([0.0002, 0.0117], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 6, 7] = 0.00022799475118517876\n",
            " somado na saída em [1, 1, 6, 7] = 0.011675408110022545\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 0\n",
            " alvo do kernel em x: x[1,0,21:26, 0:5]\n",
            " \n",
            " tensor([[0.7371, 0.6973, 0.9436, 0.9582, 0.2459],\n",
            "        [0.9167, 0.5744, 0.9391, 0.6820, 0.5729],\n",
            "        [0.7011, 0.4016, 0.5817, 0.8417, 0.9346],\n",
            "        [0.9843, 0.5677, 0.7914, 0.5784, 0.6339],\n",
            "        [0.5866, 0.3989, 0.9331, 0.8969, 0.1954]])\n",
            " produto: tensor([[[[-0.0030,  0.0002, -0.0047,  0.0036, -0.0021],\n",
            "          [ 0.0067, -0.0042, -0.0075, -0.0043,  0.0026],\n",
            "          [-0.0026,  0.0015, -0.0049, -0.0051, -0.0034],\n",
            "          [-0.0019, -0.0043,  0.0052, -0.0014,  0.0020],\n",
            "          [ 0.0041,  0.0007,  0.0026,  0.0087, -0.0009]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0023, -0.0031,  0.0067,  0.0077, -0.0023],\n",
            "          [ 0.0078,  0.0027,  0.0041,  0.0028,  0.0048],\n",
            "          [-0.0009, -0.0034, -0.0017, -0.0059,  0.0006],\n",
            "          [-0.0018, -0.0030, -0.0007,  0.0055, -0.0005],\n",
            "          [ 0.0002, -0.0006,  0.0015,  0.0080,  0.0012]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0123]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0319]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0123,  0.0319], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 7, 0] = -0.012336837127804756\n",
            " somado na saída em [1, 1, 7, 0] = 0.03188465163111687\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 1\n",
            " alvo do kernel em x: x[1,0,21:26, 3:8]\n",
            " \n",
            " tensor([[0.9582, 0.2459, 0.5400, 0.4046, 0.5502],\n",
            "        [0.6820, 0.5729, 0.9902, 0.6471, 0.7243],\n",
            "        [0.8417, 0.9346, 0.8523, 0.4845, 0.5350],\n",
            "        [0.5784, 0.6339, 0.9772, 0.9787, 0.1324],\n",
            "        [0.8969, 0.1954, 0.3380, 0.7186, 0.9188]])\n",
            " produto: tensor([[[[-3.9073e-03,  8.1452e-05, -2.6818e-03,  1.5257e-03, -4.6881e-03],\n",
            "          [ 4.9997e-03, -4.1638e-03, -7.8721e-03, -4.0888e-03,  3.2801e-03],\n",
            "          [-3.1101e-03,  3.4973e-03, -7.2338e-03, -2.9394e-03, -1.9643e-03],\n",
            "          [-1.1366e-03, -4.8356e-03,  6.3984e-03, -2.3081e-03,  4.2497e-04],\n",
            "          [ 6.3424e-03,  3.6406e-04,  9.2431e-04,  6.9363e-03, -4.1441e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 3.0351e-03, -1.0940e-03,  3.8588e-03,  3.2312e-03, -5.0728e-03],\n",
            "          [ 5.8223e-03,  2.7355e-03,  4.3148e-03,  2.6638e-03,  6.0208e-03],\n",
            "          [-1.1114e-03, -7.9037e-03, -2.4457e-03, -3.4120e-03,  3.5366e-04],\n",
            "          [-1.0799e-03, -3.4000e-03, -8.8845e-04,  9.2725e-03, -1.0443e-04],\n",
            "          [ 2.8477e-04, -3.0476e-04,  5.3139e-04,  6.4027e-03,  5.6187e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0203]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0273]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0203,  0.0273], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 7, 1] = -0.020299341529607773\n",
            " somado na saída em [1, 1, 7, 1] = 0.02732892334461212\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 2\n",
            " alvo do kernel em x: x[1,0,21:26, 6:11]\n",
            " \n",
            " tensor([[0.4046, 0.5502, 0.8006, 0.2618, 0.2237],\n",
            "        [0.6471, 0.7243, 0.0173, 0.1131, 0.4246],\n",
            "        [0.4845, 0.5350, 0.8994, 0.5151, 0.1676],\n",
            "        [0.9787, 0.1324, 0.5389, 0.8742, 0.4959],\n",
            "        [0.7186, 0.9188, 0.5348, 0.3209, 0.3265]])\n",
            " produto: tensor([[[[-1.6498e-03,  1.8225e-04, -3.9764e-03,  9.8717e-04, -1.9062e-03],\n",
            "          [ 4.7433e-03, -5.2642e-03, -1.3730e-04, -7.1492e-04,  1.9229e-03],\n",
            "          [-1.7901e-03,  2.0020e-03, -7.6332e-03, -3.1252e-03, -6.1552e-04],\n",
            "          [-1.9234e-03, -1.0100e-03,  3.5289e-03, -2.0617e-03,  1.5917e-03],\n",
            "          [ 5.0815e-03,  1.7119e-03,  1.4625e-03,  3.0978e-03, -1.4728e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2815e-03, -2.4480e-03,  5.7216e-03,  2.0906e-03, -2.0627e-03],\n",
            "          [ 5.5237e-03,  3.4585e-03,  7.5253e-05,  4.6577e-04,  3.5295e-03],\n",
            "          [-6.3969e-04, -4.5244e-03, -2.5807e-03, -3.6276e-03,  1.1082e-04],\n",
            "          [-1.8274e-03, -7.1014e-04, -4.9001e-04,  8.2823e-03, -3.9111e-04],\n",
            "          [ 2.2815e-04, -1.4330e-03,  8.4078e-04,  2.8595e-03,  1.9968e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0070]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0157]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0070,  0.0157], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 7, 2] = -0.006968832109123468\n",
            " somado na saída em [1, 1, 7, 2] = 0.015730207785964012\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 3\n",
            " alvo do kernel em x: x[1,0,21:26, 9:14]\n",
            " \n",
            " tensor([[0.2618, 0.2237, 0.5450, 0.4361, 0.8774],\n",
            "        [0.1131, 0.4246, 0.3856, 0.6224, 0.1548],\n",
            "        [0.5151, 0.1676, 0.7832, 0.9312, 0.5372],\n",
            "        [0.8742, 0.4959, 0.2900, 0.9245, 0.1980],\n",
            "        [0.3209, 0.3265, 0.3175, 0.4379, 0.3511]])\n",
            " produto: tensor([[[[-1.0674e-03,  7.4107e-05, -2.7070e-03,  1.6444e-03, -7.4755e-03],\n",
            "          [ 8.2937e-04, -3.0860e-03, -3.0661e-03, -3.9328e-03,  7.0114e-04],\n",
            "          [-1.9032e-03,  6.2731e-04, -6.6475e-03, -5.6496e-03, -1.9723e-03],\n",
            "          [-1.7180e-03, -3.7828e-03,  1.8987e-03, -2.1801e-03,  6.3561e-04],\n",
            "          [ 2.2694e-03,  6.0837e-04,  8.6829e-04,  4.2266e-03, -1.5836e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 8.2916e-04, -9.9538e-04,  3.8952e-03,  3.4826e-03, -8.0889e-03],\n",
            "          [ 9.6582e-04,  2.0274e-03,  1.6805e-03,  2.5622e-03,  1.2870e-03],\n",
            "          [-6.8012e-04, -1.4177e-03, -2.2475e-03, -6.5580e-03,  3.5509e-04],\n",
            "          [-1.6322e-03, -2.6597e-03, -2.6365e-04,  8.7583e-03, -1.5619e-04],\n",
            "          [ 1.0190e-04, -5.0928e-04,  4.9918e-04,  3.9015e-03,  2.1470e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0324]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0073]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0324,  0.0073], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 7, 3] = -0.03238857910037041\n",
            " somado na saída em [1, 1, 7, 3] = 0.007284197025001049\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 4\n",
            " alvo do kernel em x: x[1,0,21:26, 12:17]\n",
            " \n",
            " tensor([[0.4361, 0.8774, 0.4679, 0.5275, 0.6963],\n",
            "        [0.6224, 0.1548, 0.9916, 0.3327, 0.4169],\n",
            "        [0.9312, 0.5372, 0.4058, 0.4425, 0.1398],\n",
            "        [0.9245, 0.1980, 0.2055, 0.2294, 0.3256],\n",
            "        [0.4379, 0.3511, 0.4243, 0.0736, 0.5543]])\n",
            " produto: tensor([[[[-1.7781e-03,  2.9062e-04, -2.3238e-03,  1.9894e-03, -5.9325e-03],\n",
            "          [ 4.5624e-03, -1.1252e-03, -7.8839e-03, -2.1022e-03,  1.8882e-03],\n",
            "          [-3.4406e-03,  2.0101e-03, -3.4444e-03, -2.6850e-03, -5.1325e-04],\n",
            "          [-1.8167e-03, -1.5106e-03,  1.3454e-03, -5.4107e-04,  1.0450e-03],\n",
            "          [ 3.0964e-03,  6.5415e-04,  1.1603e-03,  7.1065e-04, -2.4997e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.3812e-03, -3.9035e-03,  3.3438e-03,  4.2131e-03, -6.4193e-03],\n",
            "          [ 5.3130e-03,  7.3926e-04,  4.3212e-03,  1.3696e-03,  3.4659e-03],\n",
            "          [-1.2295e-03, -4.5427e-03, -1.1645e-03, -3.1167e-03,  9.2406e-05],\n",
            "          [-1.7260e-03, -1.0621e-03, -1.8682e-04,  2.1736e-03, -2.5678e-04],\n",
            "          [ 1.3902e-04, -5.4760e-04,  6.6704e-04,  6.5599e-04,  3.3892e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0188]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0071]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0188,  0.0071], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 7, 4] = -0.018844716250896454\n",
            " somado na saída em [1, 1, 7, 4] = 0.007108778227120638\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 5\n",
            " alvo do kernel em x: x[1,0,21:26, 15:20]\n",
            " \n",
            " tensor([[0.5275, 0.6963, 0.1728, 0.2860, 0.4772],\n",
            "        [0.3327, 0.4169, 0.7053, 0.4523, 0.6017],\n",
            "        [0.4425, 0.1398, 0.5512, 0.8308, 0.0975],\n",
            "        [0.2294, 0.3256, 0.3008, 0.7301, 0.7118],\n",
            "        [0.0736, 0.5543, 0.1337, 0.2005, 0.5614]])\n",
            " produto: tensor([[[[-2.1511e-03,  2.3063e-04, -8.5814e-04,  1.0784e-03, -4.0658e-03],\n",
            "          [ 2.4387e-03, -3.0303e-03, -5.6072e-03, -2.8578e-03,  2.7250e-03],\n",
            "          [-1.6352e-03,  5.2309e-04, -4.6780e-03, -5.0406e-03, -3.5809e-04],\n",
            "          [-4.5088e-04, -2.4835e-03,  1.9694e-03, -1.7218e-03,  2.2847e-03],\n",
            "          [ 5.2062e-04,  1.0326e-03,  3.6555e-04,  1.9356e-03, -2.5318e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6709e-03, -3.0977e-03,  1.2348e-03,  2.2839e-03, -4.3994e-03],\n",
            "          [ 2.8399e-03,  1.9909e-03,  3.0733e-03,  1.8619e-03,  5.0019e-03],\n",
            "          [-5.8434e-04, -1.1821e-03, -1.5816e-03, -5.8511e-03,  6.4471e-05],\n",
            "          [-4.2836e-04, -1.7462e-03, -2.7347e-04,  6.9170e-03, -5.6142e-04],\n",
            "          [ 2.3375e-05, -8.6442e-04,  2.1016e-04,  1.7867e-03,  3.4326e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0224]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0118]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0224,  0.0118], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 7, 5] = -0.022365881130099297\n",
            " somado na saída em [1, 1, 7, 5] = 0.011821570806205273\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 6\n",
            " alvo do kernel em x: x[1,0,21:26, 18:23]\n",
            " \n",
            " tensor([[0.2860, 0.4772, 0.9857, 0.7885, 0.7155],\n",
            "        [0.4523, 0.6017, 0.1549, 0.2921, 0.7604],\n",
            "        [0.8308, 0.0975, 0.0630, 0.1442, 0.7186],\n",
            "        [0.7301, 0.7118, 0.1975, 0.6066, 0.1751],\n",
            "        [0.2005, 0.5614, 0.2318, 0.3800, 0.8036]])\n",
            " produto: tensor([[[[-1.1661e-03,  1.5806e-04, -4.8957e-03,  2.9736e-03, -6.0963e-03],\n",
            "          [ 3.3153e-03, -4.3733e-03, -1.2316e-03, -1.8455e-03,  3.4436e-03],\n",
            "          [-3.0697e-03,  3.6496e-04, -5.3434e-04, -8.7511e-04, -2.6384e-03],\n",
            "          [-1.4348e-03, -5.4299e-03,  1.2932e-03, -1.4306e-03,  5.6192e-04],\n",
            "          [ 1.4180e-03,  1.0458e-03,  6.3379e-04,  3.6678e-03, -3.6245e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 9.0580e-04, -2.1230e-03,  7.0445e-03,  6.2975e-03, -6.5965e-03],\n",
            "          [ 3.8608e-03,  2.8732e-03,  6.7507e-04,  1.2023e-03,  6.3209e-03],\n",
            "          [-1.0970e-03, -8.2478e-04, -1.8066e-04, -1.0158e-03,  4.7503e-04],\n",
            "          [-1.3631e-03, -3.8179e-03, -1.7957e-04,  5.7472e-03, -1.3808e-04],\n",
            "          [ 6.3668e-05, -8.7549e-04,  3.6437e-04,  3.3857e-03,  4.9142e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0198]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0259]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0198,  0.0259], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 7, 6] = -0.01976986974477768\n",
            " somado na saída em [1, 1, 7, 6] = 0.02591828629374504\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 7\n",
            " alvo do kernel em x: x[1,0,21:26, 21:26]\n",
            " \n",
            " tensor([[0.7885, 0.7155, 0.4654, 0.4714, 0.8246],\n",
            "        [0.2921, 0.7604, 0.0878, 0.7699, 0.3016],\n",
            "        [0.1442, 0.7186, 0.3859, 0.0693, 0.0379],\n",
            "        [0.6066, 0.1751, 0.4738, 0.3871, 0.2856],\n",
            "        [0.3800, 0.8036, 0.1356, 0.6198, 0.6628]])\n",
            " produto: tensor([[[[-3.2154e-03,  2.3700e-04, -2.3112e-03,  1.7776e-03, -7.0256e-03],\n",
            "          [ 2.1409e-03, -5.5266e-03, -6.9797e-04, -4.8652e-03,  1.3661e-03],\n",
            "          [-5.3294e-04,  2.6890e-03, -3.2755e-03, -4.2044e-04, -1.3923e-04],\n",
            "          [-1.1921e-03, -1.3355e-03,  3.1021e-03, -9.1280e-04,  9.1669e-04],\n",
            "          [ 2.6870e-03,  1.4972e-03,  3.7087e-04,  5.9823e-03, -2.9894e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.4976e-03, -3.1833e-03,  3.3257e-03,  3.7646e-03, -7.6021e-03],\n",
            "          [ 2.4931e-03,  3.6308e-03,  3.8256e-04,  3.1697e-03,  2.5075e-03],\n",
            "          [-1.9045e-04, -6.0770e-03, -1.1074e-03, -4.8804e-04,  2.5068e-05],\n",
            "          [-1.1326e-03, -9.3900e-04, -4.3075e-04,  3.6670e-03, -2.2526e-04],\n",
            "          [ 1.2065e-04, -1.2534e-03,  2.1321e-04,  5.5221e-03,  4.0531e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0117]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0127]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0117,  0.0127], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 7, 7] = -0.0116731571033597\n",
            " somado na saída em [1, 1, 7, 7] = 0.012743396684527397\n",
            " saida: tensor([[[[-0.0044, -0.0236, -0.0008, -0.0194, -0.0097, -0.0100, -0.0221,\n",
            "           -0.0180],\n",
            "          [-0.0112,  0.0024, -0.0198, -0.0037,  0.0017, -0.0081, -0.0014,\n",
            "           -0.0142],\n",
            "          [-0.0175, -0.0113, -0.0004, -0.0078, -0.0068, -0.0294, -0.0155,\n",
            "           -0.0234],\n",
            "          [-0.0155, -0.0085, -0.0225, -0.0184, -0.0093, -0.0153, -0.0204,\n",
            "           -0.0032],\n",
            "          [-0.0031, -0.0189, -0.0068, -0.0087, -0.0138, -0.0139, -0.0206,\n",
            "           -0.0194],\n",
            "          [ 0.0030, -0.0175, -0.0074, -0.0255, -0.0136, -0.0045, -0.0152,\n",
            "           -0.0099],\n",
            "          [-0.0152, -0.0176, -0.0168, -0.0025, -0.0060, -0.0111, -0.0365,\n",
            "           -0.0097],\n",
            "          [-0.0147, -0.0345, -0.0148, -0.0075, -0.0067,  0.0007, -0.0186,\n",
            "           -0.0120]],\n",
            "\n",
            "         [[ 0.0067,  0.0176,  0.0134,  0.0135,  0.0081,  0.0085,  0.0083,\n",
            "            0.0052],\n",
            "          [ 0.0049,  0.0089,  0.0169,  0.0179,  0.0183,  0.0016,  0.0156,\n",
            "            0.0093],\n",
            "          [ 0.0264,  0.0059,  0.0105,  0.0308,  0.0217,  0.0081,  0.0117,\n",
            "            0.0280],\n",
            "          [ 0.0179,  0.0140,  0.0188,  0.0162,  0.0160,  0.0058,  0.0123,\n",
            "            0.0067],\n",
            "          [ 0.0014,  0.0203,  0.0154,  0.0227,  0.0196,  0.0048,  0.0131,\n",
            "           -0.0050],\n",
            "          [ 0.0237,  0.0071,  0.0214,  0.0206,  0.0220,  0.0094,  0.0140,\n",
            "            0.0083],\n",
            "          [ 0.0132,  0.0095,  0.0060,  0.0172,  0.0211,  0.0183,  0.0058,\n",
            "            0.0268],\n",
            "          [ 0.0204,  0.0145, -0.0033,  0.0038,  0.0104,  0.0145,  0.0177,\n",
            "            0.0130]]],\n",
            "\n",
            "\n",
            "        [[[-0.0189, -0.0296, -0.0172, -0.0161, -0.0089, -0.0089, -0.0148,\n",
            "           -0.0027],\n",
            "          [ 0.0036, -0.0121,  0.0021, -0.0136, -0.0292, -0.0141, -0.0017,\n",
            "            0.0036],\n",
            "          [-0.0182, -0.0014, -0.0089,  0.0010, -0.0085, -0.0056, -0.0117,\n",
            "           -0.0125],\n",
            "          [ 0.0011, -0.0290, -0.0120, -0.0164, -0.0033, -0.0095, -0.0156,\n",
            "           -0.0057],\n",
            "          [-0.0177, -0.0168, -0.0131, -0.0099, -0.0162, -0.0116, -0.0140,\n",
            "           -0.0026],\n",
            "          [-0.0165, -0.0064, -0.0297, -0.0229, -0.0258, -0.0181, -0.0106,\n",
            "           -0.0202],\n",
            "          [-0.0084, -0.0144, -0.0127, -0.0071, -0.0198, -0.0198, -0.0100,\n",
            "            0.0002],\n",
            "          [-0.0123, -0.0203, -0.0070, -0.0324, -0.0188, -0.0224, -0.0198,\n",
            "           -0.0117]],\n",
            "\n",
            "         [[ 0.0172,  0.0041,  0.0230,  0.0203,  0.0122,  0.0183,  0.0184,\n",
            "            0.0223],\n",
            "          [ 0.0148,  0.0180,  0.0148,  0.0319,  0.0135,  0.0044,  0.0173,\n",
            "            0.0284],\n",
            "          [ 0.0222,  0.0168,  0.0179,  0.0182,  0.0124,  0.0078,  0.0140,\n",
            "            0.0023],\n",
            "          [ 0.0412,  0.0188,  0.0269,  0.0218,  0.0253,  0.0145,  0.0211,\n",
            "           -0.0043],\n",
            "          [ 0.0213,  0.0006,  0.0262,  0.0145,  0.0059,  0.0248,  0.0291,\n",
            "            0.0158],\n",
            "          [ 0.0107,  0.0244,  0.0219,  0.0174,  0.0044,  0.0109,  0.0212,\n",
            "            0.0009],\n",
            "          [ 0.0342,  0.0197,  0.0104,  0.0095, -0.0035,  0.0167,  0.0172,\n",
            "            0.0117],\n",
            "          [ 0.0319,  0.0273,  0.0157,  0.0073,  0.0071,  0.0118,  0.0259,\n",
            "            0.0127]]]], grad_fn=<CopySlices>)\n",
            "\n",
            "ndx_amostra: 0\n",
            "\n",
            "ndx_amostra: 1\n",
            " saida apos somar bias: tensor([[[[-0.0008, -0.0201,  0.0027, -0.0159, -0.0061, -0.0064, -0.0185,\n",
            "           -0.0145],\n",
            "          [-0.0077,  0.0059, -0.0163, -0.0001,  0.0053, -0.0045,  0.0022,\n",
            "           -0.0106],\n",
            "          [-0.0139, -0.0077,  0.0032, -0.0042, -0.0033, -0.0259, -0.0119,\n",
            "           -0.0199],\n",
            "          [-0.0120, -0.0049, -0.0189, -0.0148, -0.0058, -0.0117, -0.0169,\n",
            "            0.0004],\n",
            "          [ 0.0005, -0.0153, -0.0033, -0.0051, -0.0103, -0.0103, -0.0171,\n",
            "           -0.0159],\n",
            "          [ 0.0065, -0.0140, -0.0039, -0.0219, -0.0100, -0.0010, -0.0116,\n",
            "           -0.0063],\n",
            "          [-0.0116, -0.0140, -0.0132,  0.0010, -0.0025, -0.0075, -0.0329,\n",
            "           -0.0062],\n",
            "          [-0.0111, -0.0310, -0.0112, -0.0039, -0.0032,  0.0043, -0.0151,\n",
            "           -0.0084]],\n",
            "\n",
            "         [[ 0.0088,  0.0198,  0.0156,  0.0157,  0.0103,  0.0107,  0.0104,\n",
            "            0.0074],\n",
            "          [ 0.0070,  0.0111,  0.0190,  0.0201,  0.0205,  0.0038,  0.0178,\n",
            "            0.0115],\n",
            "          [ 0.0286,  0.0080,  0.0126,  0.0330,  0.0239,  0.0103,  0.0139,\n",
            "            0.0302],\n",
            "          [ 0.0201,  0.0162,  0.0210,  0.0184,  0.0182,  0.0080,  0.0145,\n",
            "            0.0089],\n",
            "          [ 0.0036,  0.0224,  0.0176,  0.0248,  0.0218,  0.0070,  0.0153,\n",
            "           -0.0028],\n",
            "          [ 0.0259,  0.0093,  0.0236,  0.0228,  0.0242,  0.0116,  0.0162,\n",
            "            0.0105],\n",
            "          [ 0.0154,  0.0117,  0.0081,  0.0194,  0.0233,  0.0205,  0.0079,\n",
            "            0.0289],\n",
            "          [ 0.0225,  0.0167, -0.0012,  0.0060,  0.0126,  0.0167,  0.0198,\n",
            "            0.0152]]],\n",
            "\n",
            "\n",
            "        [[[-0.0154, -0.0261, -0.0136, -0.0126, -0.0053, -0.0054, -0.0112,\n",
            "            0.0008],\n",
            "          [ 0.0071, -0.0085,  0.0057, -0.0101, -0.0257, -0.0106,  0.0018,\n",
            "            0.0072],\n",
            "          [-0.0147,  0.0022, -0.0054,  0.0045, -0.0049, -0.0021, -0.0081,\n",
            "           -0.0090],\n",
            "          [ 0.0046, -0.0254, -0.0084, -0.0129,  0.0002, -0.0060, -0.0121,\n",
            "           -0.0021],\n",
            "          [-0.0142, -0.0132, -0.0096, -0.0063, -0.0127, -0.0080, -0.0104,\n",
            "            0.0009],\n",
            "          [-0.0130, -0.0029, -0.0261, -0.0193, -0.0222, -0.0145, -0.0070,\n",
            "           -0.0166],\n",
            "          [-0.0049, -0.0108, -0.0092, -0.0036, -0.0162, -0.0162, -0.0064,\n",
            "            0.0038],\n",
            "          [-0.0088, -0.0167, -0.0034, -0.0288, -0.0153, -0.0188, -0.0162,\n",
            "           -0.0081]],\n",
            "\n",
            "         [[ 0.0193,  0.0063,  0.0251,  0.0225,  0.0143,  0.0205,  0.0205,\n",
            "            0.0245],\n",
            "          [ 0.0170,  0.0202,  0.0170,  0.0341,  0.0157,  0.0066,  0.0195,\n",
            "            0.0306],\n",
            "          [ 0.0244,  0.0190,  0.0200,  0.0204,  0.0146,  0.0100,  0.0162,\n",
            "            0.0045],\n",
            "          [ 0.0434,  0.0210,  0.0291,  0.0239,  0.0275,  0.0167,  0.0233,\n",
            "           -0.0021],\n",
            "          [ 0.0235,  0.0028,  0.0284,  0.0166,  0.0080,  0.0270,  0.0313,\n",
            "            0.0180],\n",
            "          [ 0.0128,  0.0266,  0.0241,  0.0196,  0.0065,  0.0131,  0.0233,\n",
            "            0.0031],\n",
            "          [ 0.0364,  0.0218,  0.0126,  0.0117, -0.0014,  0.0188,  0.0193,\n",
            "            0.0138],\n",
            "          [ 0.0341,  0.0295,  0.0179,  0.0095,  0.0093,  0.0140,  0.0281,\n",
            "            0.0149]]]], grad_fn=<CopySlices>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSTrD1WRnGng",
        "outputId": "60e86fae-1c03-4069-a823-c32a609eb454"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Usa os mesmos pesos para minha implementação e a do pytorch\n",
        "pytorch_conv_layer = torch.nn.Conv2d(out_channels=out_channels, in_channels=in_channels, kernel_size=kernel_size, stride=stride, padding=0)\n",
        "pytorch_conv_layer.load_state_dict(dict(weight=initial_conv_weight, bias=initial_conv_bias))\n",
        "\n",
        "target_out = pytorch_conv_layer(x)"
      ],
      "metadata": {
        "id": "HzIjuGpWlbIM"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2Sesz6onCEw",
        "outputId": "e93a603e-13dc-4439-ee4c-b9c2325e94d1"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert torch.allclose(out, target_out, atol=1e-6)"
      ],
      "metadata": {
        "id": "noWWzeCumRIY"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQA9Zg7GQT2G"
      },
      "source": [
        "## Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:10.802708Z",
          "start_time": "2018-08-20T21:03:10.793287Z"
        },
        "id": "_8Eg4h_kQT2H"
      },
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, height_in: int, width_in: int, in_channels: int, out_channels: int, kernel_size: int, stride: int):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv_layer = MyConv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride)\n",
        "   \n",
        "        height_out = (height_in - kernel_size - 1) // stride + 1\n",
        "        width_out = (width_in - kernel_size - 1) // stride + 1\n",
        "        self.classification_layer = torch.nn.Linear(out_channels * height_out * width_out, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        hidden = self.conv_layer(x)\n",
        "        hidden = torch.nn.functional.relu(hidden)\n",
        "        hidden = hidden.reshape(x.shape[0], -1)\n",
        "        logits = self.classification_layer(hidden)\n",
        "        return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NHQB4wGQT2K"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqs2JhJoQT2L"
      },
      "source": [
        "### Definição dos hiperparâmetros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:14.146259Z",
          "start_time": "2018-08-20T21:03:14.139515Z"
        },
        "id": "oZuYEkn_QT2M"
      },
      "source": [
        "n_epochs = 50\n",
        "lr = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmXarXeIQT2O"
      },
      "source": [
        "### Laço de treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:40.796410Z",
          "start_time": "2018-08-20T21:03:39.771981Z"
        },
        "id": "L5T_jZZPQT2P"
      },
      "source": [
        "model = Net(height_in=height_in, width_in=width_in, in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride)\n",
        "\n",
        "# Usa pesos iniciais pré-difinidos\n",
        "model.classification_layer.load_state_dict(dict(weight=initial_classification_weight, bias=initial_classification_bias))\n",
        "model.conv_layer.weight.data = initial_conv_weight\n",
        "model.conv_layer.bias.data = initial_conv_bias\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr)\n",
        "\n",
        "epochs = []\n",
        "loss_history = []\n",
        "loss_epoch_end = []\n",
        "total_trained_samples = 0\n",
        "for i in range(n_epochs):\n",
        "    for x_train, y_train in loader_train:\n",
        "        # predict da rede\n",
        "        outputs = model(x_train)\n",
        "\n",
        "        # calcula a perda\n",
        "        loss = criterion(outputs, y_train)\n",
        "\n",
        "        # zero, backpropagation, ajusta parâmetros pelo gradiente descendente\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_trained_samples += x_train.size(0)\n",
        "        epochs.append(total_trained_samples / len(dataset_train))\n",
        "        loss_history.append(loss.item())\n",
        "\n",
        "    loss_epoch_end.append(loss.item())\n",
        "    print(f'Epoch: {i:d}/{n_epochs - 1:d} Loss: {loss.item()}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLL-GQlKQT2Y"
      },
      "source": [
        "### Visualização usual da perda, somente no final de cada minibatch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:55.246851Z",
          "start_time": "2018-08-20T21:03:54.994428Z"
        },
        "id": "w38EtNxhQT2Z"
      },
      "source": [
        "n_batches_train = len(loader_train)\n",
        "plt.plot(epochs[::n_batches_train], loss_history[::n_batches_train])\n",
        "plt.xlabel('época')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_epoch_end"
      ],
      "metadata": {
        "id": "ToktJu4CK94z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:48.786969Z",
          "start_time": "2018-08-20T21:03:48.781787Z"
        },
        "id": "PiuMsjYtQT2R"
      },
      "source": [
        "# Assert do histórico de losses\n",
        "target_loss_epoch_end = np.array([\n",
        "    2.303267478942871,\n",
        "    2.227701187133789,\n",
        "    1.0923893451690674,\n",
        "    0.5867354869842529,\n",
        "    0.5144089460372925,\n",
        "    0.45026642084121704,\n",
        "    0.4075140357017517,\n",
        "    0.37713879346847534,\n",
        "    0.3534485101699829,\n",
        "    0.3341451585292816,\n",
        "    0.3181140422821045,\n",
        "    0.30457887053489685,\n",
        "    0.29283496737480164,\n",
        "    0.2827608287334442,\n",
        "    0.2738332152366638,\n",
        "    0.2657742500305176,\n",
        "    0.2583288848400116,\n",
        "    0.25117507576942444,\n",
        "    0.24439716339111328,\n",
        "    0.23789969086647034,\n",
        "    0.23167723417282104,\n",
        "    0.22562651336193085,\n",
        "    0.21984536945819855,\n",
        "    0.2142913043498993,\n",
        "    0.20894232392311096,\n",
        "    0.203872948884964,\n",
        "    0.19903430342674255,\n",
        "    0.19439971446990967,\n",
        "    0.18994088470935822,\n",
        "    0.18563991785049438,\n",
        "    0.18147490918636322,\n",
        "    0.17744913697242737,\n",
        "    0.17347246408462524,\n",
        "    0.16947467625141144,\n",
        "    0.16547319293022156,\n",
        "    0.16150487959384918,\n",
        "    0.1574639081954956,\n",
        "    0.1534043848514557,\n",
        "    0.14926929771900177,\n",
        "    0.1452063024044037,\n",
        "    0.1412365883588791,\n",
        "    0.13712672889232635,\n",
        "    0.1331038922071457,\n",
        "    0.1291467249393463,\n",
        "    0.1251506358385086,\n",
        "    0.12116757035255432,\n",
        "    0.11731722950935364,\n",
        "    0.11364627629518509,\n",
        "    0.11001908034086227,\n",
        "    0.10655981302261353])\n",
        "\n",
        "assert np.allclose(np.array(loss_epoch_end), target_loss_epoch_end, atol=1e-6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rascunho"
      ],
      "metadata": {
        "id": "yy2fvfxRnWDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_channels_dummy = 1\n",
        "out_channels_dummy = 2\n",
        "kernel_size_dummy = 3\n",
        "stride_dummy = 2\n",
        "num_amostras_dummy = 1\n",
        "x = torch.arange(30).float().reshape(num_amostras_dummy, 1, 5, 6)"
      ],
      "metadata": {
        "id": "eHg1E0xkGn-F"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dfc7424-fe9d-4b9b-dbc8-63eef6638f0b",
        "id": "GLcaZY0nGn-F"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
            "          [ 6.,  7.,  8.,  9., 10., 11.],\n",
            "          [12., 13., 14., 15., 16., 17.],\n",
            "          [18., 19., 20., 21., 22., 23.],\n",
            "          [24., 25., 26., 27., 28., 29.]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# falta stride e tratar out_channels > 1"
      ],
      "metadata": {
        "id": "G4-z1oWfI5j8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "conv_layer = MyConv2d( out_channels=out_channels_dummy, in_channels=in_channels_dummy, kernel_size=kernel_size_dummy, stride=stride_dummy)\n",
        "\n",
        "# Usa os mesmos pesos para minha implementação e a do pytorch\n",
        "initial_weights_dummy = torch.arange(in_channels_dummy * out_channels_dummy * kernel_size_dummy * kernel_size_dummy).float()\n",
        "initial_weights_dummy = initial_weights_dummy.reshape(out_channels_dummy, in_channels_dummy,  kernel_size_dummy, kernel_size_dummy)\n",
        "initial_bias_dummy = torch.arange(out_channels_dummy,).float()\n",
        "print(f\"initial_bias_dummy.shape {initial_bias_dummy.shape}, initial_weights_dummy.shape {initial_weights_dummy.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05cc0a62-a67c-4d07-a76a-6b039f15dcdf",
        "id": "m5oMLsHsGn-G"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inicializado MyConv2d\n",
            "in_channels: 1 \n",
            "out_channels: 2 \n",
            "kernel_size: 3 \n",
            "stride: 2 \n",
            "weight.shape: torch.Size([2, 1, 3, 3]) \n",
            "weight: Parameter containing:\n",
            "tensor([[[[-0.0082, -0.0041, -0.0035],\n",
            "          [ 0.0023, -0.0072,  0.0030],\n",
            "          [-0.0095,  0.0072, -0.0016]]],\n",
            "\n",
            "\n",
            "        [[[-0.0069, -0.0036,  0.0015],\n",
            "          [ 0.0053, -0.0033, -0.0039],\n",
            "          [ 0.0075,  0.0062, -0.0042]]]], requires_grad=True) \n",
            "bias.shape: torch.Size([2]) \n",
            "bias: Parameter containing:\n",
            "tensor([ 0.0033, -0.0044], requires_grad=True) \n",
            "initial_bias_dummy.shape torch.Size([2]), initial_weights_dummy.shape torch.Size([2, 1, 3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_layer.weight.data = initial_weights_dummy\n",
        "conv_layer.bias.data = initial_bias_dummy\n",
        "print(f\"conv_layer.weight.data: {conv_layer.weight.data}\")\n",
        "print(f\"conv_layer.bias.data: {conv_layer.bias.data}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5Gr8N8vXkkv",
        "outputId": "95ef5782-bb28-489d-bf51-9e630cd1748d"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv_layer.weight.data: tensor([[[[ 0.,  1.,  2.],\n",
            "          [ 3.,  4.,  5.],\n",
            "          [ 6.,  7.,  8.]]],\n",
            "\n",
            "\n",
            "        [[[ 9., 10., 11.],\n",
            "          [12., 13., 14.],\n",
            "          [15., 16., 17.]]]])\n",
            "conv_layer.bias.data: tensor([0., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW1S0eXhYQ21",
        "outputId": "fa0288df-0420-4e37-e1a5-d10709c8c0e5"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
            "          [ 6.,  7.,  8.,  9., 10., 11.],\n",
            "          [12., 13., 14., 15., 16., 17.],\n",
            "          [18., 19., 20., 21., 22., 23.],\n",
            "          [24., 25., 26., 27., 28., 29.]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = conv_layer(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVysHnpYX4O2",
        "outputId": "23a3dca3-fb28-4aa2-f2b3-c2d0170fb999"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " num_amostras: 1, self.out_channels: 2, num_linhas_entrada: 5, num_colunas_entrada: 6, num_linhas_saida: 2, num_colunas_saida: 2\n",
            "saida.shape: torch.Size([1, 2, 2, 2])\n",
            "\n",
            "ndx_amostra: 0\n",
            "\n",
            "ndx_in_channels: 0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 0\n",
            " alvo do kernel em x: x[0,0,0:3, 0:3]\n",
            " \n",
            " tensor([[ 0.,  1.,  2.],\n",
            "        [ 6.,  7.,  8.],\n",
            "        [12., 13., 14.]])\n",
            " produto: tensor([[[[  0.,   1.,   4.],\n",
            "          [ 18.,  28.,  40.],\n",
            "          [ 72.,  91., 112.]]],\n",
            "\n",
            "\n",
            "        [[[  0.,  10.,  22.],\n",
            "          [ 72.,  91., 112.],\n",
            "          [180., 208., 238.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[366.]]],\n",
            "\n",
            "\n",
            "        [[[933.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([366., 933.], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 0] = 366.0\n",
            " somado na saída em [0, 1, 0, 0] = 933.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 1\n",
            " alvo do kernel em x: x[0,0,0:3, 2:5]\n",
            " \n",
            " tensor([[ 2.,  3.,  4.],\n",
            "        [ 8.,  9., 10.],\n",
            "        [14., 15., 16.]])\n",
            " produto: tensor([[[[  0.,   3.,   8.],\n",
            "          [ 24.,  36.,  50.],\n",
            "          [ 84., 105., 128.]]],\n",
            "\n",
            "\n",
            "        [[[ 18.,  30.,  44.],\n",
            "          [ 96., 117., 140.],\n",
            "          [210., 240., 272.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[ 438.]]],\n",
            "\n",
            "\n",
            "        [[[1167.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([ 438., 1167.], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 1] = 438.0\n",
            " somado na saída em [0, 1, 0, 1] = 1167.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 0\n",
            " alvo do kernel em x: x[0,0,2:5, 0:3]\n",
            " \n",
            " tensor([[12., 13., 14.],\n",
            "        [18., 19., 20.],\n",
            "        [24., 25., 26.]])\n",
            " produto: tensor([[[[  0.,  13.,  28.],\n",
            "          [ 54.,  76., 100.],\n",
            "          [144., 175., 208.]]],\n",
            "\n",
            "\n",
            "        [[[108., 130., 154.],\n",
            "          [216., 247., 280.],\n",
            "          [360., 400., 442.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[ 798.]]],\n",
            "\n",
            "\n",
            "        [[[2337.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([ 798., 2337.], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 0] = 798.0\n",
            " somado na saída em [0, 1, 1, 0] = 2337.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 1\n",
            " alvo do kernel em x: x[0,0,2:5, 2:5]\n",
            " \n",
            " tensor([[14., 15., 16.],\n",
            "        [20., 21., 22.],\n",
            "        [26., 27., 28.]])\n",
            " produto: tensor([[[[  0.,  15.,  32.],\n",
            "          [ 60.,  84., 110.],\n",
            "          [156., 189., 224.]]],\n",
            "\n",
            "\n",
            "        [[[126., 150., 176.],\n",
            "          [240., 273., 308.],\n",
            "          [390., 432., 476.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[ 870.]]],\n",
            "\n",
            "\n",
            "        [[[2571.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([ 870., 2571.], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 1] = 870.0\n",
            " somado na saída em [0, 1, 1, 1] = 2571.0\n",
            " saida: tensor([[[[ 366.,  438.],\n",
            "          [ 798.,  870.]],\n",
            "\n",
            "         [[ 933., 1167.],\n",
            "          [2337., 2571.]]]], grad_fn=<CopySlices>)\n",
            "\n",
            "ndx_amostra: 0\n",
            " saida apos somar bias: tensor([[[[ 366.,  438.],\n",
            "          [ 798.,  870.]],\n",
            "\n",
            "         [[ 934., 1168.],\n",
            "          [2338., 2572.]]]], grad_fn=<CopySlices>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ED6gJjl7GonF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2Vcc7RvMGo2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp = torch.tensor([[[[34.]]]])"
      ],
      "metadata": {
        "id": "JZUW6dbGeULx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp.squeeze()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8ATxh3DkQlS",
        "outputId": "6dea88af-1ef6-410b-d2e1-772f55b58de1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(34.)"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp.squeeze().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijHjn6Fwk_6S",
        "outputId": "fc8bbe28-ae31-472d-d2bd-50cfaa6eae0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([])"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp.squeeze().reshape(1,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrEMRgHxk7UK",
        "outputId": "d9d8d83d-cb40-4844-8e21-c1170d9417b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([34.])"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp.view(1,-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dx_BICd-kVsC",
        "outputId": "7242672c-05da-4aeb-b8bd-e72aadfa04c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[34.]])"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp = torch.tensor([[[[ 46.]], [[134.]]]])"
      ],
      "metadata": {
        "id": "xK5LO9EikKLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp.squeeze()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zgWxyfKeYhZ",
        "outputId": "758c69e0-7669-4021-b5b7-3f364d0222e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 46., 134.])"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp.squeeze().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74ouMw6ClWhp",
        "outputId": "f7e23e94-af1e-4251-b57a-ffc992ddede0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp.squeeze().reshape(2,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVj0YgbZknZE",
        "outputId": "634e9b79-0ca4-4b6c-cb05-903b27262855"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 46., 134.])"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp.squeeze().shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NKOwsD_eYsI",
        "outputId": "8bade88a-be35-4a88-ba2c-cb85f05613e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    }
  ]
}