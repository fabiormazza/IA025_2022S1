{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "t1_IA025_1s22_Alexande_Valle",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {
        "height": "117px",
        "width": "252px"
      },
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unicamp-dl/IA025_2022S1/blob/main/ex01/Alexander_Valle/t1_IA025_1s22_Alexande_Valle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTVOQpMfhgLM"
      },
      "source": [
        "Esté um notebook Colab contendo exercícios de programação em python, numpy e pytorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMoyGt5gXMgK"
      },
      "source": [
        "## Coloque seu nome"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBHbXcibXPRe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3b0a706-48ea-4164-c1f4-6fe93c184bb3"
      },
      "source": [
        "print('Meu nome é: Rolan Alexander Valle Rey Sánchez , RA 230254')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meu nome é: Rolan Alexander Valle Rey Sánchez , RA 230254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9S5acRbm1Zr"
      },
      "source": [
        "# Parte 1:\n",
        "\n",
        "##Exercícios de Processamento de Dados\n",
        "\n",
        "Nesta parte pode-se usar as bibliotecas nativas do python como a `collections`, `re` e `random`. Também pode-se usar o NumPy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxS5h1V8nDn6"
      },
      "source": [
        "##Exercício 1.1\n",
        "Crie um dicionário com os `k` itens mais frequentes de uma lista.\n",
        "\n",
        "Por exemplo, dada a lista de itens `L=['a', 'a', 'd', 'b', 'd', 'c', 'e', 'a', 'b', 'e', 'e', 'a']` e `k=2`, o resultado deve ser um dicionário cuja chave é o item e o valor é a sua frequência: {'a': 4, 'e': 3}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "L = ['f', 'a', 'a', 'd', 'b', 'd', 'c', 'e', 'a', 'b', 'e', 'e', 'a', 'd']\n",
        "\n",
        "le=list(set(L))# list the unique elemets of L\n",
        "freqlist=[int(sum([1  for l in L if e==l])) for e in le]# get the frequency of elemets of le\n",
        "#le,freqlist\n",
        "\n",
        "data=[(e,freq) for e,freq in zip(le,freqlist) ]# generate al list of pairs\n",
        "# sort by frequense (reverse)\n",
        "data.sort(key=lambda data: data[1], reverse=True)\n",
        "#data\n",
        "\n",
        "k=2\n",
        "dicionario=dict(p for p in data[0:k])\n",
        "dicionario"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9S89J4kg8Uku",
        "outputId": "147ee780-eb88-44fa-fe9f-40950e9751aa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a': 4, 'd': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT08b5Z_nC-j"
      },
      "source": [
        "def top_k(L, k):\n",
        "  \"\"\"\"code to get an dictionary with the top elements with higth frency\n",
        "  \"L\" is the list of elemnts to anlyis, \"k\" is the size of the ranking\"\"\"\n",
        "  le=list(set(L))# list the unique elemets of L\n",
        "  freqlist=[int(sum([1  for l in L if e==l])) for e in le]# get the frequency of elemets of le\n",
        "  data=[(e,freq) for e,freq in zip(le,freqlist) ]# generate al list of pairs\n",
        "  # sort by frequense (reverse)\n",
        "  data.sort(key=lambda data: data[1], reverse=True)\n",
        "  return dict(p for p in data[0:k])# retun the top k elements with higth frecency\n",
        "    "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLD_e3C9p4xO"
      },
      "source": [
        "Mostre que sua implementação está correta usando uma entrada com poucos itens:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMW9NiBgnkvA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6bf2e6a-ac5c-43ed-81c4-9ea0b70bd1e8"
      },
      "source": [
        "L = ['f', 'a', 'a', 'd', 'b', 'd', 'c', 'e', 'a', 'b', 'e', 'e', 'a', 'd']\n",
        "k = 3\n",
        "resultado = top_k(L=L, k=k)\n",
        "print(f'resultado: {resultado}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resultado: {'a': 4, 'd': 3, 'e': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBeqZScQqJ0a"
      },
      "source": [
        "Mostre que sua implementação é eficiente usando uma entrada com 10M de itens:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_lhcm4ko8bY"
      },
      "source": [
        "import random\n",
        "L = random.choices('abcdefghijklmnopqrstuvwxyz', k=10_000_000)\n",
        "k = 10000"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9U-Bgs2o-f_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abec7e49-32b2-4ee3-f870-4e8bb9b2dc6d"
      },
      "source": [
        "%%timeit\n",
        "resultado = top_k(L=L, k=k)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 12 s per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJHDaOz_tK38"
      },
      "source": [
        "## Exercício 1.2\n",
        "\n",
        "Em processamento de linguagem natural, é comum convertemos as palavras de um texto para uma lista de identificadores dessas palavras. Dado o dicionário `V` abaixo onde as chaves são palavras e os valores são seus respectivos identificadores, converta o texto `D` para uma lista de identificadores.\n",
        "\n",
        "Palavras que não existem no dicionário deverão ser convertidas para o identificador do token `unknown`.\n",
        "\n",
        "O código deve ser insensível a maiúsculas (case-insensitive).\n",
        "\n",
        "Se atente que pontuações (vírgulas, ponto final, etc) também são consideradas palavras."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "V = {'eu': 1, 'de': 2, 'gosto': 3, 'comer': 4, '.': 5, 'unknown': -1}\n",
        "D = 'Eu gosto de comer pizza.'\n",
        "lcD=D.lower()# conver the text in lowe case\n",
        "lcD=lcD. replace(\".\", \" .\")# creates a space before\n",
        "lw=lcD.split(' ')# break the text into a lisst of words\n",
        "lw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WM3VFyLXWoVL",
        "outputId": "7bfe163c-36e2-4cd2-e9a7-ed0298670513"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['eu', 'gosto', 'de', 'comer', 'pizza', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lwords=[w for w,i in V.items()]#list of works in the dictionary\n",
        "lwords.remove('unknown')\n",
        "lwords\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fV4J-liPYyX3",
        "outputId": "f96258ff-f0b7-4dfe-9f23-438b87b15ab6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['eu', 'de', 'gosto', 'comer', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[V[w] if w in lwords else -1 for w in lw]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWPsU2pnbxTp",
        "outputId": "008c7a85-5549-47e0-c7d7-4578309e9b87"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 3, 2, 4, -1, 5]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVzv89trtTPc"
      },
      "source": [
        "def tokens_to_ids(text, vocabulary):\n",
        "  # escreva o código aqui.\n",
        "  D,V=text, vocabulary \n",
        "  lcD=D.lower()# conver the text in lowe case\n",
        "  lcD=lcD. replace(\".\", \" .\")# creates a space before\n",
        "  lw=lcD.split(' ')# break the text into a lisst of words    \n",
        "  lwords=[w for w,i in V.items()]#list of works in the dictionary\n",
        "  lwords.remove('unknown')\n",
        "  return [V[w] if w in lwords else -1 for w in lw]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCGZeiqkY-sm"
      },
      "source": [
        "Mostre que sua implementação esta correta com um exemplo pequeno:\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iApR1h7gY98E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c2ba0b2-fa96-4903-d257-a2361c4bf702"
      },
      "source": [
        "V = {'eu': 1, 'de': 2, 'gosto': 3, 'comer': 4, '.': 5, 'unknown': -1}\n",
        "D = 'Eu gosto de comer pizza.'\n",
        "\n",
        "print(tokens_to_ids(D, V))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 3, 2, 4, -1, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWtTMxlXZN25"
      },
      "source": [
        "Mostre que sua implementação é eficiente com um exemplo grande:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxT_g-ZxZUsX"
      },
      "source": [
        "V = {'eu': 1, 'de': 2, 'gosto': 3, 'comer': 4, '.': 5, 'unknown': -1}\n",
        "D = ' '.join(1_000_000 * ['Eu gosto de comer pizza.'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kp1nataGZU-V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ac07005-9352-4528-a7dc-2e6332ccd059"
      },
      "source": [
        "%%timeit\n",
        "resultado = tokens_to_ids(D, V)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 1.53 s per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRfaKfXwRXn_"
      },
      "source": [
        "## Exercício 1.3\n",
        "\n",
        "Em aprendizado profundo é comum termos que lidar com arquivos muito grandes.\n",
        "\n",
        "Dado um arquivo de texto onde cada item é separado por `\\n`, escreva um programa que amostre `k` itens desse arquivo aleatoriamente.\n",
        "\n",
        "Nota 1: Assuma amostragem de uma distribuição uniforme, ou seja, todos os itens tem a mesma probablidade de amostragem.\n",
        "\n",
        "Nota 2: Assuma que o arquivo não cabe em memória.\n",
        "\n",
        "Nota 3: Utilize apenas bibliotecas nativas do python."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9_5ssvMZhPjM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = \"\"\"a,b,c\n",
        "d,e,f\n",
        "g,h,i\n",
        "j,k,l\n",
        "d,e,f\n",
        "g,h,i\n",
        "j,k,l\n",
        "d,e,f\n",
        "g,h,i\n",
        "j,k,l\n",
        "d,e,f\n",
        "g,h,i\n",
        "j,k,l\"\"\"\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jMi6_-y9fmUn",
        "outputId": "4a620547-ec55-4849-f592-44ffd5de061e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a,b,c\\nd,e,f\\ng,h,i\\nj,k,l\\nd,e,f\\ng,h,i\\nj,k,l\\nd,e,f\\ng,h,i\\nj,k,l\\nd,e,f\\ng,h,i\\nj,k,l'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.splitlines()\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "khbi8r49f-_b",
        "outputId": "fb4b9def-c53e-4b97-b266-460723f9bf43"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a,b,c\\nd,e,f\\ng,h,i\\nj,k,l\\nd,e,f\\ng,h,i\\nj,k,l\\nd,e,f\\ng,h,i\\nj,k,l\\nd,e,f\\ng,h,i\\nj,k,l'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "li=data.split('\\n')# list of items\n",
        "li\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKGaidC1ik3C",
        "outputId": "21c5a2eb-8eb1-4cca-d238-98b2ed7839b1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a,b,c',\n",
              " 'd,e,f',\n",
              " 'g,h,i',\n",
              " 'j,k,l',\n",
              " 'd,e,f',\n",
              " 'g,h,i',\n",
              " 'j,k,l',\n",
              " 'd,e,f',\n",
              " 'g,h,i',\n",
              " 'j,k,l',\n",
              " 'd,e,f',\n",
              " 'g,h,i',\n",
              " 'j,k,l']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ld=len(li)\n",
        "ld\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hZthKGciLrv",
        "outputId": "3d116b3a-afd9-476c-f1cf-df74c83cb542"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k=5\n",
        "# np.random.uniform(1, ld+1, size=k)//1"
      ],
      "metadata": {
        "id": "rCNhZ4yYiL_D"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positionitem=np.random.randint(ld, size=100)\n",
        "positionitem\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzUkYT9Vlllw",
        "outputId": "9b927ed3-7ea9-419c-8a1e-04a411974b96"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 9,  1, 10, 11,  4,  8,  5,  4,  5, 12,  5,  6,  1,  9,  3,  0,  0,\n",
              "        8,  4,  1,  8,  9, 12,  1, 11,  7,  4,  9,  6,  1,  5, 11,  6,  9,\n",
              "        6, 11,  5,  5,  1,  2, 12,  5,  2,  4,  7, 12,  8,  3,  4,  4,  9,\n",
              "        2,  2,  6,  3, 12,  8,  3,  9,  0,  9,  6,  1,  7,  6, 10,  4, 10,\n",
              "        7, 10,  1,  0,  4,  9,  0,  6,  6,  4,  5,  8,  8,  9,  6, 11,  4,\n",
              "        4,  4,  6,  3,  2, 12, 10, 10,  6,  4,  9, 12,  4,  4, 12])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "5pAlOrJaxhJR"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(positionitem, bins =1)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "aLNASWszMzmF",
        "outputId": "7b8c2921-bebf-457f-aaef-e25d10f2ffa8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set(positionitem)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ehh3WdDMcgw",
        "outputId": "6c75ab1e-cf27-49f5-ce22-eb5fac9e62d6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercício 1.3\n",
        "\n",
        "Em aprendizado profundo é comum termos que lidar com arquivos muito grandes.\n",
        "\n",
        "Dado um arquivo de texto onde cada item é separado por `\\n`, escreva um programa que amostre `k` itens desse arquivo aleatoriamente.\n",
        "\n",
        "Nota 1: Assuma amostragem de uma distribuição uniforme, ou seja, todos os itens tem a mesma probablidade de amostragem.\n",
        "\n",
        "Nota 2: Assuma que o arquivo não cabe em memória.\n",
        "\n",
        "Nota 3: Utilize apenas bibliotecas nativas do python."
      ],
      "metadata": {
        "id": "E-uNjz46kvlc"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PsadE9SRG_9"
      },
      "source": [
        "def sample(path: str, k: int):\n",
        "  # Escreva o seu código aqui.\n",
        "  dat=path\n",
        "  Li=dat.split('\\n')# list of items\n",
        "  Ld=len(Li)\n",
        "  Pi=np.random.randint(Ld, size=k)#=Position of item\n",
        "  return [Li[i] for i in Pi]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycEnlFWxSt0i"
      },
      "source": [
        "Mostre que sua implementação está correta com um exemplo pequeno:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyLJ1e2ZSzC9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a676b54e-33b3-4583-e5e4-9b8e056fd9ff"
      },
      "source": [
        "filename = 'small.txt'\n",
        "total_size = 100\n",
        "n_samples = 10\n",
        "\n",
        "with open(filename, 'w') as fout:\n",
        "    fout.write('\\n'.join(f'line {i}' for i in range(total_size)))\n",
        "\n",
        "samples = sample(path=filename, k=n_samples)\n",
        "print(samples)\n",
        "print(len(samples) == n_samples)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['small.txt', 'small.txt', 'small.txt', 'small.txt', 'small.txt', 'small.txt', 'small.txt', 'small.txt', 'small.txt', 'small.txt']\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2r4FMiMj12Xg"
      },
      "source": [
        "Mostre que sua implementação é eficiente com um exemplo grande:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUwnNMGg18Ty"
      },
      "source": [
        "filename = 'large.txt'\n",
        "total_size = 1_000_000\n",
        "n_samples = 10000\n",
        "\n",
        "with open(filename, 'w') as fout:\n",
        "    fout.write('\\n'.join(f'line {i}' for i in range(total_size)))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA9sAZmo0UDN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf764582-d65a-4ca8-8d5e-aafeb1e4d29b"
      },
      "source": [
        "%%timeit\n",
        "samples = sample(path=filename, k=n_samples)\n",
        "assert len(samples) == n_samples"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000 loops, best of 5: 1.01 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udS0Ns4etoJs"
      },
      "source": [
        "# Parte 2:\n",
        "\n",
        "##Exercícios de Numpy\n",
        "\n",
        "Nesta parte deve-se usar apenas a biblioteca NumPy. Aqui não se pode usar o PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcMz3Vzjt144"
      },
      "source": [
        "##Exercício 2.1\n",
        "\n",
        "Quantos operações de ponto flutuante (flops) de soma e de multiplicação tem a multiplicação matricial $AB$, sendo que a matriz $A$ tem tamanho $m \\times n$ e a matriz $B$ tem tamanho $n \\times p$?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gNXj45RJqUm"
      },
      "source": [
        "Resposta:\n",
        "- número de somas: $n*m*p$\n",
        "- número de multiplicações: $n*m*p$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iI7udBFeDlP"
      },
      "source": [
        "## Exercício 2.2\n",
        "\n",
        "Em programação matricial, não se faz o loop em cada elemento da matriz,\n",
        "mas sim, utiliza-se operações matriciais.\n",
        "\n",
        "Dada a matriz `A` abaixo, calcule a média dos valores de cada linha sem utilizar laços explícitos.\n",
        "\n",
        "Utilize apenas a biblioteca numpy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjrXf18N5KrK"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fqxgNBW27Z0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67879f26-65e5-4ffe-daea-eec91ba47708"
      },
      "source": [
        "A = np.arange(24).reshape(4, 6)\n",
        "print(A)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  1  2  3  4  5]\n",
            " [ 6  7  8  9 10 11]\n",
            " [12 13 14 15 16 17]\n",
            " [18 19 20 21 22 23]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nrow=len(A)\n",
        "ncol=len(A[0])\n",
        "nrow,ncol"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_ouoGjmigok",
        "outputId": "0bad3ddf-88b4-453d-8cf9-a7bcd9945359"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c=np.ones(ncol).reshape(ncol,1)\n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pdb3QasTjvBj",
        "outputId": "afede730-fb83-4f6f-e243-c627ee4412e3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "medias=np.matmul(A,c)/ncol\n",
        "medias.T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDrDA_8ajt2V",
        "outputId": "d9374d32-66b5-4297-e242-24956767e501"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2.5,  8.5, 14.5, 20.5]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1EmKFrT5g7B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04cffd4d-9bb8-4fd2-b649-994ebd58056c"
      },
      "source": [
        "# Escreva sua solução aqui.\n",
        "list(medias.T[0])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.5, 8.5, 14.5, 20.5]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtgSAAKjUfcO"
      },
      "source": [
        "## Exercício 2.3\n",
        "\n",
        "Seja a matriz $C$ que é a normalização da matriz $A$:\n",
        "$$ C(i,j) = \\frac{A(i,j) - A_{min}}{A_{max} - A_{min}} $$\n",
        "\n",
        "Normalizar a matriz `A` do exercício acima de forma que seus valores fiquem entre 0 e 1."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=A.flatten()\n",
        "amin=min(a)\n",
        "amax=max(a)\n",
        "amin,amax"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOHhHKvEoSGi",
        "outputId": "5e9e10ff-d9f9-46ea-ee59-67d041ce0d1f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 23)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C=(A-amin)/(amax-amin)\n",
        "C"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpF2M9bCppvm",
        "outputId": "208cc636-f05d-4287-e026-2da175d3f680"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.04347826, 0.08695652, 0.13043478, 0.17391304,\n",
              "        0.2173913 ],\n",
              "       [0.26086957, 0.30434783, 0.34782609, 0.39130435, 0.43478261,\n",
              "        0.47826087],\n",
              "       [0.52173913, 0.56521739, 0.60869565, 0.65217391, 0.69565217,\n",
              "        0.73913043],\n",
              "       [0.7826087 , 0.82608696, 0.86956522, 0.91304348, 0.95652174,\n",
              "        1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-11T00:00:34.072719Z",
          "start_time": "2019-12-11T00:00:34.036017Z"
        },
        "id": "_pDhb2-0eDlS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92d24a84-9aaa-4cad-d846-ee184ad50bfe"
      },
      "source": [
        "# Escreva sua solução aqui.\n",
        "C"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.04347826, 0.08695652, 0.13043478, 0.17391304,\n",
              "        0.2173913 ],\n",
              "       [0.26086957, 0.30434783, 0.34782609, 0.39130435, 0.43478261,\n",
              "        0.47826087],\n",
              "       [0.52173913, 0.56521739, 0.60869565, 0.65217391, 0.69565217,\n",
              "        0.73913043],\n",
              "       [0.7826087 , 0.82608696, 0.86956522, 0.91304348, 0.95652174,\n",
              "        1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def nomarry(AA):\n",
        "  aa=AA.flatten()\n",
        "  return (AA-min(aa))/(max(aa)-min(aa))"
      ],
      "metadata": {
        "id": "lFgwdOi8qw2v"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF_P_GARU62m"
      },
      "source": [
        "## Exercício 2.4\n",
        "\n",
        "Modificar o exercício anterior de forma que os valores de cada *coluna* da matriz `A` sejam normalizados entre 0 e 1 independentemente dos valores das outras colunas.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-gaaYljtr-b",
        "outputId": "885ffdfe-8bec-45d2-dbdc-1f64420b8b3b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  1,  2,  3,  4,  5],\n",
              "       [ 6,  7,  8,  9, 10, 11],\n",
              "       [12, 13, 14, 15, 16, 17],\n",
              "       [18, 19, 20, 21, 22, 23]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NgVzFOYeDla"
      },
      "source": [
        "# Escreva sua solução aqui."
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "At=A.T\n",
        "At"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqoFWkDysRxV",
        "outputId": "3beba754-fb8a-41db-d320-3e08c29deb58"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  6, 12, 18],\n",
              "       [ 1,  7, 13, 19],\n",
              "       [ 2,  8, 14, 20],\n",
              "       [ 3,  9, 15, 21],\n",
              "       [ 4, 10, 16, 22],\n",
              "       [ 5, 11, 17, 23]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array([nomarry(col) for col in At]).T\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dOkX5nVsvWV",
        "outputId": "44196408-db1c-429c-ac23-3f1db52d1ac3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.33333333, 0.33333333, 0.33333333, 0.33333333, 0.33333333,\n",
              "        0.33333333],\n",
              "       [0.66666667, 0.66666667, 0.66666667, 0.66666667, 0.66666667,\n",
              "        0.66666667],\n",
              "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbXIXsDIUmtp"
      },
      "source": [
        "## Exercício 2.5\n",
        "\n",
        "Modificar o exercício anterior de forma que os valores de cada *linha* da matriz `A` sejam normalizados entre 0 e 1 independentemente dos valores das outras linhas.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.min(A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6KM9v3WugR3",
        "outputId": "6ea784ba-65b4-488f-c567-8269fcd353e4"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array([nomarry(row) for row in A])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmdYncnPvBxo",
        "outputId": "0d55cc51-50d0-4f1e-8515-55030b0a438f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0. , 0.2, 0.4, 0.6, 0.8, 1. ],\n",
              "       [0. , 0.2, 0.4, 0.6, 0.8, 1. ],\n",
              "       [0. , 0.2, 0.4, 0.6, 0.8, 1. ],\n",
              "       [0. , 0.2, 0.4, 0.6, 0.8, 1. ]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-10T17:56:40.413601Z",
          "start_time": "2019-12-10T17:56:40.405056Z"
        },
        "id": "i-5Hv8-heDlW"
      },
      "source": [
        "# Escreva sua solução aqui."
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKnLAyL7zgpa"
      },
      "source": [
        "## Exercício 2.6\n",
        "\n",
        "A [função softmax](https://en.wikipedia.org/wiki/Softmax_function) é bastante usada em apredizado de máquina para converter uma lista de números para uma distribuição de probabilidade, isto é, os números ficarão normalizados entre zero e um e sua soma será igual à um.\n",
        "\n",
        "Implemente a função softmax com suporte para batches, ou seja, o softmax deve ser aplicado a cada linha da matriz. Deve-se usar apenas a biblioteca numpy. Se atente que a exponenciação gera estouro de representação quando os números da entrada são muito grandes. Tente corrigir isto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lA5W9vxNEmOj"
      },
      "source": [
        "import numpy as np\n",
        "def softmax(AA):\n",
        "  '''\n",
        "  Aplica a função de softmax à matriz `A`.\n",
        "\n",
        "  Entrada:\n",
        "  `A` é uma matriz M x N, onde M é o número de exemplos a serem processados\n",
        "  independentemente e N é o tamanho de cada exemplo.\n",
        "\n",
        "  Saída:\n",
        "  Uma matriz M x N, onde a soma de cada linha é igual a um.\n",
        "  '''\n",
        "  # Escreva sua solução aqui.\n",
        "  # we have to be becarfull when sum  of a bach get to infinit if this is the case\n",
        "  # we have to change the expresion to the sofmax: 1/sum(np.exp(B-e)\n",
        "  # on the contrary we use the regular expresion of sofmax:  np.exp(e)/sum(np.exp(B))\n",
        "  # where B is the row of matrix AA, and e is an element of B\n",
        "  return np.array([[1/sum(np.exp(B-e)) if np.isinf(sum(np.exp(B))) else np.exp(e)/sum(np.exp(B)) for e in B] for B in AA]) "
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def softmax(AA):\n",
        "  '''\n",
        "  Aplica a função de softmax à matriz `A`.\n",
        "\n",
        "  Entrada:\n",
        "  `A` é uma matriz M x N, onde M é o número de exemplos a serem processados\n",
        "  independentemente e N é o tamanho de cada exemplo.\n",
        "\n",
        "  Saída:\n",
        "  Uma matriz M x N, onde a soma de cada linha é igual a um.\n",
        "  '''\n",
        "  # Escreva sua solução aqui.\n",
        "  # we have to be becarfull when the sum  of a bach get to infinit if this is the case\n",
        "  # we have to change the expresion to the sofmax: 1/sum(np.exp(B-e)\n",
        "  return np.array([[1/sum(np.exp(B-e))   for e in B] for B in AA]) "
      ],
      "metadata": {
        "id": "MtytKlKbr82S"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpxlbh4ND54q"
      },
      "source": [
        "Mostre que sua implementação está correta usando uma matriz pequena como entrada:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.array([[0.5, -1, 1000],\n",
        "              [-2,   0, 0.5]])\n",
        "softmax(A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wv6PFUUpsJES",
        "outputId": "6aefe3df-df1e-4e52-cd86-db1c28fb0284"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in exp\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 1.        ],\n",
              "       [0.04861082, 0.35918811, 0.59220107]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j2uXmKH8HF4"
      },
      "source": [
        "O código a seguir verifica se sua implementação do softmax está correta. \n",
        "- A soma de cada linha de A deve ser 1;\n",
        "- Os valores devem estar entre 0 e 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-sN4STk7qyN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aa3315f-6321-4b05-e398-352a5388b0cf"
      },
      "source": [
        "np.allclose(softmax(A).sum(axis=1), 1) and softmax(A).min() >= 0 and softmax(A).max() <= 1"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in exp\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(AA):\n",
        "  '''\n",
        "  Aplica a função de softmax à matriz `A`.\n",
        "\n",
        "  Entrada:\n",
        "  `A` é uma matriz M x N, onde M é o número de exemplos a serem processados\n",
        "  independentemente e N é o tamanho de cada exemplo.\n",
        "\n",
        "  Saída:\n",
        "  Uma matriz M x N, onde a soma de cada linha é igual a um.\n",
        "  '''\n",
        "  # Escreva sua solução aqui.\n",
        "  # we have to be becarfull when the sum  of a bach get to infinit if this is the case\n",
        "  # we have to limit that the program get to inf.\n",
        "  eA2=np.exp(AA-AA.max(axis=1).reshape(-1, 1))# line of code from Pedro Guilherme Siqueira Moreira (thanks)\n",
        "  return eA2/eA2.sum(axis=1).reshape(-1, 1)# line of code form Patrick de Carvalho Tavares Rezende Ferreira (thanks)"
      ],
      "metadata": {
        "id": "cvEf6Qud-o18"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5_ZRWRfCZtI"
      },
      "source": [
        "Mostre que sua implementação é eficiente usando uma matriz grande como entrada:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhUeyrGaJ3J2"
      },
      "source": [
        "A = np.random.uniform(low=-10, high=10, size=(128, 100_000))"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "softmax(A)"
      ],
      "metadata": {
        "id": "P5TUJATSsDlJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "331cde06-e34a-44f6-f23e-1c21999bf15c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 283 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XE6LaWi81zZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0cef460-1fbb-46fa-fc36-3814f0ce5dec"
      },
      "source": [
        "SM = softmax(A)\n",
        "np.allclose(SM.sum(axis=1), 1) and SM.min() >= 0 and SM.max() <= 1"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Flr1lI5o-HpG"
      },
      "source": [
        "## Exercício 2.7\n",
        "\n",
        "A codificação one-hot é usada para codificar entradas categóricas. É uma codificação onde apenas um bit é 1 e os demais são zero, conforme a tabela a seguir.\n",
        "\n",
        "| Decimal | Binary | One-hot\n",
        "| ------- | ------ | -------\n",
        "| 0 | 000    | 1 0 0 0 0 0 0 0\n",
        "| 1 | 001    | 0 1 0 0 0 0 0 0\n",
        "| 2 | 010    | 0 0 1 0 0 0 0 0\n",
        "| 3 | 011    | 0 0 0 1 0 0 0 0\n",
        "| 4 | 100    | 0 0 0 0 1 0 0 0\n",
        "| 5 | 101    | 0 0 0 0 0 1 0 0\n",
        "| 6 | 110    | 0 0 0 0 0 0 1 0\n",
        "| 7 | 111    | 0 0 0 0 0 0 0 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CqXP_5ABbfo"
      },
      "source": [
        "Implemente a função one_hot(y, n_classes) que codifique o vetor de inteiros y que possuem valores entre 0 e n_classes-1.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la-02w7qCH7L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "56a1e622-a7ec-4219-ff4f-aefb21dc9f4a"
      },
      "source": [
        "\"\"\"\n",
        "def one_hots(y, n_classes):\n",
        "  # Escreva seu código aqui.\n",
        "  lc=list(range(N_CLASSES))#class list\n",
        "  sp= ''\n",
        "  OHL=[sp.join(['1' if c1==c2 else '0' for  c1  in lc ])  for c2 in lc]\n",
        "  dec2oh=dict( (d,oh) for d,oh in zip(lc,OHL))# decimal to one hot\n",
        "  return [[i,dec2oh[i]] for i in y]\n",
        "\"\"\"  "
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef one_hots(y, n_classes):\\n  # Escreva seu código aqui.\\n  lc=list(range(N_CLASSES))#class list\\n  sp= ''\\n  OHL=[sp.join(['1' if c1==c2 else '0' for  c1  in lc ])  for c2 in lc]\\n  dec2oh=dict( (d,oh) for d,oh in zip(lc,OHL))# decimal to one hot\\n  return [[i,dec2oh[i]] for i in y]\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(y, n_classes):\n",
        "  # Escreva seu código aqui.\n",
        "  lc=list(range(N_CLASSES))#class list\n",
        "  OHL=[[1 if c1==c2 else 0 for  c1  in lc ]  for c2 in lc]\n",
        "  dec2oh=dict( (d,oh) for d,oh in zip(lc,OHL))# decimal to one hot\n",
        "  return [[i,dec2oh[i]] for i in y]"
      ],
      "metadata": {
        "id": "5AdvxNlZkxUe"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf5zyZO5Aiz_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "787a956d-7a6a-4a81-998e-4436fe2a38c3"
      },
      "source": [
        "import numpy as np\n",
        "N_CLASSES = 9\n",
        "N_SAMPLES = 10\n",
        "y = (np.random.rand((N_SAMPLES)) * N_CLASSES).astype(np.int)\n",
        "print(y)\n",
        "print(one_hot(y, N_CLASSES))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4 7 2 4 7 0 2 2 5 5]\n",
            "[[4, [0, 0, 0, 0, 1, 0, 0, 0, 0]], [7, [0, 0, 0, 0, 0, 0, 0, 1, 0]], [2, [0, 0, 1, 0, 0, 0, 0, 0, 0]], [4, [0, 0, 0, 0, 1, 0, 0, 0, 0]], [7, [0, 0, 0, 0, 0, 0, 0, 1, 0]], [0, [1, 0, 0, 0, 0, 0, 0, 0, 0]], [2, [0, 0, 1, 0, 0, 0, 0, 0, 0]], [2, [0, 0, 1, 0, 0, 0, 0, 0, 0]], [5, [0, 0, 0, 0, 0, 1, 0, 0, 0]], [5, [0, 0, 0, 0, 0, 1, 0, 0, 0]]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(one_hot(y, N_CLASSES))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxAbjktCvJp5",
        "outputId": "5621550b-a1d9-4e77-b19d-061223908cf4"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4, [0, 0, 0, 0, 1, 0, 0, 0, 0]], [7, [0, 0, 0, 0, 0, 0, 0, 1, 0]], [2, [0, 0, 1, 0, 0, 0, 0, 0, 0]], [4, [0, 0, 0, 0, 1, 0, 0, 0, 0]], [7, [0, 0, 0, 0, 0, 0, 0, 1, 0]], [0, [1, 0, 0, 0, 0, 0, 0, 0, 0]], [2, [0, 0, 1, 0, 0, 0, 0, 0, 0]], [2, [0, 0, 1, 0, 0, 0, 0, 0, 0]], [5, [0, 0, 0, 0, 0, 1, 0, 0, 0]], [5, [0, 0, 0, 0, 0, 1, 0, 0, 0]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nwuKnQUCzve"
      },
      "source": [
        "Mostre que sua implementação é eficiente usando uma matriz grande como entrada:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwuFy5rWC2tA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f24b86e-5706-4550-a6e5-6eada7ab40e5"
      },
      "source": [
        "N_SAMPLES = 100_000\n",
        "N_CLASSES = 1_000\n",
        "y = (np.random.rand((N_SAMPLES)) * N_CLASSES).astype(np.int)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7azMtF7wDJ2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef969f6f-43bf-4918-97b7-d4a930289b55"
      },
      "source": [
        "%%timeit\n",
        "one_hot(y, N_CLASSES)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loops, best of 5: 106 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercício 2.8\n",
        "\n",
        "Implemente uma classe que normalize um array de pontos flutuantes `array_a` para a mesma média e desvio padrão de um outro array `array_b`, conforme exemplo abaixo:\n",
        "```\n",
        "array_a = np.array([-1, 1.5, 0])\n",
        "array_b = np.array([1.4, 0.8, 0.3, 2.5])\n",
        "normalize = Normalizer(array_b)\n",
        "normalized_array = normalize(array_a)\n",
        "print(normalized_array)  # Deve imprimir [0.3187798  2.31425165 1.11696854]\n",
        "```"
      ],
      "metadata": {
        "id": "qmzViEtHHV41"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlkNNU6h5RbR"
      },
      "source": [
        "Mostre que seu código está correto com o exemplo abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "5m03LrYWbqN9"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Normalizer:\n",
        "  def __init__(self, arrb):\n",
        "    self.meanb = np.mean(arrb)\n",
        "    self.sdtb=np.std(arrb)\n",
        "  def __call__(self,arr):\n",
        "    self.arr=arr\n",
        "    self.mean = np.mean(arr)\n",
        "    self.sdt=np.std(arr)    \n",
        "    M=self.arr-self.mean\n",
        "    D=self.sdtb/self.sdt\n",
        "    return M*D+self.meanb  "
      ],
      "metadata": {
        "id": "ga-l1hufrE2v"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "array_a = np.array([-1, 1.5, 0])\n",
        "array_b = np.array([1.4, 0.8, 0.3, 2.5])\n",
        "normalize = Normalizer(array_b)\n",
        "normalized_array = normalize(array_a)\n",
        "print(normalized_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "646c63ae-a6e4-4de6-c2e3-d8cbadbf129e",
        "id": "mfqa9a6TrFNM"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.3187798  2.31425165 1.11696854]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrGVQFUYI_LP"
      },
      "source": [
        "# Parte 3:\n",
        "\n",
        "##Exercícios Pytorch: Grafo Computacional e Gradientes\n",
        "\n",
        "Nesta parte pode-se usar quaisquer bibliotecas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIlQdKAuCZtR"
      },
      "source": [
        "Um dos principais fundamentos para que o PyTorch seja adequado para deep learning é a sua habilidade de calcular o gradiente automaticamente a partir da expressões definidas. Essa facilidade é implementada através do cálculo automático do gradiente e construção dinâmica do grafo computacional."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF_-dJ2nCZtT"
      },
      "source": [
        "## Grafo computacional\n",
        "\n",
        "Seja um exemplo simples de uma função de perda J dada pela Soma dos Erros ao Quadrado (SEQ - Sum of Squared Errors): \n",
        "$$ J = \\sum_i (x_i w - y_i)^2 $$\n",
        "que pode ser reescrita como:\n",
        "$$ \\hat{y_i} = x_i w $$\n",
        "$$ e_i = \\hat{y_i} - y_i $$\n",
        "$$ e2_i = e_i^2 $$\n",
        "$$ J = \\sum_i e2_i $$\n",
        "\n",
        "As redes neurais são treinadas através da minimização de uma função de perda usando o método do gradiente descendente. Para ajustar o parâmetro $w$ precisamos calcular o gradiente $  \\frac{ \\partial J}{\\partial w} $. Usando a\n",
        "regra da cadeia podemos escrever:\n",
        "$$ \\frac{ \\partial J}{\\partial w} = \\frac{ \\partial J}{\\partial e2_i} \\frac{ \\partial e2_i}{\\partial e_i} \\frac{ \\partial e_i}{\\partial \\hat{y_i} } \\frac{ \\partial \\hat{y_i}}{\\partial w}$$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jboejVQMCZtU"
      },
      "source": [
        "```\n",
        "    y_pred = x * w\n",
        "    e = y_pred - y\n",
        "    e2 = e**2\n",
        "    J = e2.sum()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7JmU6qhc2Y2"
      },
      "source": [
        "As quatro expressões acima, para o cálculo do J podem ser representadas pelo grafo computacional visualizado a seguir: os círculos são as variáveis (tensores), os quadrados são as operações, os números em preto são os cálculos durante a execução das quatro expressões para calcular o J (forward, predict). O cálculo do gradiente, mostrado em vermelho, é calculado pela regra da cadeia, de trás para frente (backward)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeeEBKl4CZtV"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/robertoalotufo/files/master/figures/GrafoComputacional.png\" width=\"600pt\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yZun7wrCZtX"
      },
      "source": [
        "Para entender melhor o funcionamento do grafo computacional com os tensores, recomenda-se leitura em:\n",
        "\n",
        "https://pytorch.org/docs/stable/notes/autograd.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-11T00:23:00.431853Z",
          "start_time": "2019-12-11T00:23:00.414813Z"
        },
        "id": "HlT2d-4fCZtZ"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-11T00:23:00.863228Z",
          "start_time": "2019-12-11T00:23:00.844457Z"
        },
        "id": "xX0QwUduCZtf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "526fe811-aca3-4552-c6cb-d9e0de0b197b"
      },
      "source": [
        "torch.__version__"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.10.0+cu111'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsqzALS4CZtl"
      },
      "source": [
        "**Tensor com atributo .requires_grad=True**\n",
        "\n",
        "Quando um tensor possui o atributo `requires_grad` como verdadeiro, qualquer expressão que utilizar esse tensor irá construir um grafo computacional para permitir posteriormente, após calcular a função a ser derivada, poder usar a regra da cadeia e calcular o gradiente da função em termos dos tensores que possuem o atributo `requires_grad`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:22.117010Z",
          "start_time": "2019-09-29T03:07:22.041861Z"
        },
        "id": "foaAb94aCZtm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cea8cfb0-007b-4910-fcd8-7cb5832c0577"
      },
      "source": [
        "y = torch.arange(0, 8, 2).float()\n",
        "y"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 2., 4., 6.])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:28.610934Z",
          "start_time": "2019-09-29T03:07:28.598223Z"
        },
        "id": "no6SdSyICZtr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0369ccb5-9191-4ce1-8749-2296c68d4013"
      },
      "source": [
        "x = torch.arange(0, 4).float()\n",
        "x"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:31.523762Z",
          "start_time": "2019-09-29T03:07:31.497683Z"
        },
        "id": "eL_i1mwGCZtw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37faa274-b71e-404c-c816-e4028ba25ff2"
      },
      "source": [
        "w = torch.ones(1, requires_grad=True)\n",
        "w"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjEl-0l7CZt0"
      },
      "source": [
        "## Cálculo automático do gradiente da função perda J"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pUh-SCnCZt1"
      },
      "source": [
        "Seja a expressão: $$ J = \\sum_i ((x_i  w) - y_i)^2 $$\n",
        "\n",
        "Queremos calcular a derivada de $J$ em relação a $w$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMwwVtJ1CZt2"
      },
      "source": [
        "## Forward pass\n",
        "\n",
        "Durante a execução da expressão, o grafo computacional é criado. Compare os valores de cada parcela calculada com os valores em preto da figura ilustrativa do grafo computacional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:36.290122Z",
          "start_time": "2019-09-29T03:07:36.273229Z"
        },
        "id": "zp2aK4YhCZt3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5e247d1-f6e4-4133-fecf-e22833bb9cd6"
      },
      "source": [
        "# predict (forward)\n",
        "y_pred = x * w; print('y_pred =', y_pred)\n",
        "\n",
        "# cálculo da perda J: loss\n",
        "e = y_pred - y; print('e =',e)\n",
        "e2 = e.pow(2) ; print('e2 =', e2)\n",
        "J = e2.sum()  ; print('J =', J)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_pred = tensor([0., 1., 2., 3.], grad_fn=<MulBackward0>)\n",
            "e = tensor([ 0., -1., -2., -3.], grad_fn=<SubBackward0>)\n",
            "e2 = tensor([0., 1., 4., 9.], grad_fn=<PowBackward0>)\n",
            "J = tensor(14., grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC96wB7PCZt8"
      },
      "source": [
        "## Backward pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-10-04T15:55:45.308858",
          "start_time": "2017-10-04T15:55:45.304654"
        },
        "id": "kKbf4D0CCZt-"
      },
      "source": [
        "O `backward()` varre o grafo computacional a partir da variável a ele associada (raiz) e calcula o gradiente para todos os tensores que possuem o atributo `requires_grad` como verdadeiro.\n",
        "Observe que os tensores que tiverem o atributo `requires_grad` serão sempre folhas no grafo computacional.\n",
        "O `backward()` destroi o grafo após sua execução. Esse comportamento é padrão no PyTorch. \n",
        "\n",
        "A título ilustrativo, se quisermos depurar os gradientes dos nós que não são folhas no grafo computacional, precisamos primeiro invocar `retain_grad()` em cada um desses nós, como a seguir. Entretanto nos exemplos reais não há necessidade de verificar o gradiente desses nós."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-CjLPu6clVo"
      },
      "source": [
        "e2.retain_grad()\n",
        "e.retain_grad()\n",
        "y_pred.retain_grad()"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtsZS2Bicof-"
      },
      "source": [
        "E agora calculamos os gradientes com o `backward()`.\n",
        "\n",
        "w.grad é o gradiente de J em relação a w."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:40.267334Z",
          "start_time": "2019-09-29T03:07:40.247422Z"
        },
        "id": "Z1lnkb0GCZt_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f290cf71-aead-45de-bc96-42b4085dacb1"
      },
      "source": [
        "if w.grad: w.grad.zero_()\n",
        "J.backward()\n",
        "print(w.grad)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-28.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1xYDPR_uOcZ"
      },
      "source": [
        "Mostramos agora os gradientes que estão grafados em vermelho no grafo computacional:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Enuk2tf0sDyO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "283b34a9-13e0-4666-cb53-729d67be23a2"
      },
      "source": [
        "print(e2.grad)\n",
        "print(e.grad)\n",
        "print(y_pred.grad)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1.])\n",
            "tensor([ 0., -2., -4., -6.])\n",
            "tensor([ 0., -2., -4., -6.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsOThnt8fDJV"
      },
      "source": [
        "##Exercício 3.1\n",
        "Calcule o mesmo gradiente ilustrado no exemplo anterior usando a regra das diferenças finitas, de acordo com a equação a seguir, utilizando um valor de $\\Delta w$ bem pequeno.\n",
        "\n",
        "$$ \\frac{\\partial J}{\\partial w} = \\frac{J(w + \\Delta w) - J(w - \\Delta w)}{2 \\Delta w} $$"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def J_func(w,x,y):\n",
        "  y_pred=x*w\n",
        "  e=y_pred-y\n",
        "  e2=e**2\n",
        "  J=e2.sum()\n",
        "  return J\n",
        "  \n",
        "def Gradj(w,x,y):\n",
        "  dJdw=2*x*(x*w-y)\n",
        "  return dJdw.sum()\n"
      ],
      "metadata": {
        "id": "lkAyuZhHgJsq"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "62nZAfUoCZu5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "094c50de-1d39-4755-aceb-24ca60d3f66f"
      },
      "source": [
        "# Calcule o gradiente usando a regra diferenças finitas\n",
        "# Confira com o valor já calculado anteriormente\n",
        "x = torch.arange(0, 4).float()\n",
        "y = torch.arange(0, 8, 2).float()\n",
        "w = torch.ones(1)\n",
        "grad = Gradj(w,x,y)#?\n",
        "print('grad=', grad)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grad= tensor(-28.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_Sx1QXZxJ3u"
      },
      "source": [
        "##Exercício 3.2\n",
        "\n",
        "Minimizando $J$ pelo gradiente descendente\n",
        "\n",
        "$$ w_{k+1} = w_k - \\lambda \\frac {\\partial J}{\\partial w} $$\n",
        "\n",
        "Supondo que valor inicial ($k=0$) $w_0 = 1$, use learning rate $\\lambda = 0.01$ para calcular o valor do novo $w_{20}$, ou seja, fazendo 20 atualizações de gradientes. Deve-se usar a função `J_func` criada no exercício anterior.\n",
        "\n",
        "Confira se o valor do primeiro gradiente está de acordo com os valores já calculado acima"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNszCOED1Wtu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5dec7fa-aabf-461a-b3ba-1fea58bd37bf"
      },
      "source": [
        "learning_rate =lr= 0.01\n",
        "iteracoes = 20\n",
        "\n",
        "x = torch.arange(0, 4).float()\n",
        "y = torch.arange(0, 8, 2).float()\n",
        "w = torch.ones(1)\n",
        "\n",
        "lossJ=[]\n",
        "for i in range(iteracoes):\n",
        "    print('i =', i)\n",
        "    J = J_func(w, x, y)\n",
        "    print('J=', J)\n",
        "    lossJ.append(J.detach().numpy())# convertin into a numpy array\n",
        "    grad = Gradj(w,x,y)#?\n",
        "    print('grad =',grad)\n",
        "    w =w-lr*grad# ?\n",
        "    print('i:',i,' w =', w)\n",
        "\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i = 0\n",
            "J= tensor(14.)\n",
            "grad = tensor(-28.)\n",
            "i: 0  w = tensor([1.2800])\n",
            "i = 1\n",
            "J= tensor(7.2576)\n",
            "grad = tensor(-20.1600)\n",
            "i: 1  w = tensor([1.4816])\n",
            "i = 2\n",
            "J= tensor(3.7623)\n",
            "grad = tensor(-14.5152)\n",
            "i: 2  w = tensor([1.6268])\n",
            "i = 3\n",
            "J= tensor(1.9504)\n",
            "grad = tensor(-10.4509)\n",
            "i: 3  w = tensor([1.7313])\n",
            "i = 4\n",
            "J= tensor(1.0111)\n",
            "grad = tensor(-7.5247)\n",
            "i: 4  w = tensor([1.8065])\n",
            "i = 5\n",
            "J= tensor(0.5241)\n",
            "grad = tensor(-5.4178)\n",
            "i: 5  w = tensor([1.8607])\n",
            "i = 6\n",
            "J= tensor(0.2717)\n",
            "grad = tensor(-3.9008)\n",
            "i: 6  w = tensor([1.8997])\n",
            "i = 7\n",
            "J= tensor(0.1409)\n",
            "grad = tensor(-2.8086)\n",
            "i: 7  w = tensor([1.9278])\n",
            "i = 8\n",
            "J= tensor(0.0730)\n",
            "grad = tensor(-2.0222)\n",
            "i: 8  w = tensor([1.9480])\n",
            "i = 9\n",
            "J= tensor(0.0379)\n",
            "grad = tensor(-1.4560)\n",
            "i: 9  w = tensor([1.9626])\n",
            "i = 10\n",
            "J= tensor(0.0196)\n",
            "grad = tensor(-1.0483)\n",
            "i: 10  w = tensor([1.9730])\n",
            "i = 11\n",
            "J= tensor(0.0102)\n",
            "grad = tensor(-0.7548)\n",
            "i: 11  w = tensor([1.9806])\n",
            "i = 12\n",
            "J= tensor(0.0053)\n",
            "grad = tensor(-0.5434)\n",
            "i: 12  w = tensor([1.9860])\n",
            "i = 13\n",
            "J= tensor(0.0027)\n",
            "grad = tensor(-0.3913)\n",
            "i: 13  w = tensor([1.9899])\n",
            "i = 14\n",
            "J= tensor(0.0014)\n",
            "grad = tensor(-0.2817)\n",
            "i: 14  w = tensor([1.9928])\n",
            "i = 15\n",
            "J= tensor(0.0007)\n",
            "grad = tensor(-0.2028)\n",
            "i: 15  w = tensor([1.9948])\n",
            "i = 16\n",
            "J= tensor(0.0004)\n",
            "grad = tensor(-0.1460)\n",
            "i: 16  w = tensor([1.9962])\n",
            "i = 17\n",
            "J= tensor(0.0002)\n",
            "grad = tensor(-0.1052)\n",
            "i: 17  w = tensor([1.9973])\n",
            "i = 18\n",
            "J= tensor(0.0001)\n",
            "grad = tensor(-0.0757)\n",
            "i: 18  w = tensor([1.9981])\n",
            "i = 19\n",
            "J= tensor(5.3059e-05)\n",
            "grad = tensor(-0.0545)\n",
            "i: 19  w = tensor([1.9986])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iteracoes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkHx4Yy000iu",
        "outputId": "58981d8c-c9cc-4b8e-8f8c-dbcb7006222d"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plote o gráfico da loss J pela iteração i\n",
        "\n",
        "def plotlossji(it,lj):\n",
        "  \"\"\"\n",
        "  it=iteracoes\n",
        "  lj=lossJ\n",
        "  \"\"\"\n",
        "  x=1+np.arange(it)\n",
        "  y=np.array(lossJ)\n",
        "  plt.figure(figsize=(7,5))\n",
        "  plt.plot(x,y, 's-', color='blue', linewidth =2, markersize=5, label='Loss J')\n",
        "  plt.xticks(np.arange(0, 22, step=1))\n",
        "  plt.grid()\n",
        "  plt.legend()\n",
        "  plt.ylabel('loss (J)')\n",
        "  plt.xlabel('iteração(i)')\n",
        "  plt.title('Gráfico da loss J pela iteração i')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "plotlossji(iteracoes,lossJ)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "YS96wwaiulOv",
        "outputId": "ed95eea5-b3ae-4015-9ad5-3e9d23f1fb42"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBXxBmWGK3IU"
      },
      "source": [
        "##Exercício 3.3\n",
        "\n",
        "Repita o exercício 2 mas usando agora o calculando o gradiente usando o método backward() do pytorch. Confira se o primeiro valor do gradiente está de acordo com os valores anteriores. Execute essa próxima célula duas vezes. Os valores devem ser iguais.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def GradjT(w,x,y):\n",
        "  a=x*w\n",
        "  b=a-y\n",
        "  c=torch.sum(b)\n",
        "  c.backward()\n",
        "  return c#.grad#_fn"
      ],
      "metadata": {
        "id": "0qRNF9jXWny1"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "N,D=3,4\n",
        "x= torch.rand((N,D),requires_grad=True)\n",
        "y= torch.rand((N,D),requires_grad=True)\n",
        "z= torch.rand((N,D),requires_grad=True)\n",
        "a=x*w\n",
        "b=(a-y)**2\n",
        "c=torch.sum(b)\n",
        "c.backward()"
      ],
      "metadata": {
        "id": "M4uiQ2k-3ErB"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMP4d5vtHtqy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b4c1c3d3-4dbb-42c0-f919-d3d48de931b8"
      },
      "source": [
        "learning_rate = 0.01\n",
        "lr=learning_rate\n",
        "iteracoes = 20\n",
        "\n",
        "x = torch.arange(0, 4).float()\n",
        "y = torch.arange(0, 8, 2).float()\n",
        "w = torch.ones(1, requires_grad=True)\n",
        "\n",
        "lossJ=[]\n",
        "\"\"\"\n",
        "we use the auxiliars \"a\", \"b\" and c\" to make an computational graph\n",
        "to calculate the loss J in \"c\"\n",
        "\"\"\"\n",
        "for i in range(iteracoes):\n",
        "    print('i =', i)\n",
        "    J = J_func(w, x, y)\n",
        "    print('J=', J)\n",
        "    lossJ.append(J.detach().numpy())\n",
        "    w.retain_grad()# line of code from Patrick de Carvalho Tavares Rezende Ferreira (thanks)\n",
        "    a=x*w\n",
        "    b=(a-y)**2\n",
        "    c=torch.sum(b)\n",
        "    c.backward()#  Cálculo automático do gradiente da função perda J\n",
        "    grad = w.grad#_fn#?\n",
        "    print('grad =',grad)\n",
        "    w = w-lr*grad\n",
        "    print('w =', w)\n",
        "\n",
        "# Plote aqui a loss pela iteração\n",
        "plotlossji(iteracoes,lossJ)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i = 0\n",
            "J= tensor(14., grad_fn=<SumBackward0>)\n",
            "grad = tensor([-28.])\n",
            "w = tensor([1.2800], grad_fn=<SubBackward0>)\n",
            "i = 1\n",
            "J= tensor(7.2576, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-20.1600])\n",
            "w = tensor([1.4816], grad_fn=<SubBackward0>)\n",
            "i = 2\n",
            "J= tensor(3.7623, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-14.5152])\n",
            "w = tensor([1.6268], grad_fn=<SubBackward0>)\n",
            "i = 3\n",
            "J= tensor(1.9504, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-10.4509])\n",
            "w = tensor([1.7313], grad_fn=<SubBackward0>)\n",
            "i = 4\n",
            "J= tensor(1.0111, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-7.5247])\n",
            "w = tensor([1.8065], grad_fn=<SubBackward0>)\n",
            "i = 5\n",
            "J= tensor(0.5241, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-5.4178])\n",
            "w = tensor([1.8607], grad_fn=<SubBackward0>)\n",
            "i = 6\n",
            "J= tensor(0.2717, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-3.9008])\n",
            "w = tensor([1.8997], grad_fn=<SubBackward0>)\n",
            "i = 7\n",
            "J= tensor(0.1409, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-2.8086])\n",
            "w = tensor([1.9278], grad_fn=<SubBackward0>)\n",
            "i = 8\n",
            "J= tensor(0.0730, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-2.0222])\n",
            "w = tensor([1.9480], grad_fn=<SubBackward0>)\n",
            "i = 9\n",
            "J= tensor(0.0379, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-1.4560])\n",
            "w = tensor([1.9626], grad_fn=<SubBackward0>)\n",
            "i = 10\n",
            "J= tensor(0.0196, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-1.0483])\n",
            "w = tensor([1.9730], grad_fn=<SubBackward0>)\n",
            "i = 11\n",
            "J= tensor(0.0102, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.7548])\n",
            "w = tensor([1.9806], grad_fn=<SubBackward0>)\n",
            "i = 12\n",
            "J= tensor(0.0053, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.5434])\n",
            "w = tensor([1.9860], grad_fn=<SubBackward0>)\n",
            "i = 13\n",
            "J= tensor(0.0027, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.3913])\n",
            "w = tensor([1.9899], grad_fn=<SubBackward0>)\n",
            "i = 14\n",
            "J= tensor(0.0014, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.2817])\n",
            "w = tensor([1.9928], grad_fn=<SubBackward0>)\n",
            "i = 15\n",
            "J= tensor(0.0007, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.2028])\n",
            "w = tensor([1.9948], grad_fn=<SubBackward0>)\n",
            "i = 16\n",
            "J= tensor(0.0004, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.1460])\n",
            "w = tensor([1.9962], grad_fn=<SubBackward0>)\n",
            "i = 17\n",
            "J= tensor(0.0002, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.1052])\n",
            "w = tensor([1.9973], grad_fn=<SubBackward0>)\n",
            "i = 18\n",
            "J= tensor(0.0001, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.0757])\n",
            "w = tensor([1.9981], grad_fn=<SubBackward0>)\n",
            "i = 19\n",
            "J= tensor(5.3059e-05, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.0545])\n",
            "w = tensor([1.9986], grad_fn=<SubBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x360 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb0AAAFNCAYAAACUvLFdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5xUdf3H8dcHFlxhkZuwXkAhcdEyAsG8kMGipqZpXjItK7NCLdPU+mlX/XkpzUtqpnbxlhW/KMtIzfviJRUFREUBxURZgwURkAVRLp/fH9+zMiwzu3M/c3k/H495zJkzcz7nM8Mw7z3fOXOOuTsiIiLVoEvcDYiIiBSLQk9ERKqGQk9ERKqGQk9ERKqGQk9ERKqGQk9ERKqGQk9iZ2b3mNlp7eYdZWYLzazVzEaZ2YtmNr7AfdxqZhdnuewCMzsw3z0Vk5kNMTM3s5oslv2imd1fiL4yZWb1Zva6mV0XvY/OyLLO/mY2L9/9SbwUepIzMzvezKaZ2WozWxJNf9PMLI1lvwy87e43tLvrCuB0d69z92fd/SPuPrUQ/ZcbM7vAzP4Qdx+J3P2P7v6ptttReA6LqZ0xwCXAAuBc4B/ZFHH3x9x9eB77khKQ8V90IonM7Bzgf4BvAfcBrcBI4LvATcB7SZbp6u4bopt1wClJSu8MvFiInqW0mVmNu6/Pdnl3vzvh5hV5aEkqiLb0JGtm1hu4EPimu//V3Vd58Ky7f9Hd34sed6uZ3RANY64GGs3sMDN7FrgUmGtmF0SP3crMWoGuwHNm9mo0/4PhQzPramY/MLNXzWyVmc0ws8HRffuZ2TNmtjK63q+D/keZ2cyoxp+B2oT7+prZXWa21MyWR9OD0nxdtjKzq83sv9HlajPbKrpv26jWCjN728weM7Mu0X3nmtmbUT/zzOyAjP5B2GyIcmK07kVm9t2E+7uY2XnRa7fMzCabWb8Utb5qZnOifv5jZsn+OGl77Elm9ng0/Wg0+7loePrz0fzDzWxW9NyfMLMRCcsviJ7/88BqM6tJ6HOVmb1kZke1W+c3Evp7ycz2jOanXC56/j+Khj+XmNnvo/dxsuc03syaO3vNpcy4uy66ZHUBDgHWAzWdPO5WYCUwlvCHVi0wAfhodHsEsAT4bMIyDgxLuL0AODCa/h7wAjAcMOBjQH+gH7Ac+BJhFOOE6Hb/JD11B14HzgK6AccC64CLo/v7A8cAPYBewF+AOzt4jon9XQg8BQwEBgBPABdF9/0MuDFaZzdg/+g5DAcWAjtEjxsC7JJiXRcAf0hx35DotZsE9Ixe46UJvZ0Z9TYI2Ar4NTCp3bI10e3DgF2i/sYBa4A9U6z3JODxDv79RkX/xnsT/qD5SvSabZXw+s0CBgNbR/M+B+wQvUc+D6wGtk+4701gr6i/YcDOaSx3MjAf+BBhlOFvwO0pntN4oDnu/2e65PcSewO6lO8FOBFY3G7eE8AK4F3gk9G8W4Hfd1LrauAXCbc7Cr15wJFJanwJeLrdvCeBk5I89pPAfwFr1/vFKfobCSzvoP/E/l4FPp1w38HAgmj6QsJ3TMPaLT8sCoUDgW6dvFYX0Hno7ZYw7+fATdH0HOCAhPu2J4R9De1CL0ntO4EzU9x3Eh2H3g1EwZ8wbx4wLuH1O7mT5z2r7d+dMJSetJdOlnuIMDLRdt/wtuefZDmFXgVeNLwpuVgGbGsJe/u5+37u3ie6L/H9tTBxQTPb08z+FQ1rvU740Nw2zfUOJgRLezsQtt4SvQ7smOKxb3r06Zbw2Lb+epjZr6NhsHeAR4E+ZtY1jf7a9/F6NA/gcsKWxv3RkOF5AO4+H/gOIdCWmNn/mdkOZC/x9U5c/87A36MhxhWEENwA1LcvYGaHmtlT0TDsCuDTpP9v1N7OwDlt643qDU7oq33PmNmXE4ZDVwB7JKw/1Xugs+WS/dvUkOT5S2VS6EkuniTsqHJkGo9tfzqPPwN3EbYGdgZuIwxTpWMhYditvf8SPlwT7UQYBmtvEbCj2WZ7mO6UMH0OYStgb3ffhrBlSJo9tu9jp2geHr73PMfdPwQcAZzd9t2du//J3T8RLevAZWmsK5XBydZPeO0Odfc+CZdad9/sNYq+g7yDsCNIffSHzD2k/2/U3kLgknbr7eHukxIe88F7xMx2Bn4LnE4Ynu4DzE5Yf9L3QBrLJfu3WQ+0ZPm8pMwo9CRr7r4C+F/gejM71sx6RTsKjCR8n9SRPsC77r7ezD5O+P4tXb8DLjKzXS0YYWb9CR/KDWb2hWhHiM8DHyaEa3tPEj7szjCzbmZ2NPDxhPt7EYZoV0Q7epyfQX+TgB+Z2QAz2xb4CfAH+GBnjmFR2K4kbGVtNLPhZjYhCpu10bo3ZrDO9n4cba1+BPgq4Y8MCN8nXhKFA1GPyf5o6U74zm8psN7MDgU+leRxqbQQvjdr81vgVDPbO/o362lhZ6ZeKZbvSQjBpVGfXyVssbX5HfBdMxsd1RsWPafOlpsEnGVmQ82sDvgp8GfPYW9RKS8KPcmJu/8cOJvws4WW6PJrwu+jnuhg0dOA881sFSEUJmew2quix98PvEP4acTW7r4MOJywlbYs6ulwd38rSd/vA0cThlXfJuzw8LeEh1wNbA28Rdjx494M+rsYmA48T9jhZmY0D2BX4EHCTzueBK539yZCwFwarW8xYSeY73ewjs5OhPkIYRj1IeAKd2/74fg1wBTC8Oqq6LntvUVx91XAGYTXeTnwhWi5dF0A3BYNMR7n7tOBbwDXRfXmE177pNz9JeBKwmvUQtgh598J9/+F8Fu8PxH+OLgT6NfZcsDNwO2E4erXCH9gfDuD5yVlzjb/SkNESp2ZXQV0cffvJLlvCOHDvFu1bL2Y2a+BK9395bh7kdKnLT2RMmJmfQh7g06Pu5dSEA1R/pdN37mKdEhHZBEpE2Z2OGGHn3+Q2XBwJXuVMLyZ8Q/5pTppeFNERKqGhjdFRKRqKPRERKRqlMV3en369PFhw/JzlpLVq1fTs2dnPyErXp181irFnvJZSz0Vv5Z6Kn4t9ZS+GTNmvOXuAzJaKO7joKVzaWho8HxpamoqqTr5rFWKPeWzlnoqfi31VPxa6il9wHTXsTdFRESSU+iJiEjVUOiJiEjVKIsdWUREqt26detobm5m7dq1aS/Tu3dv5syZk/O681Un21q1tbUMGjSIbt265bx+hZ6ISBlobm6mV69eDBkyhM3PiJXaqlWr6NUr1Yks0pevOtnUcneWLVtGc3MzQ4cOzXn9Gt4UESkDa9eupX///mkHXqUwM/r375/RFm5HFHoiImWi2gKvTT6fd8FCz8xuNrMlZjY7yX3nmJlHJ9gUEZEyUFdXV/brKOSW3q3AIe1nmtlgwhmY3yjgurew3XZgBo2N4zEL09ttV8wOREQkbgULPXd/lHBG6vZ+QTijdVFP79DSkt48ERFJ36xZs9hnn30YMWIERx11FMuXLwfg2muv5cMf/jAjRozg+OOPB+CRRx5h7NixjBw5klGjRrFq1aqi91vQUwtFZ3G+y933iG4fCUxw9zPNbAEwxt3fSrHsRGAiwIABA0ZPnpzb6cMaG8cnnd/UNDWreq2trXnbDM9XrVLsKZ+11FPxa6mn4tdKVad3795kcgziYcN6smTJ5ts1AwduZP781Rn3tGHDBrp27cr222/PokWLNrtv33335fLLL+cTn/gEF198MatWreKyyy6joaGBF154ga222ooVK1bQp08fjjvuOM4880zGjh1La2srtbW11NRs/iOCZOsAmD9/PitXrtxsXmNj4wx3H5PRk8n0uGWZXIAhwOxougcwDegd3V4AbJtOnXwcexOSX7JViseiK8We8llLPRW/lnoqfq1UdV566aUPplN9nuV6SeWdd95xd/eePXtuNn/FihU+ePDgD27Pnz/fR40a5e7uBx98sB9zzDF+++23+6pVq9zd/Wc/+5mPHj3ar7nmGl+4cGHSdbVfR7Lnv+l1KO1jb+4CDAWei7byBgEzzUzfrImIVJi7776bb33rW8ycOZO99tqL9evXc95553Hdddfx7rvvMnbsWObOnVv0vooWeu7+grsPdPch7j4EaAb2dPfFxVh/fX1680RESl06223ZLJup3r1707dvXx577DEAbr/9dsaNG8fGjRtZuHAhjY2NXHbZZaxcuZLW1lZeffVVPvKRj3Duueey1157xRJ6BTsii5lNAsYD25pZM3C+u99UqPV1ZvFi+NjH4Pnn4emnYa+94upERKQ8rVmzhkGDBn1w++yzz+a2227j1FNPZc2aNXzoQx/illtuYcOGDZx44omsXLkSd+eMM86gT58+/PjHP+ahhx6ipqaGj3zkIxx66KGb1V+/fj1bbbVVQZ9DwULP3U/o5P4hhVp3KrvtFkJv7lyFnohUtvr6LfdQz3V0a+PGjUnnP/XUU1vMe/zxx7eY98tf/rLDw5C9+OKL7LLLLrk12YmqOiLLbruF6xi2qEVEimrxYnjnnVWbDV8uLsqXSdm58cYbOeGEE7j44osLup6qOuC0Qk9EpDSdeuqpnHrqqQVfj7b0RESkalRV6DU0hOtXXoH16+PtRUQkU17Ag4mUsnw+76oKvZ49ob5+LevWwWuvxd2NiEj6amtrWbZsWdUFn0fn06utrc1Lvar6Tg9g8OA1tLTUMncu7Lpr3N2IiKRn0KBBNDc3s3Tp0rSXWbt2bV7CIl91sq3Vdub0fKi60NtppzVMn96PuXPhM5+JuxsRkfR069Yt4zOHT506lVGjRuW87nzVyXetbFTV8CaE0APtzCIiUo0UeiIiUjWqNvTmzMnuWHMiIlK+qi70+vV7n222geXL4a2kZ/ITEZFKVXWhZ6YfqYuIVKuqCz1Q6ImIVCuFnoiIVA2FnoiIVA2FnoiIVI2qDL1ddoGuXcPxN9eujbsbEREplqoMve7dQ/C5w8svx92NiIgUS1WGHmiIU0SkGin0FHoiIlVDoafQExGpGgo9hZ6ISNWo2tAbPjxcz5sHGzfG24uIiBRH1YZev34wcCCsWQPNzXF3IyIixVC1oQca4hQRqTYKPRR6IiLVomChZ2Y3m9kSM5udMO9yM5trZs+b2d/NrE+h1p8OhZ6ISHUp5JbercAh7eY9AOzh7iOAl4HvF3D9nVLoiYhUl4KFnrs/Crzdbt797r4+uvkUMKhQ60+HQk9EpLrE+Z3eycC/Ylw/O+0EtbWwaBGsXBlnJyIiUgzm7oUrbjYEuMvd92g3/4fAGOBoT9GAmU0EJgIMGDBg9OTJk/PSU2trK3V1dR/c/trXxvCf/9Rx/fUz2H33VVnXyWdPcdcp1Vrqqfi11FPxa6mn9DU2Ns5w9zEZLeTuBbsAQ4DZ7eadBDwJ9Ei3TkNDg+dLU1PTZrePO84d3G+7Lbc6+ewp7jqlWks9Fb+Weip+LfWUPmC6Z5hLNXmJ2zSZ2SHA/wDj3H1NMdedir7XExGpHoX8ycIkwhbdcDNrNrOvAdcBvYAHzGyWmd1YqPWnS6EnIlI9Cral5+4nJJl9U6HWly2FnohI9ajqI7IANDSE6/nzYd26eHsREZHCqvrQ69kz/HRh3Tp47bW4uxERkUKq+tADDXGKiFQLhR4KPRGRaqHQQ6EnIlItFHoo9EREqoVCj81Dr4BHZRMRkZgp9IDttoNttoHly2Hp0ri7ERGRQlHoAWYa4hQRqQYKvYhCT0Sk8in0Igo9EZHKp9CLKPRERCqfQi+i0BMRqXwKvcguu0DXrrBgAbz7btzdiIhIISj0It27h+Bzh1deibsbEREpBIVeAg1xiohUNoVeAoWeiEhlU+glUOiJiFQ2hV4ChZ6ISGVT6CUYPjxcz5sHGzfG24uIiOSfQi9Bv34wcCCsWQPNzXF3IyIi+abQa0dDnCIilUuh145CT0Skcin02tl993Ct0BMRqTwKvXa0pSciUrkUeu0o9EREKlfBQs/MbjazJWY2O2FePzN7wMxeia77Fmr92dppJ6ithUWLYOXKuLsREZF8KuSW3q3AIe3mnQc85O67Ag9Ft0tKly6b/15PREQqR8FCz90fBd5uN/tI4LZo+jbgs4Vafy40xCkiUpmK/Z1evbsviqYXA/VFXn9aFHoiIpXJ3L1wxc2GAHe5+x7R7RXu3ifh/uXunvR7PTObCEwEGDBgwOjJkyfnpafW1lbq6uo6fMzDDw/koos+zP77L+XCC1/Muk4+eypmnVKtpZ6KX0s9Fb+WekpfY2PjDHcfk9FC7l6wCzAEmJ1wex6wfTS9PTAvnToNDQ2eL01NTZ0+5tln3cF9991zq5PPnopZp1Rrqafi11JPxa+lntIHTPcMc6nYw5tTgK9E018B/lHk9aeloSFcz58P69bF24uIiORPIX+yMAl4EhhuZs1m9jXgUuAgM3sFODC6XXJ69ICddw6B99prcXcjIiL5UlOowu5+Qoq7DijUOvNpt93g9dfDzixtW34iIlLedESWFLQHp4hI5VHopaDQExGpPAq9FBR6IiKVR6GXQmLoFfCnjCIiUkQKvRTq66F3b1i+HJYsibsbERHJB4VeCmYa4hQRqTQKvQ4o9EREKotCrwMKPRGRyqLQ64BCT0Sksij0OqDQExGpLAq9DuyyC9TUhMORrVkTdzciIpIrhV4HunULwecOr7wSdzciIpIrhV4nNMQpIlI5FHqdUOiJiFQOhV4nFHoiIpVDodcJhZ6ISOVQ6HVi+PBwPW8ebNwYby8iIpIbhV4n+vYNB59+911YuDDubkREJBcKvTRoiFNEpDIo9NKg0BMRqQwKvTQo9EREKoNCLw0KPRGRyqDQS4NCT0SkMij00rDTTlBbC4sXw4oVcXcjIiLZUuiloUuXzX+vJyIi5UmhlyYNcYqIlL9YQs/MzjKzF81stplNMrPaOPrIhEJPRKT8FT30zGxH4AxgjLvvAXQFji92H5lS6ImIlL+4hjdrgK3NrAboAfw3pj7SptATESl/RQ89d38TuAJ4A1gErHT3+4vdR6YaGsL1/Pmwbl28vYiISHbM3Yu7QrO+wB3A54EVwF+Av7r7H9o9biIwEWDAgAGjJ0+enJf1t7a2UldXl9Wyxx+/Dy0ttdx22zT69VuadZ189lSIOqVaSz0Vv5Z6Kn4t9ZS+xsbGGe4+JqOF3L2oF+BzwE0Jt78MXN/RMg0NDZ4vTU1NWS978MHu4H7nnbnVyWdPhahTqrXUU/Frqafi11JP6QOme4YZFMd3em8A+5hZDzMz4ABgTgx9ZEzf64mIlLdOQ8/MupjZKDM7zMwmmNnAXFbo7tOAvwIzgReiHn6TS81iUeiJiJS3mlR3mNkuwLnAgcArwFKgFmgwszXAr4Hb3D3j84m7+/nA+Vl1HCOFnohIeUsZesDFwA3AKdHY6Qeirb0vAF8Cbitce6UlMfSKvP+PiIjkQcrQc/cTOrhvCXB1QToqYfX10Lt3OOj08uXd4m5HREQy1NHw5tEdLPce8Kq7V9VAn1nY2ps2Dd54o0fc7YiISIY6Gt78TCfL7W5mT7j7GXnuqaQp9EREyldHw5tf7WhBM+tC2PuyqrR9r7dwoUJPRKTcpPzJgpmdGAVbKkOBU/PfUmlrCz1t6YmIlJ+Ohjf7A8+a2QxgBpt+sjAMGAe8BZxX8A5LzDe+Ea6ffro/ZmG6vj6cVV1EREpbR8Ob15jZdcAEYCwwAniXcPSUL7n7G8VpsbS89daW81pait+HiIhkrqMtPdx9A/BAdBERESlrcZ1PT0REpOgUeiIiUjUUehmqr09vnoiIlJ50zrJwppltY8FNZjbTzD5VjOZK0eLF4bibEyaEvVeuvFJ7boqIlIt0tvROdvd3gE8BfQkHmb60oF2Vgf32WwbAP/8ZcyMiIpK2dEIv+jUanwZud/cXE+ZVrY9//G26doXHHoPly+PuRkRE0pFO6M0ws/sJoXefmfUCMj6HXqXp1Ws9++8PGzbAvffG3Y2IiKQjndD7GuHIK3u5+xqgG9DhcTmrxRFHhOspU+LtQ0RE0pNO6O0LzHP3FWZ2IvAjYGVh2yoPn4nOQ/Gvf8G6dfH2IiIinUsn9G4A1pjZx4BzgFeB3xe0qzIxbFg4APXKlfD443F3IyIinUkn9Na7uwNHAte5+6+AXoVtq3y0be1pL04RkdKXTuitMrPvE36qcHd0uqFuhW2rfLSF3pQp4fd7IiJSutIJvc8D7xF+r7cYGARcXtCuysi++0K/fvDqqzB3btzdiIhIRzoNvSjo/gj0NrPDgbXuru/0IjU1cNhhYVpDnCIipS2dw5AdBzwNfA44DphmZscWurFyou/1RETKQ4fn04v8kPAbvSUAZjYAeBD4ayEbKycHHwzdusETT8CyZdC/f9wdiYhIMul8p9elLfAiy9Jcrmpssw2MGwcbN8I998TdjYiIpJJOeN1rZveZ2UlmdhJwN6CP9nY0xCkiUvrS2ZHle8BvgBHR5Tfufm4uKzWzPmb2VzOba2ZzzGzfXOqVgrbQu/deeP/9eHsREZHk0vlOD3e/A7gjj+u9BrjX3Y81s+5AjzzWjsXQobDHHjB7NjzyCBx0UNwdiYhIeym39MxslZm9k+SyyszeyXaFZtYb+CRwE4C7v+/uK7KtV0o0xCkiUtpShp6793L3bZJcern7NjmscyiwFLjFzJ41s9+ZWc8c6pWMxNDT0VlEREqPeZE/nc1sDPAUMNbdp5nZNcA77v7jdo+bCEwEGDBgwOjJkyfnZf2tra3U1dUVpM6GDXDssfuxYkV3br75GYYOXR17T5VUSz0Vv5Z6Kn4t9ZS+xsbGGe4+JqOF3L2oF2A7YEHC7f2BuztapqGhwfOlqampoHW++lV3cL/kktLpqVJqqafi11JPxa+lntIHTPcMM6jov7fzcFizhWY2PJp1APBSsfsoFH2vJyJSutLae7MAvg38Mdpz8z9U0JnYDzoIuneHadNgyRIYODDujkREpE0sR1Zx91nuPsbdR7j7Z919eRx9FEJdHUyYEHZkufvuuLsREZFEOpxYAWiIU0SkNCn0CqAt9O6/H9aujbcXERHZRKFXAIMHw8iRsHo1NDXF3Y2IiLRR6BWIhjhFREqPQq9A2kLvrrt0dBYRkVKh0CuQ0aNhu+1g4UJ47rm4uxEREVDoFUyXLhriFBEpNQq9AlLoiYiUFoVeAR1wANTWwjPPwH//G3c3IiKi0CugHj3gwAPDtI7OIiISP4VegWmIU0SkdCj0Cuzww8P1gw/Cu+/G24uISLVT6BXYDjvAmDEh8B56KO5uRESqm0KvCNqGOKdMibcPEZFqp9ArgsSjs2zcGG8vIiLVTKFXBCNHwqBBsGgRzJwZdzciItVLoVcEZtqLU0SkFCj0ikShJyISP4VekTQ2Qs+e8Oyz0NwcdzciItVJoVcktbVw0EFhWlt7IiLxUOgVkYY4RUTipdArosMOCzu1PPwwrF4ddzciItVHoVdE9fWw997w3nvwwANxdyMiUn0UekWmIU4Rkfgo9IpMR2cREYmPQq/I9tgDdt4ZliyBp5+OuxsRkeoSW+iZWVcze9bM7oqrhzjo6CwiIvGJc0vvTGBOjOuPzRFHhGuFnohIccUSemY2CDgM+F0c64/buHHQqxe88AK8/nrc3YiIVI+4tvSuBv4HqMpdObp3h4MPDtPa2hMRKR5z9+Ku0Oxw4NPu/k0zGw98190PT/K4icBEgAEDBoyePHlyXtbf2tpKXV1d7HXuu6+eSy/dnTFj3ub8858oiZ5KvZZ6Kn4t9VT8WuopfY2NjTPcfUxGC7l7US/Az4BmYAGwGFgD/KGjZRoaGjxfmpqaSqLO0qXuXbq4d+vmftddj5ZET6VeSz0Vv5Z6Kn4t9ZQ+YLpnmEFFH9509++7+yB3HwIcDzzs7icWu4+4bbstdO0K69bB4Yfvj1nYs3O77eLuTESkcul3ejFat27LeS0txe9DRKRa1MS5cnefCkyNswcREake2tITEZGqodATEZGqodCLUX39lvMGDix+HyIi1UKhF6PFi8EdHnxwKiNHhnnf/Ga8PYmIVDKFXgno2hWuvTZMX3YZvPFGvP2IiFQqhV6J2H9/+Pzn4d134Xvfi7sbEZHKpNArIZdfDltvDZMnwyOPxN2NiEjlUeiVkMGD4bzzwvSZZ8KGDfH2IyJSaRR6JeZ73wtnVn/uOfjtb+PuRkSksij0SszWW8MVV4TpH/0Ili+Ptx8RkUqi0CtBxxwD48fDsmVw/vlxdyMiUjkUeiXIDK65Brp0geuvh9mz4+5IRKQyKPRK1IgRcMopYWeW73wn/IhdRERyo9ArYRddBH37wkMPwT/+EXc3IiLlT6FXwvr3hwsvDNNnnw1r18bbj4hIuVPolbhTT4U99oDXXoOrroq7GxGR8qbQK3E1NWGnFoCf/hTefDPefkREyplCrwxMmABHHw2rV8O558bdjYhI+VLolYkrroCttoI//hGeeCLubkREypNCr0wMHbrp7AtnnAEbN8bbj4hIOVLolZHzzoMdd4QZM+CWW+LuRkSk/Cj0ykjPnvDzn4fpH/wAVq6Mtx8RkXKj0CszJ5wAY8fCkiXhx+siIpI+hV6ZMYNrr910fM558+LuSESkfCj0ytCee8LXvgbr18NZZ8XdjYhI+VDolalLLoHeveFf/4K77467GxGR8lD00DOzwWbWZGYvmdmLZnZmsXuoBAMHbjrX3llnwfvvx9uPiEg5iGNLbz1wjrt/GNgH+JaZfTiGPsre6afDbrvBK69sOlSZiIikVvTQc/dF7j4zml4FzAF2LHYflaBbN/jFL8L0RRfB2293j7chEZESF+t3emY2BBgFTIuzj3J2yCHQvTusWgXHHLMfZmHPzu22i7szEZHSYx7TKbnNrA54BLjE3f+W5P6JwESAAQMGjJ48eXJe1tva2kpdXV3J1MlHrcbG8UnnNzVNzbpmKT2/fNfJZ61S7CmftdRT8Wupp/Q1NjbOcPcxGS3k7kW/AN2A+4Cz03l8Q0OD50tTU1NJ1clHLUh+ibOnQtRST8WvpZ6KX0s9pQ+Y7hnmTxx7bxpwEzDH3XVa1AKKaSNeRKRkxfGd3ljgS8AEM5sVXT4dQx8V7+tfh3Xr4u5CRKR01BR7he7+OGDFXm8lq6+HlpYt5wvWK9IAABFGSURBVN98MyxaBJMnQ56G0EVEypqOyFIBFi8OQ5lNTVM/+Ebvqadg223DEVsaG8MBqkVEqp1Cr0LtvTf8+9/h5LPTp8N++8H8+XF3JSISL4VeBWtogCefDAeofvXVEHzPPBN3VyIi8VHoVbj6epg6FQ4+GJYuhfHjw5CniEg1UuhVgV694J//hC9/Gdasgc98Bm65Je6uRESKT6FXJbp1g1tvhR/8ADZsgJNPDsfr1G/5RKSaKPSqiFk4D9+vfhWmf/ITOO20cDJaEZFqoNCrQt/8JtxxB9TWwq9/DcccE4Y9RUQqnUKvSh11FDz4IPTtC1OmwIEHwrJlcXclIlJYCr0qNnZs+C3fTjuFnzaMHQuvvRZ3VyIihaPQq3K77x4C72Mfg3nzwm/5nn027q5ERApDoSfssAM88ghMmBAOabbnnuEcfTohrYhUGoWeANC7d+ofrSc7mLWISDlS6MkHundPfd9vfgNr1xavFxGRQlDoSVpOOQWGDIGf/QyWL4+7GxGR7Cj0JC2jRoVhzh/8IOztec450Nwcd1ciIplR6Mlm6uuTz5sxAx54AA46CFpb4aqrwmmLTjoJZs8uepsiIllR6Mlmkp2QdvHisBfngQfC/feHADz+eNi4EW67DT76UTj8cHj0UR3LU0RKm0JPMrbnnjBpUjgp7be+BVtvDXffDePGhd/5/f3vIRBFREqNQk+yNnQoXHcdvP46nH8+9OsHTz0FRx8dfvTeu3fYQtRv/kSkVCj0JGcDBsAFF8Abb8C118LOO8PLL8M772z5WP3mT0TipNCTvOnZE7797TDs+ac/pX7cF74AN9wQdoDRMKiIFJNCT/KupgZOOCH1/ZMmhdMbffSjYSvxyCPhiitg2jRYt654fYpI9amJuwGpPtdfD489Fvb2fPPNcGqjKVPCfT16wL77wv77h8s++4R5IiL5oNCTgqmv3/I7vPr6cLb2004LP29YsGBTAD72WPgu8KGHwgWgW7dwHbYAx29WZ/HiIjwJEakoCj0pmLZQmjp1KuPHj9/ifrOwB+jQofDlL4d5LS0h/Nous2Yl/+1fSwuMGBEOjdZ22XnnTdP9+oX6IiKJFHpSUurr4dhjwwVg5Uro0yf5Y194IVySqavbMgiHDAnHEH37bdBWo0h1iiX0zOwQ4BqgK/A7d780jj6k9PXunfq+6dPD8Ojrr4frxMuqVWHv0HQOkdbSAgccAH37hoDt7LpPnxCgYeh2/Ad1FJ4ipa/ooWdmXYFfAQcBzcAzZjbF3V8qdi9S3kaPDpf23GHFis1DsC0Y//GP5LUefjj3flpa4LDDwhFqamvTv/7qV9vOXDH+g1r9+8MTT4TvNGtqUl93abf/9Xbb5SeM81Wn0nvKZy31VBxxbOl9HJjv7v8BMLP/A44EFHqSVKodYlIxC1tlffuGs0O0vy+ZBx4IwbNiRXrXqX5acc896T+vjixbBsOHd/64Ll02D8GVK7d8TEsL7LpreGzbpWvXjm8nO4hASwscckh4Dbt04YOj7LRdks0zS13rxBM3PQY2v042narOKadsup3479vRdKpap5+efJlE7eenqnXmmZ0vm06ds85KvUyha6Wqc/bZ+eup2MyLfIRgMzsWOMTdvx7d/hKwt7uf3u5xE4GJAAMGDBg9efLkvKy/tbWVurq6kqmTz1ql2FM+a+WjTmPj+KTzm5qmpl3DHSZMSF7npz99gfff78J773XZ7Lrt8t57XT+Y/957XVi3rgtPPLFt0lo77riG9eu7sGGDbXZZv77tWj+zlfKXyf+99hobG2e4+5hMlinZ0Es0fPhwnzdvXl7Wn2pPwrjq5LNWKfaUz1r5qLNpiGWTbIZYUv3Fns1/p2xruYcj2qxbB+vXh+t+/ZI/9uWXw2M3boQNGzZNp7o9blzyOvfcwwdn39i4cdN0R/OOPz55rd//ftNzTLxONf2NbySvc+ONW75enU2fnuLT5pe/3HKZRMnmJ9uiA7j66s6XTZRqK+yqqzpeLplUW2KZ1kpV58orM6sD4RycyeQSQWaWcejh7kW9APsC9yXc/j7w/Y6WaWho8HxpamoqqTr5rFWKPeWzVin1VF/f/qM9zMvGljERLnHWUk/Fr6WesqnJdM8wg+IYH3kG2NXMhppZd+B4YEoMfYhkLdV5B7OR6sS9cdZST8WvpZ6Ko+ih5+7rgdOB+4A5wGR3f7HYfYiUinwGaL5qqafi11JPxRHL7/Tc/R4gT/u5iYiIpEe7f4mISNVQ6ImISNVQ6ImISNVQ6ImISNVQ6ImISNVQ6ImISNVQ6ImISNUo+rE3s2Fmq4D8HHwTtgXeKqE6+axVij3ls5Z6Kn4t9VT8WuopfcPdvVcmC5TLmdPneaYHFU3BzKbno1a+6lR6T/mspZ6KX0s9Fb+WesqsVqbLaHhTRESqhkJPRESqRrmE3m9KsJZ6Kn4t9VT8Wuqp+LXUUwFrlcWOLCIiIvlQLlt6IiIiOSvp0DOzQ8xsnpnNN7Pzcqhzs5ktMbPZeehpsJk1mdlLZvaimZ2ZZZ1aM3vazJ6L6vxvHnrrambPmtldOdZZYGYvmNmsbPaOSqjTx8z+amZzzWyOme2bZZ3hUS9tl3fM7DtZ1jorer1nm9kkM6vNpk5U68yozouZ9pPsPWlm/czsATN7Jbrum2Wdz0U9bTSztPeSS1Hr8ujf73kz+7uZ9cmh1kVRnVlmdr+Z7ZBNnYT7zjEzN7Ntc+jpAjN7M+G99elsezKzb0ev1Ytm9vMcevpzQj8LzGxWDrVGmtlTbf+XzezjWdb5mJk9GX0u/NPMtkmjTtLPyizf56lqZf5ez/RU68W6AF2BV4EPAd2B54APZ1nrk8CewOw89LU9sGc03Qt4OZu+AAPqouluwDRgnxx7Oxv4E3BXjnUWANvm4bW6Dfh6NN0d6JOn98ViYOcslt0ReA3YOro9GTgpyz72AGYDPQg//XkQGJbB8lu8J4GfA+dF0+cBl2VZZ3dgODAVGJNjT58CaqLpy9LpqYNa2yRMnwHcmE2daP5gwomoX0/3vZqipwuA72b4b5+sTmP0Htgquj0w21rt7r8S+EkOfd0PHBpNfxqYmmWdZ4Bx0fTJwEVp1En6WZnl+zxVrYzf66W8pfdxYL67/8fd3wf+Dzgym0Lu/ijwdj6acvdF7j4zml5FOPv7jlnUcXdvjW52iy5Zf8FqZoOAw4DfZVsjn8ysN+E/z00A7v6+u6/IQ+kDgFfd/fUsl68BtjazGkJg/TfLOrsD09x9jbuvBx4Bjk534RTvySMJfygQXX82mzruPsfdMz6YQ4pa90fPD+ApYFAOtd5JuNmTNN7vHfzf/QXwP+nUSKNWRlLUOQ241N3fix6zJNeezMyA44BJOdRyoG2rrDdpvN9T1GkAHo2mHwCOSaNOqs/KbN7nSWtl814v5dDbEViYcLuZLMKlkMxsCDCKsJWWzfJdo6GLJcAD7p5VncjVhA+BjTnUaOPA/WY2w8wmZlljKLAUuMXCkOvvzKxnHno7njQ/BNpz9zeBK4A3gEXASne/P8s+ZgP7m1l/M+tB+Ct6cJa12tS7+6JoejFQn2O9fDsZ+FcuBczsEjNbCHwR+EmWNY4E3nT353LpJcHp0bDrzekMtaXQQHg/TDOzR8xsrzz0tT/Q4u6v5FDjO8Dl0Wt+BfD9LOu8yKaNjs+R4Xu93WdlTu/zXD93Szn0SpqZ1QF3AN9p9xds2tx9g7uPJPz1/HEz2yPLXg4Hlrj7jGyWT+IT7r4ncCjwLTP7ZBY1aghDJDe4+yhgNWEoI2tm1h04AvhLlsv3JfzHHQrsAPQ0sxOzqeXucwjDffcD9wKzgA3Z1EpR38lhyz/fzOyHwHrgj7nUcfcfuvvgqM7pWfTRA/gBWQZmEjcAuwAjCX8IXZllnRqgH7AP8D1gcrSllosTyPIPvASnAWdFr/lZRCMvWTgZ+KaZzSAML76f7oIdfVZm+j7Px+duKYfem2z+18SgaF7szKwb4YX/o7v/Ldd60bBfE3BIliXGAkeY2QLCMPAEM/tDDv28GV0vAf5OGGrOVDPQnLD1+ldCCObiUGCmu7dkufyBwGvuvtTd1wF/A/bLthl3v8ndR7v7J4HlhO8ZctFiZtsDRNdpDZEVmpmdBBwOfDH6kMqHP5LGEFkSuxD+aHkuer8PAmaa2XbZNOHuLdEfnxuB35Ldex3C+/1v0dcWTxNGXNLawSaZaPj9aODP2daIfIXwPofwx2JWz8/d57r7p9x9NCGIX01nuRSflVm9z/P1uVvKofcMsKuZDY3+wj8emBJzT23j7DcBc9z9qhzqDLBoTzgz2xo4CJibTS13/767D3L3IYTX6WF3z2oLxsx6mlmvtmnCjgwZ7/Xq7ouBhWY2PJp1APBSNj0lyPUv3zeAfcysR/TveADhu4GsmNnA6HonwgfUn3LoDcL7+yvR9FeAf+RYL2dmdghh2PwId1+TY61dE24eSRbvd3d/wd0HuvuQ6P3eTNjBYXGWPW2fcPMosnivR+4k7MyCmTUQdtzK5aDKBwJz3b05hxoQvsMbF01PALIaKk14r3cBfgTcmMYyqT4rM36f5+tzFyjdvTd9095GLxP+qvhhDnUmEYYu1hH+k3wth1qfIGyOP08Y0poFfDqLOiOAZ6M6s0lzD6006o4nh703CXvLPhddXszxdR8JTI+e451A3xxq9QSWAb1zfH3+l/BhOxu4nWhvuyxrPUYI8ueAA3J9TwL9gYcIH0wPAv2yrHNUNP0e0ALcl0NP8wnfrbe91zvd47KDWndEr/vzwD8JOyJkXKfd/QtIf+/NZD3dDrwQ9TQF2D7LOt2BP0TPbyYwIdueovm3Aqfm4T31CWBG9B6dBozOss6ZhM/il4FLiQ5s0kmdpJ+VWb7PU9XK+L2uI7KIiEjVKOXhTRERkbxS6ImISNVQ6ImISNVQ6ImISNVQ6ImISNVQ6InkkZk9EV0PMbMvFGF93c3sHjN7yMw6/e1UtMxnzewn0fSpZvblaPoKM5tQyH5F4qafLIgUgJmNJxy9//AMlqnxTQd3LpgomI9w97fazd8Z+K27f6rQPYjERVt6InlkZm1nzriUcADiWRbO4dfVwrnpnokObnxK9PjxZvaYmU0hOmKNmd0ZHez7xcQDfls4v+RMC+dgvCea95noIMfPmtmDZlYfze8X1XnewvnURkTzG4D32gLPwvnkvgvg4cwV/bM9pJdIOaiJuwGRCnUeCVt6UXitdPe9zGwr4N9m1naGhz2BPdz9tej2ye7+dnR4umfM7A7CH6i/Bj7p7q+bWb/osY8TzsPoZvZ1wiHDziEceeZZd/9sNGT5e8IRcsYSjhiSyszoMXfk5VUQKTEKPZHi+BQwwsyOjW73BnYlHK3+6YTAAzjDzI6KpgdHjxsAPBZtjeHubec7GwT8OTqGZHfCSXIhHLbpmOixD1s4BdI2hJNxLu2gzyWEM1CIVCQNb4oUhwHfdveR0WWobzqX3+oPHhS+CzwQ2NfdP0Y4PmttB3V/CVzn7h8FTunksQDvdvKY2ugxIhVJoSdSGKsI5x1rcx9wWnR6FMyswZKfVLc3sNzd15jZboTzs0E4a/n+0c4mJAxv9mbTKbe+klDnMcKJWtuC9C0P5x+bAwzroO8Gsj/TgEjJU+iJFMbzwIZop5OzgN8RdlSZaWazCd/PJft64V6gxszmEHaGeQrA3ZcCpwJ3mtmbhO/oAC4A/hKd3DNxb8wLgNFm9nxUpy0QHwVGJTvBaRTIwwhnxhCpSPrJgkiZMbMrgQvdfWWWy18D/NPdH2w3/yjCuel+nIc2RUqStvREyoiZTQI+A3TLocxPgR5J5tcAV+ZQV6TkaUtPRESqhrb0RESkaij0RESkaij0RESkaij0RESkaij0RESkaij0RESkavw/bfwzdXB1TogAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GulfYtzBMx2e"
      },
      "source": [
        "##Exercício 3.4\n",
        "\n",
        "Quais são as restrições na escolha dos valores de $\\Delta w$ no cálculo do gradiente por diferenças finitas?\n",
        "\n",
        "*   A small learning rate could achieve good performance, but a small learning rate could take too much time or fall into a local minimum.\n",
        "\n",
        "*   Although a big learning rate permits scanning a much larger part of the parameter space, the rate will make learning faster in the case of a big learning rate. But it will make de model fall into a suboptimal solution.\n",
        "\n",
        "*   However, recently it was shown that moderately large learning rates could achieve higher test accuracies by Samuel L. Smith https://openreview.net/pdf?id=rq_Qr0c1Hyo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXQGEyvtiTAR"
      },
      "source": [
        "Resposta:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsrSF8GEiXk4"
      },
      "source": [
        "##Exercício 3.5\n",
        "\n",
        "Até agora trabalhamos com $w$ contendo apenas um parâmetro. Suponha agora que $w$ seja uma matriz com $N$ parâmetros e que o custo para executar $(x_i w - y_i)^2$ seja $O(N)$.\n",
        "> a) Qual é o custo computacional para fazer uma única atualização (um passo de gradiente) dos parâmetros de $w$ usando o método das diferencas finitas?\n",
        ">\n",
        "> b) Qual é o custo computacional para fazer uma única atualização (um passo de gradiente) dos parâmetros de $w$ usando o método do backpropagation?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4Pna3bcicHj"
      },
      "source": [
        "Resposta (justifique):\n",
        "\n",
        "a) from $ \\frac{\\partial J}{\\partial w} = \\frac{J(w + \\Delta w) - J(w - \\Delta w)}{2 \\Delta w} $ , we got $ \\frac{\\partial J}{\\partial w}=  2\\sum_i (x_i(x_i w - y_i)) =2*x(x*w-y).sum() $ \n",
        "\n",
        "the cost of $x_i(x_i w - y_i)$ is $O(N)$ ,since $w$ has $N$ parameters  , the cost of execution is **$N.O(N) =O(N^2)$**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "b) after made the partial derivaties we get 2*x(x*w-y).sum() so the cost is **$O(N^2)$**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35I5w8EZdjIo"
      },
      "source": [
        "##Exercício 3.6\n",
        "\n",
        "Qual o custo (entropia cruzada) esperado para um exemplo (uma amostra) no começo do treinamento de um classificador inicializado aleatoriamente?\n",
        "\n",
        "A equação da entropia cruzada é:\n",
        "$$L = - \\sum_{j=0}^{K-1} y_j \\log p_j, $$\n",
        "Onde:\n",
        "\n",
        "- K é o número de classes;\n",
        "\n",
        "- $y_j=1$ se $j$ é a classe do exemplo (ground-truth), 0 caso contrário. Ou seja, $y$ é um vetor one-hot;\n",
        "\n",
        "- $p_j$ é a probabilidade predita pelo modelo para a classe $j$.\n",
        "\n",
        "A resposta tem que ser em função de uma ou mais das seguintes variáveis:\n",
        "\n",
        "- K = número de classes\n",
        "\n",
        "- B = batch size\n",
        "\n",
        "- D = dimensão de qualquer vetor do modelo\n",
        "\n",
        "- LR = learning rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swTOphiVs6eN"
      },
      "source": [
        "Resposta: we have to compute the cross-entropy term $ y_j \\log p_j$ for each class and for batch size so the cost for a multiple class classifications is  $O(B*K)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UNdHqgSB6S9"
      },
      "source": [
        "Fim do notebook."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lvj9Mh3zu1eT"
      },
      "execution_count": 78,
      "outputs": []
    }
  ]
}