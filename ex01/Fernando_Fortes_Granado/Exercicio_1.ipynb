{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cópia de Exercícios - 20210718",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {
        "height": "117px",
        "width": "252px"
      },
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unicamp-dl/IA025_2022S1/blob/main/ex01/Fernando_Fortes_Granado/Exercicio_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTVOQpMfhgLM"
      },
      "source": [
        "Esté um notebook Colab contendo exercícios de programação em python, numpy e pytorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMoyGt5gXMgK"
      },
      "source": [
        "## Coloque seu nome"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBHbXcibXPRe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff4ba950-dff5-4f5f-afaa-2561c187f07e"
      },
      "source": [
        "print('Meu nome é: Fernando Fortes Granado')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meu nome é: Fernando Fortes Granado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9S5acRbm1Zr"
      },
      "source": [
        "# Parte 1:\n",
        "\n",
        "##Exercícios de Processamento de Dados\n",
        "\n",
        "Nesta parte pode-se usar as bibliotecas nativas do python como a `collections`, `re` e `random`. Também pode-se usar o NumPy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxS5h1V8nDn6"
      },
      "source": [
        "##Exercício 1.1\n",
        "Crie um dicionário com os `k` itens mais frequentes de uma lista.\n",
        "\n",
        "Por exemplo, dada a lista de itens `L=['a', 'a', 'd', 'b', 'd', 'c', 'e', 'a', 'b', 'e', 'e', 'a']` e `k=2`, o resultado deve ser um dicionário cuja chave é o item e o valor é a sua frequência: {'a': 4, 'e': 3}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT08b5Z_nC-j"
      },
      "source": [
        "from typing import List, Tuple, Dict\n",
        "import collections\n",
        "\n",
        "def top_k(L, k):\n",
        "    list_counter = collections.Counter(L)\n",
        "    most_common = list_counter.most_common(k)\n",
        "    return convert_to_dict(most_common)\n",
        "\n",
        "\n",
        "def convert_to_dict(my_list: List[Tuple[str, int]]) -> Dict[str, int]:\n",
        "    my_dict = {}\n",
        "    for key, occurences in my_list:\n",
        "        my_dict[key] = occurences\n",
        "    return my_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLD_e3C9p4xO"
      },
      "source": [
        "Mostre que sua implementação está correta usando uma entrada com poucos itens:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMW9NiBgnkvA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "919c4c72-c570-4c6f-ca3a-2561692a1ff7"
      },
      "source": [
        "L = ['f', 'a', 'a', 'd', 'b', 'd', 'c', 'e', 'a', 'b', 'e', 'e', 'a', 'd']\n",
        "k = 3\n",
        "resultado = top_k(L=L, k=k)\n",
        "print(f'resultado: {resultado}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resultado: {'a': 4, 'd': 3, 'e': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBeqZScQqJ0a"
      },
      "source": [
        "Mostre que sua implementação é eficiente usando uma entrada com 10M de itens:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_lhcm4ko8bY"
      },
      "source": [
        "import random\n",
        "L = random.choices('abcdefghijklmnopqrstuvwxyz', k=10_000_000)\n",
        "k = 10000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9U-Bgs2o-f_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f13f0891-b75c-46c5-cb4a-7768faa11846"
      },
      "source": [
        "%%timeit\n",
        "resultado = top_k(L=L, k=k)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 595 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJHDaOz_tK38"
      },
      "source": [
        "## Exercício 1.2\n",
        "\n",
        "Em processamento de linguagem natural, é comum convertemos as palavras de um texto para uma lista de identificadores dessas palavras. Dado o dicionário `V` abaixo onde as chaves são palavras e os valores são seus respectivos identificadores, converta o texto `D` para uma lista de identificadores.\n",
        "\n",
        "Palavras que não existem no dicionário deverão ser convertidas para o identificador do token `unknown`.\n",
        "\n",
        "O código deve ser insensível a maiúsculas (case-insensitive).\n",
        "\n",
        "Se atente que pontuações (vírgulas, ponto final, etc) também são consideradas palavras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVzv89trtTPc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "645650e8-8ec2-4062-c624-7f066f958db1"
      },
      "source": [
        "from typing import List, Dict\n",
        "import re\n",
        "\n",
        "print(\n",
        "    \"\"\"\n",
        "    Our simple preprocessing step assumes the punctuation elements are  \n",
        "    written according to the ortography standards. E.g. every\n",
        "    comma must be followed by a space before continuing the phrase.\n",
        "    \n",
        "    This function can be optimized by doing all the replacements in one go,\n",
        "    instead of two, using regex. However, this is enough for the task.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "\n",
        "def tokens_to_ids(text, vocabulary):\n",
        "    text = preprocess(text)\n",
        "    words = text.split()\n",
        "    return embed_words(words, vocabulary)\n",
        "\n",
        "\n",
        "def preprocess(text):\n",
        "    text = add_space_before_relevant_punctuations(text)\n",
        "    text = add_space_after_relevant_punctuations(text)\n",
        "    text = text.lower()\n",
        "    return text \n",
        "\n",
        "\n",
        "def add_space_before_relevant_punctuations(text):\n",
        "    return re.sub(r\"(?=[\\x2c\\x2e\\x7d\\x3b\\x3a\\x3f\\x2f])\", r' ', text)\n",
        "\n",
        "\n",
        "def add_space_after_relevant_punctuations(text):\n",
        "    return re.sub(r\"(?<=[\\x2f\\x28\\x7b\\x5b])\", r' ', text)\n",
        "\n",
        "\n",
        "def embed_words(words: List[str], vocabulary: Dict[str, int]) -> List[int]:\n",
        "    embedded_phrase = []\n",
        "    for word in words:\n",
        "        embedded_phrase.append(vocabulary.get(word, vocabulary[\"unknown\"]))\n",
        "    return embedded_phrase"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    Our simple preprocessing step assumes the punctuation elements are  \n",
            "    written according to the ortography standards. E.g. every\n",
            "    comma must be followed by a space before continuing the phrase.\n",
            "    \n",
            "    This function can be optimized by doing all the replacements in one go,\n",
            "    instead of two, using regex. However, this is enough for the task.\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCGZeiqkY-sm"
      },
      "source": [
        "Mostre que sua implementação esta correta com um exemplo pequeno:\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iApR1h7gY98E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbb4d11d-3ae2-49b5-d8ea-947a97577966"
      },
      "source": [
        "V = {'eu': 1, 'de': 2, 'gosto': 3, 'comer': 4, '.': 5, 'unknown': -1}\n",
        "D = 'Eu gosto de comer pizza.'\n",
        "\n",
        "print(tokens_to_ids(D, V))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 3, 2, 4, -1, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWtTMxlXZN25"
      },
      "source": [
        "Mostre que sua implementação é eficiente com um exemplo grande:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxT_g-ZxZUsX"
      },
      "source": [
        "V = {'eu': 1, 'de': 2, 'gosto': 3, 'comer': 4, '.': 5, 'unknown': -1}\n",
        "D = ' '.join(1_000_000 * ['Eu gosto de comer pizza.'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kp1nataGZU-V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1708112-39cd-454d-f368-a20fc4f54a62"
      },
      "source": [
        "%%timeit\n",
        "resultado = tokens_to_ids(D, V)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 3.07 s per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRfaKfXwRXn_"
      },
      "source": [
        "## Exercício 1.3\n",
        "\n",
        "Em aprendizado profundo é comum termos que lidar com arquivos muito grandes.\n",
        "\n",
        "Dado um arquivo de texto onde cada item é separado por `\\n`, escreva um programa que amostre `k` itens desse arquivo aleatoriamente.\n",
        "\n",
        "Nota 1: Assuma amostragem de uma distribuição uniforme, ou seja, todos os itens tem a mesma probablidade de amostragem.\n",
        "\n",
        "Nota 2: Assuma que o arquivo não cabe em memória.\n",
        "\n",
        "Nota 3: Utilize apenas bibliotecas nativas do python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PsadE9SRG_9"
      },
      "source": [
        "import random\n",
        "from typing import List, Set\n",
        "\n",
        "def sample(path: str, k: int) -> List[str]:\n",
        "    num_lines = get_file_num_lines(path)\n",
        "    line_idxs = sample_indexes(num_lines, k)\n",
        "    line_samples = sample_lines(path, line_idxs)\n",
        "    line_samples = remove_new_line_separator(line_samples)\n",
        "    return line_samples\n",
        "\n",
        "\n",
        "def get_file_num_lines(path):\n",
        "    with open(path, 'r') as file:\n",
        "        for i, _ in enumerate(file):\n",
        "            pass\n",
        "    return i\n",
        "\n",
        "\n",
        "def sample_indexes(\n",
        "        total_lines: int, \n",
        "        num_sample: int\n",
        "    ) -> Set[int]:\n",
        "\n",
        "    return set(random.sample(range(total_lines), num_sample))\n",
        "\n",
        "\n",
        "def sample_lines(path: str, line_idxs: Set[int]) -> List[str]:\n",
        "    with open(path, 'r') as file:\n",
        "        line_samples = []\n",
        "        for line_number, line in enumerate(file):\n",
        "            if line_number in line_idxs:\n",
        "                line_samples.append(line)\n",
        "\n",
        "    random.shuffle(line_samples)\n",
        "    return line_samples\n",
        "\n",
        "\n",
        "def remove_new_line_separator(lines: List[str]) -> List[str]:\n",
        "    precessed_lines = []\n",
        "    for line in lines:\n",
        "        if line.endswith(\"\\n\"):\n",
        "            precessed_lines.append(line[0:-1])\n",
        "        else:\n",
        "            precessed_lines.append(line)\n",
        "    return precessed_lines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycEnlFWxSt0i"
      },
      "source": [
        "Mostre que sua implementação está correta com um exemplo pequeno:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyLJ1e2ZSzC9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efb41dda-4bb2-4276-dd47-4cc1dffe3268"
      },
      "source": [
        "filename = 'small.txt'\n",
        "total_size = 100\n",
        "n_samples = 10\n",
        "\n",
        "with open(filename, 'w') as fout:\n",
        "    fout.write('\\n'.join(f'line {i}' for i in range(total_size)))\n",
        "\n",
        "samples = sample(path=filename, k=n_samples)\n",
        "print(samples)\n",
        "print(len(samples) == n_samples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['line 42', 'line 55', 'line 36', 'line 73', 'line 69', 'line 71', 'line 65', 'line 90', 'line 96', 'line 95']\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2r4FMiMj12Xg"
      },
      "source": [
        "Mostre que sua implementação é eficiente com um exemplo grande:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUwnNMGg18Ty"
      },
      "source": [
        "filename = 'large.txt'\n",
        "total_size = 1_000_000\n",
        "n_samples = 10000\n",
        "\n",
        "with open(filename, 'w') as fout:\n",
        "    fout.write('\\n'.join(f'line {i}' for i in range(total_size)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA9sAZmo0UDN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88452943-8ed7-4d6c-9e65-18bca41ff05f"
      },
      "source": [
        "%%timeit\n",
        "samples = sample(path=filename, k=n_samples)\n",
        "assert len(samples) == n_samples"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 267 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udS0Ns4etoJs"
      },
      "source": [
        "# Parte 2:\n",
        "\n",
        "##Exercícios de Numpy\n",
        "\n",
        "Nesta parte deve-se usar apenas a biblioteca NumPy. Aqui não se pode usar o PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcMz3Vzjt144"
      },
      "source": [
        "##Exercício 2.1\n",
        "\n",
        "Quantos operações de ponto flutuante (flops) de soma e de multiplicação tem a multiplicação matricial $AB$, sendo que a matriz $A$ tem tamanho $m \\times n$ e a matriz $B$ tem tamanho $n \\times p$?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gNXj45RJqUm"
      },
      "source": [
        "Resposta:\n",
        "- número de somas: (n-1).p.m\n",
        "- número de multiplicações: n.p.m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iI7udBFeDlP"
      },
      "source": [
        "## Exercício 2.2\n",
        "\n",
        "Em programação matricial, não se faz o loop em cada elemento da matriz,\n",
        "mas sim, utiliza-se operações matriciais.\n",
        "\n",
        "Dada a matriz `A` abaixo, calcule a média dos valores de cada linha sem utilizar laços explícitos.\n",
        "\n",
        "Utilize apenas a biblioteca numpy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjrXf18N5KrK"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fqxgNBW27Z0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ffab1aa-b502-4f17-f492-c243c72be822"
      },
      "source": [
        "A = np.arange(24).reshape(4, 6)\n",
        "print(A)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  1  2  3  4  5]\n",
            " [ 6  7  8  9 10 11]\n",
            " [12 13 14 15 16 17]\n",
            " [18 19 20 21 22 23]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1EmKFrT5g7B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4461efe-8b62-4cb1-e5c7-f637e2bf5de8"
      },
      "source": [
        "np.average(A, axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2.5,  8.5, 14.5, 20.5])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtgSAAKjUfcO"
      },
      "source": [
        "## Exercício 2.3\n",
        "\n",
        "Seja a matriz $C$ que é a normalização da matriz $A$:\n",
        "$$ C(i,j) = \\frac{A(i,j) - A_{min}}{A_{max} - A_{min}} $$\n",
        "\n",
        "Normalizar a matriz `A` do exercício acima de forma que seus valores fiquem entre 0 e 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-11T00:00:34.072719Z",
          "start_time": "2019-12-11T00:00:34.036017Z"
        },
        "id": "_pDhb2-0eDlS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "018cf062-fe3b-45d1-f72d-31c0c8e68101"
      },
      "source": [
        "A_min = A.min()\n",
        "A_max = A.max()\n",
        "\n",
        "C = (A - A_min) / (A_max - A_min)\n",
        "C"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.04347826, 0.08695652, 0.13043478, 0.17391304,\n",
              "        0.2173913 ],\n",
              "       [0.26086957, 0.30434783, 0.34782609, 0.39130435, 0.43478261,\n",
              "        0.47826087],\n",
              "       [0.52173913, 0.56521739, 0.60869565, 0.65217391, 0.69565217,\n",
              "        0.73913043],\n",
              "       [0.7826087 , 0.82608696, 0.86956522, 0.91304348, 0.95652174,\n",
              "        1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF_P_GARU62m"
      },
      "source": [
        "## Exercício 2.4\n",
        "\n",
        "Modificar o exercício anterior de forma que os valores de cada *coluna* da matriz `A` sejam normalizados entre 0 e 1 independentemente dos valores das outras colunas.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NgVzFOYeDla",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0647637-5d15-4838-ddb0-c200ee7208f3"
      },
      "source": [
        "A_min = A.min(axis=0)\n",
        "A_max = A.max(axis=0)\n",
        "\n",
        "C = (A - A_min) / (A_max - A_min)\n",
        "C"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.33333333, 0.33333333, 0.33333333, 0.33333333, 0.33333333,\n",
              "        0.33333333],\n",
              "       [0.66666667, 0.66666667, 0.66666667, 0.66666667, 0.66666667,\n",
              "        0.66666667],\n",
              "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbXIXsDIUmtp"
      },
      "source": [
        "## Exercício 2.5\n",
        "\n",
        "Modificar o exercício anterior de forma que os valores de cada *linha* da matriz `A` sejam normalizados entre 0 e 1 independentemente dos valores das outras linhas.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-10T17:56:40.413601Z",
          "start_time": "2019-12-10T17:56:40.405056Z"
        },
        "id": "i-5Hv8-heDlW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8e36916-16b6-4d44-afa7-1cae443fd6a0"
      },
      "source": [
        "A_min = A.min(axis=1, keepdims=True)\n",
        "A_max = A.max(axis=1, keepdims=True)\n",
        "\n",
        "C = (A - A_min) / (A_max - A_min)\n",
        "C"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0. , 0.2, 0.4, 0.6, 0.8, 1. ],\n",
              "       [0. , 0.2, 0.4, 0.6, 0.8, 1. ],\n",
              "       [0. , 0.2, 0.4, 0.6, 0.8, 1. ],\n",
              "       [0. , 0.2, 0.4, 0.6, 0.8, 1. ]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKnLAyL7zgpa"
      },
      "source": [
        "## Exercício 2.6\n",
        "\n",
        "A [função softmax](https://en.wikipedia.org/wiki/Softmax_function) é bastante usada em apredizado de máquina para converter uma lista de números para uma distribuição de probabilidade, isto é, os números ficarão normalizados entre zero e um e sua soma será igual à um.\n",
        "\n",
        "Implemente a função softmax com suporte para batches, ou seja, o softmax deve ser aplicado a cada linha da matriz. Deve-se usar apenas a biblioteca numpy. Se atente que a exponenciação gera estouro de representação quando os números da entrada são muito grandes. Tente corrigir isto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lA5W9vxNEmOj"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def softmax(A):\n",
        "    '''\n",
        "    Aplica a função de softmax à matriz `A`.\n",
        "\n",
        "    Entrada:\n",
        "      `A` é uma matriz M x N, onde M é o número de exemplos a serem processados\n",
        "      independentemente e N é o tamanho de cada exemplo.\n",
        "    \n",
        "    Saída:\n",
        "      Uma matriz M x N, onde a soma de cada linha é igual a um.\n",
        "    '''\n",
        "    A_norm = A - np.max(A, axis=1, keepdims=True)\n",
        "    A_exp = np.exp(A_norm)\n",
        "    return A_exp / A_exp.sum(axis=1, keepdims=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpxlbh4ND54q"
      },
      "source": [
        "Mostre que sua implementação está correta usando uma matriz pequena como entrada:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6EZ5ZD7HFao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b07b6ee-451e-48c1-ece8-7af10418d680"
      },
      "source": [
        "A = np.array([[0.5, -1, 1000],\n",
        "              [-2,   0, 0.5]])\n",
        "softmax(A)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 1.        ],\n",
              "       [0.04861082, 0.35918811, 0.59220107]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j2uXmKH8HF4"
      },
      "source": [
        "O código a seguir verifica se sua implementação do softmax está correta. \n",
        "- A soma de cada linha de A deve ser 1;\n",
        "- Os valores devem estar entre 0 e 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-sN4STk7qyN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2519c6f4-1f57-4f69-93d1-842b0ec9a766"
      },
      "source": [
        "np.allclose(softmax(A).sum(axis=1), 1) and softmax(A).min() >= 0 and softmax(A).max() <= 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5_ZRWRfCZtI"
      },
      "source": [
        "Mostre que sua implementação é eficiente usando uma matriz grande como entrada:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhUeyrGaJ3J2"
      },
      "source": [
        "A = np.random.uniform(low=-10, high=10, size=(128, 100_000))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaa-C8XkKJin",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9dfd700-18d2-44c0-b644-8cc2d40dcd70"
      },
      "source": [
        "%%timeit\n",
        "softmax(A)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 293 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XE6LaWi81zZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3389af3d-8c7e-478a-a5df-40dcaf14c145"
      },
      "source": [
        "SM = softmax(A)\n",
        "np.allclose(SM.sum(axis=1), 1) and SM.min() >= 0 and SM.max() <= 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Flr1lI5o-HpG"
      },
      "source": [
        "## Exercício 2.7\n",
        "\n",
        "A codificação one-hot é usada para codificar entradas categóricas. É uma codificação onde apenas um bit é 1 e os demais são zero, conforme a tabela a seguir.\n",
        "\n",
        "| Decimal | Binary | One-hot\n",
        "| ------- | ------ | -------\n",
        "| 0 | 000    | 1 0 0 0 0 0 0 0\n",
        "| 1 | 001    | 0 1 0 0 0 0 0 0\n",
        "| 2 | 010    | 0 0 1 0 0 0 0 0\n",
        "| 3 | 011    | 0 0 0 1 0 0 0 0\n",
        "| 4 | 100    | 0 0 0 0 1 0 0 0\n",
        "| 5 | 101    | 0 0 0 0 0 1 0 0\n",
        "| 6 | 110    | 0 0 0 0 0 0 1 0\n",
        "| 7 | 111    | 0 0 0 0 0 0 0 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CqXP_5ABbfo"
      },
      "source": [
        "Implemente a função one_hot(y, n_classes) que codifique o vetor de inteiros y que possuem valores entre 0 e n_classes-1.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la-02w7qCH7L"
      },
      "source": [
        "def one_hot(y, n_classes):\n",
        "    return np.eye(n_classes)[y]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf5zyZO5Aiz_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0b14fd2-6d17-4c4c-bb67-e93550c653f2"
      },
      "source": [
        "N_CLASSES = 9\n",
        "N_SAMPLES = 10\n",
        "y = (np.random.rand((N_SAMPLES)) * N_CLASSES).astype(np.int)\n",
        "print(y)\n",
        "print(one_hot(y, N_CLASSES))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8 0 4 3 6 0 6 4 8 5]\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nwuKnQUCzve"
      },
      "source": [
        "Mostre que sua implementação é eficiente usando uma matriz grande como entrada:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwuFy5rWC2tA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2321dc66-fbe4-4b2a-ee4e-40ab12c676f9"
      },
      "source": [
        "N_SAMPLES = 100_000\n",
        "N_CLASSES = 1_000\n",
        "y = (np.random.rand((N_SAMPLES)) * N_CLASSES).astype(np.int)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7azMtF7wDJ2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0462cc2e-0288-48ae-e104-3c510bf44249"
      },
      "source": [
        "%%timeit\n",
        "one_hot(y, N_CLASSES)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 155 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqMroZay2ubi"
      },
      "source": [
        "## Exercício 2.8\n",
        "\n",
        "Implemente uma classe que normalize um array de pontos flutuantes `array_a` para a mesma média e desvio padrão de um outro array `array_b`, conforme exemplo abaixo:\n",
        "```\n",
        "array_a = np.array([-1, 1.5, 0])\n",
        "array_b = np.array([1.4, 0.8, 0.3, 2.5])\n",
        "normalize = Normalizer(array_b)\n",
        "normalized_array = normalize(array_a)\n",
        "print(normalized_array)  # Deve imprimir [0.3187798  2.31425165 1.11696854]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaedJ5Cf5Oy2"
      },
      "source": [
        "# Solução baseada em Closure\n",
        "\n",
        "def Normalizer(list_config):\n",
        "    array_config = np.array(list_config)\n",
        "    config_mean = array_config.mean()\n",
        "    config_std = array_config.std()\n",
        "\n",
        "    def normalize(list_to_normalize):\n",
        "        array = np.array(list_to_normalize)\n",
        "        mean = array.mean()\n",
        "        std = array.std()\n",
        "        \n",
        "        return ((array - mean) / std) * config_std + config_mean\n",
        "\n",
        "    return normalize\n",
        "\n",
        "# Outra solucao possivel seria definir uma classe Normalizer com as variaveis \n",
        "# self.config_mean e self.config_std e definir um método __call__."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlkNNU6h5RbR"
      },
      "source": [
        "Mostre que seu código está correto com o exemplo abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gad6zsbh5a0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51c31944-9b96-47d3-ab68-656dd5573036"
      },
      "source": [
        "array_a = [-1, 1.5, 0]\n",
        "array_b = [1.4, 0.8, 0.3, 2.5]\n",
        "normalize = Normalizer(array_b)\n",
        "normalized_array = normalize(array_a)\n",
        "print(normalized_array)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.3187798  2.31425165 1.11696854]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrGVQFUYI_LP"
      },
      "source": [
        "# Parte 3:\n",
        "\n",
        "##Exercícios Pytorch: Grafo Computacional e Gradientes\n",
        "\n",
        "Nesta parte pode-se usar quaisquer bibliotecas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIlQdKAuCZtR"
      },
      "source": [
        "Um dos principais fundamentos para que o PyTorch seja adequado para deep learning é a sua habilidade de calcular o gradiente automaticamente a partir da expressões definidas. Essa facilidade é implementada através do cálculo automático do gradiente e construção dinâmica do grafo computacional."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF_-dJ2nCZtT"
      },
      "source": [
        "## Grafo computacional\n",
        "\n",
        "Seja um exemplo simples de uma função de perda J dada pela Soma dos Erros ao Quadrado (SEQ - Sum of Squared Errors): \n",
        "$$ J = \\sum_i (x_i w - y_i)^2 $$\n",
        "que pode ser reescrita como:\n",
        "$$ \\hat{y_i} = x_i w $$\n",
        "$$ e_i = \\hat{y_i} - y_i $$\n",
        "$$ e2_i = e_i^2 $$\n",
        "$$ J = \\sum_i e2_i $$\n",
        "\n",
        "As redes neurais são treinadas através da minimização de uma função de perda usando o método do gradiente descendente. Para ajustar o parâmetro $w$ precisamos calcular o gradiente $  \\frac{ \\partial J}{\\partial w} $. Usando a\n",
        "regra da cadeia podemos escrever:\n",
        "$$ \\frac{ \\partial J}{\\partial w} = \\frac{ \\partial J}{\\partial e2_i} \\frac{ \\partial e2_i}{\\partial e_i} \\frac{ \\partial e_i}{\\partial \\hat{y_i} } \\frac{ \\partial \\hat{y_i}}{\\partial w}$$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jboejVQMCZtU"
      },
      "source": [
        "```\n",
        "    y_pred = x * w\n",
        "    e = y_pred - y\n",
        "    e2 = e**2\n",
        "    J = e2.sum()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7JmU6qhc2Y2"
      },
      "source": [
        "As quatro expressões acima, para o cálculo do J podem ser representadas pelo grafo computacional visualizado a seguir: os círculos são as variáveis (tensores), os quadrados são as operações, os números em preto são os cálculos durante a execução das quatro expressões para calcular o J (forward, predict). O cálculo do gradiente, mostrado em vermelho, é calculado pela regra da cadeia, de trás para frente (backward)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeeEBKl4CZtV"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/robertoalotufo/files/master/figures/GrafoComputacional.png\" width=\"600pt\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yZun7wrCZtX"
      },
      "source": [
        "Para entender melhor o funcionamento do grafo computacional com os tensores, recomenda-se leitura em:\n",
        "\n",
        "https://pytorch.org/docs/stable/notes/autograd.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-11T00:23:00.431853Z",
          "start_time": "2019-12-11T00:23:00.414813Z"
        },
        "id": "HlT2d-4fCZtZ"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-11T00:23:00.863228Z",
          "start_time": "2019-12-11T00:23:00.844457Z"
        },
        "id": "xX0QwUduCZtf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d01814dd-44f4-439b-8b06-99e321a47212"
      },
      "source": [
        "torch.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.10.0+cu111'"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsqzALS4CZtl"
      },
      "source": [
        "**Tensor com atributo .requires_grad=True**\n",
        "\n",
        "Quando um tensor possui o atributo `requires_grad` como verdadeiro, qualquer expressão que utilizar esse tensor irá construir um grafo computacional para permitir posteriormente, após calcular a função a ser derivada, poder usar a regra da cadeia e calcular o gradiente da função em termos dos tensores que possuem o atributo `requires_grad`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:22.117010Z",
          "start_time": "2019-09-29T03:07:22.041861Z"
        },
        "id": "foaAb94aCZtm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8969e129-5f0c-4187-cddb-9cebd9c56442"
      },
      "source": [
        "y = torch.arange(0, 8, 2).float()\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 2., 4., 6.])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:28.610934Z",
          "start_time": "2019-09-29T03:07:28.598223Z"
        },
        "id": "no6SdSyICZtr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52ded17a-f7c7-485e-c80e-2a0cbf7beb49"
      },
      "source": [
        "x = torch.arange(0, 4).float()\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:31.523762Z",
          "start_time": "2019-09-29T03:07:31.497683Z"
        },
        "id": "eL_i1mwGCZtw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32bb0177-5771-49c5-80c4-aed0acc5d416"
      },
      "source": [
        "w = torch.ones(1, requires_grad=True)\n",
        "w"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjEl-0l7CZt0"
      },
      "source": [
        "## Cálculo automático do gradiente da função perda J"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pUh-SCnCZt1"
      },
      "source": [
        "Seja a expressão: $$ J = \\sum_i ((x_i  w) - y_i)^2 $$\n",
        "\n",
        "Queremos calcular a derivada de $J$ em relação a $w$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMwwVtJ1CZt2"
      },
      "source": [
        "## Forward pass\n",
        "\n",
        "Durante a execução da expressão, o grafo computacional é criado. Compare os valores de cada parcela calculada com os valores em preto da figura ilustrativa do grafo computacional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:36.290122Z",
          "start_time": "2019-09-29T03:07:36.273229Z"
        },
        "id": "zp2aK4YhCZt3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaa02359-2f23-4eca-850a-c139ba95fdc5"
      },
      "source": [
        "# predict (forward)\n",
        "y_pred = x * w; print('y_pred =', y_pred)\n",
        "\n",
        "# cálculo da perda J: loss\n",
        "e = y_pred - y; print('e =',e)\n",
        "e2 = e.pow(2) ; print('e2 =', e2)\n",
        "J = e2.sum()  ; print('J =', J)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_pred = tensor([0., 1., 2., 3.], grad_fn=<MulBackward0>)\n",
            "e = tensor([ 0., -1., -2., -3.], grad_fn=<SubBackward0>)\n",
            "e2 = tensor([0., 1., 4., 9.], grad_fn=<PowBackward0>)\n",
            "J = tensor(14., grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC96wB7PCZt8"
      },
      "source": [
        "## Backward pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-10-04T15:55:45.308858",
          "start_time": "2017-10-04T15:55:45.304654"
        },
        "id": "kKbf4D0CCZt-"
      },
      "source": [
        "O `backward()` varre o grafo computacional a partir da variável a ele associada (raiz) e calcula o gradiente para todos os tensores que possuem o atributo `requires_grad` como verdadeiro.\n",
        "Observe que os tensores que tiverem o atributo `requires_grad` serão sempre folhas no grafo computacional.\n",
        "O `backward()` destroi o grafo após sua execução. Esse comportamento é padrão no PyTorch. \n",
        "\n",
        "A título ilustrativo, se quisermos depurar os gradientes dos nós que não são folhas no grafo computacional, precisamos primeiro invocar `retain_grad()` em cada um desses nós, como a seguir. Entretanto nos exemplos reais não há necessidade de verificar o gradiente desses nós."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-CjLPu6clVo"
      },
      "source": [
        "e2.retain_grad()\n",
        "e.retain_grad()\n",
        "y_pred.retain_grad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtsZS2Bicof-"
      },
      "source": [
        "E agora calculamos os gradientes com o `backward()`.\n",
        "\n",
        "w.grad é o gradiente de J em relação a w."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:40.267334Z",
          "start_time": "2019-09-29T03:07:40.247422Z"
        },
        "id": "Z1lnkb0GCZt_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5396a5e-c155-4f7e-c5b2-53d8ae4ecaf7"
      },
      "source": [
        "if w.grad: w.grad.zero_()\n",
        "J.backward()\n",
        "print(w.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-28.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1xYDPR_uOcZ"
      },
      "source": [
        "Mostramos agora os gradientes que estão grafados em vermelho no grafo computacional:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Enuk2tf0sDyO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b81035a7-850b-496f-c4d4-7576a3788895"
      },
      "source": [
        "print(e2.grad)\n",
        "print(e.grad)\n",
        "print(y_pred.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1.])\n",
            "tensor([ 0., -2., -4., -6.])\n",
            "tensor([ 0., -2., -4., -6.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsOThnt8fDJV"
      },
      "source": [
        "##Exercício 3.1\n",
        "Calcule o mesmo gradiente ilustrado no exemplo anterior usando a regra das diferenças finitas, de acordo com a equação a seguir, utilizando um valor de $\\Delta w$ bem pequeno.\n",
        "\n",
        "$$ \\frac{\\partial J}{\\partial w} = \\frac{J(w + \\Delta w) - J(w - \\Delta w)}{2 \\Delta w} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "62nZAfUoCZu5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06585d3a-2b1d-4a6a-e14b-baecff297cca"
      },
      "source": [
        "def J_func(w, x, y):\n",
        "    y_pred = x * w\n",
        "    e = y_pred - y\n",
        "    e2 = e.pow(2)\n",
        "    J = e2.sum()\n",
        "    return J\n",
        "\n",
        "# Calcule o gradiente usando a regra diferenças finitas\n",
        "# Confira com o valor já calculado anteriormente\n",
        "x = torch.arange(0, 4).float()\n",
        "y = torch.arange(0, 8, 2).float()\n",
        "w = torch.ones(1)\n",
        "\n",
        "epsilon = 1e-4\n",
        "grad = (J_func(w + epsilon, x, y) - J_func(w - epsilon, x, y)) / (2*epsilon)\n",
        "print('grad=', grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grad= tensor(-27.9999)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_Sx1QXZxJ3u"
      },
      "source": [
        "##Exercício 3.2\n",
        "\n",
        "Minimizando $J$ pelo gradiente descendente\n",
        "\n",
        "$$ w_{k+1} = w_k - \\lambda \\frac {\\partial J}{\\partial w} $$\n",
        "\n",
        "Supondo que valor inicial ($k=0$) $w_0 = 1$, use learning rate $\\lambda = 0.01$ para calcular o valor do novo $w_{20}$, ou seja, fazendo 20 atualizações de gradientes. Deve-se usar a função `J_func` criada no exercício anterior.\n",
        "\n",
        "Confira se o valor do primeiro gradiente está de acordo com os valores já calculado acima"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNszCOED1Wtu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c23c5318-f812-46b7-a6d1-efbde714dbb5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "learning_rate = 0.01\n",
        "iteracoes = 20\n",
        "epsilon = 1e-4\n",
        "grad = (J_func(w + epsilon, x, y) - J_func(w - epsilon, x, y)) / (2*epsilon)\n",
        "\n",
        "x = torch.arange(0, 4).float()\n",
        "y = torch.arange(0, 8, 2).float()\n",
        "w = torch.ones(1)\n",
        "\n",
        "J_history = []\n",
        "i_history = []\n",
        "\n",
        "for i in range(iteracoes):\n",
        "    i_history.append(i)\n",
        "\n",
        "    print('i =', i)\n",
        "    J = J_func(w, x, y)\n",
        "    print('J=', J)\n",
        "    J_history.append(J.item())\n",
        "    \n",
        "    grad = (J_func(w + epsilon, x, y) - J_func(w - epsilon, x, y)) / (2*epsilon)\n",
        "    print('grad =',grad)\n",
        "\n",
        "    w = w - learning_rate * grad\n",
        "    print('w =', w)\n",
        "\n",
        "# Plote o gráfico da loss J pela iteração i\n",
        "plt.plot(J_history, i_history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i = 0\n",
            "J= tensor(14.)\n",
            "grad = tensor(-27.9999)\n",
            "w = tensor([1.2800])\n",
            "i = 1\n",
            "J= tensor(7.2576)\n",
            "grad = tensor(-20.1607)\n",
            "w = tensor([1.4816])\n",
            "i = 2\n",
            "J= tensor(3.7623)\n",
            "grad = tensor(-14.5137)\n",
            "w = tensor([1.6267])\n",
            "i = 3\n",
            "J= tensor(1.9505)\n",
            "grad = tensor(-10.4505)\n",
            "w = tensor([1.7312])\n",
            "i = 4\n",
            "J= tensor(1.0112)\n",
            "grad = tensor(-7.5281)\n",
            "w = tensor([1.8065])\n",
            "i = 5\n",
            "J= tensor(0.5240)\n",
            "grad = tensor(-5.4196)\n",
            "w = tensor([1.8607])\n",
            "i = 6\n",
            "J= tensor(0.2716)\n",
            "grad = tensor(-3.9014)\n",
            "w = tensor([1.8997])\n",
            "i = 7\n",
            "J= tensor(0.1407)\n",
            "grad = tensor(-2.8086)\n",
            "w = tensor([1.9278])\n",
            "i = 8\n",
            "J= tensor(0.0729)\n",
            "grad = tensor(-2.0218)\n",
            "w = tensor([1.9480])\n",
            "i = 9\n",
            "J= tensor(0.0378)\n",
            "grad = tensor(-1.4555)\n",
            "w = tensor([1.9626])\n",
            "i = 10\n",
            "J= tensor(0.0196)\n",
            "grad = tensor(-1.0472)\n",
            "w = tensor([1.9731])\n",
            "i = 11\n",
            "J= tensor(0.0102)\n",
            "grad = tensor(-0.7540)\n",
            "w = tensor([1.9806])\n",
            "i = 12\n",
            "J= tensor(0.0053)\n",
            "grad = tensor(-0.5432)\n",
            "w = tensor([1.9860])\n",
            "i = 13\n",
            "J= tensor(0.0027)\n",
            "grad = tensor(-0.3910)\n",
            "w = tensor([1.9900])\n",
            "i = 14\n",
            "J= tensor(0.0014)\n",
            "grad = tensor(-0.2814)\n",
            "w = tensor([1.9928])\n",
            "i = 15\n",
            "J= tensor(0.0007)\n",
            "grad = tensor(-0.2027)\n",
            "w = tensor([1.9948])\n",
            "i = 16\n",
            "J= tensor(0.0004)\n",
            "grad = tensor(-0.1458)\n",
            "w = tensor([1.9962])\n",
            "i = 17\n",
            "J= tensor(0.0002)\n",
            "grad = tensor(-0.1051)\n",
            "w = tensor([1.9973])\n",
            "i = 18\n",
            "J= tensor(0.0001)\n",
            "grad = tensor(-0.0756)\n",
            "w = tensor([1.9981])\n",
            "i = 19\n",
            "J= tensor(5.2911e-05)\n",
            "grad = tensor(-0.0544)\n",
            "w = tensor([1.9986])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd3db6a5690>]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBXxBmWGK3IU"
      },
      "source": [
        "##Exercício 3.3\n",
        "\n",
        "Repita o exercício 2 mas usando agora o calculando o gradiente usando o método backward() do pytorch. Confira se o primeiro valor do gradiente está de acordo com os valores anteriores. Execute essa próxima célula duas vezes. Os valores devem ser iguais.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMP4d5vtHtqy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b6a86501-63eb-44f0-b6e4-834e2b31fc8f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "learning_rate = 0.01\n",
        "iteracoes = 20\n",
        "\n",
        "x = torch.arange(0, 4).float()\n",
        "y = torch.arange(0, 8, 2).float()\n",
        "w = torch.ones(1, requires_grad=True)\n",
        "\n",
        "J_history = []\n",
        "i_history = []\n",
        "\n",
        "for i in range(iteracoes):\n",
        "    i_history.append(i)\n",
        "\n",
        "    print('i =', i)\n",
        "    J = J_func(w, x, y)\n",
        "    print('J=', J)\n",
        "    J_history.append(J.item())\n",
        "    \n",
        "    w.retain_grad()\n",
        "    if w.grad: w.grad.zero_()\n",
        "    J.backward()\n",
        "    grad = w.grad\n",
        "    print('grad =',grad)\n",
        "\n",
        "    w = w - learning_rate * grad\n",
        "    print('w =', w)\n",
        "\n",
        "# Plote o gráfico da loss J pela iteração i\n",
        "plt.plot(J_history, i_history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i = 0\n",
            "J= tensor(14., grad_fn=<SumBackward0>)\n",
            "grad = tensor([-28.])\n",
            "w = tensor([1.2800], grad_fn=<SubBackward0>)\n",
            "i = 1\n",
            "J= tensor(7.2576, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-20.1600])\n",
            "w = tensor([1.4816], grad_fn=<SubBackward0>)\n",
            "i = 2\n",
            "J= tensor(3.7623, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-14.5152])\n",
            "w = tensor([1.6268], grad_fn=<SubBackward0>)\n",
            "i = 3\n",
            "J= tensor(1.9504, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-10.4509])\n",
            "w = tensor([1.7313], grad_fn=<SubBackward0>)\n",
            "i = 4\n",
            "J= tensor(1.0111, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-7.5247])\n",
            "w = tensor([1.8065], grad_fn=<SubBackward0>)\n",
            "i = 5\n",
            "J= tensor(0.5241, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-5.4178])\n",
            "w = tensor([1.8607], grad_fn=<SubBackward0>)\n",
            "i = 6\n",
            "J= tensor(0.2717, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-3.9008])\n",
            "w = tensor([1.8997], grad_fn=<SubBackward0>)\n",
            "i = 7\n",
            "J= tensor(0.1409, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-2.8086])\n",
            "w = tensor([1.9278], grad_fn=<SubBackward0>)\n",
            "i = 8\n",
            "J= tensor(0.0730, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-2.0222])\n",
            "w = tensor([1.9480], grad_fn=<SubBackward0>)\n",
            "i = 9\n",
            "J= tensor(0.0379, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-1.4560])\n",
            "w = tensor([1.9626], grad_fn=<SubBackward0>)\n",
            "i = 10\n",
            "J= tensor(0.0196, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-1.0483])\n",
            "w = tensor([1.9730], grad_fn=<SubBackward0>)\n",
            "i = 11\n",
            "J= tensor(0.0102, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.7548])\n",
            "w = tensor([1.9806], grad_fn=<SubBackward0>)\n",
            "i = 12\n",
            "J= tensor(0.0053, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.5434])\n",
            "w = tensor([1.9860], grad_fn=<SubBackward0>)\n",
            "i = 13\n",
            "J= tensor(0.0027, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.3913])\n",
            "w = tensor([1.9899], grad_fn=<SubBackward0>)\n",
            "i = 14\n",
            "J= tensor(0.0014, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.2817])\n",
            "w = tensor([1.9928], grad_fn=<SubBackward0>)\n",
            "i = 15\n",
            "J= tensor(0.0007, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.2028])\n",
            "w = tensor([1.9948], grad_fn=<SubBackward0>)\n",
            "i = 16\n",
            "J= tensor(0.0004, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.1460])\n",
            "w = tensor([1.9962], grad_fn=<SubBackward0>)\n",
            "i = 17\n",
            "J= tensor(0.0002, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.1052])\n",
            "w = tensor([1.9973], grad_fn=<SubBackward0>)\n",
            "i = 18\n",
            "J= tensor(0.0001, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.0757])\n",
            "w = tensor([1.9981], grad_fn=<SubBackward0>)\n",
            "i = 19\n",
            "J= tensor(5.3059e-05, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.0545])\n",
            "w = tensor([1.9986], grad_fn=<SubBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd3db153a90>]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GulfYtzBMx2e"
      },
      "source": [
        "##Exercício 3.4\n",
        "\n",
        "Quais são as restrições na escolha dos valores de $\\Delta w$ no cálculo do gradiente por diferenças finitas?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXQGEyvtiTAR"
      },
      "source": [
        "Resposta: $\\Delta w$ deve ser muito pequeno, de forma que uma expansão de Taylor de primeiro grau seja uma boa aproximação para J no ponto  $w_0$. Porém, não pode ser pequeno ao ponto de gerar erros muito grandes por conta de operações de ponto flutuante."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsrSF8GEiXk4"
      },
      "source": [
        "##Exercício 3.5\n",
        "\n",
        "Até agora trabalhamos com $w$ contendo apenas um parâmetro. Suponha agora que $w$ seja uma matriz com $N$ parâmetros e que o custo para executar $(x_i w - y_i)^2$ seja $O(N)$.\n",
        "> a) Qual é o custo computacional para fazer uma única atualização (um passo de gradiente) dos parâmetros de $w$ usando o método das diferencas finitas?\n",
        ">\n",
        "> b) Qual é o custo computacional para fazer uma única atualização (um passo de gradiente) dos parâmetros de $w$ usando o método do backpropagation?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4Pna3bcicHj"
      },
      "source": [
        "Resposta (justifique):\n",
        "\n",
        "a) $O(N^2)$, porque devemos calcular o gradiente em relação a cada um dos N parâmetros, e cada cálculo de gradiente é $O(N)$ (depende de duas execuções de $(x_i w - y_i)^2$, que é $O(N)$ por hipótese). \n",
        "\n",
        "b) $O(N)$, pois a etapa de forward e de backward do backpropagation são $O(N)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35I5w8EZdjIo"
      },
      "source": [
        "##Exercício 3.6\n",
        "\n",
        "Qual o custo (entropia cruzada) esperado para um exemplo (uma amostra) no começo do treinamento de um classificador inicializado aleatoriamente?\n",
        "\n",
        "A equação da entropia cruzada é:\n",
        "$$L = - \\sum_{j=0}^{K-1} y_j \\log p_j, $$\n",
        "Onde:\n",
        "\n",
        "- K é o número de classes;\n",
        "\n",
        "- $y_j=1$ se $j$ é a classe do exemplo (ground-truth), 0 caso contrário. Ou seja, $y$ é um vetor one-hot;\n",
        "\n",
        "- $p_j$ é a probabilidade predita pelo modelo para a classe $j$.\n",
        "\n",
        "A resposta tem que ser em função de uma ou mais das seguintes variáveis:\n",
        "\n",
        "- K = número de classes\n",
        "\n",
        "- B = batch size\n",
        "\n",
        "- D = dimensão de qualquer vetor do modelo\n",
        "\n",
        "- LR = learning rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swTOphiVs6eN"
      },
      "source": [
        "Resposta: Para calcular o custo esperado, precisamos de uma hipótese sobre a distribuição de $p_j$ e $y_j$. A distribuição de $p_j$, por sua vez, depende da arquitura da rede e de uma hipótese sobre a distribuição dos dados. Por exemplo, uma rede aleatória muito profunda com problema de explosão de gradientes tende a gerar probabilidades muito próximas de 0 ou 1. Porém, uma rede aleatória sem camadas ocultas (regressão logística), vai gerar probabilidades mais bem distribuídas entre 0-1. Além disso, a esperança de L varia se o dataset é balanceado (mesmo quantidade de amostras pertencentes a cada classe) ou desbalanceado. Portanto, só é possível responder a pergunta se assumirmos hipóteses sobre os dados, o classificador e sua inicialização, que influenciam a distribuição de $p_j$ e $y_j$. Assumindo que as classes são balanceadas e que o classificador dá uma probabilidade igual e constante para todas as classes, a esperança é: $$E(L) = - \\sum_{j=0}^{K-1} y_j \\log (1/K) = - log (1/K) = log (K) $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UNdHqgSB6S9"
      },
      "source": [
        "Fim do notebook."
      ]
    }
  ]
}