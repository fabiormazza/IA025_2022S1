{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTVOQpMfhgLM"
      },
      "source": [
        "Esté um notebook Colab contendo exercícios de programação em python, numpy e pytorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMoyGt5gXMgK"
      },
      "source": [
        "## Coloque seu nome"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBHbXcibXPRe",
        "outputId": "c1e0ece2-6544-42fe-e5ac-291484121812"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meu nome é: Pedro Cintra\n"
          ]
        }
      ],
      "source": [
        "print('Meu nome é: Pedro Cintra')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9S5acRbm1Zr"
      },
      "source": [
        "# Parte 1:\n",
        "\n",
        "##Exercícios de Processamento de Dados\n",
        "\n",
        "Nesta parte pode-se usar as bibliotecas nativas do python como a `collections`, `re` e `random`. Também pode-se usar o NumPy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxS5h1V8nDn6"
      },
      "source": [
        "##Exercício 1.1\n",
        "Crie um dicionário com os `k` itens mais frequentes de uma lista.\n",
        "\n",
        "Por exemplo, dada a lista de itens `L=['a', 'a', 'd', 'b', 'd', 'c', 'e', 'a', 'b', 'e', 'e', 'a']` e `k=2`, o resultado deve ser um dicionário cuja chave é o item e o valor é a sua frequência: {'a': 4, 'e': 3}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gT08b5Z_nC-j"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def top_k(L, k):\n",
        "  top = dict(Counter(L).most_common(k))\n",
        "  return top"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLD_e3C9p4xO"
      },
      "source": [
        "Mostre que sua implementação está correta usando uma entrada com poucos itens:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMW9NiBgnkvA",
        "outputId": "c626da1f-d725-4918-f0b7-0eb2dda7276f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resultado: {'a': 4, 'd': 3, 'e': 3}\n"
          ]
        }
      ],
      "source": [
        "L = ['f', 'a', 'a', 'd', 'b', 'd', 'c', 'e', 'a', 'b', 'e', 'e', 'a', 'd']\n",
        "k = 3\n",
        "resultado = top_k(L=L, k=k)\n",
        "print(f'resultado: {resultado}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBeqZScQqJ0a"
      },
      "source": [
        "Mostre que sua implementação é eficiente usando uma entrada com 10M de itens:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "O_lhcm4ko8bY"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "L = random.choices('abcdefghijklmnopqrstuvwxyz', k=10_000_000)\n",
        "k = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9U-Bgs2o-f_",
        "outputId": "39590447-869d-4c35-d268-9470eed4adff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 549 ms per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "resultado = top_k(L=L, k=k)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJHDaOz_tK38"
      },
      "source": [
        "## Exercício 1.2\n",
        "\n",
        "Em processamento de linguagem natural, é comum convertemos as palavras de um texto para uma lista de identificadores dessas palavras. Dado o dicionário `V` abaixo onde as chaves são palavras e os valores são seus respectivos identificadores, converta o texto `D` para uma lista de identificadores.\n",
        "\n",
        "Palavras que não existem no dicionário deverão ser convertidas para o identificador do token `unknown`.\n",
        "\n",
        "O código deve ser insensível a maiúsculas (case-insensitive).\n",
        "\n",
        "Se atente que pontuações (vírgulas, ponto final, etc) também são consideradas palavras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVzv89trtTPc"
      },
      "outputs": [],
      "source": [
        "def tokens_to_ids(text, vocabulary):\n",
        "  first_entries = text.lower().split(' ')\n",
        "  for i in range(len(first_entries)):\n",
        "    if '.' in first_entries[i] or ',' in first_entries[i] or '...' in first_entries[i] or '!' in first_entries[i] or '?' in first_entries[i]:\n",
        "      first_entries.append(list(first_entries[i])[-1])\n",
        "  code = []\n",
        "  for i in range(len(first_entries)):\n",
        "    try:\n",
        "      code.append(vocabulary[first_entries[i]])\n",
        "    except:\n",
        "      code.append(vocabulary['unknown'])\n",
        "  return code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCGZeiqkY-sm"
      },
      "source": [
        "Mostre que sua implementação esta correta com um exemplo pequeno:\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iApR1h7gY98E",
        "outputId": "bb656815-96f4-44e0-a183-98d6d4c0faba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 3, 2, 4, -1, 5]\n"
          ]
        }
      ],
      "source": [
        "V = {'eu': 1, 'de': 2, 'gosto': 3, 'comer': 4, '.': 5, 'unknown': -1}\n",
        "D = 'Eu gosto de comer pizza.'\n",
        "\n",
        "print(tokens_to_ids(D, V))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWtTMxlXZN25"
      },
      "source": [
        "Mostre que sua implementação é eficiente com um exemplo grande:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxT_g-ZxZUsX"
      },
      "outputs": [],
      "source": [
        "V = {'eu': 1, 'de': 2, 'gosto': 3, 'comer': 4, '.': 5, 'unknown': -1}\n",
        "D = ' '.join(1_000_000 * ['Eu gosto de comer pizza.'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kp1nataGZU-V",
        "outputId": "7d34b9ed-f557-43da-8dba-87cea6629268"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 loop, best of 5: 3.58 s per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "resultado = tokens_to_ids(D, V)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRfaKfXwRXn_"
      },
      "source": [
        "## Exercício 1.3\n",
        "\n",
        "Em aprendizado profundo é comum termos que lidar com arquivos muito grandes.\n",
        "\n",
        "Dado um arquivo de texto onde cada item é separado por `\\n`, escreva um programa que amostre `k` itens desse arquivo aleatoriamente.\n",
        "\n",
        "Nota 1: Assuma amostragem de uma distribuição uniforme, ou seja, todos os itens tem a mesma probablidade de amostragem.\n",
        "\n",
        "Nota 2: Assuma que o arquivo não cabe em memória.\n",
        "\n",
        "Nota 3: Utilize apenas bibliotecas nativas do python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2PsadE9SRG_9"
      },
      "outputs": [],
      "source": [
        "from random import choices\n",
        "\n",
        "def sample(path: str, k: int):\n",
        "  f = open(path, \"r\")\n",
        "  return choices(f.readlines(), k=k)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycEnlFWxSt0i"
      },
      "source": [
        "Mostre que sua implementação está correta com um exemplo pequeno:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyLJ1e2ZSzC9",
        "outputId": "fdfcef36-a748-4130-dcd2-8bb058df92f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['line 65\\n', 'line 42\\n', 'line 81\\n', 'line 57\\n', 'line 2\\n', 'line 66\\n', 'line 48\\n', 'line 9\\n', 'line 59\\n', 'line 20\\n']\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "filename = 'small.txt'\n",
        "total_size = 100\n",
        "n_samples = 10\n",
        "\n",
        "with open(filename, 'w') as fout:\n",
        "    fout.write('\\n'.join(f'line {i}' for i in range(total_size)))\n",
        "\n",
        "samples = sample(path=filename, k=n_samples)\n",
        "print(samples)\n",
        "print(len(samples) == n_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2r4FMiMj12Xg"
      },
      "source": [
        "Mostre que sua implementação é eficiente com um exemplo grande:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PUwnNMGg18Ty"
      },
      "outputs": [],
      "source": [
        "filename = 'large.txt'\n",
        "total_size = 1_000_000\n",
        "n_samples = 10000\n",
        "\n",
        "with open(filename, 'w') as fout:\n",
        "    fout.write('\\n'.join(f'line {i}' for i in range(total_size)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iA9sAZmo0UDN",
        "outputId": "45873df3-30b5-4384-a826-2f8fd4bd8ebe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loops, best of 5: 88.4 ms per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "samples = sample(path=filename, k=n_samples)\n",
        "assert len(samples) == n_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udS0Ns4etoJs"
      },
      "source": [
        "# Parte 2:\n",
        "\n",
        "##Exercícios de Numpy\n",
        "\n",
        "Nesta parte deve-se usar apenas a biblioteca NumPy. Aqui não se pode usar o PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcMz3Vzjt144"
      },
      "source": [
        "##Exercício 2.1\n",
        "\n",
        "Quantos operações de ponto flutuante (flops) de soma e de multiplicação tem a multiplicação matricial $AB$, sendo que a matriz $A$ tem tamanho $m \\times n$ e a matriz $B$ tem tamanho $n \\times p$?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gNXj45RJqUm"
      },
      "source": [
        "Resposta:\n",
        "- número de somas: $(n-1)mp$\n",
        "- número de multiplicações: $nmp$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iI7udBFeDlP"
      },
      "source": [
        "## Exercício 2.2\n",
        "\n",
        "Em programação matricial, não se faz o loop em cada elemento da matriz,\n",
        "mas sim, utiliza-se operações matriciais.\n",
        "\n",
        "Dada a matriz `A` abaixo, calcule a média dos valores de cada linha sem utilizar laços explícitos.\n",
        "\n",
        "Utilize apenas a biblioteca numpy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjrXf18N5KrK"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fqxgNBW27Z0",
        "outputId": "406d9620-6598-48b8-c938-01e6ab66472d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  1  2  3  4  5]\n",
            " [ 6  7  8  9 10 11]\n",
            " [12 13 14 15 16 17]\n",
            " [18 19 20 21 22 23]]\n"
          ]
        }
      ],
      "source": [
        "A = np.arange(24).reshape(4, 6)\n",
        "print(A)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1EmKFrT5g7B",
        "outputId": "dbdfd191-4db5-45d0-d1ef-aab1dd082161"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2.5,  8.5, 14.5, 20.5])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "np.mean(A, axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtgSAAKjUfcO"
      },
      "source": [
        "## Exercício 2.3\n",
        "\n",
        "Seja a matriz $C$ que é a normalização da matriz $A$:\n",
        "$$ C(i,j) = \\frac{A(i,j) - A_{min}}{A_{max} - A_{min}} $$\n",
        "\n",
        "Normalizar a matriz `A` do exercício acima de forma que seus valores fiquem entre 0 e 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pDhb2-0eDlS",
        "outputId": "29890ead-69fd-4067-851d-56d3d5762e0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.04347826 0.08695652 0.13043478 0.17391304 0.2173913 ]\n",
            " [0.26086957 0.30434783 0.34782609 0.39130435 0.43478261 0.47826087]\n",
            " [0.52173913 0.56521739 0.60869565 0.65217391 0.69565217 0.73913043]\n",
            " [0.7826087  0.82608696 0.86956522 0.91304348 0.95652174 1.        ]]\n"
          ]
        }
      ],
      "source": [
        "C = (A-np.min(A))/(np.max(A)-np.min(A))\n",
        "print(C)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF_P_GARU62m"
      },
      "source": [
        "## Exercício 2.4\n",
        "\n",
        "Modificar o exercício anterior de forma que os valores de cada *coluna* da matriz `A` sejam normalizados entre 0 e 1 independentemente dos valores das outras colunas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVDVR5kESLEP"
      },
      "outputs": [],
      "source": [
        "C = np.zeros((4,6))\n",
        "\n",
        "for i in range(6):\n",
        "  C[:,i] = (A[:,i]-np.min(A[:,i]))/(np.max(A[:,i])-np.min(A[:,i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDSe4m8ZSvii",
        "outputId": "b84aa565-07ea-41a9-e7ca-5dec9b2aef21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.         0.         0.         0.         0.        ]\n",
            " [0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.33333333]\n",
            " [0.66666667 0.66666667 0.66666667 0.66666667 0.66666667 0.66666667]\n",
            " [1.         1.         1.         1.         1.         1.        ]]\n"
          ]
        }
      ],
      "source": [
        "print(C)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbXIXsDIUmtp"
      },
      "source": [
        "## Exercício 2.5\n",
        "\n",
        "Modificar o exercício anterior de forma que os valores de cada *linha* da matriz `A` sejam normalizados entre 0 e 1 independentemente dos valores das outras linhas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-5Hv8-heDlW",
        "outputId": "6bdbe25c-c819-4b41-d487-b0777c07bbb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.  0.2 0.4 0.6 0.8 1. ]\n",
            " [0.  0.2 0.4 0.6 0.8 1. ]\n",
            " [0.  0.2 0.4 0.6 0.8 1. ]\n",
            " [0.  0.2 0.4 0.6 0.8 1. ]]\n"
          ]
        }
      ],
      "source": [
        "C = np.zeros((4,6))\n",
        "\n",
        "for i in range(4):\n",
        "  C[i,:] = (A[i,:]-np.min(A[i,:]))/(np.max(A[i,:])-np.min(A[i,:]))\n",
        "\n",
        "print(C)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKnLAyL7zgpa"
      },
      "source": [
        "## Exercício 2.6\n",
        "\n",
        "A [função softmax](https://en.wikipedia.org/wiki/Softmax_function) é bastante usada em apredizado de máquina para converter uma lista de números para uma distribuição de probabilidade, isto é, os números ficarão normalizados entre zero e um e sua soma será igual à um.\n",
        "\n",
        "Implemente a função softmax com suporte para batches, ou seja, o softmax deve ser aplicado a cada linha da matriz. Deve-se usar apenas a biblioteca numpy. Se atente que a exponenciação gera estouro de representação quando os números da entrada são muito grandes. Tente corrigir isto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lA5W9vxNEmOj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def softmax(A):\n",
        "    '''\n",
        "    Aplica a função de softmax à matriz `A`.\n",
        "\n",
        "    Entrada:\n",
        "      `A` é uma matriz M x N, onde M é o número de exemplos a serem processados\n",
        "      independentemente e N é o tamanho de cada exemplo.\n",
        "    \n",
        "    Saída:\n",
        "      Uma matriz M x N, onde a soma de cada linha é igual a um.\n",
        "    '''\n",
        "    C = np.zeros((len(A[:,0]),len(A[0,:])))\n",
        "    for i in range(len(A[:,0])):\n",
        "      A_norm = (A[i,:]-np.min(A[i,:]))/(np.max(A[i,:])-np.min(A[i,:])) #Normalização para eliminar valores muito grandes\n",
        "      C[i,:] = np.exp(A_norm)/np.sum(np.exp(A_norm)) #Softmax\n",
        "    \n",
        "    return C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpxlbh4ND54q"
      },
      "source": [
        "Mostre que sua implementação está correta usando uma matriz pequena como entrada:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6EZ5ZD7HFao",
        "outputId": "79a1bede-6b90-4053-8cba-9f5e0dcc8686"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.21219195, 0.21187422, 0.57593383],\n",
              "       [0.16824189, 0.37442922, 0.45732888]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "A = np.array([[0.5, -1, 1000],\n",
        "              [-2,   0, 0.5]])\n",
        "softmax(A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j2uXmKH8HF4"
      },
      "source": [
        "O código a seguir verifica se sua implementação do softmax está correta. \n",
        "- A soma de cada linha de A deve ser 1;\n",
        "- Os valores devem estar entre 0 e 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-sN4STk7qyN",
        "outputId": "3c4ffa93-7440-4dc9-f91d-a82f5f6f7e93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "np.allclose(softmax(A).sum(axis=1), 1) and softmax(A).min() >= 0 and softmax(A).max() <= 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5_ZRWRfCZtI"
      },
      "source": [
        "Mostre que sua implementação é eficiente usando uma matriz grande como entrada:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhUeyrGaJ3J2"
      },
      "outputs": [],
      "source": [
        "A = np.random.uniform(low=-10, high=10, size=(128, 100_000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaa-C8XkKJin",
        "outputId": "d4ad5cce-2066-4b5d-af0d-fd2b7813d4df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 584 ms per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "softmax(A)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XE6LaWi81zZ",
        "outputId": "23397915-44e1-4752-aecb-e23af52649bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "SM = softmax(A)\n",
        "np.allclose(SM.sum(axis=1), 1) and SM.min() >= 0 and SM.max() <= 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Flr1lI5o-HpG"
      },
      "source": [
        "## Exercício 2.7\n",
        "\n",
        "A codificação one-hot é usada para codificar entradas categóricas. É uma codificação onde apenas um bit é 1 e os demais são zero, conforme a tabela a seguir.\n",
        "\n",
        "| Decimal | Binary | One-hot\n",
        "| ------- | ------ | -------\n",
        "| 0 | 000    | 1 0 0 0 0 0 0 0\n",
        "| 1 | 001    | 0 1 0 0 0 0 0 0\n",
        "| 2 | 010    | 0 0 1 0 0 0 0 0\n",
        "| 3 | 011    | 0 0 0 1 0 0 0 0\n",
        "| 4 | 100    | 0 0 0 0 1 0 0 0\n",
        "| 5 | 101    | 0 0 0 0 0 1 0 0\n",
        "| 6 | 110    | 0 0 0 0 0 0 1 0\n",
        "| 7 | 111    | 0 0 0 0 0 0 0 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CqXP_5ABbfo"
      },
      "source": [
        "Implemente a função one_hot(y, n_classes) que codifique o vetor de inteiros y que possuem valores entre 0 e n_classes-1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "la-02w7qCH7L"
      },
      "outputs": [],
      "source": [
        "def one_hot(y, n_classes):\n",
        "  one_hots = []\n",
        "  for i in range(len(y)):\n",
        "    bits = np.zeros(n_classes)\n",
        "    bits[y[i]] = 1\n",
        "    one_hots.append(bits)\n",
        "  return np.array(one_hots)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf5zyZO5Aiz_",
        "outputId": "834a1505-3aea-440a-de05-495355721ae4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7 4 0 3 3 5 8 7 2 6]\n",
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "N_CLASSES = 9\n",
        "N_SAMPLES = 10\n",
        "y = (np.random.rand((N_SAMPLES)) * N_CLASSES).astype(int)\n",
        "print(y)\n",
        "print(one_hot(y, N_CLASSES))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nwuKnQUCzve"
      },
      "source": [
        "Mostre que sua implementação é eficiente usando uma matriz grande como entrada:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwuFy5rWC2tA"
      },
      "outputs": [],
      "source": [
        "N_SAMPLES = 100_000\n",
        "N_CLASSES = 1_000\n",
        "y = (np.random.rand((N_SAMPLES)) * N_CLASSES).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7azMtF7wDJ2_",
        "outputId": "0318bb7c-a9fd-4534-f645-82826ff8f936"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 1.03 s per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "one_hot(y, N_CLASSES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqMroZay2ubi"
      },
      "source": [
        "## Exercício 2.8\n",
        "\n",
        "Implemente uma classe que normalize um array de pontos flutuantes `array_a` para a mesma média e desvio padrão de um outro array `array_b`, conforme exemplo abaixo:\n",
        "```\n",
        "array_a = np.array([-1, 1.5, 0])\n",
        "array_b = np.array([1.4, 0.8, 0.3, 2.5])\n",
        "normalize = Normalizer(array_b)\n",
        "normalized_array = normalize(array_a)\n",
        "print(normalized_array)  # Deve imprimir [0.3187798  2.31425165 1.11696854]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaedJ5Cf5Oy2"
      },
      "outputs": [],
      "source": [
        "class Normalizer():\n",
        "  def __init__(self, array_b):\n",
        "    self.mean_array = np.mean(array_b)\n",
        "    self.std_array = np.std(array_b)\n",
        "\n",
        "  def __call__(self, array_a):\n",
        "    final_array = (array_a-np.mean(array_a))*self.std_array/np.std(array_a) + self.mean_array\n",
        "    return final_array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlkNNU6h5RbR"
      },
      "source": [
        "Mostre que seu código está correto com o exemplo abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gad6zsbh5a0D",
        "outputId": "c518bd25-dd6a-416a-bffc-6d1a21080a62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.3187798  2.31425165 1.11696854]\n"
          ]
        }
      ],
      "source": [
        "array_a = [-1, 1.5, 0]\n",
        "array_b = [1.4, 0.8, 0.3, 2.5]\n",
        "normalize = Normalizer(array_b)\n",
        "normalized_array = normalize(array_a)\n",
        "print(normalized_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrGVQFUYI_LP"
      },
      "source": [
        "# Parte 3:\n",
        "\n",
        "##Exercícios Pytorch: Grafo Computacional e Gradientes\n",
        "\n",
        "Nesta parte pode-se usar quaisquer bibliotecas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIlQdKAuCZtR"
      },
      "source": [
        "Um dos principais fundamentos para que o PyTorch seja adequado para deep learning é a sua habilidade de calcular o gradiente automaticamente a partir da expressões definidas. Essa facilidade é implementada através do cálculo automático do gradiente e construção dinâmica do grafo computacional."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF_-dJ2nCZtT"
      },
      "source": [
        "## Grafo computacional\n",
        "\n",
        "Seja um exemplo simples de uma função de perda J dada pela Soma dos Erros ao Quadrado (SEQ - Sum of Squared Errors): \n",
        "$$ J = \\sum_i (x_i w - y_i)^2 $$\n",
        "que pode ser reescrita como:\n",
        "$$ \\hat{y_i} = x_i w $$\n",
        "$$ e_i = \\hat{y_i} - y_i $$\n",
        "$$ e2_i = e_i^2 $$\n",
        "$$ J = \\sum_i e2_i $$\n",
        "\n",
        "As redes neurais são treinadas através da minimização de uma função de perda usando o método do gradiente descendente. Para ajustar o parâmetro $w$ precisamos calcular o gradiente $  \\frac{ \\partial J}{\\partial w} $. Usando a\n",
        "regra da cadeia podemos escrever:\n",
        "$$ \\frac{ \\partial J}{\\partial w} = \\frac{ \\partial J}{\\partial e2_i} \\frac{ \\partial e2_i}{\\partial e_i} \\frac{ \\partial e_i}{\\partial \\hat{y_i} } \\frac{ \\partial \\hat{y_i}}{\\partial w}$$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jboejVQMCZtU"
      },
      "source": [
        "```\n",
        "    y_pred = x * w\n",
        "    e = y_pred - y\n",
        "    e2 = e**2\n",
        "    J = e2.sum()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7JmU6qhc2Y2"
      },
      "source": [
        "As quatro expressões acima, para o cálculo do J podem ser representadas pelo grafo computacional visualizado a seguir: os círculos são as variáveis (tensores), os quadrados são as operações, os números em preto são os cálculos durante a execução das quatro expressões para calcular o J (forward, predict). O cálculo do gradiente, mostrado em vermelho, é calculado pela regra da cadeia, de trás para frente (backward)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeeEBKl4CZtV"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/robertoalotufo/files/master/figures/GrafoComputacional.png\" width=\"600pt\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yZun7wrCZtX"
      },
      "source": [
        "Para entender melhor o funcionamento do grafo computacional com os tensores, recomenda-se leitura em:\n",
        "\n",
        "https://pytorch.org/docs/stable/notes/autograd.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HlT2d-4fCZtZ"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xX0QwUduCZtf",
        "outputId": "d1f7e62d-9816-441e-ad46-b3e377bddcd2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.10.0+cu111'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsqzALS4CZtl"
      },
      "source": [
        "**Tensor com atributo .requires_grad=True**\n",
        "\n",
        "Quando um tensor possui o atributo `requires_grad` como verdadeiro, qualquer expressão que utilizar esse tensor irá construir um grafo computacional para permitir posteriormente, após calcular a função a ser derivada, poder usar a regra da cadeia e calcular o gradiente da função em termos dos tensores que possuem o atributo `requires_grad`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "foaAb94aCZtm",
        "outputId": "27e3f3fd-b2cb-46bf-c4e2-a2c348655ab2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0., 2., 4., 6.])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = torch.arange(0, 8, 2).float()\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "no6SdSyICZtr",
        "outputId": "0a3d5dc7-4883-4638-baae-1aaa8c116d92"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3.])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.arange(0, 4).float()\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eL_i1mwGCZtw",
        "outputId": "87193c60-e2d9-483e-a1d1-4494ca37f648"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1.], requires_grad=True)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w = torch.ones(1, requires_grad=True)\n",
        "w"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjEl-0l7CZt0"
      },
      "source": [
        "## Cálculo automático do gradiente da função perda J"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pUh-SCnCZt1"
      },
      "source": [
        "Seja a expressão: $$ J = \\sum_i ((x_i  w) - y_i)^2 $$\n",
        "\n",
        "Queremos calcular a derivada de $J$ em relação a $w$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMwwVtJ1CZt2"
      },
      "source": [
        "## Forward pass\n",
        "\n",
        "Durante a execução da expressão, o grafo computacional é criado. Compare os valores de cada parcela calculada com os valores em preto da figura ilustrativa do grafo computacional."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zp2aK4YhCZt3",
        "outputId": "19f2a786-8465-4015-9a3e-fb59cefff465"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y_pred = tensor([0., 1., 2., 3.], grad_fn=<MulBackward0>)\n",
            "e = tensor([ 0., -1., -2., -3.], grad_fn=<SubBackward0>)\n",
            "e2 = tensor([0., 1., 4., 9.], grad_fn=<PowBackward0>)\n",
            "J = tensor(14., grad_fn=<SumBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# predict (forward)\n",
        "y_pred = x * w; print('y_pred =', y_pred)\n",
        "\n",
        "# cálculo da perda J: loss\n",
        "e = y_pred - y; print('e =',e)\n",
        "e2 = e.pow(2) ; print('e2 =', e2)\n",
        "J = e2.sum()  ; print('J =', J)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC96wB7PCZt8"
      },
      "source": [
        "## Backward pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKbf4D0CCZt-"
      },
      "source": [
        "O `backward()` varre o grafo computacional a partir da variável a ele associada (raiz) e calcula o gradiente para todos os tensores que possuem o atributo `requires_grad` como verdadeiro.\n",
        "Observe que os tensores que tiverem o atributo `requires_grad` serão sempre folhas no grafo computacional.\n",
        "O `backward()` destroi o grafo após sua execução. Esse comportamento é padrão no PyTorch. \n",
        "\n",
        "A título ilustrativo, se quisermos depurar os gradientes dos nós que não são folhas no grafo computacional, precisamos primeiro invocar `retain_grad()` em cada um desses nós, como a seguir. Entretanto nos exemplos reais não há necessidade de verificar o gradiente desses nós."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "f-CjLPu6clVo"
      },
      "outputs": [],
      "source": [
        "e2.retain_grad()\n",
        "e.retain_grad()\n",
        "y_pred.retain_grad()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtsZS2Bicof-"
      },
      "source": [
        "E agora calculamos os gradientes com o `backward()`.\n",
        "\n",
        "w.grad é o gradiente de J em relação a w."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Z1lnkb0GCZt_",
        "outputId": "02d9e956-58c1-43b6-bcff-5993ccc98120"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-28.])\n"
          ]
        }
      ],
      "source": [
        "if w.grad: w.grad.zero_()\n",
        "J.backward()\n",
        "print(w.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1xYDPR_uOcZ"
      },
      "source": [
        "Mostramos agora os gradientes que estão grafados em vermelho no grafo computacional:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Enuk2tf0sDyO",
        "outputId": "7c3f59e5-f8fb-45ab-ac2c-07db592c0c65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1.])\n",
            "tensor([ 0., -2., -4., -6.])\n",
            "tensor([ 0., -2., -4., -6.])\n"
          ]
        }
      ],
      "source": [
        "print(e2.grad)\n",
        "print(e.grad)\n",
        "print(y_pred.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsOThnt8fDJV"
      },
      "source": [
        "##Exercício 3.1\n",
        "Calcule o mesmo gradiente ilustrado no exemplo anterior usando a regra das diferenças finitas, de acordo com a equação a seguir, utilizando um valor de $\\Delta w$ bem pequeno.\n",
        "\n",
        "$$ \\frac{\\partial J}{\\partial w} = \\frac{J(w + \\Delta w) - J(w - \\Delta w)}{2 \\Delta w} $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "62nZAfUoCZu5",
        "outputId": "af80b079-daa4-4cf2-9ac1-4194b9037a38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grad= tensor(-28.0000)\n"
          ]
        }
      ],
      "source": [
        "def J_func(w, x, y):\n",
        "  delta_w = 0.01\n",
        "  y1_pred = x * (w + delta_w)\n",
        "  e1 = y1_pred - y\n",
        "  e21 = e1.pow(2)\n",
        "  J_1 = e21.sum()\n",
        "\n",
        "  y2_pred = x * (w - delta_w)\n",
        "  e2 = y2_pred - y\n",
        "  e22 = e2.pow(2)\n",
        "  J_2 = e22.sum()\n",
        "  grad = (J_1 - J_2)/(2*delta_w)\n",
        "  # programe a função J_func, para facilitar\n",
        "  return grad\n",
        "\n",
        "# Calcule o gradiente usando a regra diferenças finitas\n",
        "# Confira com o valor já calculado anteriormente\n",
        "x = torch.arange(0, 4).float()\n",
        "y = torch.arange(0, 8, 2).float()\n",
        "w = torch.ones(1)\n",
        "grad = J_func(w, x, y)\n",
        "print('grad=', grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_Sx1QXZxJ3u"
      },
      "source": [
        "##Exercício 3.2\n",
        "\n",
        "Minimizando $J$ pelo gradiente descendente\n",
        "\n",
        "$$ w_{k+1} = w_k - \\lambda \\frac {\\partial J}{\\partial w} $$\n",
        "\n",
        "Supondo que valor inicial ($k=0$) $w_0 = 1$, use learning rate $\\lambda = 0.01$ para calcular o valor do novo $w_{20}$, ou seja, fazendo 20 atualizações de gradientes. Deve-se usar a função `J_func` criada no exercício anterior.\n",
        "\n",
        "Confira se o valor do primeiro gradiente está de acordo com os valores já calculado acima"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PNszCOED1Wtu",
        "outputId": "ce0f3938-f6fd-4c35-949d-a7f72b6f2f4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i = 0\n",
            "J= tensor(-28.0000)\n",
            "grad = tensor(-28.0000)\n",
            "w = tensor([1.0100])\n",
            "i = 1\n",
            "J= tensor(-27.7200)\n",
            "grad = tensor(-27.7200)\n",
            "w = tensor([1.0200])\n",
            "i = 2\n",
            "J= tensor(-27.4400)\n",
            "grad = tensor(-27.4400)\n",
            "w = tensor([1.0300])\n",
            "i = 3\n",
            "J= tensor(-27.1600)\n",
            "grad = tensor(-27.1600)\n",
            "w = tensor([1.0400])\n",
            "i = 4\n",
            "J= tensor(-26.8800)\n",
            "grad = tensor(-26.8800)\n",
            "w = tensor([1.0500])\n",
            "i = 5\n",
            "J= tensor(-26.6000)\n",
            "grad = tensor(-26.6000)\n",
            "w = tensor([1.0600])\n",
            "i = 6\n",
            "J= tensor(-26.3199)\n",
            "grad = tensor(-26.3199)\n",
            "w = tensor([1.0700])\n",
            "i = 7\n",
            "J= tensor(-26.0400)\n",
            "grad = tensor(-26.0400)\n",
            "w = tensor([1.0800])\n",
            "i = 8\n",
            "J= tensor(-25.7600)\n",
            "grad = tensor(-25.7600)\n",
            "w = tensor([1.0900])\n",
            "i = 9\n",
            "J= tensor(-25.4800)\n",
            "grad = tensor(-25.4800)\n",
            "w = tensor([1.1000])\n",
            "i = 10\n",
            "J= tensor(-25.2000)\n",
            "grad = tensor(-25.2000)\n",
            "w = tensor([1.1100])\n",
            "i = 11\n",
            "J= tensor(-24.9200)\n",
            "grad = tensor(-24.9200)\n",
            "w = tensor([1.1200])\n",
            "i = 12\n",
            "J= tensor(-24.6399)\n",
            "grad = tensor(-24.6399)\n",
            "w = tensor([1.1300])\n",
            "i = 13\n",
            "J= tensor(-24.3599)\n",
            "grad = tensor(-24.3599)\n",
            "w = tensor([1.1400])\n",
            "i = 14\n",
            "J= tensor(-24.0800)\n",
            "grad = tensor(-24.0800)\n",
            "w = tensor([1.1500])\n",
            "i = 15\n",
            "J= tensor(-23.8000)\n",
            "grad = tensor(-23.8000)\n",
            "w = tensor([1.1600])\n",
            "i = 16\n",
            "J= tensor(-23.5200)\n",
            "grad = tensor(-23.5200)\n",
            "w = tensor([1.1700])\n",
            "i = 17\n",
            "J= tensor(-23.2400)\n",
            "grad = tensor(-23.2400)\n",
            "w = tensor([1.1800])\n",
            "i = 18\n",
            "J= tensor(-22.9600)\n",
            "grad = tensor(-22.9600)\n",
            "w = tensor([1.1900])\n",
            "i = 19\n",
            "J= tensor(-22.6800)\n",
            "grad = tensor(-22.6800)\n",
            "w = tensor([1.2000])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Iterations')"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "learning_rate = 0.01\n",
        "iteracoes = 20\n",
        "\n",
        "x = torch.arange(0, 4).float()\n",
        "y = torch.arange(0, 8, 2).float()\n",
        "w = torch.ones(1)\n",
        "\n",
        "Js = []\n",
        "for i in range(iteracoes):\n",
        "  print('i =', i)\n",
        "  J = J_func(w, x, y)\n",
        "  Js.append(J)\n",
        "  print('J=', J)\n",
        "  grad = J_func(w, x, y)\n",
        "  print('grad =',grad)\n",
        "  w = w + learning_rate\n",
        "  print('w =', w)\n",
        "\n",
        "# Plote o gráfico da loss J pela iteração i\n",
        "plt.scatter([i for i in range(iteracoes)], Js)\n",
        "plt.ylabel(r'Loss $J$')\n",
        "plt.xlabel('Iterations')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBXxBmWGK3IU"
      },
      "source": [
        "##Exercício 3.3\n",
        "\n",
        "Repita o exercício 2 mas usando agora o calculando o gradiente usando o método backward() do pytorch. Confira se o primeiro valor do gradiente está de acordo com os valores anteriores. Execute essa próxima célula duas vezes. Os valores devem ser iguais.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lMP4d5vtHtqy",
        "outputId": "166c6107-b982-4c7f-8598-5500fecfabdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i = 0\n",
            "J= tensor(-28.0000, grad_fn=<DivBackward0>)\n",
            "grad = tensor([28.])\n",
            "w = tensor([1.0100], grad_fn=<AddBackward0>)\n",
            "i = 1\n",
            "J= tensor(-27.7200, grad_fn=<DivBackward0>)\n",
            "grad = None\n",
            "w = tensor([1.0200], grad_fn=<AddBackward0>)\n",
            "i = 2\n",
            "J= tensor(-27.4400, grad_fn=<DivBackward0>)\n",
            "grad = None\n",
            "w = tensor([1.0300], grad_fn=<AddBackward0>)\n",
            "i = 3\n",
            "J= tensor(-27.1600, grad_fn=<DivBackward0>)\n",
            "grad = None\n",
            "w = tensor([1.0400], grad_fn=<AddBackward0>)\n",
            "i = 4\n",
            "J= tensor(-26.8800, grad_fn=<DivBackward0>)\n",
            "grad = None\n",
            "w = tensor([1.0500], grad_fn=<AddBackward0>)\n",
            "i = 5\n",
            "J= tensor(-26.6000, grad_fn=<DivBackward0>)\n",
            "grad = None\n",
            "w = tensor([1.0600], grad_fn=<AddBackward0>)\n",
            "i = 6\n",
            "J= tensor(-26.3199, grad_fn=<DivBackward0>)\n",
            "grad = None\n",
            "w = tensor([1.0700], grad_fn=<AddBackward0>)\n",
            "i = 7\n",
            "J= tensor(-26.0400, grad_fn=<DivBackward0>)\n",
            "grad = None\n",
            "w = tensor([1.0800], grad_fn=<AddBackward0>)\n",
            "i = 8\n",
            "J= tensor(-25.7600, grad_fn=<DivBackward0>)\n",
            "grad = None\n",
            "w = tensor([1.0900], grad_fn=<AddBackward0>)\n",
            "i = 9\n",
            "J= tensor(-25.4800, grad_fn=<DivBackward0>)\n",
            "grad = None\n",
            "w = tensor([1.1000], grad_fn=<AddBackward0>)\n",
            "i = 10\n",
            "J= tensor(-25.2000, grad_fn=<DivBackward0>)\n",
            "grad = None\n",
            "w = tensor([1.1100], grad_fn=<AddBackward0>)\n",
            "i = 11\n",
            "J= tensor(-24.9200, grad_fn=<DivBackward0>)\n",
            "grad = None\n",
            "w = tensor([1.1200], grad_fn=<AddBackward0>)\n",
            "i = 12\n",
            "J= tensor(-24.6399, grad_fn=<DivBackward0>)\n",
            "grad = None\n",
            "w = tensor([1.1300], grad_fn=<AddBackward0>)\n",
            "i = 13\n",
            "J= tensor(-24.3599, grad_fn=<DivBackward0>)\n",
            "grad = None\n",
            "w = tensor([1.1400], grad_fn=<AddBackward0>)\n",
            "i = 14\n",
            "J= tensor(-24.0800, grad_fn=<DivBackward0>)\n",
            "grad = None\n",
            "w = tensor([1.1500], grad_fn=<AddBackward0>)\n",
            "i = 15\n",
            "J= tensor(-23.8000, grad_fn=<DivBackward0>)\n",
            "grad = None\n",
            "w = tensor([1.1600], grad_fn=<AddBackward0>)\n",
            "i = 16\n",
            "J= tensor(-23.5200, grad_fn=<DivBackward0>)\n",
            "grad = None\n",
            "w = tensor([1.1700], grad_fn=<AddBackward0>)\n",
            "i = 17\n",
            "J= tensor(-23.2400, grad_fn=<DivBackward0>)\n",
            "grad = None\n",
            "w = tensor([1.1800], grad_fn=<AddBackward0>)\n",
            "i = 18\n",
            "J= tensor(-22.9600, grad_fn=<DivBackward0>)\n",
            "grad = None\n",
            "w = tensor([1.1900], grad_fn=<AddBackward0>)\n",
            "i = 19\n",
            "J= tensor(-22.6800, grad_fn=<DivBackward0>)\n",
            "grad = None\n",
            "w = tensor([1.2000], grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:1013: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  aten/src/ATen/core/TensorBody.h:417.)\n",
            "  return self._grad\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Iterations')"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "learning_rate = 0.01\n",
        "iteracoes = 20\n",
        "\n",
        "x = torch.arange(0, 4).float()\n",
        "y = torch.arange(0, 8, 2).float()\n",
        "w = torch.ones(1, requires_grad=True)\n",
        "\n",
        "for i in range(iteracoes):\n",
        "    print('i =', i)\n",
        "    J = J_func(w, x, y)\n",
        "    print('J=', J)\n",
        "    if w.grad: w.grad.zero_()\n",
        "    J.backward()\n",
        "    grad = w.grad\n",
        "    print('grad =',grad)\n",
        "    w = w + learning_rate\n",
        "    print('w =', w)\n",
        "\n",
        "# Plote aqui a loss pela iteração\n",
        "plt.scatter([i for i in range(iteracoes)], Js)\n",
        "plt.ylabel(r'Loss $J$')\n",
        "plt.xlabel('Iterations')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GulfYtzBMx2e"
      },
      "source": [
        "##Exercício 3.4\n",
        "\n",
        "Quais são as restrições na escolha dos valores de $\\Delta w$ no cálculo do gradiente por diferenças finitas?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXQGEyvtiTAR"
      },
      "source": [
        "Resposta: **$\\Delta w$ deve ser um valor pequeno, comparado ao valor de $x$ e $y$**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsrSF8GEiXk4"
      },
      "source": [
        "##Exercício 3.5\n",
        "\n",
        "Até agora trabalhamos com $w$ contendo apenas um parâmetro. Suponha agora que $w$ seja uma matriz com $N$ parâmetros e que o custo para executar $(x_i w - y_i)^2$ seja $O(N)$.\n",
        "> a) Qual é o custo computacional para fazer uma única atualização (um passo de gradiente) dos parâmetros de $w$ usando o método das diferencas finitas?\n",
        ">\n",
        "> b) Qual é o custo computacional para fazer uma única atualização (um passo de gradiente) dos parâmetros de $w$ usando o método do backpropagation?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4Pna3bcicHj"
      },
      "source": [
        "Resposta (justifique):\n",
        "\n",
        "a) O método de diferenças finitas envolve a operação $(x_i w - y_i)^2$ em dois pontos diferentes, portanto seu custo é da ordem $\\mathcal{O}(2N)$.\n",
        "\n",
        "b) O método do _backpropagation_ utiliza regra da cadeia e derivadas, eliminando a necessidade de se realizar a operação $(x_i w - y_i)^2$ mais de uma vez. Portanto o custo é da ordem $\\mathcal{O}(N)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35I5w8EZdjIo"
      },
      "source": [
        "##Exercício 3.6\n",
        "\n",
        "Qual o custo (entropia cruzada) esperado para um exemplo (uma amostra) no começo do treinamento de um classificador inicializado aleatoriamente?\n",
        "\n",
        "A equação da entropia cruzada é:\n",
        "$$L = - \\sum_{j=0}^{K-1} y_j \\log p_j, $$\n",
        "Onde:\n",
        "\n",
        "- K é o número de classes;\n",
        "\n",
        "- $y_j=1$ se $j$ é a classe do exemplo (ground-truth), 0 caso contrário. Ou seja, $y$ é um vetor one-hot;\n",
        "\n",
        "- $p_j$ é a probabilidade predita pelo modelo para a classe $j$.\n",
        "\n",
        "A resposta tem que ser em função de uma ou mais das seguintes variáveis:\n",
        "\n",
        "- K = número de classes\n",
        "\n",
        "- B = batch size\n",
        "\n",
        "- D = dimensão de qualquer vetor do modelo\n",
        "\n",
        "- LR = learning rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swTOphiVs6eN"
      },
      "source": [
        "Resposta:\n",
        "\n",
        "Se a inicialização é aleatória, a probabilidade de uma dada classe $j$ é a mesma para todas as outras classes $k \\neq j$. Portanto, a probabilidade $p_j$ é uma distribuição uniforme onde $\\sum_{j=0}^{K-1} p_j = 1$, logo $p_j = 1/K$. Dessa forma, devido ao vetor one-hot $y_j$, a entropia assume a forma\n",
        "\n",
        "$$ L = - \\sum_{j=0}^{K-1} y_j \\log \\left( \\frac{1}{K} \\right) = - K \\log \\left( \\frac{1}{K} \\right)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UNdHqgSB6S9"
      },
      "source": [
        "Fim do notebook."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Exercícios - 20210718",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {
        "height": "117px",
        "width": "252px"
      },
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}