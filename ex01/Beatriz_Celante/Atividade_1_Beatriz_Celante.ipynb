{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Atividade_1_Beatriz_Celante",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {
        "height": "117px",
        "width": "252px"
      },
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTVOQpMfhgLM"
      },
      "source": [
        "Esté um notebook Colab contendo exercícios de programação em python, numpy e pytorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMoyGt5gXMgK"
      },
      "source": [
        "## Coloque seu nome"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBHbXcibXPRe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b53a6ed2-52da-46c6-e708-31704f9fbdd8"
      },
      "source": [
        "print('Meu nome é: Beatriz Celante Vicente')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meu nome é: Beatriz Celante Vicente\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9S5acRbm1Zr"
      },
      "source": [
        "# Parte 1:\n",
        "\n",
        "##Exercícios de Processamento de Dados\n",
        "\n",
        "Nesta parte pode-se usar as bibliotecas nativas do python como a `collections`, `re` e `random`. Também pode-se usar o NumPy."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Bibliotecas importadas\n",
        "import collections"
      ],
      "metadata": {
        "id": "krs4Wmz1fAVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxS5h1V8nDn6"
      },
      "source": [
        "##Exercício 1.1\n",
        "Crie um dicionário com os `k` itens mais frequentes de uma lista.\n",
        "\n",
        "Por exemplo, dada a lista de itens `L=['a', 'a', 'd', 'b', 'd', 'c', 'e', 'a', 'b', 'e', 'e', 'a']` e `k=2`, o resultado deve ser um dicionário cuja chave é o item e o valor é a sua frequência: {'a': 4, 'e': 3}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT08b5Z_nC-j"
      },
      "source": [
        "def top_k(L, k):\n",
        "    frequencia = collections.Counter(L)\n",
        "    k_frequencias = dict(list(frequencia.items())[:k])\n",
        "    return k_frequencias"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLD_e3C9p4xO"
      },
      "source": [
        "Mostre que sua implementação está correta usando uma entrada com poucos itens:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMW9NiBgnkvA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63d18286-8482-4012-8ab0-37a1d98281ed"
      },
      "source": [
        "L = ['f', 'a', 'a', 'd', 'b', 'd', 'c', 'e', 'a', 'b', 'e', 'e', 'a', 'd']\n",
        "k = 3\n",
        "resultado = top_k(L=L, k=k)\n",
        "print(f'resultado: {resultado}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resultado: {'f': 1, 'a': 4, 'd': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBeqZScQqJ0a"
      },
      "source": [
        "Mostre que sua implementação é eficiente usando uma entrada com 10M de itens:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_lhcm4ko8bY"
      },
      "source": [
        "import random\n",
        "L = random.choices('abcdefghijklmnopqrstuvwxyz', k=10_000_000)\n",
        "k = 10000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9U-Bgs2o-f_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e03b637d-bc6f-45c4-fb11-31813f95d64d"
      },
      "source": [
        "%%timeit\n",
        "resultado = top_k(L=L, k=k)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 509 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJHDaOz_tK38"
      },
      "source": [
        "## Exercício 1.2\n",
        "\n",
        "Em processamento de linguagem natural, é comum convertemos as palavras de um texto para uma lista de identificadores dessas palavras. Dado o dicionário `V` abaixo onde as chaves são palavras e os valores são seus respectivos identificadores, converta o texto `D` para uma lista de identificadores.\n",
        "\n",
        "Palavras que não existem no dicionário deverão ser convertidas para o identificador do token `unknown`.\n",
        "\n",
        "O código deve ser insensível a maiúsculas (case-insensitive).\n",
        "\n",
        "Se atente que pontuações (vírgulas, ponto final, etc) também são consideradas palavras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVzv89trtTPc"
      },
      "source": [
        "import re\n",
        "\n",
        "def tokens_to_ids(text, vocabulary):\n",
        "  lower_text  = text.lower()\n",
        "  sep = re.split('(\\W)', lower_text)\n",
        "  palavras = [x for x in sep if x != ' ' and x != '']\n",
        "  ident = []\n",
        "\n",
        "  for item in palavras:\n",
        "    if item in vocabulary.keys():\n",
        "      ident.append(vocabulary[item])\n",
        "    else:\n",
        "      ident.append(vocabulary['unknown'])\n",
        "  return ident\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCGZeiqkY-sm"
      },
      "source": [
        "Mostre que sua implementação esta correta com um exemplo pequeno:\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iApR1h7gY98E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a9782cd-cc5e-4851-b4ec-fb4318bb945f"
      },
      "source": [
        "V = {'eu': 1, 'de': 2, 'gosto': 3, 'comer': 4, '.': 5, 'unknown': -1}\n",
        "D = 'Eu gosto de comer pizza.'\n",
        "\n",
        "print(tokens_to_ids(D, V))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 3, 2, 4, -1, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostre que sua implementação é eficiente com um exemplo grande:\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BiwrERuYUU6o"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxT_g-ZxZUsX"
      },
      "source": [
        "V = {'eu': 1, 'de': 2, 'gosto': 3, 'comer': 4, '.': 5, 'unknown': -1}\n",
        "D = ' '.join(1_000_000 * ['Eu gosto de comer pizza.'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kp1nataGZU-V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ed4e007-5cf9-476a-ed19-1e0715021bf6"
      },
      "source": [
        "%%timeit\n",
        "resultado = tokens_to_ids(D, V)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 3.93 s per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRfaKfXwRXn_"
      },
      "source": [
        "## Exercício 1.3\n",
        "\n",
        "Em aprendizado profundo é comum termos que lidar com arquivos muito grandes.\n",
        "\n",
        "Dado um arquivo de texto onde cada item é separado por `\\n`, escreva um programa que amostre `k` itens desse arquivo aleatoriamente.\n",
        "\n",
        "Nota 1: Assuma amostragem de uma distribuição uniforme, ou seja, todos os itens tem a mesma probablidade de amostragem.\n",
        "\n",
        "Nota 2: Assuma que o arquivo não cabe em memória.\n",
        "\n",
        "Nota 3: Utilize apenas bibliotecas nativas do python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PsadE9SRG_9"
      },
      "source": [
        "from numpy.random.mtrand import random_integers\n",
        "def sample(path: str, k: int):\n",
        "    # Escreva o seu código aqui.\n",
        "    arquivo = open(filename)\n",
        "    lines_read = arquivo.readlines()\n",
        "    total_len = len(lines_read)\n",
        "    lista_aleatoria = []\n",
        "    amostra = []\n",
        "\n",
        "    for i in range(0,k):\n",
        "      lista_aleatoria.append(random.randint(0, total_len)\n",
        "  \n",
        "    for j in lista_aleatoria:\n",
        "      amostra.append(lines_read[j])\n",
        "      \n",
        "    return amostra\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycEnlFWxSt0i"
      },
      "source": [
        "Mostre que sua implementação está correta com um exemplo pequeno:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyLJ1e2ZSzC9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecb525e1-b324-4227-b09d-44c029ddef29"
      },
      "source": [
        "filename = 'small.txt'\n",
        "total_size = 100\n",
        "n_samples = 10\n",
        "\n",
        "with open(filename, 'w') as fout:\n",
        "    fout.write('\\n'.join(f'line {i}' for i in range(total_size)))\n",
        "\n",
        "samples = sample(path=filename, k=n_samples)\n",
        "print(samples)\n",
        "print(len(samples) == n_samples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['line 38\\n', 'line 64\\n', 'line 12\\n', 'line 19\\n', 'line 0\\n', 'line 55\\n', 'line 7\\n', 'line 26\\n', 'line 91\\n', 'line 32\\n']\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2r4FMiMj12Xg"
      },
      "source": [
        "Mostre que sua implementação é eficiente com um exemplo grande:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUwnNMGg18Ty"
      },
      "source": [
        "filename = 'large.txt'\n",
        "total_size = 1_000_000\n",
        "n_samples = 10000\n",
        "\n",
        "with open(filename, 'w') as fout:\n",
        "    fout.write('\\n'.join(f'line {i}' for i in range(total_size)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA9sAZmo0UDN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4a84e65-a294-4900-fb52-80258d1f233f"
      },
      "source": [
        "%%timeit\n",
        "samples = sample(path=filename, k=n_samples)\n",
        "assert len(samples) == n_samples"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loops, best of 5: 101 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udS0Ns4etoJs"
      },
      "source": [
        "# Parte 2:\n",
        "\n",
        "##Exercícios de Numpy\n",
        "\n",
        "Nesta parte deve-se usar apenas a biblioteca NumPy. Aqui não se pode usar o PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcMz3Vzjt144"
      },
      "source": [
        "##Exercício 2.1\n",
        "\n",
        "Quantos operações de ponto flutuante (flops) de soma e de multiplicação tem a multiplicação matricial $AB$, sendo que a matriz $A$ tem tamanho $m \\times n$ e a matriz $B$ tem tamanho $n \\times p$?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gNXj45RJqUm"
      },
      "source": [
        "Resposta:\n",
        "- número de somas: m x n x (p - 1)\n",
        "- número de multiplicações: m x n x p"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iI7udBFeDlP"
      },
      "source": [
        "## Exercício 2.2\n",
        "\n",
        "Em programação matricial, não se faz o loop em cada elemento da matriz,\n",
        "mas sim, utiliza-se operações matriciais.\n",
        "\n",
        "Dada a matriz `A` abaixo, calcule a média dos valores de cada linha sem utilizar laços explícitos.\n",
        "\n",
        "Utilize apenas a biblioteca numpy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjrXf18N5KrK"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fqxgNBW27Z0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d6e57d6-a55f-4540-c322-aba7874a084a"
      },
      "source": [
        "A = np.arange(24).reshape(4, 6)\n",
        "print(A)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  1  2  3  4  5]\n",
            " [ 6  7  8  9 10 11]\n",
            " [12 13 14 15 16 17]\n",
            " [18 19 20 21 22 23]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1EmKFrT5g7B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ac39ff2-61d9-498d-dfeb-333e43bab4f6"
      },
      "source": [
        "# Utilizando numpy.matrix.mean:\n",
        "A.mean(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2.5,  8.5, 14.5, 20.5])"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtgSAAKjUfcO"
      },
      "source": [
        "## Exercício 2.3\n",
        "\n",
        "Seja a matriz $C$ que é a normalização da matriz $A$:\n",
        "$$ C(i,j) = \\frac{A(i,j) - A_{min}}{A_{max} - A_{min}} $$\n",
        "\n",
        "Normalizar a matriz `A` do exercício acima de forma que seus valores fiquem entre 0 e 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-11T00:00:34.072719Z",
          "start_time": "2019-12-11T00:00:34.036017Z"
        },
        "id": "_pDhb2-0eDlS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2adf5a79-3685-49a3-b5f9-45dfeb21fe59"
      },
      "source": [
        "C = (A - np.min(A))/np.ptp(A)\n",
        "\n",
        "print(C)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.04347826 0.08695652 0.13043478 0.17391304 0.2173913 ]\n",
            " [0.26086957 0.30434783 0.34782609 0.39130435 0.43478261 0.47826087]\n",
            " [0.52173913 0.56521739 0.60869565 0.65217391 0.69565217 0.73913043]\n",
            " [0.7826087  0.82608696 0.86956522 0.91304348 0.95652174 1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF_P_GARU62m"
      },
      "source": [
        "## Exercício 2.4\n",
        "\n",
        "Modificar o exercício anterior de forma que os valores de cada *coluna* da matriz `A` sejam normalizados entre 0 e 1 independentemente dos valores das outras colunas.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NgVzFOYeDla",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48ce57bb-e82c-4efe-9242-671610215a24"
      },
      "source": [
        "C_colunas = (A - A.min(0)) /np.ptp(A,0)\n",
        "print(C_colunas)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.         0.         0.         0.         0.        ]\n",
            " [0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.33333333]\n",
            " [0.66666667 0.66666667 0.66666667 0.66666667 0.66666667 0.66666667]\n",
            " [1.         1.         1.         1.         1.         1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbXIXsDIUmtp"
      },
      "source": [
        "## Exercício 2.5\n",
        "\n",
        "Modificar o exercício anterior de forma que os valores de cada *linha* da matriz `A` sejam normalizados entre 0 e 1 independentemente dos valores das outras linhas.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-10T17:56:40.413601Z",
          "start_time": "2019-12-10T17:56:40.405056Z"
        },
        "id": "i-5Hv8-heDlW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e06484a4-a28e-47f5-d729-4f2ac4d7ce27"
      },
      "source": [
        "ptp_linha = A.ptp(axis = 1)\n",
        "min_linhas = A.min(axis = 1)\n",
        "print(min_linhas)\n",
        "C_linhas = (A - min_linhas[:, np.newaxis])/ptp_linha[:,np.newaxis]\n",
        "print(C_linhas)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  6 12 18]\n",
            "[[0.  0.2 0.4 0.6 0.8 1. ]\n",
            " [0.  0.2 0.4 0.6 0.8 1. ]\n",
            " [0.  0.2 0.4 0.6 0.8 1. ]\n",
            " [0.  0.2 0.4 0.6 0.8 1. ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKnLAyL7zgpa"
      },
      "source": [
        "## Exercício 2.6\n",
        "\n",
        "A [função softmax](https://en.wikipedia.org/wiki/Softmax_function) é bastante usada em apredizado de máquina para converter uma lista de números para uma distribuição de probabilidade, isto é, os números ficarão normalizados entre zero e um e sua soma será igual à um.\n",
        "\n",
        "Implemente a função softmax com suporte para batches, ou seja, o softmax deve ser aplicado a cada linha da matriz. Deve-se usar apenas a biblioteca numpy. Se atente que a exponenciação gera estouro de representação quando os números da entrada são muito grandes. Tente corrigir isto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lA5W9vxNEmOj"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def softmax(A):\n",
        "    '''\n",
        "    Aplica a função de softmax à matriz `A`.\n",
        "\n",
        "    Entrada:\n",
        "      `A` é uma matriz M x N, onde M é o número de exemplos a serem processados\n",
        "      independentemente e N é o tamanho de cada exemplo.\n",
        "    \n",
        "    Saída:\n",
        "      Uma matriz M x N, onde a soma de cada linha é igual a um.\n",
        "    '''\n",
        "    # Escreva sua solução aqui.\n",
        "\n",
        "    max = np.max(A,axis=1,keepdims=True) \n",
        "    e_A = np.exp(A - max) #Subtrai cada linha pelo valor máximo e exponencia\n",
        "    soma_linhas = np.sum(e_A,axis=1,keepdims=True) \n",
        "    \n",
        "    return e_A/soma_linhas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpxlbh4ND54q"
      },
      "source": [
        "Mostre que sua implementação está correta usando uma matriz pequena como entrada:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6EZ5ZD7HFao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "232ca689-09e7-4ef8-e5bd-ca5c3166dd26"
      },
      "source": [
        "A = np.array([[0.5, -1, 1000],\n",
        "              [-2,   0, 0.5]])\n",
        "softmax(A)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 1.        ],\n",
              "       [0.04861082, 0.35918811, 0.59220107]])"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j2uXmKH8HF4"
      },
      "source": [
        "O código a seguir verifica se sua implementação do softmax está correta. \n",
        "- A soma de cada linha de A deve ser 1;\n",
        "- Os valores devem estar entre 0 e 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-sN4STk7qyN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e797aaf5-bd16-4c65-bb32-3c4833c2da8b"
      },
      "source": [
        "np.allclose(softmax(A).sum(axis=1), 1) and softmax(A).min() >= 0 and softmax(A).max() <= 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5_ZRWRfCZtI"
      },
      "source": [
        "Mostre que sua implementação é eficiente usando uma matriz grande como entrada:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhUeyrGaJ3J2"
      },
      "source": [
        "A = np.random.uniform(low=-10, high=10, size=(128, 100_000))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaa-C8XkKJin",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc66e0b3-2d6e-401c-b3b3-76bf90da40bf"
      },
      "source": [
        "%%timeit\n",
        "softmax(A)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 294 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XE6LaWi81zZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1249ae2e-08d2-4667-abe2-70de29b88f7c"
      },
      "source": [
        "SM = softmax(A)\n",
        "np.allclose(SM.sum(axis=1), 1) and SM.min() >= 0 and SM.max() <= 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Flr1lI5o-HpG"
      },
      "source": [
        "## Exercício 2.7\n",
        "\n",
        "A codificação one-hot é usada para codificar entradas categóricas. É uma codificação onde apenas um bit é 1 e os demais são zero, conforme a tabela a seguir.\n",
        "\n",
        "| Decimal | Binary | One-hot\n",
        "| ------- | ------ | -------\n",
        "| 0 | 000    | 1 0 0 0 0 0 0 0\n",
        "| 1 | 001    | 0 1 0 0 0 0 0 0\n",
        "| 2 | 010    | 0 0 1 0 0 0 0 0\n",
        "| 3 | 011    | 0 0 0 1 0 0 0 0\n",
        "| 4 | 100    | 0 0 0 0 1 0 0 0\n",
        "| 5 | 101    | 0 0 0 0 0 1 0 0\n",
        "| 6 | 110    | 0 0 0 0 0 0 1 0\n",
        "| 7 | 111    | 0 0 0 0 0 0 0 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CqXP_5ABbfo"
      },
      "source": [
        "Implemente a função one_hot(y, n_classes) que codifique o vetor de inteiros y que possuem valores entre 0 e n_classes-1.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la-02w7qCH7L"
      },
      "source": [
        "def one_hot(y, n_classes):\n",
        "    # Escreva seu código aqui.\n",
        "    shape = (y.size, n_classes) #forma da matriz\n",
        "    one_hot = np.zeros(shape)\n",
        "    linhas = np.arange(y.size) #função similar à range, mas retorna um ndarray ao invés de uma lista\n",
        "    one_hot[linhas, y] = 1\n",
        "\n",
        "    print(one_hot)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf5zyZO5Aiz_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d40b7d1e-fe7c-4f5e-a838-4055d112335d"
      },
      "source": [
        "N_CLASSES = 9\n",
        "N_SAMPLES = 10\n",
        "y = (np.random.rand((N_SAMPLES)) * N_CLASSES).astype(np.int)\n",
        "print(y)\n",
        "print(one_hot(y, N_CLASSES))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 0 1 3 8 7 2 4 5 8]\n",
            "[[0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nwuKnQUCzve"
      },
      "source": [
        "Mostre que sua implementação é eficiente usando uma matriz grande como entrada:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwuFy5rWC2tA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a65c594d-97e1-493f-d74d-f474fca23390"
      },
      "source": [
        "N_SAMPLES = 100_000\n",
        "N_CLASSES = 1_000\n",
        "y = (np.random.rand((N_SAMPLES)) * N_CLASSES).astype(np.int)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7azMtF7wDJ2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e482b13-7b69-415c-fd6f-15d574cc0f34"
      },
      "source": [
        "%%timeit\n",
        "one_hot(y, N_CLASSES)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "1 loop, best of 5: 190 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqMroZay2ubi"
      },
      "source": [
        "## Exercício 2.8\n",
        "\n",
        "Implemente uma classe que normalize um array de pontos flutuantes `array_a` para a mesma média e desvio padrão de um outro array `array_b`, conforme exemplo abaixo:\n",
        "```\n",
        "array_a = np.array([-1, 1.5, 0])\n",
        "array_b = np.array([1.4, 0.8, 0.3, 2.5])\n",
        "normalize = Normalizer(array_b)\n",
        "normalized_array = normalize(array_a)\n",
        "print(normalized_array)  # Deve imprimir [0.3187798  2.31425165 1.11696854]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaedJ5Cf5Oy2"
      },
      "source": [
        "import numpy as np\n",
        "# Escreva seu código aqui.\n",
        "class Normalizer:\n",
        "  def __init__(self, array_1):\n",
        "    self.desv_pad_1 = np.std(array_1)\n",
        "    self.media_1 = np.mean(array_1)\n",
        "\n",
        "  def funcao_que_normaliza(self, array_2):\n",
        "    media_2 = np.mean(array_2)\n",
        "    desv_pad_2 = np.std(array_2)\n",
        "    normalizado = self.media_1 + (array_2 - media_2) * (self.desv_pad_1/desv_pad_2)\n",
        "    return normalizado"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlkNNU6h5RbR"
      },
      "source": [
        "Mostre que seu código está correto com o exemplo abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gad6zsbh5a0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "198f0f49-637c-437a-bdfc-d9d8092643eb"
      },
      "source": [
        "array_a = [-1, 1.5, 0]\n",
        "array_b = [1.4, 0.8, 0.3, 2.5]\n",
        "normalize = Normalizer(array_b)\n",
        "#Na linha abaixo fiz uma pequena alteração pois acredito que alguma sintaxe para acessar a função da classe tenha mudado com a versão do python\n",
        "normalized_array = normalize.funcao_que_normaliza(array_a) \n",
        "print(normalized_array)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.3187798  2.31425165 1.11696854]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrGVQFUYI_LP"
      },
      "source": [
        "# Parte 3:\n",
        "\n",
        "##Exercícios Pytorch: Grafo Computacional e Gradientes\n",
        "\n",
        "Nesta parte pode-se usar quaisquer bibliotecas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIlQdKAuCZtR"
      },
      "source": [
        "Um dos principais fundamentos para que o PyTorch seja adequado para deep learning é a sua habilidade de calcular o gradiente automaticamente a partir da expressões definidas. Essa facilidade é implementada através do cálculo automático do gradiente e construção dinâmica do grafo computacional."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF_-dJ2nCZtT"
      },
      "source": [
        "## Grafo computacional\n",
        "\n",
        "Seja um exemplo simples de uma função de perda J dada pela Soma dos Erros ao Quadrado (SEQ - Sum of Squared Errors): \n",
        "$$ J = \\sum_i (x_i w - y_i)^2 $$\n",
        "que pode ser reescrita como:\n",
        "$$ \\hat{y_i} = x_i w $$\n",
        "$$ e_i = \\hat{y_i} - y_i $$\n",
        "$$ e2_i = e_i^2 $$\n",
        "$$ J = \\sum_i e2_i $$\n",
        "\n",
        "As redes neurais são treinadas através da minimização de uma função de perda usando o método do gradiente descendente. Para ajustar o parâmetro $w$ precisamos calcular o gradiente $  \\frac{ \\partial J}{\\partial w} $. Usando a\n",
        "regra da cadeia podemos escrever:\n",
        "$$ \\frac{ \\partial J}{\\partial w} = \\frac{ \\partial J}{\\partial e2_i} \\frac{ \\partial e2_i}{\\partial e_i} \\frac{ \\partial e_i}{\\partial \\hat{y_i} } \\frac{ \\partial \\hat{y_i}}{\\partial w}$$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jboejVQMCZtU"
      },
      "source": [
        "```\n",
        "    y_pred = x * w\n",
        "    e = y_pred - y\n",
        "    e2 = e**2\n",
        "    J = e2.sum()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7JmU6qhc2Y2"
      },
      "source": [
        "As quatro expressões acima, para o cálculo do J podem ser representadas pelo grafo computacional visualizado a seguir: os círculos são as variáveis (tensores), os quadrados são as operações, os números em preto são os cálculos durante a execução das quatro expressões para calcular o J (forward, predict). O cálculo do gradiente, mostrado em vermelho, é calculado pela regra da cadeia, de trás para frente (backward)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeeEBKl4CZtV"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/robertoalotufo/files/master/figures/GrafoComputacional.png\" width=\"600pt\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yZun7wrCZtX"
      },
      "source": [
        "Para entender melhor o funcionamento do grafo computacional com os tensores, recomenda-se leitura em:\n",
        "\n",
        "https://pytorch.org/docs/stable/notes/autograd.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-11T00:23:00.431853Z",
          "start_time": "2019-12-11T00:23:00.414813Z"
        },
        "id": "HlT2d-4fCZtZ"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-11T00:23:00.863228Z",
          "start_time": "2019-12-11T00:23:00.844457Z"
        },
        "id": "xX0QwUduCZtf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9cdbc5df-0c7b-4220-b459-9084fa3ae915"
      },
      "source": [
        "torch.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.10.0+cu111'"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsqzALS4CZtl"
      },
      "source": [
        "**Tensor com atributo .requires_grad=True**\n",
        "\n",
        "Quando um tensor possui o atributo `requires_grad` como verdadeiro, qualquer expressão que utilizar esse tensor irá construir um grafo computacional para permitir posteriormente, após calcular a função a ser derivada, poder usar a regra da cadeia e calcular o gradiente da função em termos dos tensores que possuem o atributo `requires_grad`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:22.117010Z",
          "start_time": "2019-09-29T03:07:22.041861Z"
        },
        "id": "foaAb94aCZtm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a49eab8f-0cfa-46fb-c4a7-9aef2bae72a2"
      },
      "source": [
        "y = torch.arange(0, 8, 2).float()\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 2., 4., 6.])"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:28.610934Z",
          "start_time": "2019-09-29T03:07:28.598223Z"
        },
        "id": "no6SdSyICZtr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63439dd3-7b19-4cf4-e2f1-8743bf98d14c"
      },
      "source": [
        "x = torch.arange(0, 4).float()\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:31.523762Z",
          "start_time": "2019-09-29T03:07:31.497683Z"
        },
        "id": "eL_i1mwGCZtw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cc0b38a-33e6-4fb0-c432-e5612a8e0d4d"
      },
      "source": [
        "w = torch.ones(1, requires_grad=True)\n",
        "w"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjEl-0l7CZt0"
      },
      "source": [
        "## Cálculo automático do gradiente da função perda J"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pUh-SCnCZt1"
      },
      "source": [
        "Seja a expressão: $$ J = \\sum_i ((x_i  w) - y_i)^2 $$\n",
        "\n",
        "Queremos calcular a derivada de $J$ em relação a $w$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMwwVtJ1CZt2"
      },
      "source": [
        "## Forward pass\n",
        "\n",
        "Durante a execução da expressão, o grafo computacional é criado. Compare os valores de cada parcela calculada com os valores em preto da figura ilustrativa do grafo computacional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:36.290122Z",
          "start_time": "2019-09-29T03:07:36.273229Z"
        },
        "id": "zp2aK4YhCZt3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8a4bf82-5c47-42bf-b968-627ecdde965c"
      },
      "source": [
        "# predict (forward)\n",
        "y_pred = x * w; print('y_pred =', y_pred)\n",
        "\n",
        "# cálculo da perda J: loss\n",
        "e = y_pred - y; print('e =',e)\n",
        "e2 = e.pow(2) ; print('e2 =', e2)\n",
        "J = e2.sum()  ; print('J =', J)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_pred = tensor([0., 1., 2., 3.], grad_fn=<MulBackward0>)\n",
            "e = tensor([ 0., -1., -2., -3.], grad_fn=<SubBackward0>)\n",
            "e2 = tensor([0., 1., 4., 9.], grad_fn=<PowBackward0>)\n",
            "J = tensor(14., grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC96wB7PCZt8"
      },
      "source": [
        "## Backward pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-10-04T15:55:45.308858",
          "start_time": "2017-10-04T15:55:45.304654"
        },
        "id": "kKbf4D0CCZt-"
      },
      "source": [
        "O `backward()` varre o grafo computacional a partir da variável a ele associada (raiz) e calcula o gradiente para todos os tensores que possuem o atributo `requires_grad` como verdadeiro.\n",
        "Observe que os tensores que tiverem o atributo `requires_grad` serão sempre folhas no grafo computacional.\n",
        "O `backward()` destroi o grafo após sua execução. Esse comportamento é padrão no PyTorch. \n",
        "\n",
        "A título ilustrativo, se quisermos depurar os gradientes dos nós que não são folhas no grafo computacional, precisamos primeiro invocar `retain_grad()` em cada um desses nós, como a seguir. Entretanto nos exemplos reais não há necessidade de verificar o gradiente desses nós."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-CjLPu6clVo"
      },
      "source": [
        "e2.retain_grad()\n",
        "e.retain_grad()\n",
        "y_pred.retain_grad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtsZS2Bicof-"
      },
      "source": [
        "E agora calculamos os gradientes com o `backward()`.\n",
        "\n",
        "w.grad é o gradiente de J em relação a w."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:40.267334Z",
          "start_time": "2019-09-29T03:07:40.247422Z"
        },
        "id": "Z1lnkb0GCZt_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa81b321-524d-45dc-d446-17779630ba5f"
      },
      "source": [
        "if w.grad: w.grad.zero_()\n",
        "J.backward()\n",
        "print(w.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-28.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1xYDPR_uOcZ"
      },
      "source": [
        "Mostramos agora os gradientes que estão grafados em vermelho no grafo computacional:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(w.grad[0].item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_FcXpcycTZC",
        "outputId": "47a94805-e287-4c1a-97ed-379b55800bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Enuk2tf0sDyO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d6cb5fb-e1b5-4017-a5e1-352614d696cf"
      },
      "source": [
        "print(e2.grad)\n",
        "print(e.grad)\n",
        "print(y_pred.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1.])\n",
            "tensor([ 0., -2., -4., -6.])\n",
            "tensor([ 0., -2., -4., -6.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsOThnt8fDJV"
      },
      "source": [
        "##Exercício 3.1\n",
        "Calcule o mesmo gradiente ilustrado no exemplo anterior usando a regra das diferenças finitas, de acordo com a equação a seguir, utilizando um valor de $\\Delta w$ bem pequeno.\n",
        "\n",
        "$$ \\frac{\\partial J}{\\partial w} = \\frac{J(w + \\Delta w) - J(w - \\Delta w)}{2 \\Delta w} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "62nZAfUoCZu5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec17f5d4-6679-45d5-abbb-3edda252043d"
      },
      "source": [
        "\n",
        "def J_func(w, x, y):\n",
        "    # programe a função J_func, para facilitar\n",
        "    y_pred = x * w\n",
        "    e = y_pred - y\n",
        "    e2 = e**2\n",
        "    return e2.sum()\n",
        "   \n",
        "#Definindo x, y e w\n",
        "x = torch.arange(0, 4).float()\n",
        "y = torch.arange(0, 8, 2).float()\n",
        "w = torch.ones(1)\n",
        "\n",
        "# Calcule o gradiente usando a regra diferenças finitas\n",
        "delta = 10**(-5) #delta w\n",
        "gradiente = (J_func(w + delta, x, y) - J_func(w - delta, x, y))/(2*delta)\n",
        "\n",
        "\n",
        "# Confira com o valor já calculado anteriormente\n",
        "x = torch.arange(0, 4).float()\n",
        "y = torch.arange(0, 8, 2).float()\n",
        "w = torch.ones(1)\n",
        "grad = gradiente\n",
        "print('grad=', grad)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grad= tensor(-28.0380)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_Sx1QXZxJ3u"
      },
      "source": [
        "##Exercício 3.2\n",
        "\n",
        "Minimizando $J$ pelo gradiente descendente\n",
        "\n",
        "$$ w_{k+1} = w_k - \\lambda \\frac {\\partial J}{\\partial w} $$\n",
        "\n",
        "Supondo que valor inicial ($k=0$) $w_0 = 1$, use learning rate $\\lambda = 0.01$ para calcular o valor do novo $w_{20}$, ou seja, fazendo 20 atualizações de gradientes. Deve-se usar a função `J_func` criada no exercício anterior.\n",
        "\n",
        "Confira se o valor do primeiro gradiente está de acordo com os valores já calculado acima"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNszCOED1Wtu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "760adbaa-8b08-4faf-e7b8-3d79166708c2"
      },
      "source": [
        "learning_rate = 0.01\n",
        "iteracoes = 20\n",
        "\n",
        "x = torch.arange(0, 4).float()\n",
        "y = torch.arange(0, 8, 2).float()\n",
        "w = torch.ones(1)\n",
        "\n",
        "#Definindo a função utilizada no exercício anterior\n",
        "\n",
        "def gradiente(w,x,y):\n",
        "  return (J_func(w + delta, x, y) - J_func(w - delta, x, y))/(2*delta)\n",
        "\n",
        "print('Valor do primeiro gradiente = ', gradiente(w,x,y))\n",
        "\n",
        "#Vetor em branco para conseguir plotar o gráfico\n",
        "J_grafico = []\n",
        "for i in range(iteracoes):\n",
        "    print('i =', i)\n",
        "    J = J_func(w, x, y)\n",
        "    J_grafico.append(J)\n",
        "    print('J=', J)\n",
        "    grad = gradiente(w,x,y)\n",
        "    print('grad =',grad)\n",
        "    w = w - learning_rate * gradiente(w,x,y)\n",
        "    print('w =', w)\n",
        "\n",
        "# Plote o gráfico da loss J pela iteração i\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(J_grafico,range(iteracoes))\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valor do primeiro gradiente =  tensor(-28.0380)\n",
            "i = 0\n",
            "J= tensor(14.)\n",
            "grad = tensor(-28.0380)\n",
            "w = tensor([1.2804])\n",
            "i = 1\n",
            "J= tensor(7.2499)\n",
            "grad = tensor(-20.1702)\n",
            "w = tensor([1.4821])\n",
            "i = 2\n",
            "J= tensor(3.7553)\n",
            "grad = tensor(-14.5197)\n",
            "w = tensor([1.6273])\n",
            "i = 3\n",
            "J= tensor(1.9449)\n",
            "grad = tensor(-10.4487)\n",
            "w = tensor([1.7318])\n",
            "i = 4\n",
            "J= tensor(1.0073)\n",
            "grad = tensor(-7.5221)\n",
            "w = tensor([1.8070])\n",
            "i = 5\n",
            "J= tensor(0.5216)\n",
            "grad = tensor(-5.4121)\n",
            "w = tensor([1.8611])\n",
            "i = 6\n",
            "J= tensor(0.2701)\n",
            "grad = tensor(-3.8937)\n",
            "w = tensor([1.9000])\n",
            "i = 7\n",
            "J= tensor(0.1399)\n",
            "grad = tensor(-2.8022)\n",
            "w = tensor([1.9281])\n",
            "i = 8\n",
            "J= tensor(0.0724)\n",
            "grad = tensor(-2.0169)\n",
            "w = tensor([1.9482])\n",
            "i = 9\n",
            "J= tensor(0.0375)\n",
            "grad = tensor(-1.4514)\n",
            "w = tensor([1.9627])\n",
            "i = 10\n",
            "J= tensor(0.0194)\n",
            "grad = tensor(-1.0444)\n",
            "w = tensor([1.9732])\n",
            "i = 11\n",
            "J= tensor(0.0101)\n",
            "grad = tensor(-0.7516)\n",
            "w = tensor([1.9807])\n",
            "i = 12\n",
            "J= tensor(0.0052)\n",
            "grad = tensor(-0.5409)\n",
            "w = tensor([1.9861])\n",
            "i = 13\n",
            "J= tensor(0.0027)\n",
            "grad = tensor(-0.3892)\n",
            "w = tensor([1.9900])\n",
            "i = 14\n",
            "J= tensor(0.0014)\n",
            "grad = tensor(-0.2801)\n",
            "w = tensor([1.9928])\n",
            "i = 15\n",
            "J= tensor(0.0007)\n",
            "grad = tensor(-0.2016)\n",
            "w = tensor([1.9948])\n",
            "i = 16\n",
            "J= tensor(0.0004)\n",
            "grad = tensor(-0.1451)\n",
            "w = tensor([1.9963])\n",
            "i = 17\n",
            "J= tensor(0.0002)\n",
            "grad = tensor(-0.1044)\n",
            "w = tensor([1.9973])\n",
            "i = 18\n",
            "J= tensor(0.0001)\n",
            "grad = tensor(-0.0751)\n",
            "w = tensor([1.9981])\n",
            "i = 19\n",
            "J= tensor(5.2033e-05)\n",
            "grad = tensor(-0.0541)\n",
            "w = tensor([1.9986])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBXxBmWGK3IU"
      },
      "source": [
        "##Exercício 3.3\n",
        "\n",
        "Repita o exercício 2 mas usando agora o calculando o gradiente usando o método backward() do pytorch. Confira se o primeiro valor do gradiente está de acordo com os valores anteriores. Execute essa próxima célula duas vezes. Os valores devem ser iguais.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMP4d5vtHtqy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9f74d94c-243c-40ff-faa0-f8a2178dd8f3"
      },
      "source": [
        "learning_rate = 0.01\n",
        "iteracoes = 20\n",
        "\n",
        "x = torch.arange(0, 4).float()\n",
        "y = torch.arange(0, 8, 2).float()\n",
        "w = torch.ones(1, requires_grad=True)\n",
        "\n",
        "#Vetor em branco para conseguir plotar o gráfico\n",
        "J_grafico2 = []\n",
        "\n",
        "for i in range(iteracoes):\n",
        "    print('i =', i)\n",
        "    J = J_func(w, x, y)\n",
        "    print('J =', J)\n",
        "    J_grafico2.append(J)\n",
        "    if w.grad: w.grad.zero_()\n",
        "    J.backward()\n",
        "    grad = w.grad\n",
        "    print('grad =', grad.item())\n",
        "    w = w - learning_rate * grad.item()\n",
        "    w.retain_grad()\n",
        "    print('w =', w.item())\n",
        "\n",
        "# Plote aqui a loss pela iteração\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(J_grafico,range(iteracoes))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i = 0\n",
            "J = tensor(14., grad_fn=<SumBackward0>)\n",
            "grad = -28.0\n",
            "w = 1.2799999713897705\n",
            "i = 1\n",
            "J = tensor(7.2576, grad_fn=<SumBackward0>)\n",
            "grad = -20.160001754760742\n",
            "w = 1.481600046157837\n",
            "i = 2\n",
            "J = tensor(3.7623, grad_fn=<SumBackward0>)\n",
            "grad = -14.51519775390625\n",
            "w = 1.6267520189285278\n",
            "i = 3\n",
            "J = tensor(1.9504, grad_fn=<SumBackward0>)\n",
            "grad = -10.450942993164062\n",
            "w = 1.7312614917755127\n",
            "i = 4\n",
            "J = tensor(1.0111, grad_fn=<SumBackward0>)\n",
            "grad = -7.52467679977417\n",
            "w = 1.8065083026885986\n",
            "i = 5\n",
            "J = tensor(0.5241, grad_fn=<SumBackward0>)\n",
            "grad = -5.417766094207764\n",
            "w = 1.86068594455719\n",
            "i = 6\n",
            "J = tensor(0.2717, grad_fn=<SumBackward0>)\n",
            "grad = -3.9007928371429443\n",
            "w = 1.8996938467025757\n",
            "i = 7\n",
            "J = tensor(0.1409, grad_fn=<SumBackward0>)\n",
            "grad = -2.808573007583618\n",
            "w = 1.9277795553207397\n",
            "i = 8\n",
            "J = tensor(0.0730, grad_fn=<SumBackward0>)\n",
            "grad = -2.0221731662750244\n",
            "w = 1.9480012655258179\n",
            "i = 9\n",
            "J = tensor(0.0379, grad_fn=<SumBackward0>)\n",
            "grad = -1.455965280532837\n",
            "w = 1.9625608921051025\n",
            "i = 10\n",
            "J = tensor(0.0196, grad_fn=<SumBackward0>)\n",
            "grad = -1.0482935905456543\n",
            "w = 1.9730437994003296\n",
            "i = 11\n",
            "J = tensor(0.0102, grad_fn=<SumBackward0>)\n",
            "grad = -0.7547743320465088\n",
            "w = 1.9805915355682373\n",
            "i = 12\n",
            "J = tensor(0.0053, grad_fn=<SumBackward0>)\n",
            "grad = -0.5434384346008301\n",
            "w = 1.9860259294509888\n",
            "i = 13\n",
            "J = tensor(0.0027, grad_fn=<SumBackward0>)\n",
            "grad = -0.39127326011657715\n",
            "w = 1.9899386167526245\n",
            "i = 14\n",
            "J = tensor(0.0014, grad_fn=<SumBackward0>)\n",
            "grad = -0.281719446182251\n",
            "w = 1.9927557706832886\n",
            "i = 15\n",
            "J = tensor(0.0007, grad_fn=<SumBackward0>)\n",
            "grad = -0.20283913612365723\n",
            "w = 1.9947841167449951\n",
            "i = 16\n",
            "J = tensor(0.0004, grad_fn=<SumBackward0>)\n",
            "grad = -0.14604616165161133\n",
            "w = 1.9962445497512817\n",
            "i = 17\n",
            "J = tensor(0.0002, grad_fn=<SumBackward0>)\n",
            "grad = -0.10515189170837402\n",
            "w = 1.9972960948944092\n",
            "i = 18\n",
            "J = tensor(0.0001, grad_fn=<SumBackward0>)\n",
            "grad = -0.07571077346801758\n",
            "w = 1.9980531930923462\n",
            "i = 19\n",
            "J = tensor(5.3059e-05, grad_fn=<SumBackward0>)\n",
            "grad = -0.054509878158569336\n",
            "w = 1.998598337173462\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GulfYtzBMx2e"
      },
      "source": [
        "##Exercício 3.4\n",
        "\n",
        "Quais são as restrições na escolha dos valores de $\\Delta w$ no cálculo do gradiente por diferenças finitas?\n",
        "\n",
        "1 - $\\Delta w$ não pode ser zero ou próximo suficiente para ser considerado zero \\\\\n",
        "2 - É necessário ser um valor pequeno, ou seja, algumas ordens de grandeza menor do que o w."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXQGEyvtiTAR"
      },
      "source": [
        "Resposta:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsrSF8GEiXk4"
      },
      "source": [
        "##Exercício 3.5\n",
        "\n",
        "Até agora trabalhamos com $w$ contendo apenas um parâmetro. Suponha agora que $w$ seja uma matriz com $N$ parâmetros e que o custo para executar $(x_i w - y_i)^2$ seja $O(N)$.\n",
        "> a) Qual é o custo computacional para fazer uma única atualização (um passo de gradiente) dos parâmetros de $w$ usando o método das diferencas finitas?\n",
        ">\n",
        "> b) Qual é o custo computacional para fazer uma única atualização (um passo de gradiente) dos parâmetros de $w$ usando o método do backpropagation?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4Pna3bcicHj"
      },
      "source": [
        "Resposta (justifique):\n",
        "\n",
        "a) NxO(N). Como o custo computacional de apenas um parâmetro é O(N), quando temos N entradas na matriz dos parâmetros, precisamos rodar um laço para calcular todos eles e concluir um passo, sendo assim, o custo passa a ser N*O(N)\n",
        "\n",
        "b) O backpropagation não realiza a operação $(x_iω - y_i)^2$ pois baseia-se nos cálculos de gradientes que advém da regra da cadeia, portanto o custo é $O(N)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35I5w8EZdjIo"
      },
      "source": [
        "##Exercício 3.6\n",
        "\n",
        "Qual o custo (entropia cruzada) esperado para um exemplo (uma amostra) no começo do treinamento de um classificador inicializado aleatoriamente?\n",
        "\n",
        "A equação da entropia cruzada é:\n",
        "$$L = - \\sum_{j=0}^{K-1} y_j \\log p_j, $$\n",
        "Onde:\n",
        "\n",
        "- K é o número de classes;\n",
        "\n",
        "- $y_j=1$ se $j$ é a classe do exemplo (ground-truth), 0 caso contrário. Ou seja, $y$ é um vetor one-hot;\n",
        "\n",
        "- $p_j$ é a probabilidade predita pelo modelo para a classe $j$.\n",
        "\n",
        "A resposta tem que ser em função de uma ou mais das seguintes variáveis:\n",
        "\n",
        "- K = número de classes\n",
        "\n",
        "- B = batch size\n",
        "\n",
        "- D = dimensão de qualquer vetor do modelo\n",
        "\n",
        "- LR = learning rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swTOphiVs6eN"
      },
      "source": [
        "**Resposta:**\n",
        "Como a distribuição é aleatória, a probabilidade de ocorrência é a mesma para cada uma das classes, sendo assim, a probabilidade de uma classe é $1/K$, e dessa maneira:\n",
        "\n",
        "$$ L = - ∑_{j = 0} ^{K-1} y_j log(1/K)$$.\n",
        "\n",
        "Por o vetor ser do tipo one-hot, ou seja, apenas uma entrada é 1 e todas as outras são zero, como temos K classes, a entropia cruzada se torna\n",
        "\n",
        "$$ L  = -K log(1/K)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UNdHqgSB6S9"
      },
      "source": [
        "Fim do notebook."
      ]
    }
  ]
}
