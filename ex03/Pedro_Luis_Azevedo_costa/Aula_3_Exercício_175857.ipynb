{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aula 3 - Exercício - 175857",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {
        "height": "117px",
        "width": "252px"
      },
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unicamp-dl/IA025_2022S1/blob/main/ex03/Pedro_Luis_Azevedo_costa/Aula_3_Exerc%C3%ADcio_175857.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zK-o03OW4rWq"
      },
      "source": [
        "### Escreva aqui seu nome: Pedro Luís Azevedo Costa (RA 175857)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5_ZRWRfCZtI"
      },
      "source": [
        "# PyTorch: Gradientes e Grafo Computacional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQcJKilSCZtO"
      },
      "source": [
        "## Objetivos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFWv6Mi-CZtQ"
      },
      "source": [
        "Este notebook introduz \n",
        "- o conceito de autograd do PyTorch,\n",
        "- uma interpretação numérica intuitiva do gradiente, e o\n",
        "- grafo computacional, utilizado para o cálculo automático do gradiente de uma função."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIlQdKAuCZtR"
      },
      "source": [
        "Um dos principais fundamentos para que o PyTorch seja adequado para deep learning é a sua habilidade de\n",
        "calcular o gradiente automaticamente a partir da expressões definidas. Essa facilidade é implementada\n",
        "pelo tensor através do cálculo automático do gradiente pela construção dinâmica do grafo computacional."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF_-dJ2nCZtT"
      },
      "source": [
        "## Grafo computacional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jboejVQMCZtU"
      },
      "source": [
        "```\n",
        "    y_pred = x * w\n",
        "    e = y_pred - y\n",
        "    e2 = e**2\n",
        "    J = e2.sum()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeeEBKl4CZtV"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/robertoalotufo/files/master/figures/GrafoComputacional.png\" width=\"600pt\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yZun7wrCZtX"
      },
      "source": [
        "Para conhecer com maior profundidade a diferenciação automática usando grafo computacional, veja esta nota de aula:\n",
        "https://cs231n.github.io/optimization-2/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-11T00:23:00.431853Z",
          "start_time": "2019-12-11T00:23:00.414813Z"
        },
        "id": "HlT2d-4fCZtZ"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-11T00:23:00.863228Z",
          "start_time": "2019-12-11T00:23:00.844457Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "xX0QwUduCZtf",
        "outputId": "21fc3c89-443c-4026-9235-526243faf1c2"
      },
      "source": [
        "torch.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.10.0+cu111'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsqzALS4CZtl"
      },
      "source": [
        "## Se um tensor possui .requires_grad=True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:22.117010Z",
          "start_time": "2019-09-29T03:07:22.041861Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foaAb94aCZtm",
        "outputId": "3956440c-a4af-4fb6-f086-b77b06eebb1b"
      },
      "source": [
        "y = 2 * torch.arange(0,4).float()\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 2., 4., 6.])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:28.610934Z",
          "start_time": "2019-09-29T03:07:28.598223Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "no6SdSyICZtr",
        "outputId": "64745ee5-fd47-43f3-8fd9-e48f136ed3b5"
      },
      "source": [
        "x = torch.arange(0,4).float(); x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:31.523762Z",
          "start_time": "2019-09-29T03:07:31.497683Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eL_i1mwGCZtw",
        "outputId": "820dd417-195e-4085-9b0d-7dd666aa94ea"
      },
      "source": [
        "w = torch.ones(1,requires_grad=True); w"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjEl-0l7CZt0"
      },
      "source": [
        "## Cálculo automático do gradiente da função perda J"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pUh-SCnCZt1"
      },
      "source": [
        "Seja a expressão: $$ J = \\sum ((x  w) - y)^2 $$\n",
        "\n",
        "Queremos calcular a derivada de $J$ em relação a $w$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMwwVtJ1CZt2"
      },
      "source": [
        "### Montagem do grafo computacional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:36.290122Z",
          "start_time": "2019-09-29T03:07:36.273229Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zp2aK4YhCZt3",
        "outputId": "7db88cb8-7976-481a-d64c-4adb6e2aa78d"
      },
      "source": [
        "# predict (forward)\n",
        "y_pred = x * w\n",
        "\n",
        "# cálculo da perda J: loss\n",
        "e = y_pred - y\n",
        "e2 = e.pow(2)\n",
        "J = e2.sum()\n",
        "J"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14., grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC96wB7PCZt8"
      },
      "source": [
        "## Auto grad - processa o grafo computacional backwards"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-10-04T15:55:45.308858",
          "start_time": "2017-10-04T15:55:45.304654"
        },
        "id": "kKbf4D0CCZt-"
      },
      "source": [
        "O `backward()` varre o grafo computacional a partir da variável a ele associada e calcula o gradiente para todos os tensores que possuem o atributo `requires_grad` como verdadeiro.\n",
        "O `backward()` destroi o grafo após sua execução. Isso é intrínsico ao PyTorch pelo fato dele ser uma rede dinâmica."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:40.267334Z",
          "start_time": "2019-09-29T03:07:40.247422Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1lnkb0GCZt_",
        "outputId": "e9076e7e-0de1-4170-d99b-38ab8be4e76f"
      },
      "source": [
        "J.backward()\n",
        "print(w.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-28.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:42.637508Z",
          "start_time": "2019-09-29T03:07:42.627818Z"
        },
        "id": "NJWgpQbICZuD"
      },
      "source": [
        "w.grad.data.zero_();\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-HTDCpBCZuH"
      },
      "source": [
        "## Interpretação do Gradiente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQCUPkozCZuI"
      },
      "source": [
        "O gradiente de uma variável final (J) com respeito à outra variável de entrada (w) pode ser interpretado como o quanto a variável final J vai aumentar se houver um pequeno aumento na variável de entrada (w).\n",
        "Por exemplo suponha que o gradiente seja 28. Isto significa se aumentarmos a variável w de 0.001, então J vai aumentar de 0.028."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:46.287734Z",
          "start_time": "2019-09-29T03:07:46.276014Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNUws23uCZuK",
        "outputId": "d7dc86e7-1924-422c-ed97-73013ac883f0"
      },
      "source": [
        "eps = 0.001\n",
        "y_pred = x * (w + eps)\n",
        "J_new = (y_pred - y).pow(2).sum()\n",
        "J_new"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(13.9720, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:49.279766Z",
          "start_time": "2019-09-29T03:07:49.267111Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYghg1bnCZuP",
        "outputId": "814279ad-5137-4f59-cc26-c431d250215b"
      },
      "source": [
        "print(J_new - J)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-0.0280, grad_fn=<SubBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zlm30rdnCZuT"
      },
      "source": [
        "## Backpropagation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GREsFSQWCZuU"
      },
      "source": [
        "Uma forma equivalente explícita de calcular o gradiente é fazendo o processamento do backpropagation no grafo computacional, de forma explícita.\n",
        "Apenas como ilustração."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:52.889088Z",
          "start_time": "2019-09-29T03:07:52.861404Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYmJImp2CZuW",
        "scrolled": false,
        "outputId": "5441712c-8cef-47fc-c018-eaff89040dbe"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "dJ = 1.\n",
        "de2 = dJ * np.ones((4,))\n",
        "de = de2 * 2 * e.data.numpy()\n",
        "dy_pred = de\n",
        "dw = (dy_pred * x.data.numpy()).sum()\n",
        "print(dJ)\n",
        "print(de2)\n",
        "print(de)\n",
        "print(dw)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "[1. 1. 1. 1.]\n",
            "[ 0. -2. -4. -6.]\n",
            "-28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6-bQzqsCZuZ"
      },
      "source": [
        "## Visualizando o grafo computacional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:55.440538Z",
          "start_time": "2019-09-29T03:07:55.419663Z"
        },
        "id": "pjGruWPTCZub",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6de894e-299a-47e1-c7d8-e4e330805669"
      },
      "source": [
        "!pip install torchviz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchviz) (1.10.0+cu111)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchviz) (3.10.0.2)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4150 sha256=0ce61689d464ab420e34af25a89b2a0a01a3670920d9c43308851470437bad72\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/38/f5/dc4f85c3909051823df49901e72015d2d750bd26b086480ec2\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:56.829863Z",
          "start_time": "2019-09-29T03:07:56.003452Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "Lbi_GDjWCZuf",
        "outputId": "4fff9106-9828-48f3-80e8-49bdb2e797a6"
      },
      "source": [
        "import torchviz\n",
        "J = ((w * x) - y).pow(2).sum()\n",
        "p = {'w':w} # dicionário de parâmetros\n",
        "out = torchviz.make_dot(J,params=p)\n",
        "out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f0765392690>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"109pt\" height=\"380pt\"\n viewBox=\"0.00 0.00 109.00 380.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 376)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-376 105,-376 105,4 -4,4\"/>\n<!-- 139669731072240 -->\n<g id=\"node1\" class=\"node\">\n<title>139669731072240</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"77.5,-31 23.5,-31 23.5,0 77.5,0 77.5,-31\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> ()</text>\n</g>\n<!-- 139669739745104 -->\n<g id=\"node2\" class=\"node\">\n<title>139669739745104</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"95,-86 6,-86 6,-67 95,-67 95,-86\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">SumBackward0</text>\n</g>\n<!-- 139669739745104&#45;&gt;139669731072240 -->\n<g id=\"edge6\" class=\"edge\">\n<title>139669739745104&#45;&gt;139669731072240</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M50.5,-66.9688C50.5,-60.1289 50.5,-50.5621 50.5,-41.5298\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"54.0001,-41.3678 50.5,-31.3678 47.0001,-41.3678 54.0001,-41.3678\"/>\n</g>\n<!-- 139669739741968 -->\n<g id=\"node3\" class=\"node\">\n<title>139669739741968</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"95,-141 6,-141 6,-122 95,-122 95,-141\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">PowBackward0</text>\n</g>\n<!-- 139669739741968&#45;&gt;139669739745104 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139669739741968&#45;&gt;139669739745104</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M50.5,-121.9197C50.5,-114.9083 50.5,-105.1442 50.5,-96.4652\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"54.0001,-96.3408 50.5,-86.3408 47.0001,-96.3409 54.0001,-96.3408\"/>\n</g>\n<!-- 139669739742096 -->\n<g id=\"node4\" class=\"node\">\n<title>139669739742096</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"95,-196 6,-196 6,-177 95,-177 95,-196\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">SubBackward0</text>\n</g>\n<!-- 139669739742096&#45;&gt;139669739741968 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139669739742096&#45;&gt;139669739741968</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M50.5,-176.9197C50.5,-169.9083 50.5,-160.1442 50.5,-151.4652\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"54.0001,-151.3408 50.5,-141.3408 47.0001,-151.3409 54.0001,-151.3408\"/>\n</g>\n<!-- 139669739743376 -->\n<g id=\"node5\" class=\"node\">\n<title>139669739743376</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"95,-251 6,-251 6,-232 95,-232 95,-251\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MulBackward0</text>\n</g>\n<!-- 139669739743376&#45;&gt;139669739742096 -->\n<g id=\"edge3\" class=\"edge\">\n<title>139669739743376&#45;&gt;139669739742096</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M50.5,-231.9197C50.5,-224.9083 50.5,-215.1442 50.5,-206.4652\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"54.0001,-206.3408 50.5,-196.3408 47.0001,-206.3409 54.0001,-206.3408\"/>\n</g>\n<!-- 139669739742800 -->\n<g id=\"node6\" class=\"node\">\n<title>139669739742800</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"101,-306 0,-306 0,-287 101,-287 101,-306\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 139669739742800&#45;&gt;139669739743376 -->\n<g id=\"edge4\" class=\"edge\">\n<title>139669739742800&#45;&gt;139669739743376</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M50.5,-286.9197C50.5,-279.9083 50.5,-270.1442 50.5,-261.4652\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"54.0001,-261.3408 50.5,-251.3408 47.0001,-261.3409 54.0001,-261.3408\"/>\n</g>\n<!-- 139669740189648 -->\n<g id=\"node7\" class=\"node\">\n<title>139669740189648</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"77.5,-372 23.5,-372 23.5,-342 77.5,-342 77.5,-372\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-360\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">w</text>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-349\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139669740189648&#45;&gt;139669739742800 -->\n<g id=\"edge5\" class=\"edge\">\n<title>139669740189648&#45;&gt;139669739742800</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M50.5,-341.7333C50.5,-334.0322 50.5,-324.5977 50.5,-316.3414\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"54.0001,-316.0864 50.5,-306.0864 47.0001,-316.0864 54.0001,-316.0864\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRCxXDiIzYT7"
      },
      "source": [
        "Iremos agora visualizar a Resnet, que é uma rede neural bastante popular em visão computacional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmhanmVFzhiQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "outputId": "05bc541a-306b-4a77-9598-105afd2d9c72"
      },
      "source": [
        "import torch\n",
        "model = torch.hub.load('pytorch/vision:v0.9.0', 'resnet18', pretrained=True)\n",
        "x_temp = torch.randn(1,3,224,224)  # First, create a random image.\n",
        "y_temp = model(x_temp)  # We need one forward pass so the graph can be build.\n",
        "out = torchviz.make_dot(y_temp, params=dict(model.named_parameters()))  # Create a figure from the computaional graph..\n",
        "torchviz.dot.resize_graph(out, size_per_element=0.05)  # Resize to fit on the screen.\n",
        "out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.9.0\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "URLError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1349\u001b[0m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0;32m-> 1350\u001b[0;31m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0m\u001b[1;32m   1351\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1280\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1281\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1326\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1275\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    975\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1450\u001b[0m             self.sock = self._context.wrap_socket(self.sock,\n\u001b[0;32m-> 1451\u001b[0;31m                                                   server_hostname=server_hostname)\n\u001b[0m\u001b[1;32m   1452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m         )\n",
            "\u001b[0;32m/usr/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36m_create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m    869\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1138\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1091)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-0a7f418e3433>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pytorch/vision:v0.9.0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'resnet18'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mx_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# First, create a random image.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_temp\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# We need one forward pass so the graph can be build.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchviz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Create a figure from the computaional graph..\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(repo_or_dir, model, source, force_reload, verbose, skip_validation, *args, **kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0mrepo_or_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_cache_or_reload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_or_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_reload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_or_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36m_load_local\u001b[0;34m(hubconf_dir, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0mentry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_entry_from_hubconf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhub_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhubconf_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/root/.cache/torch/hub/pytorch_vision_v0.9.0/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mresnet18\u001b[0;34m(pretrained, progress, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \"\"\"\n\u001b[1;32m    276\u001b[0m     return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress,\n\u001b[0;32m--> 277\u001b[0;31m                    **kwargs)\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/root/.cache/torch/hub/pytorch_vision_v0.9.0/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_resnet\u001b[0;34m(arch, block, layers, pretrained, progress, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         state_dict = load_state_dict_from_url(model_urls[arch],\n\u001b[0;32m--> 263\u001b[0;31m                                               progress=progress)\n\u001b[0m\u001b[1;32m    264\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36mload_state_dict_from_url\u001b[0;34m(url, model_dir, map_location, progress, check_hash, file_name)\u001b[0m\n\u001b[1;32m    584\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHASH_REGEX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# r is Optional[Match[str]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0mhash_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m         \u001b[0mdownload_url_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhash_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_legacy_zip_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36mdownload_url_to_file\u001b[0;34m(url, dst, hash_prefix, progress)\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0mfile_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"torch.hub\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m     \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'getheaders'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 543\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0;32m-> 1393\u001b[0;31m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m         \u001b[0mhttps_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1350\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[1;32m   1351\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mURLError\u001b[0m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1091)>"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "7mIP_gnbral2"
      },
      "source": [
        "# Exercício 1\n",
        "\n",
        "O que acontece com o grafo computacional após execução do `backward()`?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dg34dQHdk5KG"
      },
      "source": [
        "Resposta: O grafo computacional que havia sido construído através do método ```forward()``` é percorrido de sua raíz até suas folhas recursivamente, calculando o gradiente de cada um de seus nós através da regra da cadeia. Além disso os nós vão sendo destruídos ordenadamente, um por um, até que no final da execucão o grafo computacional inteiro tenha sido destruído.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "0RkjpqfprZ_t"
      },
      "source": [
        "# Exercício 2\n",
        "\n",
        "Execute um passo de atualização do valor de w, pelo \n",
        "gradiente descendente. Utilize um fator de aprendizado (*learning rate*) de 0.01 \n",
        "para atualizar o `w`. Após, recalcule a função de perda:\n",
        "\n",
        "    - w = w - lr * w.grad.data\n",
        "    - Verifique o quanto que a perda J diminuiu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np7D022AO2gM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe1fd134-b0d9-480e-d92c-76d38d42bcbb"
      },
      "source": [
        "\n",
        "y = 2 * torch.arange(0,4).float()\n",
        "x = torch.arange(0,4).float()\n",
        "w = torch.ones(1,requires_grad=True)\n",
        "\n",
        "lr = 0.01\n",
        "y_pred = x * w\n",
        "\n",
        "# cálculo da perda J: loss\n",
        "def loss_calc(x, y_target):\n",
        "    y_pred = x * w\n",
        "    e = y_pred - y_target\n",
        "    e2 = e.pow(2)\n",
        "    J = e2.sum()\n",
        "    return J\n",
        "\n",
        "J = loss_calc(x, y)\n",
        "J.backward()\n",
        "print(\"Fucao de perda incial: \", J)\n",
        "\n",
        "\n",
        "w = w - w.grad.data * lr\n",
        "J = loss_calc(x,y)\n",
        "J.backward()\n",
        "print(\"Fucao de perda após uma iteracao: \", J)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fucao de perda incial:  tensor(14., grad_fn=<SumBackward0>)\n",
            "Fucao de perda após uma iteracao:  tensor(7.2576, grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiO_v7fDzZIm",
        "outputId": "4bc1cc58-781e-4b1b-909c-0fed840542e7"
      },
      "source": [
        "eps = 0.001\n",
        "y_pred = x * (w + eps)\n",
        "J_new = (y_pred - y).pow(2).sum()\n",
        "J_new"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.2375, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hozksnNDXx4G"
      },
      "source": [
        "## Treinando uma rede no Pytorch\n",
        "\n",
        "Para ajudar na entendimento dos exercícios abaixo, apresentamos o código em Pytorch para treinar uma rede de uma camada não-linear, com pesos `w` e `b`:\n",
        "$y' = \\sigma(wx + b)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp9dSVjXy4gy"
      },
      "source": [
        "<img src=\"https://github.com/robertoalotufo/files/blob/master/figures/simple_graph.png?raw=true\" width=\"600pt\"/>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# É importante fixar as seeds para passar nos asserts abaixo.\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "random.seed(123)\n",
        "np.random.seed(123)\n",
        "torch.manual_seed(123)"
      ],
      "metadata": {
        "id": "9KYYzSqoZ3iM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2e27fab-eb2c-4b3c-9ee2-c3d9ff0dccb5"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fa12365ae70>"
            ]
          },
          "metadata": {},
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhXl4fkxYv2z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f3b2858-087b-4213-8fbc-f83337bb0a85"
      },
      "source": [
        "from typing import List\n",
        "\n",
        "class NonLinearPytorch(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NonLinearPytorch, self).__init__()\n",
        "\n",
        "        self.layer1 = torch.nn.Linear(1, 1)\n",
        "        # Inicializa os pesos w e b em zero.\n",
        "        self.layer1.load_state_dict(dict(weight=torch.zeros(1,1), bias=torch.zeros(1)))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        y_pred = torch.sigmoid(self.layer1(x))\n",
        "        return y_pred\n",
        "\n",
        "learning_rate = 0.1\n",
        "model = NonLinearPytorch()\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "x = torch.tensor([-5], dtype=torch.float)\n",
        "y_target = torch.tensor([0.76], dtype=torch.float)\n",
        "num_iterations = 50\n",
        "for i in range(num_iterations):\n",
        "    # Zere os gradientes dos passo anterior.\n",
        "    optimizer.zero_grad()\n",
        "    # Rode a um passo forward do modelo.\n",
        "    y_pred = model.forward(x)\n",
        "    # Calcule a loss\n",
        "    loss = loss_fn(y_pred, y_target)\n",
        "    # Calcule os gradientes\n",
        "    loss.backward()\n",
        "    # Atualize os pesos\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f'iter:{i}: y_prime: {y_pred}')"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter:0: y_prime: tensor([0.5000], grad_fn=<SigmoidBackward0>)\n",
            "iter:1: y_prime: tensor([0.5837], grad_fn=<SigmoidBackward0>)\n",
            "iter:2: y_prime: tensor([0.6366], grad_fn=<SigmoidBackward0>)\n",
            "iter:3: y_prime: tensor([0.6702], grad_fn=<SigmoidBackward0>)\n",
            "iter:4: y_prime: tensor([0.6926], grad_fn=<SigmoidBackward0>)\n",
            "iter:5: y_prime: tensor([0.7083], grad_fn=<SigmoidBackward0>)\n",
            "iter:6: y_prime: tensor([0.7196], grad_fn=<SigmoidBackward0>)\n",
            "iter:7: y_prime: tensor([0.7281], grad_fn=<SigmoidBackward0>)\n",
            "iter:8: y_prime: tensor([0.7345], grad_fn=<SigmoidBackward0>)\n",
            "iter:9: y_prime: tensor([0.7395], grad_fn=<SigmoidBackward0>)\n",
            "iter:10: y_prime: tensor([0.7435], grad_fn=<SigmoidBackward0>)\n",
            "iter:11: y_prime: tensor([0.7466], grad_fn=<SigmoidBackward0>)\n",
            "iter:12: y_prime: tensor([0.7491], grad_fn=<SigmoidBackward0>)\n",
            "iter:13: y_prime: tensor([0.7511], grad_fn=<SigmoidBackward0>)\n",
            "iter:14: y_prime: tensor([0.7527], grad_fn=<SigmoidBackward0>)\n",
            "iter:15: y_prime: tensor([0.7540], grad_fn=<SigmoidBackward0>)\n",
            "iter:16: y_prime: tensor([0.7551], grad_fn=<SigmoidBackward0>)\n",
            "iter:17: y_prime: tensor([0.7560], grad_fn=<SigmoidBackward0>)\n",
            "iter:18: y_prime: tensor([0.7567], grad_fn=<SigmoidBackward0>)\n",
            "iter:19: y_prime: tensor([0.7573], grad_fn=<SigmoidBackward0>)\n",
            "iter:20: y_prime: tensor([0.7577], grad_fn=<SigmoidBackward0>)\n",
            "iter:21: y_prime: tensor([0.7581], grad_fn=<SigmoidBackward0>)\n",
            "iter:22: y_prime: tensor([0.7585], grad_fn=<SigmoidBackward0>)\n",
            "iter:23: y_prime: tensor([0.7587], grad_fn=<SigmoidBackward0>)\n",
            "iter:24: y_prime: tensor([0.7589], grad_fn=<SigmoidBackward0>)\n",
            "iter:25: y_prime: tensor([0.7591], grad_fn=<SigmoidBackward0>)\n",
            "iter:26: y_prime: tensor([0.7593], grad_fn=<SigmoidBackward0>)\n",
            "iter:27: y_prime: tensor([0.7594], grad_fn=<SigmoidBackward0>)\n",
            "iter:28: y_prime: tensor([0.7595], grad_fn=<SigmoidBackward0>)\n",
            "iter:29: y_prime: tensor([0.7596], grad_fn=<SigmoidBackward0>)\n",
            "iter:30: y_prime: tensor([0.7597], grad_fn=<SigmoidBackward0>)\n",
            "iter:31: y_prime: tensor([0.7597], grad_fn=<SigmoidBackward0>)\n",
            "iter:32: y_prime: tensor([0.7598], grad_fn=<SigmoidBackward0>)\n",
            "iter:33: y_prime: tensor([0.7598], grad_fn=<SigmoidBackward0>)\n",
            "iter:34: y_prime: tensor([0.7598], grad_fn=<SigmoidBackward0>)\n",
            "iter:35: y_prime: tensor([0.7599], grad_fn=<SigmoidBackward0>)\n",
            "iter:36: y_prime: tensor([0.7599], grad_fn=<SigmoidBackward0>)\n",
            "iter:37: y_prime: tensor([0.7599], grad_fn=<SigmoidBackward0>)\n",
            "iter:38: y_prime: tensor([0.7599], grad_fn=<SigmoidBackward0>)\n",
            "iter:39: y_prime: tensor([0.7599], grad_fn=<SigmoidBackward0>)\n",
            "iter:40: y_prime: tensor([0.7600], grad_fn=<SigmoidBackward0>)\n",
            "iter:41: y_prime: tensor([0.7600], grad_fn=<SigmoidBackward0>)\n",
            "iter:42: y_prime: tensor([0.7600], grad_fn=<SigmoidBackward0>)\n",
            "iter:43: y_prime: tensor([0.7600], grad_fn=<SigmoidBackward0>)\n",
            "iter:44: y_prime: tensor([0.7600], grad_fn=<SigmoidBackward0>)\n",
            "iter:45: y_prime: tensor([0.7600], grad_fn=<SigmoidBackward0>)\n",
            "iter:46: y_prime: tensor([0.7600], grad_fn=<SigmoidBackward0>)\n",
            "iter:47: y_prime: tensor([0.7600], grad_fn=<SigmoidBackward0>)\n",
            "iter:48: y_prime: tensor([0.7600], grad_fn=<SigmoidBackward0>)\n",
            "iter:49: y_prime: tensor([0.7600], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dCpic0_XhKE"
      },
      "source": [
        "# Exercício 3\n",
        "\n",
        "Vamos agora escrever nosso próprio código para calcular os gradientes da rede apresentada acima.\n",
        "\n",
        "Para tanto, temos que primeiro implementar a classe Tensor, que é parecida com a classe Tensor do pytorch. Quando instanciada, o objeto resultante armazena o valor do tensor e uma referencia para o nó do grafo computacional que gerou os valores do tensor, quando houver. Com isso podemos construir percorrer o grafo computacional no sentido reverso, realizando o passo `backward` do algoritmo de backpropagation.\n",
        "\n",
        "Para simplificar a implementação, o gradiente também pode ser armazenado nesta variável. Com isso, podemos tratar os pesos da rede como Tensor's. Isso dispensa a necessidade de criarmos a classe Parameters, como é feito no pytorch."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Me baseei em algumas partes do código do Leonardo Augusto da Silva Pacheco. Gostaria de deixar meus agradecimentos.**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "r6fjWIYG-Pnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Tensor():\n",
        "    def __init__(self, data: float, previous_node=None):\n",
        "        self.data = data\n",
        "        self.previous_node = previous_node\n",
        "        self.grad = 0.\n",
        "        return\n",
        "\n",
        "    def backward(self, upstream_grad: float = 1):\n",
        "        # Esta vai ser uma chamada recursiva cujo critéria de parada é quando previous_node==None.\n",
        "        self.grad += upstream_grad\n",
        "        if self.previous_node:\n",
        "            self.previous_node.backward(self.grad)\n",
        "        return\n",
        "        \n",
        "\n",
        "    # Implementar as funções abaixo é opcional.\n",
        "    def __add__(self, other: 'Tensor'):\n",
        "        #raise Exception(\"Escreva seu código aqui\")\n",
        "        return Tensor(self.data + other.data)\n",
        "\n",
        "    def __sub__(self, other: 'Tensor'):\n",
        "        #raise Exception(\"Escreva seu código aqui\")\n",
        "        return Tensor(self.data - other.data)\n",
        "\n",
        "    def __mul__(self, other: 'Tensor'):\n",
        "        #raise Exception(\"Escreva seu código aqui\")\n",
        "        return Tensor(self.data * other.data)\n",
        "   \n",
        "    def __pow__(self, other: 'Tensor'):\n",
        "        return Tensor(self.data ** other.data)\n",
        "\n",
        "tensor_1 = Tensor(1)\n",
        "tensor_2 = Tensor(2)\n",
        "tensor_3 = tensor_1 + tensor_2\n",
        "tensor_4 = tensor_2 ** Tensor(2)\n",
        "print(tensor_3.data)\n",
        "print(tensor_4.data)\n"
      ],
      "metadata": {
        "id": "T3vkPX65NYAS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd3fa0dc-2e50-4503-de5c-2f3980945141"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A seguir, implementaremos as funções `forward` e `backward` de cada um dos nós do grafo acima, além do nó de subtração, que é usado pela função de custo.\n",
        "Vamos começar pelo nó da função sigmoid ($\\sigma$), cuja derivada é:\n",
        "\n",
        "$\\frac{\\delta\\sigma}{\\delta x} = \\sigma(x)(1-\\sigma(x))$"
      ],
      "metadata": {
        "id": "9PWNVg4wMS9t"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up1GixP9PFjG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9681ca7-e66e-4c3f-c28f-b4c674acb665"
      },
      "source": [
        "def sigmoid_func(x: Tensor):\n",
        "      calc_expression = 1/(1+np.exp(-x.data))\n",
        "      return Tensor(calc_expression)\n",
        "\n",
        "class SigmoidNode():\n",
        "    def forward(self, x: Tensor):\n",
        "        #raise Exception(\"Escreva seu código aqui\")\n",
        "        self.x = x\n",
        "        self.forward_value = sigmoid_func(x)\n",
        "        self.forward_value.previous_node = self\n",
        "        return self.forward_value\n",
        "\n",
        "    def backward(self, upstream_grad: float = 1):\n",
        "        #raise Exception(\"Escreva seu código aqui\")\n",
        "        #self.grad = upstream_grad * \n",
        "\n",
        "        self.forward_value.grad = upstream_grad\n",
        "        self.local_grad = sigmoid_func(self.x).data * (1 - sigmoid_func(self.x).data)\n",
        "        self.x.backward(self.local_grad * upstream_grad)\n",
        "        return\n",
        "\n",
        "\n",
        "\n",
        "tensor_1 = Tensor(10)\n",
        "sig = SigmoidNode()\n",
        "sig.forward(tensor_1)\n",
        "\n",
        "sig.backward()\n",
        "print(sig.local_grad)\n",
        "print(sig.x.grad)"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.5395807735907655e-05\n",
            "4.5395807735907655e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWxNzGVZXvU7"
      },
      "source": [
        "Implementamos agora o `forward` e `backward` do nó da soma $z = x + y$, cujas derivadas parciais em relação a cada entrada $x$ e $y$ são:\n",
        "\n",
        "$\\frac{\\delta z}{\\delta x} = 1$\n",
        "\n",
        "$\\frac{\\delta z}{\\delta y} = 1$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiGB3rhaXvxC"
      },
      "source": [
        "class AddNode():\n",
        "    def forward(self, x: Tensor, y: Tensor):\n",
        "        #raise Exception(\"Escreva seu código aqui\")\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.forward_value = x + y\n",
        "        self.forward_value.previous_node = self\n",
        "        return self.forward_value\n",
        "      \n",
        "    def backward(self, upstream_grad: float=1):\n",
        "        # A operação de soma tem o objetivo de ser um \"distribuidor\", logo a derivada de z /derivada de x = 1 \n",
        "        # basta então, multiplicar 1 (gradiente local) pelo gradiente da frente.\n",
        "        #raise Exception(\"Escreva seu código aqui\")\n",
        "        self.forward_value.grad = upstream_grad\n",
        "        self.x_grad = self.x.backward(upstream_grad)\n",
        "        self.y_grad = self.y.backward(upstream_grad)\n",
        "        return \n",
        "\n"
      ],
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementamos agora o `forward` e `backward` do nó da subtração $z = x - y$, cujas derivadas parciais em relação a cada entrada $x$ e $y$ são:\n",
        "\n",
        "$\\frac{\\delta z}{\\delta x} = 1$\n",
        "\n",
        "$\\frac{\\delta z}{\\delta y} = -1$"
      ],
      "metadata": {
        "id": "-XbKz0z0VfdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SubNode():\n",
        "    def forward(self, x: Tensor, y: Tensor):\n",
        "        #raise Exception(\"Escreva seu código aqui\")\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.forward_value = x - y\n",
        "        self.forward_value.previous_node = self\n",
        "        return self.forward_value\n",
        "      \n",
        "    def backward(self, upstream_grad: float=1):\n",
        "        # A operação de soma tem o objetivo de ser um \"distribuidor\", logo a derivada de z /derivada de x = 1 \n",
        "        # basta então, multiplicar 1 (gradiente local) pelo gradiente da frente.\n",
        "        #raise Exception(\"Escreva seu código aqui\")\n",
        "        self.forward_value.grad = upstream_grad\n",
        "        self.x.backward(upstream_grad)\n",
        "        self.y.backward(-upstream_grad)\n",
        "        return\n",
        "\n"
      ],
      "metadata": {
        "id": "ztsGOWudV3X7"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSEUWtP_qSqW"
      },
      "source": [
        "Implementamos agora o `forward` e `backward` do nó da multiplicação $z = xy$, cujas derivadas parciais em relação a cada entrada $x$ e $y$ são:\n",
        "\n",
        "$\\frac{\\delta z}{\\delta x} = y$\n",
        "\n",
        "$\\frac{\\delta z}{\\delta y} = x$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWzSxUU-Zlel",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11f47701-ea76-478e-e984-c11a8d0a57b8"
      },
      "source": [
        "class MulNode():\n",
        "    def forward(self, x: Tensor, y: Tensor):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.forward_value = x*y\n",
        "        self.forward_value.previous_node = self\n",
        "        return self.forward_value\n",
        "        #raise Exception(\"Escreva seu código aqui\")\n",
        "    \n",
        "    def backward(self, upstream_grad: float = 1):\n",
        "        self.forward_value.grad = upstream_grad\n",
        "        self.x.backward(self.y.data * upstream_grad)\n",
        "        self.y.backward(self.x.data * upstream_grad)\n",
        "\n",
        "x_t = Tensor(1)\n",
        "y_t = Tensor(2)\n",
        "print(x_t.grad, y_t.grad)\n",
        "mul = MulNode()\n",
        "sig = SigmoidNode()\n",
        "sig.forward(mul.forward(x_t, y_t))\n",
        "sig.backward()\n",
        "print(x_t.grad, y_t.grad)\n",
        "\n"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 0.0\n",
            "0.20998717080701323 0.10499358540350662\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PowNode():\n",
        "    def forward(self, x: Tensor):\n",
        "        self.x = x\n",
        "        self.forward_value = x**Tensor(2)\n",
        "        self.forward_value.previous_node = self\n",
        "        return self.forward_value\n",
        "\n",
        "    def backward(self, upstream_grad: float = 1):\n",
        "        self.forward_value.grad = upstream_grad\n",
        "        self.x.backward(2*self.x.data*upstream_grad)\n",
        "PowNode().forward(Tensor(2)).data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3J3GmstMW9x",
        "outputId": "ee9441ab-47e5-4f8b-f2d3-cd1ccfdeee38"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61FgtL-6Z0y2"
      },
      "source": [
        "Agora que temos todos os nós implementados, podemos implementar as funções `forward` e `backward` de uma camada não-linear."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1N4eVVMaCIP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1be5ea8-d7d0-4619-8994-e5d4bbc266c7"
      },
      "source": [
        "class NonLinear():\n",
        "    def __init__(self):\n",
        "        self.w = Tensor(0)\n",
        "        self.b = Tensor(0)\n",
        "        self.add_node = AddNode()\n",
        "        self.sub_node = SubNode()\n",
        "        self.mul_node = MulNode()\n",
        "        self.sig_node = SigmoidNode()\n",
        "        self.pow_node = PowNode()\n",
        "        ...\n",
        "\n",
        "    def forward(self, x: Tensor):\n",
        "        self.x = x\n",
        "        self.mul = self.mul_node.forward(self.x, self.w)\n",
        "        self.add = self.add_node.forward(self.mul, self.b)\n",
        "        self.sig = self.sig_node.forward(self.add)\n",
        "        self.forward_value = self.sig\n",
        "        #self.forward_value.previous_node = self\n",
        "        return self.forward_value\n",
        "        \n",
        "nonlinear = NonLinear()\n",
        "nonlinear.forward(Tensor(1))\n",
        "nonlinear.forward_value.backward()\n",
        "print(nonlinear.w.grad)"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIb90Wu1aGB3"
      },
      "source": [
        "Para treinar esta rede, usaremos a função de custo Mean Squared Error (MSE):\n",
        "\n",
        "$L = (y_\\text{pred} - y_\\text{target})^2$\n",
        "\n",
        "Como por simplicidade optamos por não criar o nó de exponenciação, iremos substituir a operação de elevar ao quadrado pela multiplicacão das diferenças:\n",
        "$L = (y_\\text{pred} - y_\\text{target}) * (y_\\text{pred} - y_\\text{target})$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prm0OP27pynW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f14894b-cc29-4b71-9f1c-e0c16542f1e5"
      },
      "source": [
        "def compute_loss(y_target: Tensor, y_pred: Tensor):\n",
        "\n",
        "    pow_node = PowNode()\n",
        "    sub_node = SubNode()\n",
        "    forward_value = pow_node.forward(sub_node.forward(y_target, y_pred))\n",
        "    return forward_value\n",
        "\n",
        "a= Tensor(0.76)\n",
        "b = Tensor(0.5)\n",
        "x = compute_loss(a,b )\n",
        "x.backward()\n",
        "a.grad"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.52"
            ]
          },
          "metadata": {},
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Também precisamos criar a classe do optimizador SGD, para atualizar os pesos da rede."
      ],
      "metadata": {
        "id": "12HHy6jV6bfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SGD():\n",
        "    def __init__(self, parameters, learning_rate: float):\n",
        "        self.parameters = parameters\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def step(self):\n",
        "        for parameter in self.parameters:\n",
        "            parameter.data -= self.learning_rate * parameter.grad\n",
        "            \n",
        "    def zero_grad(self):\n",
        "        for parameter in self.parameters:\n",
        "            parameter.grad = 0\n"
      ],
      "metadata": {
        "id": "4R8_Qyfj6avq"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plTCBJWjpwCp"
      },
      "source": [
        "Por fim, vamos aprender os pesos `w` e `b` para mapear um valor de entrada $x$ para um valor de saída $y_\\text{target}$. Para isso, inicializamos o grafo da rede e rodamos o laço de optimização, que vai aplicar a descida do gradiente a cada iteração:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rp5ttTsGaPmA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30a689a0-2f13-47dd-8abe-8c76d3dcc7c3"
      },
      "source": [
        "learning_rate = 0.1\n",
        "\n",
        "model = NonLinear()\n",
        "optimizer = SGD(parameters=[model.w, model.b], learning_rate=learning_rate)\n",
        "x = Tensor(-5)\n",
        "y_target = Tensor(0.76)\n",
        "num_iterations = 50\n",
        "loss_history = []\n",
        "for i in range(num_iterations):\n",
        "    # Zera os gradientes dos passo anterior.\n",
        "    optimizer.zero_grad()\n",
        "    # Roda a um passo forward do modelo.\n",
        "    y_pred = model.forward(x)\n",
        "    # Calcula o gradiente do erro, data a predição do modelo.\n",
        "    loss_grad = compute_loss(y_target=y_target, y_pred=y_pred)\n",
        "    # Calcula agora os gradientes de w e b usando a função backward do modelo.\n",
        "    loss_grad.backward()\n",
        "    loss_history.append(loss_grad.data)\n",
        "\n",
        "    # Atualiza os pesos w e b usando os seus respectivos gradientes.\n",
        "    optimizer.step()\n",
        "    print(f'iter:{i}: y_prime: {y_pred.data}')\n"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter:0: y_prime: 0.5\n",
            "iter:1: y_prime: 0.5837046173683925\n",
            "iter:2: y_prime: 0.6366285843520386\n",
            "iter:3: y_prime: 0.6702173049125246\n",
            "iter:4: y_prime: 0.6926118588833087\n",
            "iter:5: y_prime: 0.7082630037746998\n",
            "iter:6: y_prime: 0.7196148662766375\n",
            "iter:7: y_prime: 0.7280841768455426\n",
            "iter:8: y_prime: 0.7345401280962437\n",
            "iter:9: y_prime: 0.7395432699196375\n",
            "iter:10: y_prime: 0.7434705908546596\n",
            "iter:11: y_prime: 0.7465846221394693\n",
            "iter:12: y_prime: 0.749073553182271\n",
            "iter:13: y_prime: 0.7510755634376279\n",
            "iter:14: y_prime: 0.752694160393387\n",
            "iter:15: y_prime: 0.7540081808314562\n",
            "iter:16: y_prime: 0.7550785096793768\n",
            "iter:17: y_prime: 0.755952714496937\n",
            "iter:18: y_prime: 0.7566683180371979\n",
            "iter:19: y_prime: 0.7572551577602015\n",
            "iter:20: y_prime: 0.7577371188227114\n",
            "iter:21: y_prime: 0.7581334279605325\n",
            "iter:22: y_prime: 0.7584596336238502\n",
            "iter:23: y_prime: 0.7587283579606848\n",
            "iter:24: y_prime: 0.7589498802167108\n",
            "iter:25: y_prime: 0.759132593748223\n",
            "iter:26: y_prime: 0.7592833670372603\n",
            "iter:27: y_prime: 0.7594078309332755\n",
            "iter:28: y_prime: 0.7595106086081933\n",
            "iter:29: y_prime: 0.7595955006174161\n",
            "iter:30: y_prime: 0.75966563449483\n",
            "iter:31: y_prime: 0.7597235861335783\n",
            "iter:32: y_prime: 0.7597714785857903\n",
            "iter:33: y_prime: 0.7598110626958986\n",
            "iter:34: y_prime: 0.7598437830543183\n",
            "iter:35: y_prime: 0.7598708320443492\n",
            "iter:36: y_prime: 0.7598931942006135\n",
            "iter:37: y_prime: 0.7599116826628661\n",
            "iter:38: y_prime: 0.7599269691660118\n",
            "iter:39: y_prime: 0.7599396087345267\n",
            "iter:40: y_prime: 0.7599500600314741\n",
            "iter:41: y_prime: 0.759958702137105\n",
            "iter:42: y_prime: 0.759965848390577\n",
            "iter:43: y_prime: 0.759971757813698\n",
            "iter:44: y_prime: 0.7599766445423947\n",
            "iter:45: y_prime: 0.7599806856156233\n",
            "iter:46: y_prime: 0.7599840274093325\n",
            "iter:47: y_prime: 0.7599867909522462\n",
            "iter:48: y_prime: 0.7599890763185229\n",
            "iter:49: y_prime: 0.7599909662580948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assert do histórico de losses\n",
        "target_loss_history = np.array([\n",
        "    0.06760000000000001,\n",
        "    0.03108006193722489,\n",
        "    0.015220506198982053,\n",
        "    0.008060932337170576,\n",
        "    0.004541161563163106,\n",
        "    0.002676716778416733,\n",
        "    0.0016309590258538709,\n",
        "    0.0010186197676265991,\n",
        "    0.0006482050773556802,\n",
        "    0.0004184778055808091,\n",
        "    0.0002732213666940629,\n",
        "    0.0001799723631408175,\n",
        "    0.00011938724006066084,\n",
        "    7.964556795580347e-05,\n",
        "    5.337529235755546e-05,\n",
        "    3.590189694852957e-05,\n",
        "    2.4221066975987528e-05,\n",
        "    1.6380519943303855e-05,\n",
        "    1.1100104701260794e-05,\n",
        "    7.534158921382263e-06,\n",
        "    5.1206312225268915e-06,\n",
        "    3.484091178521846e-06,\n",
        "    2.372728572773017e-06,\n",
        "    1.6170734761536686e-06,\n",
        "    1.102751559255297e-06,\n",
        "    7.523936056219261e-07,\n",
        "    5.135628032851034e-07,\n",
        "    3.506642035854199e-07,\n",
        "    2.395039343745027e-07,\n",
        "    1.6361975051076568e-07,\n",
        "    1.1180029104756559e-07,\n",
        "    7.64046255502172e-08,\n",
        "    5.222203675240293e-08,\n",
        "    3.5697304881109e-08,\n",
        "    2.440373411811497e-08,\n",
        "    1.6684360766998337e-08,\n",
        "    1.1407478782586943e-08,\n",
        "    7.799952038419558e-09,\n",
        "    5.333502713018058e-09,\n",
        "    3.6471049454669566e-09,\n",
        "    2.4940004563648322e-09,\n",
        "    1.70551347969202e-09,\n",
        "    1.1663324261807554e-09,\n",
        "    7.976210871191926e-10,\n",
        "    5.454773999550763e-10,\n",
        "    3.7304544385265726e-10,\n",
        "    2.55123652632966e-10,\n",
        "    1.744789425625632e-10,\n",
        "    1.1932681701419737e-10,\n",
        "    8.160849280968648e-11])\n",
        "\n",
        "assert np.allclose(np.array(loss_history), target_loss_history, atol=1e-6)\n"
      ],
      "metadata": {
        "id": "YMwyzXtsVa9_"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "V8AqQ0n7raQI"
      },
      "source": [
        "# Exercício 4\n",
        "\n",
        "Repita o exercício 3 mas usando uma rede com duas camadas não-lineares:\n",
        "\n",
        "$a = \\sigma(w_1x + b_1)$\n",
        "\n",
        "$y' = \\sigma(w_2a + b_2)$\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net():\n",
        "    def __init__(self):\n",
        "        self.layer1 = NonLinear()\n",
        "        self.layer2 = NonLinear()\n",
        "\n",
        "    def forward(self, x: Tensor):\n",
        "        l1_f = self.layer1.forward(x)\n",
        "        l2_f = self.layer2.forward(l1_f)\n",
        "        return l2_f"
      ],
      "metadata": {
        "id": "fkBfLU3Tlhq3"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AN6PzkylXYR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70b40c3e-f2d3-45c8-e569-05fb6c25dcb3"
      },
      "source": [
        "learning_rate = 1.0\n",
        "\n",
        "model = Net()\n",
        "optimizer = SGD(parameters=[model.layer1.w, model.layer1.b, model.layer2.w, model.layer2.b], learning_rate=learning_rate)\n",
        "x = Tensor(-5)\n",
        "y_target = Tensor(0.76)\n",
        "num_iterations = 50\n",
        "loss_history = []\n",
        "for i in range(num_iterations):\n",
        "    # Zera os gradientes dos passo anterior.\n",
        "    optimizer.zero_grad()\n",
        "    # Roda a um passo forward do modelo.\n",
        "    y_pred = model.forward(x)\n",
        "    # Calcula o gradiente do erro, data a predição do modelo.\n",
        "    loss_grad = compute_loss(y_target=y_target, y_pred=y_pred)\n",
        "    loss_history.append(loss_grad.data)\n",
        "\n",
        "    # Calcula agora os gradientes de w e b usando a função backward do modelo.\n",
        "    loss_grad.backward()\n",
        "    # Atualiza os pesos w e b usando os seus respectivos gradientes.\n",
        "    optimizer.step()\n",
        "    print(f'iter:{i}: y_prime: {y_pred.data}')"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter:0: y_prime: 0.5\n",
            "iter:1: y_prime: 0.5405358392737893\n",
            "iter:2: y_prime: 0.5744765796464588\n",
            "iter:3: y_prime: 0.6028826261849123\n",
            "iter:4: y_prime: 0.6266601390643447\n",
            "iter:5: y_prime: 0.6465730536971908\n",
            "iter:6: y_prime: 0.6632636033204088\n",
            "iter:7: y_prime: 0.6772724051828616\n",
            "iter:8: y_prime: 0.6890538573727616\n",
            "iter:9: y_prime: 0.6989878133763727\n",
            "iter:10: y_prime: 0.7073895435533437\n",
            "iter:11: y_prime: 0.7145190255456287\n",
            "iter:12: y_prime: 0.7205896871536633\n",
            "iter:13: y_prime: 0.7257763735847048\n",
            "iter:14: y_prime: 0.7302223284146934\n",
            "iter:15: y_prime: 0.7340451105726138\n",
            "iter:16: y_prime: 0.7373414881814685\n",
            "iter:17: y_prime: 0.7401914194890802\n",
            "iter:18: y_prime: 0.742661257784815\n",
            "iter:19: y_prime: 0.7448063169691611\n",
            "iter:20: y_prime: 0.7466729207172407\n",
            "iter:21: y_prime: 0.7483000395535451\n",
            "iter:22: y_prime: 0.749720601305897\n",
            "iter:23: y_prime: 0.7509625434772211\n",
            "iter:24: y_prime: 0.7520496617896798\n",
            "iter:25: y_prime: 0.7530022975318224\n",
            "iter:26: y_prime: 0.7538378970841556\n",
            "iter:27: y_prime: 0.7545714697255682\n",
            "iter:28: y_prime: 0.7552159641511622\n",
            "iter:29: y_prime: 0.7557825797261443\n",
            "iter:30: y_prime: 0.7562810250827815\n",
            "iter:31: y_prime: 0.7567197340153864\n",
            "iter:32: y_prime: 0.7571060465670375\n",
            "iter:33: y_prime: 0.7574463615956193\n",
            "iter:34: y_prime: 0.7577462658512927\n",
            "iter:35: y_prime: 0.7580106436125471\n",
            "iter:36: y_prime: 0.7582437701521315\n",
            "iter:37: y_prime: 0.7584493916904136\n",
            "iter:38: y_prime: 0.7586307940060157\n",
            "iter:39: y_prime: 0.7587908614842627\n",
            "iter:40: y_prime: 0.7589321280717001\n",
            "iter:41: y_prime: 0.7590568213533003\n",
            "iter:42: y_prime: 0.7591669007651616\n",
            "iter:43: y_prime: 0.7592640907896789\n",
            "iter:44: y_prime: 0.7593499098445585\n",
            "iter:45: y_prime: 0.7594256954656404\n",
            "iter:46: y_prime: 0.7594926262915308\n",
            "iter:47: y_prime: 0.7595517412817729\n",
            "iter:48: y_prime: 0.759603956536761\n",
            "iter:49: y_prime: 0.7596500800344381\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assert do histórico de losses\n",
        "target_loss_history = np.array([\n",
        "    0.06760000000000001,\n",
        "    0.04816451784326003,\n",
        "    0.03441893949967674,\n",
        "    0.024685869154550014,\n",
        "    0.017779518514339895,\n",
        "    0.012865672147580373,\n",
        "    0.009357930442551227,\n",
        "    0.006843854944228629,\n",
        "    0.005033355153684456,\n",
        "    0.003722486916596324,\n",
        "    0.002767860127525519,\n",
        "    0.002068519037319172,\n",
        "    0.0015531727586461292,\n",
        "    0.001171256605013691,\n",
        "    0.0008867097250423786,\n",
        "    0.0006736562851878449,\n",
        "    0.0005134081578305322,\n",
        "    0.00039237986185759277,\n",
        "    0.00030063198160464033,\n",
        "    0.00023084800404160196,\n",
        "    0.0001776110422089531,\n",
        "    0.00013688907444861002,\n",
        "    0.00010566603751232631,\n",
        "    8.167562040111844e-05,\n",
        "    6.320787765847752e-05,\n",
        "    4.8967839833139685e-05,\n",
        "    3.797151234545809e-05,\n",
        "    2.9468940940422566e-05,\n",
        "    2.2886999002965188e-05,\n",
        "    1.778663376632945e-05,\n",
        "    1.3830774434900419e-05,\n",
        "    1.0760144929813144e-05,\n",
        "    8.37496647215546e-06,\n",
        "    6.521069100328111e-06,\n",
        "    5.07931761304956e-06,\n",
        "    3.957538836299656e-06,\n",
        "    3.0843432785441995e-06,\n",
        "    2.4043861297584576e-06,\n",
        "    1.874725053962448e-06,\n",
        "    1.4620159502394981e-06,\n",
        "    1.1403504552510215e-06,\n",
        "    8.89585959590245e-07,\n",
        "    6.94054335088378e-07,\n",
        "    5.415623658353852e-07,\n",
        "    4.2261721020193424e-07,\n",
        "    3.298256981859764e-07,\n",
        "    2.574280800457942e-07,\n",
        "    2.0093587846657402e-07,\n",
        "    1.568504247743093e-07,\n",
        "    1.2244398229883047e-07\n",
        "    ])\n",
        "\n",
        "assert np.allclose(np.array(loss_history), target_loss_history, atol=1e-6)\n"
      ],
      "metadata": {
        "id": "IkfHFVqQ5OwU"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "YNAx30ZLCZuj"
      },
      "source": [
        "# Exercício 5\n",
        "\n",
        "Repita o exercício 4 mas compartilhando os pesos das duas camadas não-lineares. Mostre que ambas tem os mesmos pesos após o treino."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M78rgX2OlHWI"
      },
      "source": [
        "class NetShared():\n",
        "    def __init__(self):\n",
        "        self.layer1 = NonLinear()\n",
        "        self.layer2 = NonLinear()\n",
        "        self.layer1.w = self.layer2.w\n",
        "        self.layer1.b = self.layer2.b\n",
        "        \n",
        "    def forward(self, x: Tensor):\n",
        "        l1_f = self.layer1.forward(x)\n",
        "        l2_f = self.layer2.forward(l1_f)\n",
        "        return l2_f"
      ],
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1.0\n",
        "\n",
        "model = NetShared()\n",
        "optimizer = SGD(parameters=[model.layer1.w, model.layer1.b, model.layer2.w, model.layer2.b], learning_rate=learning_rate)\n",
        "x = Tensor(-5)\n",
        "y_target = Tensor(0.76)\n",
        "num_iterations = 50\n",
        "loss_history = []\n",
        "for i in range(num_iterations):\n",
        "    # Zera os gradientes dos passo anterior.\n",
        "    optimizer.zero_grad()\n",
        "    # Roda a um passo forward do modelo.\n",
        "    y_pred = model.forward(x)\n",
        "    # Calcula o gradiente do erro, data a predição do modelo.\n",
        "    loss_grad = compute_loss(y_target=y_target, y_pred=y_pred)\n",
        "    loss_history.append(loss_grad.data)\n",
        "\n",
        "    # Calcula agora os gradientes de w e b usando a função backward do modelo.\n",
        "    loss_grad.backward()\n",
        "    # Atualiza os pesos w e b usando os seus respectivos gradientes.\n",
        "    optimizer.step()\n",
        "    print(f'iter:{i}: y_prime: {y_pred.data}')"
      ],
      "metadata": {
        "id": "gItHAnBDmPJj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9442c25-5532-49ff-b593-6f8f145a403c"
      },
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter:0: y_prime: 0.5\n",
            "iter:1: y_prime: 0.5774912780514719\n",
            "iter:2: y_prime: 0.6253779622655635\n",
            "iter:3: y_prime: 0.6578655017550175\n",
            "iter:4: y_prime: 0.6807328108988013\n",
            "iter:5: y_prime: 0.6973774332712795\n",
            "iter:6: y_prime: 0.7098411147456785\n",
            "iter:7: y_prime: 0.7193911708955711\n",
            "iter:8: y_prime: 0.7268447609574145\n",
            "iter:9: y_prime: 0.7327485645138105\n",
            "iter:10: y_prime: 0.7374806433171459\n",
            "iter:11: y_prime: 0.7413101440045682\n",
            "iter:12: y_prime: 0.7444335393522467\n",
            "iter:13: y_prime: 0.7469973778336035\n",
            "iter:14: y_prime: 0.7491130124010403\n",
            "iter:15: y_prime: 0.7508664080493641\n",
            "iter:16: y_prime: 0.7523248405269709\n",
            "iter:17: y_prime: 0.7535415779825293\n",
            "iter:18: y_prime: 0.7545592216561374\n",
            "iter:19: y_prime: 0.7554121350522226\n",
            "iter:20: y_prime: 0.7561282407597014\n",
            "iter:21: y_prime: 0.7567303703001164\n",
            "iter:22: y_prime: 0.7572372925390789\n",
            "iter:23: y_prime: 0.7576645072211388\n",
            "iter:24: y_prime: 0.7580248643237054\n",
            "iter:25: y_prime: 0.7583290524611063\n",
            "iter:26: y_prime: 0.7585859875856809\n",
            "iter:27: y_prime: 0.7588031248845588\n",
            "iter:28: y_prime: 0.758986710872597\n",
            "iter:29: y_prime: 0.7591419884587386\n",
            "iter:30: y_prime: 0.7592733647005662\n",
            "iter:31: y_prime: 0.7593845487139749\n",
            "iter:32: y_prime: 0.75947866553577\n",
            "iter:33: y_prime: 0.7595583504837528\n",
            "iter:34: y_prime: 0.759625827607847\n",
            "iter:35: y_prime: 0.7596829750967667\n",
            "iter:36: y_prime: 0.7597313799404289\n",
            "iter:37: y_prime: 0.759772383707522\n",
            "iter:38: y_prime: 0.7598071209503666\n",
            "iter:39: y_prime: 0.7598365514734053\n",
            "iter:40: y_prime: 0.7598614874809957\n",
            "iter:41: y_prime: 0.7598826164424276\n",
            "iter:42: y_prime: 0.7599005203680184\n",
            "iter:43: y_prime: 0.7599156920726978\n",
            "iter:44: y_prime: 0.7599285489073003\n",
            "iter:45: y_prime: 0.7599394443586185\n",
            "iter:46: y_prime: 0.7599486778538727\n",
            "iter:47: y_prime: 0.7599565030510335\n",
            "iter:48: y_prime: 0.7599631348513477\n",
            "iter:49: y_prime: 0.7599687553328208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert model.layer1.w.data == model.layer2.w.data\n",
        "assert model.layer1.b.data == model.layer2.b.data"
      ],
      "metadata": {
        "id": "ayTpeISUpZet"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assert do histórico de losses\n",
        "target_loss_history = np.array([\n",
        "    0.06760000000000001,\n",
        "    0.03330943358728514,\n",
        "    0.01812309304377204,\n",
        "    0.010431455731754344,\n",
        "    0.00628328726800519,\n",
        "    0.003921585863693047,\n",
        "    0.002515913769956196,\n",
        "    0.0016490770012327091,\n",
        "    0.001099269875970989,\n",
        "    0.0007426407360579466,\n",
        "    0.0005071214254096055,\n",
        "    0.00034931071712997896,\n",
        "    0.0002423146970980538,\n",
        "    0.00016906818320206488,\n",
        "    0.00011852649897990173,\n",
        "    8.34225019207209e-05,\n",
        "    5.8908072936428374e-05,\n",
        "    4.1711214955750446e-05,\n",
        "    2.9602068987044087e-05,\n",
        "    2.104850477904461e-05,\n",
        "    1.4990519614837506e-05,\n",
        "    1.0690478374361229e-05,\n",
        "    7.632552514629166e-06,\n",
        "    5.454526520113034e-06,\n",
        "    3.901160939771698e-06,\n",
        "    2.7920656777350508e-06,\n",
        "    1.9994311078486844e-06,\n",
        "    1.4325100419623816e-06,\n",
        "    1.0267548557132565e-06,\n",
        "    7.361838049377913e-07,\n",
        "    5.279988583833094e-07,\n",
        "    3.787802854699951e-07,\n",
        "    2.717896235939522e-07,\n",
        "    1.9505429520143487e-07,\n",
        "    1.4000497904948548e-07,\n",
        "    1.0050478927006106e-07,\n",
        "    7.215673640396385e-08,\n",
        "    5.180917660144311e-08,\n",
        "    3.7202327787478815e-08,\n",
        "    2.6715420845967644e-08,\n",
        "    1.9185717920921844e-08,\n",
        "    1.377889958835379e-08,\n",
        "    9.896197179203946e-09,\n",
        "    7.10782660599054e-09,\n",
        "    5.105258647978467e-09,\n",
        "    3.6669857031273956e-09,\n",
        "    2.633962683117349e-09,\n",
        "    1.8919845693984993e-09,\n",
        "    1.3590391851568933e-09,\n",
        "    9.762292271381411e-10\n",
        "    ])\n",
        "\n",
        "assert np.allclose(np.array(loss_history), target_loss_history, atol=1e-6)\n"
      ],
      "metadata": {
        "id": "R75jxk-X5ntD"
      },
      "execution_count": 235,
      "outputs": []
    }
  ]
}